{
  "best_metric": 0.2729106545448303,
  "best_model_checkpoint": "/home/jgroen/NEU/dstl/transformer/outputs/trained/checkpoint-49000",
  "epoch": 100.0,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 2.0999999999999997e-07,
      "loss": 1.6423,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 5.099999999999999e-07,
      "loss": 1.6825,
      "step": 20
    },
    {
      "epoch": 0.03,
      "learning_rate": 8.1e-07,
      "loss": 1.6329,
      "step": 30
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.11e-06,
      "loss": 1.5882,
      "step": 40
    },
    {
      "epoch": 0.05,
      "learning_rate": 1.4099999999999998e-06,
      "loss": 1.4967,
      "step": 50
    },
    {
      "epoch": 0.06,
      "learning_rate": 1.71e-06,
      "loss": 1.4131,
      "step": 60
    },
    {
      "epoch": 0.07,
      "learning_rate": 2.01e-06,
      "loss": 1.3524,
      "step": 70
    },
    {
      "epoch": 0.08,
      "learning_rate": 2.31e-06,
      "loss": 1.2561,
      "step": 80
    },
    {
      "epoch": 0.09,
      "learning_rate": 2.6099999999999996e-06,
      "loss": 1.1676,
      "step": 90
    },
    {
      "epoch": 0.1,
      "learning_rate": 2.9099999999999997e-06,
      "loss": 1.0283,
      "step": 100
    },
    {
      "epoch": 0.11,
      "learning_rate": 3.2099999999999998e-06,
      "loss": 0.9467,
      "step": 110
    },
    {
      "epoch": 0.12,
      "learning_rate": 3.51e-06,
      "loss": 0.8305,
      "step": 120
    },
    {
      "epoch": 0.13,
      "learning_rate": 3.8099999999999995e-06,
      "loss": 0.6974,
      "step": 130
    },
    {
      "epoch": 0.14,
      "learning_rate": 4.11e-06,
      "loss": 0.6145,
      "step": 140
    },
    {
      "epoch": 0.15,
      "learning_rate": 4.409999999999999e-06,
      "loss": 0.5217,
      "step": 150
    },
    {
      "epoch": 0.16,
      "learning_rate": 4.709999999999999e-06,
      "loss": 0.4164,
      "step": 160
    },
    {
      "epoch": 0.17,
      "learning_rate": 5.0099999999999995e-06,
      "loss": 0.3463,
      "step": 170
    },
    {
      "epoch": 0.18,
      "learning_rate": 5.31e-06,
      "loss": 0.4097,
      "step": 180
    },
    {
      "epoch": 0.19,
      "learning_rate": 5.61e-06,
      "loss": 0.2515,
      "step": 190
    },
    {
      "epoch": 0.2,
      "learning_rate": 5.909999999999999e-06,
      "loss": 0.309,
      "step": 200
    },
    {
      "epoch": 0.21,
      "learning_rate": 6.209999999999999e-06,
      "loss": 0.2506,
      "step": 210
    },
    {
      "epoch": 0.22,
      "learning_rate": 6.5099999999999995e-06,
      "loss": 0.4333,
      "step": 220
    },
    {
      "epoch": 0.23,
      "learning_rate": 6.81e-06,
      "loss": 0.3863,
      "step": 230
    },
    {
      "epoch": 0.24,
      "learning_rate": 7.109999999999999e-06,
      "loss": 0.2647,
      "step": 240
    },
    {
      "epoch": 0.25,
      "learning_rate": 7.409999999999999e-06,
      "loss": 0.3214,
      "step": 250
    },
    {
      "epoch": 0.26,
      "learning_rate": 7.709999999999999e-06,
      "loss": 0.3211,
      "step": 260
    },
    {
      "epoch": 0.27,
      "learning_rate": 8.01e-06,
      "loss": 0.3,
      "step": 270
    },
    {
      "epoch": 0.28,
      "learning_rate": 8.309999999999998e-06,
      "loss": 0.492,
      "step": 280
    },
    {
      "epoch": 0.29,
      "learning_rate": 8.609999999999999e-06,
      "loss": 0.3394,
      "step": 290
    },
    {
      "epoch": 0.3,
      "learning_rate": 8.91e-06,
      "loss": 0.3338,
      "step": 300
    },
    {
      "epoch": 0.31,
      "learning_rate": 9.21e-06,
      "loss": 0.3277,
      "step": 310
    },
    {
      "epoch": 0.32,
      "learning_rate": 9.509999999999999e-06,
      "loss": 0.2561,
      "step": 320
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.81e-06,
      "loss": 0.2919,
      "step": 330
    },
    {
      "epoch": 0.34,
      "learning_rate": 1.011e-05,
      "loss": 0.2969,
      "step": 340
    },
    {
      "epoch": 0.35,
      "learning_rate": 1.041e-05,
      "loss": 0.3756,
      "step": 350
    },
    {
      "epoch": 0.36,
      "learning_rate": 1.0709999999999999e-05,
      "loss": 0.2903,
      "step": 360
    },
    {
      "epoch": 0.37,
      "learning_rate": 1.101e-05,
      "loss": 0.2514,
      "step": 370
    },
    {
      "epoch": 0.38,
      "learning_rate": 1.1309999999999998e-05,
      "loss": 0.288,
      "step": 380
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.1609999999999999e-05,
      "loss": 0.2912,
      "step": 390
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.191e-05,
      "loss": 0.3457,
      "step": 400
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.2209999999999998e-05,
      "loss": 0.3447,
      "step": 410
    },
    {
      "epoch": 0.42,
      "learning_rate": 1.2509999999999999e-05,
      "loss": 0.3074,
      "step": 420
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.281e-05,
      "loss": 0.3304,
      "step": 430
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.311e-05,
      "loss": 0.3724,
      "step": 440
    },
    {
      "epoch": 0.45,
      "learning_rate": 1.3409999999999999e-05,
      "loss": 0.3163,
      "step": 450
    },
    {
      "epoch": 0.46,
      "learning_rate": 1.3709999999999997e-05,
      "loss": 0.2953,
      "step": 460
    },
    {
      "epoch": 0.47,
      "learning_rate": 1.4009999999999998e-05,
      "loss": 0.3239,
      "step": 470
    },
    {
      "epoch": 0.48,
      "learning_rate": 1.4309999999999999e-05,
      "loss": 0.2022,
      "step": 480
    },
    {
      "epoch": 0.49,
      "learning_rate": 1.4609999999999999e-05,
      "loss": 0.2672,
      "step": 490
    },
    {
      "epoch": 0.5,
      "learning_rate": 1.491e-05,
      "loss": 0.2744,
      "step": 500
    },
    {
      "epoch": 0.51,
      "learning_rate": 1.521e-05,
      "loss": 0.3519,
      "step": 510
    },
    {
      "epoch": 0.52,
      "learning_rate": 1.551e-05,
      "loss": 0.3434,
      "step": 520
    },
    {
      "epoch": 0.53,
      "learning_rate": 1.5809999999999996e-05,
      "loss": 0.2833,
      "step": 530
    },
    {
      "epoch": 0.54,
      "learning_rate": 1.6109999999999997e-05,
      "loss": 0.303,
      "step": 540
    },
    {
      "epoch": 0.55,
      "learning_rate": 1.6409999999999997e-05,
      "loss": 0.3339,
      "step": 550
    },
    {
      "epoch": 0.56,
      "learning_rate": 1.6709999999999998e-05,
      "loss": 0.2044,
      "step": 560
    },
    {
      "epoch": 0.57,
      "learning_rate": 1.7009999999999998e-05,
      "loss": 0.3306,
      "step": 570
    },
    {
      "epoch": 0.58,
      "learning_rate": 1.731e-05,
      "loss": 0.2568,
      "step": 580
    },
    {
      "epoch": 0.59,
      "learning_rate": 1.761e-05,
      "loss": 0.2523,
      "step": 590
    },
    {
      "epoch": 0.6,
      "learning_rate": 1.791e-05,
      "loss": 0.3603,
      "step": 600
    },
    {
      "epoch": 0.61,
      "learning_rate": 1.8209999999999997e-05,
      "loss": 0.2652,
      "step": 610
    },
    {
      "epoch": 0.62,
      "learning_rate": 1.8509999999999997e-05,
      "loss": 0.2912,
      "step": 620
    },
    {
      "epoch": 0.63,
      "learning_rate": 1.881e-05,
      "loss": 0.3278,
      "step": 630
    },
    {
      "epoch": 0.64,
      "learning_rate": 1.911e-05,
      "loss": 0.3055,
      "step": 640
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.9409999999999995e-05,
      "loss": 0.3515,
      "step": 650
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.9709999999999996e-05,
      "loss": 0.2952,
      "step": 660
    },
    {
      "epoch": 0.67,
      "learning_rate": 2.0009999999999996e-05,
      "loss": 0.2584,
      "step": 670
    },
    {
      "epoch": 0.68,
      "learning_rate": 2.0309999999999997e-05,
      "loss": 0.2748,
      "step": 680
    },
    {
      "epoch": 0.69,
      "learning_rate": 2.0609999999999997e-05,
      "loss": 0.2996,
      "step": 690
    },
    {
      "epoch": 0.7,
      "learning_rate": 2.0909999999999998e-05,
      "loss": 0.3343,
      "step": 700
    },
    {
      "epoch": 0.71,
      "learning_rate": 2.121e-05,
      "loss": 0.2913,
      "step": 710
    },
    {
      "epoch": 0.72,
      "learning_rate": 2.151e-05,
      "loss": 0.2622,
      "step": 720
    },
    {
      "epoch": 0.73,
      "learning_rate": 2.181e-05,
      "loss": 0.3232,
      "step": 730
    },
    {
      "epoch": 0.74,
      "learning_rate": 2.211e-05,
      "loss": 0.3458,
      "step": 740
    },
    {
      "epoch": 0.75,
      "learning_rate": 2.2409999999999997e-05,
      "loss": 0.2921,
      "step": 750
    },
    {
      "epoch": 0.76,
      "learning_rate": 2.2709999999999998e-05,
      "loss": 0.2552,
      "step": 760
    },
    {
      "epoch": 0.77,
      "learning_rate": 2.3009999999999998e-05,
      "loss": 0.3006,
      "step": 770
    },
    {
      "epoch": 0.78,
      "learning_rate": 2.331e-05,
      "loss": 0.2593,
      "step": 780
    },
    {
      "epoch": 0.79,
      "learning_rate": 2.361e-05,
      "loss": 0.1694,
      "step": 790
    },
    {
      "epoch": 0.8,
      "learning_rate": 2.3909999999999996e-05,
      "loss": 0.2918,
      "step": 800
    },
    {
      "epoch": 0.81,
      "learning_rate": 2.4209999999999997e-05,
      "loss": 0.2647,
      "step": 810
    },
    {
      "epoch": 0.82,
      "learning_rate": 2.4509999999999997e-05,
      "loss": 0.2791,
      "step": 820
    },
    {
      "epoch": 0.83,
      "learning_rate": 2.4809999999999998e-05,
      "loss": 0.332,
      "step": 830
    },
    {
      "epoch": 0.84,
      "learning_rate": 2.511e-05,
      "loss": 0.2924,
      "step": 840
    },
    {
      "epoch": 0.85,
      "learning_rate": 2.5409999999999996e-05,
      "loss": 0.3671,
      "step": 850
    },
    {
      "epoch": 0.86,
      "learning_rate": 2.5709999999999996e-05,
      "loss": 0.3161,
      "step": 860
    },
    {
      "epoch": 0.87,
      "learning_rate": 2.6009999999999997e-05,
      "loss": 0.2496,
      "step": 870
    },
    {
      "epoch": 0.88,
      "learning_rate": 2.6309999999999997e-05,
      "loss": 0.3263,
      "step": 880
    },
    {
      "epoch": 0.89,
      "learning_rate": 2.6609999999999998e-05,
      "loss": 0.2175,
      "step": 890
    },
    {
      "epoch": 0.9,
      "learning_rate": 2.6909999999999998e-05,
      "loss": 0.3431,
      "step": 900
    },
    {
      "epoch": 0.91,
      "learning_rate": 2.721e-05,
      "loss": 0.2876,
      "step": 910
    },
    {
      "epoch": 0.92,
      "learning_rate": 2.751e-05,
      "loss": 0.2425,
      "step": 920
    },
    {
      "epoch": 0.93,
      "learning_rate": 2.781e-05,
      "loss": 0.4097,
      "step": 930
    },
    {
      "epoch": 0.94,
      "learning_rate": 2.811e-05,
      "loss": 0.2664,
      "step": 940
    },
    {
      "epoch": 0.95,
      "learning_rate": 2.841e-05,
      "loss": 0.2626,
      "step": 950
    },
    {
      "epoch": 0.96,
      "learning_rate": 2.8709999999999994e-05,
      "loss": 0.3084,
      "step": 960
    },
    {
      "epoch": 0.97,
      "learning_rate": 2.9009999999999995e-05,
      "loss": 0.3314,
      "step": 970
    },
    {
      "epoch": 0.98,
      "learning_rate": 2.9309999999999996e-05,
      "loss": 0.3282,
      "step": 980
    },
    {
      "epoch": 0.99,
      "learning_rate": 2.9609999999999996e-05,
      "loss": 0.2751,
      "step": 990
    },
    {
      "epoch": 1.0,
      "learning_rate": 2.9909999999999997e-05,
      "loss": 0.2422,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.29082781076431274,
      "eval_runtime": 14.9492,
      "eval_samples_per_second": 133.786,
      "eval_steps_per_second": 16.723,
      "step": 1000
    },
    {
      "epoch": 1.01,
      "learning_rate": 3.0209999999999997e-05,
      "loss": 0.2997,
      "step": 1010
    },
    {
      "epoch": 1.02,
      "learning_rate": 3.0509999999999998e-05,
      "loss": 0.2945,
      "step": 1020
    },
    {
      "epoch": 1.03,
      "learning_rate": 3.081e-05,
      "loss": 0.2373,
      "step": 1030
    },
    {
      "epoch": 1.04,
      "learning_rate": 3.111e-05,
      "loss": 0.2571,
      "step": 1040
    },
    {
      "epoch": 1.05,
      "learning_rate": 3.141e-05,
      "loss": 0.2711,
      "step": 1050
    },
    {
      "epoch": 1.06,
      "learning_rate": 3.171e-05,
      "loss": 0.2539,
      "step": 1060
    },
    {
      "epoch": 1.07,
      "learning_rate": 3.201e-05,
      "loss": 0.3195,
      "step": 1070
    },
    {
      "epoch": 1.08,
      "learning_rate": 3.231e-05,
      "loss": 0.2967,
      "step": 1080
    },
    {
      "epoch": 1.09,
      "learning_rate": 3.261e-05,
      "loss": 0.2662,
      "step": 1090
    },
    {
      "epoch": 1.1,
      "learning_rate": 3.291e-05,
      "loss": 0.2472,
      "step": 1100
    },
    {
      "epoch": 1.11,
      "learning_rate": 3.321e-05,
      "loss": 0.2508,
      "step": 1110
    },
    {
      "epoch": 1.12,
      "learning_rate": 3.3509999999999996e-05,
      "loss": 0.2853,
      "step": 1120
    },
    {
      "epoch": 1.13,
      "learning_rate": 3.3809999999999996e-05,
      "loss": 0.2436,
      "step": 1130
    },
    {
      "epoch": 1.14,
      "learning_rate": 3.411e-05,
      "loss": 0.3041,
      "step": 1140
    },
    {
      "epoch": 1.15,
      "learning_rate": 3.441e-05,
      "loss": 0.2656,
      "step": 1150
    },
    {
      "epoch": 1.16,
      "learning_rate": 3.471e-05,
      "loss": 0.2613,
      "step": 1160
    },
    {
      "epoch": 1.17,
      "learning_rate": 3.501e-05,
      "loss": 0.2966,
      "step": 1170
    },
    {
      "epoch": 1.18,
      "learning_rate": 3.531e-05,
      "loss": 0.3431,
      "step": 1180
    },
    {
      "epoch": 1.19,
      "learning_rate": 3.561e-05,
      "loss": 0.2682,
      "step": 1190
    },
    {
      "epoch": 1.2,
      "learning_rate": 3.591e-05,
      "loss": 0.2775,
      "step": 1200
    },
    {
      "epoch": 1.21,
      "learning_rate": 3.621e-05,
      "loss": 0.3083,
      "step": 1210
    },
    {
      "epoch": 1.22,
      "learning_rate": 3.6509999999999994e-05,
      "loss": 0.3066,
      "step": 1220
    },
    {
      "epoch": 1.23,
      "learning_rate": 3.6809999999999995e-05,
      "loss": 0.2526,
      "step": 1230
    },
    {
      "epoch": 1.24,
      "learning_rate": 3.7109999999999995e-05,
      "loss": 0.3262,
      "step": 1240
    },
    {
      "epoch": 1.25,
      "learning_rate": 3.7409999999999996e-05,
      "loss": 0.2904,
      "step": 1250
    },
    {
      "epoch": 1.26,
      "learning_rate": 3.7709999999999996e-05,
      "loss": 0.3205,
      "step": 1260
    },
    {
      "epoch": 1.27,
      "learning_rate": 3.801e-05,
      "loss": 0.2062,
      "step": 1270
    },
    {
      "epoch": 1.28,
      "learning_rate": 3.831e-05,
      "loss": 0.3081,
      "step": 1280
    },
    {
      "epoch": 1.29,
      "learning_rate": 3.861e-05,
      "loss": 0.3031,
      "step": 1290
    },
    {
      "epoch": 1.3,
      "learning_rate": 3.891e-05,
      "loss": 0.2891,
      "step": 1300
    },
    {
      "epoch": 1.31,
      "learning_rate": 3.921e-05,
      "loss": 0.2639,
      "step": 1310
    },
    {
      "epoch": 1.32,
      "learning_rate": 3.951e-05,
      "loss": 0.2369,
      "step": 1320
    },
    {
      "epoch": 1.33,
      "learning_rate": 3.981e-05,
      "loss": 0.3167,
      "step": 1330
    },
    {
      "epoch": 1.34,
      "learning_rate": 4.011e-05,
      "loss": 0.363,
      "step": 1340
    },
    {
      "epoch": 1.35,
      "learning_rate": 4.0409999999999994e-05,
      "loss": 0.3393,
      "step": 1350
    },
    {
      "epoch": 1.36,
      "learning_rate": 4.0709999999999995e-05,
      "loss": 0.2955,
      "step": 1360
    },
    {
      "epoch": 1.37,
      "learning_rate": 4.1009999999999995e-05,
      "loss": 0.3092,
      "step": 1370
    },
    {
      "epoch": 1.38,
      "learning_rate": 4.1309999999999996e-05,
      "loss": 0.3338,
      "step": 1380
    },
    {
      "epoch": 1.39,
      "learning_rate": 4.1609999999999996e-05,
      "loss": 0.2792,
      "step": 1390
    },
    {
      "epoch": 1.4,
      "learning_rate": 4.191e-05,
      "loss": 0.3685,
      "step": 1400
    },
    {
      "epoch": 1.41,
      "learning_rate": 4.220999999999999e-05,
      "loss": 0.4062,
      "step": 1410
    },
    {
      "epoch": 1.42,
      "learning_rate": 4.250999999999999e-05,
      "loss": 0.31,
      "step": 1420
    },
    {
      "epoch": 1.43,
      "learning_rate": 4.280999999999999e-05,
      "loss": 0.2579,
      "step": 1430
    },
    {
      "epoch": 1.44,
      "learning_rate": 4.310999999999999e-05,
      "loss": 0.2513,
      "step": 1440
    },
    {
      "epoch": 1.45,
      "learning_rate": 4.340999999999999e-05,
      "loss": 0.2913,
      "step": 1450
    },
    {
      "epoch": 1.46,
      "learning_rate": 4.370999999999999e-05,
      "loss": 0.2689,
      "step": 1460
    },
    {
      "epoch": 1.47,
      "learning_rate": 4.4009999999999994e-05,
      "loss": 0.2498,
      "step": 1470
    },
    {
      "epoch": 1.48,
      "learning_rate": 4.4309999999999994e-05,
      "loss": 0.3141,
      "step": 1480
    },
    {
      "epoch": 1.49,
      "learning_rate": 4.4609999999999995e-05,
      "loss": 0.3695,
      "step": 1490
    },
    {
      "epoch": 1.5,
      "learning_rate": 4.4909999999999995e-05,
      "loss": 0.2751,
      "step": 1500
    },
    {
      "epoch": 1.51,
      "learning_rate": 4.5209999999999996e-05,
      "loss": 0.365,
      "step": 1510
    },
    {
      "epoch": 1.52,
      "learning_rate": 4.5509999999999996e-05,
      "loss": 0.275,
      "step": 1520
    },
    {
      "epoch": 1.53,
      "learning_rate": 4.581e-05,
      "loss": 0.2444,
      "step": 1530
    },
    {
      "epoch": 1.54,
      "learning_rate": 4.611e-05,
      "loss": 0.2602,
      "step": 1540
    },
    {
      "epoch": 1.55,
      "learning_rate": 4.641e-05,
      "loss": 0.2927,
      "step": 1550
    },
    {
      "epoch": 1.56,
      "learning_rate": 4.671e-05,
      "loss": 0.3811,
      "step": 1560
    },
    {
      "epoch": 1.57,
      "learning_rate": 4.701e-05,
      "loss": 0.3098,
      "step": 1570
    },
    {
      "epoch": 1.58,
      "learning_rate": 4.731e-05,
      "loss": 0.2137,
      "step": 1580
    },
    {
      "epoch": 1.59,
      "learning_rate": 4.761e-05,
      "loss": 0.2563,
      "step": 1590
    },
    {
      "epoch": 1.6,
      "learning_rate": 4.791e-05,
      "loss": 0.3445,
      "step": 1600
    },
    {
      "epoch": 1.61,
      "learning_rate": 4.821e-05,
      "loss": 0.3398,
      "step": 1610
    },
    {
      "epoch": 1.62,
      "learning_rate": 4.851e-05,
      "loss": 0.3203,
      "step": 1620
    },
    {
      "epoch": 1.63,
      "learning_rate": 4.881e-05,
      "loss": 0.2606,
      "step": 1630
    },
    {
      "epoch": 1.64,
      "learning_rate": 4.911e-05,
      "loss": 0.2912,
      "step": 1640
    },
    {
      "epoch": 1.65,
      "learning_rate": 4.941e-05,
      "loss": 0.2664,
      "step": 1650
    },
    {
      "epoch": 1.66,
      "learning_rate": 4.970999999999999e-05,
      "loss": 0.3402,
      "step": 1660
    },
    {
      "epoch": 1.67,
      "learning_rate": 5.000999999999999e-05,
      "loss": 0.2912,
      "step": 1670
    },
    {
      "epoch": 1.68,
      "learning_rate": 5.030999999999999e-05,
      "loss": 0.3285,
      "step": 1680
    },
    {
      "epoch": 1.69,
      "learning_rate": 5.060999999999999e-05,
      "loss": 0.2597,
      "step": 1690
    },
    {
      "epoch": 1.7,
      "learning_rate": 5.090999999999999e-05,
      "loss": 0.2923,
      "step": 1700
    },
    {
      "epoch": 1.71,
      "learning_rate": 5.120999999999999e-05,
      "loss": 0.2954,
      "step": 1710
    },
    {
      "epoch": 1.72,
      "learning_rate": 5.150999999999999e-05,
      "loss": 0.2719,
      "step": 1720
    },
    {
      "epoch": 1.73,
      "learning_rate": 5.1809999999999994e-05,
      "loss": 0.249,
      "step": 1730
    },
    {
      "epoch": 1.74,
      "learning_rate": 5.2109999999999994e-05,
      "loss": 0.3985,
      "step": 1740
    },
    {
      "epoch": 1.75,
      "learning_rate": 5.2409999999999995e-05,
      "loss": 0.2045,
      "step": 1750
    },
    {
      "epoch": 1.76,
      "learning_rate": 5.2709999999999995e-05,
      "loss": 0.293,
      "step": 1760
    },
    {
      "epoch": 1.77,
      "learning_rate": 5.3009999999999996e-05,
      "loss": 0.2636,
      "step": 1770
    },
    {
      "epoch": 1.78,
      "learning_rate": 5.3309999999999996e-05,
      "loss": 0.2093,
      "step": 1780
    },
    {
      "epoch": 1.79,
      "learning_rate": 5.361e-05,
      "loss": 0.2808,
      "step": 1790
    },
    {
      "epoch": 1.8,
      "learning_rate": 5.391e-05,
      "loss": 0.2803,
      "step": 1800
    },
    {
      "epoch": 1.81,
      "learning_rate": 5.421e-05,
      "loss": 0.3443,
      "step": 1810
    },
    {
      "epoch": 1.82,
      "learning_rate": 5.451e-05,
      "loss": 0.3411,
      "step": 1820
    },
    {
      "epoch": 1.83,
      "learning_rate": 5.481e-05,
      "loss": 0.1688,
      "step": 1830
    },
    {
      "epoch": 1.84,
      "learning_rate": 5.511e-05,
      "loss": 0.3036,
      "step": 1840
    },
    {
      "epoch": 1.85,
      "learning_rate": 5.540999999999999e-05,
      "loss": 0.2866,
      "step": 1850
    },
    {
      "epoch": 1.86,
      "learning_rate": 5.5709999999999993e-05,
      "loss": 0.3365,
      "step": 1860
    },
    {
      "epoch": 1.87,
      "learning_rate": 5.6009999999999994e-05,
      "loss": 0.305,
      "step": 1870
    },
    {
      "epoch": 1.88,
      "learning_rate": 5.6309999999999994e-05,
      "loss": 0.2988,
      "step": 1880
    },
    {
      "epoch": 1.89,
      "learning_rate": 5.6609999999999995e-05,
      "loss": 0.2786,
      "step": 1890
    },
    {
      "epoch": 1.9,
      "learning_rate": 5.6909999999999996e-05,
      "loss": 0.3287,
      "step": 1900
    },
    {
      "epoch": 1.91,
      "learning_rate": 5.7209999999999996e-05,
      "loss": 0.2943,
      "step": 1910
    },
    {
      "epoch": 1.92,
      "learning_rate": 5.7509999999999997e-05,
      "loss": 0.3175,
      "step": 1920
    },
    {
      "epoch": 1.93,
      "learning_rate": 5.781e-05,
      "loss": 0.2843,
      "step": 1930
    },
    {
      "epoch": 1.94,
      "learning_rate": 5.811e-05,
      "loss": 0.2316,
      "step": 1940
    },
    {
      "epoch": 1.95,
      "learning_rate": 5.841e-05,
      "loss": 0.2994,
      "step": 1950
    },
    {
      "epoch": 1.96,
      "learning_rate": 5.871e-05,
      "loss": 0.2762,
      "step": 1960
    },
    {
      "epoch": 1.97,
      "learning_rate": 5.901e-05,
      "loss": 0.2727,
      "step": 1970
    },
    {
      "epoch": 1.98,
      "learning_rate": 5.930999999999999e-05,
      "loss": 0.2938,
      "step": 1980
    },
    {
      "epoch": 1.99,
      "learning_rate": 5.9609999999999993e-05,
      "loss": 0.3384,
      "step": 1990
    },
    {
      "epoch": 2.0,
      "learning_rate": 5.9909999999999994e-05,
      "loss": 0.3094,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27994295954704285,
      "eval_runtime": 14.9995,
      "eval_samples_per_second": 133.338,
      "eval_steps_per_second": 16.667,
      "step": 2000
    },
    {
      "epoch": 2.01,
      "learning_rate": 6.0209999999999994e-05,
      "loss": 0.3392,
      "step": 2010
    },
    {
      "epoch": 2.02,
      "learning_rate": 6.0509999999999995e-05,
      "loss": 0.2494,
      "step": 2020
    },
    {
      "epoch": 2.03,
      "learning_rate": 6.080999999999999e-05,
      "loss": 0.2776,
      "step": 2030
    },
    {
      "epoch": 2.04,
      "learning_rate": 6.110999999999999e-05,
      "loss": 0.2686,
      "step": 2040
    },
    {
      "epoch": 2.05,
      "learning_rate": 6.141e-05,
      "loss": 0.2532,
      "step": 2050
    },
    {
      "epoch": 2.06,
      "learning_rate": 6.170999999999999e-05,
      "loss": 0.3345,
      "step": 2060
    },
    {
      "epoch": 2.07,
      "learning_rate": 6.201e-05,
      "loss": 0.2872,
      "step": 2070
    },
    {
      "epoch": 2.08,
      "learning_rate": 6.230999999999999e-05,
      "loss": 0.2584,
      "step": 2080
    },
    {
      "epoch": 2.09,
      "learning_rate": 6.261e-05,
      "loss": 0.3457,
      "step": 2090
    },
    {
      "epoch": 2.1,
      "learning_rate": 6.290999999999999e-05,
      "loss": 0.3783,
      "step": 2100
    },
    {
      "epoch": 2.11,
      "learning_rate": 6.321e-05,
      "loss": 0.2252,
      "step": 2110
    },
    {
      "epoch": 2.12,
      "learning_rate": 6.351e-05,
      "loss": 0.2808,
      "step": 2120
    },
    {
      "epoch": 2.13,
      "learning_rate": 6.381e-05,
      "loss": 0.3223,
      "step": 2130
    },
    {
      "epoch": 2.14,
      "learning_rate": 6.411e-05,
      "loss": 0.2192,
      "step": 2140
    },
    {
      "epoch": 2.15,
      "learning_rate": 6.441e-05,
      "loss": 0.2559,
      "step": 2150
    },
    {
      "epoch": 2.16,
      "learning_rate": 6.471e-05,
      "loss": 0.3094,
      "step": 2160
    },
    {
      "epoch": 2.17,
      "learning_rate": 6.500999999999999e-05,
      "loss": 0.3138,
      "step": 2170
    },
    {
      "epoch": 2.18,
      "learning_rate": 6.531e-05,
      "loss": 0.2097,
      "step": 2180
    },
    {
      "epoch": 2.19,
      "learning_rate": 6.560999999999999e-05,
      "loss": 0.2873,
      "step": 2190
    },
    {
      "epoch": 2.2,
      "learning_rate": 6.591e-05,
      "loss": 0.3037,
      "step": 2200
    },
    {
      "epoch": 2.21,
      "learning_rate": 6.620999999999999e-05,
      "loss": 0.2719,
      "step": 2210
    },
    {
      "epoch": 2.22,
      "learning_rate": 6.651e-05,
      "loss": 0.2282,
      "step": 2220
    },
    {
      "epoch": 2.23,
      "learning_rate": 6.680999999999999e-05,
      "loss": 0.3033,
      "step": 2230
    },
    {
      "epoch": 2.24,
      "learning_rate": 6.711e-05,
      "loss": 0.3612,
      "step": 2240
    },
    {
      "epoch": 2.25,
      "learning_rate": 6.741e-05,
      "loss": 0.3063,
      "step": 2250
    },
    {
      "epoch": 2.26,
      "learning_rate": 6.771e-05,
      "loss": 0.3232,
      "step": 2260
    },
    {
      "epoch": 2.27,
      "learning_rate": 6.801e-05,
      "loss": 0.2742,
      "step": 2270
    },
    {
      "epoch": 2.28,
      "learning_rate": 6.831e-05,
      "loss": 0.2671,
      "step": 2280
    },
    {
      "epoch": 2.29,
      "learning_rate": 6.861e-05,
      "loss": 0.285,
      "step": 2290
    },
    {
      "epoch": 2.3,
      "learning_rate": 6.890999999999999e-05,
      "loss": 0.2678,
      "step": 2300
    },
    {
      "epoch": 2.31,
      "learning_rate": 6.921e-05,
      "loss": 0.3114,
      "step": 2310
    },
    {
      "epoch": 2.32,
      "learning_rate": 6.950999999999999e-05,
      "loss": 0.3256,
      "step": 2320
    },
    {
      "epoch": 2.33,
      "learning_rate": 6.981e-05,
      "loss": 0.2825,
      "step": 2330
    },
    {
      "epoch": 2.34,
      "learning_rate": 7.010999999999999e-05,
      "loss": 0.3079,
      "step": 2340
    },
    {
      "epoch": 2.35,
      "learning_rate": 7.040999999999998e-05,
      "loss": 0.262,
      "step": 2350
    },
    {
      "epoch": 2.36,
      "learning_rate": 7.070999999999999e-05,
      "loss": 0.3239,
      "step": 2360
    },
    {
      "epoch": 2.37,
      "learning_rate": 7.100999999999999e-05,
      "loss": 0.2889,
      "step": 2370
    },
    {
      "epoch": 2.38,
      "learning_rate": 7.130999999999999e-05,
      "loss": 0.3302,
      "step": 2380
    },
    {
      "epoch": 2.39,
      "learning_rate": 7.160999999999999e-05,
      "loss": 0.2955,
      "step": 2390
    },
    {
      "epoch": 2.4,
      "learning_rate": 7.191e-05,
      "loss": 0.3032,
      "step": 2400
    },
    {
      "epoch": 2.41,
      "learning_rate": 7.220999999999999e-05,
      "loss": 0.2366,
      "step": 2410
    },
    {
      "epoch": 2.42,
      "learning_rate": 7.251e-05,
      "loss": 0.2506,
      "step": 2420
    },
    {
      "epoch": 2.43,
      "learning_rate": 7.280999999999999e-05,
      "loss": 0.3345,
      "step": 2430
    },
    {
      "epoch": 2.44,
      "learning_rate": 7.311e-05,
      "loss": 0.3478,
      "step": 2440
    },
    {
      "epoch": 2.45,
      "learning_rate": 7.340999999999999e-05,
      "loss": 0.2903,
      "step": 2450
    },
    {
      "epoch": 2.46,
      "learning_rate": 7.371e-05,
      "loss": 0.2274,
      "step": 2460
    },
    {
      "epoch": 2.47,
      "learning_rate": 7.400999999999999e-05,
      "loss": 0.3456,
      "step": 2470
    },
    {
      "epoch": 2.48,
      "learning_rate": 7.431e-05,
      "loss": 0.286,
      "step": 2480
    },
    {
      "epoch": 2.49,
      "learning_rate": 7.460999999999999e-05,
      "loss": 0.3566,
      "step": 2490
    },
    {
      "epoch": 2.5,
      "learning_rate": 7.491e-05,
      "loss": 0.2333,
      "step": 2500
    },
    {
      "epoch": 2.51,
      "learning_rate": 7.520999999999999e-05,
      "loss": 0.333,
      "step": 2510
    },
    {
      "epoch": 2.52,
      "learning_rate": 7.550999999999999e-05,
      "loss": 0.3484,
      "step": 2520
    },
    {
      "epoch": 2.53,
      "learning_rate": 7.581e-05,
      "loss": 0.3277,
      "step": 2530
    },
    {
      "epoch": 2.54,
      "learning_rate": 7.610999999999999e-05,
      "loss": 0.3123,
      "step": 2540
    },
    {
      "epoch": 2.55,
      "learning_rate": 7.640999999999998e-05,
      "loss": 0.2953,
      "step": 2550
    },
    {
      "epoch": 2.56,
      "learning_rate": 7.670999999999999e-05,
      "loss": 0.309,
      "step": 2560
    },
    {
      "epoch": 2.57,
      "learning_rate": 7.700999999999998e-05,
      "loss": 0.3044,
      "step": 2570
    },
    {
      "epoch": 2.58,
      "learning_rate": 7.730999999999999e-05,
      "loss": 0.3636,
      "step": 2580
    },
    {
      "epoch": 2.59,
      "learning_rate": 7.760999999999998e-05,
      "loss": 0.3291,
      "step": 2590
    },
    {
      "epoch": 2.6,
      "learning_rate": 7.790999999999999e-05,
      "loss": 0.2809,
      "step": 2600
    },
    {
      "epoch": 2.61,
      "learning_rate": 7.820999999999998e-05,
      "loss": 0.2865,
      "step": 2610
    },
    {
      "epoch": 2.62,
      "learning_rate": 7.850999999999999e-05,
      "loss": 0.3341,
      "step": 2620
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.880999999999999e-05,
      "loss": 0.2738,
      "step": 2630
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.910999999999999e-05,
      "loss": 0.221,
      "step": 2640
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.940999999999999e-05,
      "loss": 0.2526,
      "step": 2650
    },
    {
      "epoch": 2.66,
      "learning_rate": 7.971e-05,
      "loss": 0.2399,
      "step": 2660
    },
    {
      "epoch": 2.67,
      "learning_rate": 8.000999999999999e-05,
      "loss": 0.2717,
      "step": 2670
    },
    {
      "epoch": 2.68,
      "learning_rate": 8.031e-05,
      "loss": 0.2423,
      "step": 2680
    },
    {
      "epoch": 2.69,
      "learning_rate": 8.060999999999999e-05,
      "loss": 0.2556,
      "step": 2690
    },
    {
      "epoch": 2.7,
      "learning_rate": 8.091e-05,
      "loss": 0.2455,
      "step": 2700
    },
    {
      "epoch": 2.71,
      "learning_rate": 8.120999999999999e-05,
      "loss": 0.3304,
      "step": 2710
    },
    {
      "epoch": 2.72,
      "learning_rate": 8.151e-05,
      "loss": 0.3253,
      "step": 2720
    },
    {
      "epoch": 2.73,
      "learning_rate": 8.180999999999999e-05,
      "loss": 0.2467,
      "step": 2730
    },
    {
      "epoch": 2.74,
      "learning_rate": 8.211e-05,
      "loss": 0.2434,
      "step": 2740
    },
    {
      "epoch": 2.75,
      "learning_rate": 8.240999999999999e-05,
      "loss": 0.2719,
      "step": 2750
    },
    {
      "epoch": 2.76,
      "learning_rate": 8.271e-05,
      "loss": 0.277,
      "step": 2760
    },
    {
      "epoch": 2.77,
      "learning_rate": 8.300999999999999e-05,
      "loss": 0.2089,
      "step": 2770
    },
    {
      "epoch": 2.78,
      "learning_rate": 8.330999999999999e-05,
      "loss": 0.2463,
      "step": 2780
    },
    {
      "epoch": 2.79,
      "learning_rate": 8.361e-05,
      "loss": 0.2831,
      "step": 2790
    },
    {
      "epoch": 2.8,
      "learning_rate": 8.390999999999999e-05,
      "loss": 0.2544,
      "step": 2800
    },
    {
      "epoch": 2.81,
      "learning_rate": 8.421e-05,
      "loss": 0.2711,
      "step": 2810
    },
    {
      "epoch": 2.82,
      "learning_rate": 8.450999999999999e-05,
      "loss": 0.2648,
      "step": 2820
    },
    {
      "epoch": 2.83,
      "learning_rate": 8.481e-05,
      "loss": 0.2716,
      "step": 2830
    },
    {
      "epoch": 2.84,
      "learning_rate": 8.510999999999999e-05,
      "loss": 0.2699,
      "step": 2840
    },
    {
      "epoch": 2.85,
      "learning_rate": 8.541e-05,
      "loss": 0.2652,
      "step": 2850
    },
    {
      "epoch": 2.86,
      "learning_rate": 8.570999999999999e-05,
      "loss": 0.3203,
      "step": 2860
    },
    {
      "epoch": 2.87,
      "learning_rate": 8.598e-05,
      "loss": 0.2639,
      "step": 2870
    },
    {
      "epoch": 2.88,
      "learning_rate": 8.628e-05,
      "loss": 0.2847,
      "step": 2880
    },
    {
      "epoch": 2.89,
      "learning_rate": 8.658e-05,
      "loss": 0.2855,
      "step": 2890
    },
    {
      "epoch": 2.9,
      "learning_rate": 8.688e-05,
      "loss": 0.3342,
      "step": 2900
    },
    {
      "epoch": 2.91,
      "learning_rate": 8.718e-05,
      "loss": 0.3286,
      "step": 2910
    },
    {
      "epoch": 2.92,
      "learning_rate": 8.748e-05,
      "loss": 0.2995,
      "step": 2920
    },
    {
      "epoch": 2.93,
      "learning_rate": 8.778e-05,
      "loss": 0.2928,
      "step": 2930
    },
    {
      "epoch": 2.94,
      "learning_rate": 8.808e-05,
      "loss": 0.261,
      "step": 2940
    },
    {
      "epoch": 2.95,
      "learning_rate": 8.837999999999999e-05,
      "loss": 0.2772,
      "step": 2950
    },
    {
      "epoch": 2.96,
      "learning_rate": 8.867999999999998e-05,
      "loss": 0.2996,
      "step": 2960
    },
    {
      "epoch": 2.97,
      "learning_rate": 8.897999999999998e-05,
      "loss": 0.2656,
      "step": 2970
    },
    {
      "epoch": 2.98,
      "learning_rate": 8.927999999999999e-05,
      "loss": 0.3093,
      "step": 2980
    },
    {
      "epoch": 2.99,
      "learning_rate": 8.957999999999998e-05,
      "loss": 0.2448,
      "step": 2990
    },
    {
      "epoch": 3.0,
      "learning_rate": 8.987999999999999e-05,
      "loss": 0.3317,
      "step": 3000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2804775536060333,
      "eval_runtime": 14.9924,
      "eval_samples_per_second": 133.401,
      "eval_steps_per_second": 16.675,
      "step": 3000
    },
    {
      "epoch": 3.01,
      "learning_rate": 9.017999999999998e-05,
      "loss": 0.2591,
      "step": 3010
    },
    {
      "epoch": 3.02,
      "learning_rate": 9.047999999999999e-05,
      "loss": 0.2884,
      "step": 3020
    },
    {
      "epoch": 3.03,
      "learning_rate": 9.077999999999998e-05,
      "loss": 0.289,
      "step": 3030
    },
    {
      "epoch": 3.04,
      "learning_rate": 9.107999999999999e-05,
      "loss": 0.2777,
      "step": 3040
    },
    {
      "epoch": 3.05,
      "learning_rate": 9.137999999999998e-05,
      "loss": 0.2287,
      "step": 3050
    },
    {
      "epoch": 3.06,
      "learning_rate": 9.167999999999999e-05,
      "loss": 0.3358,
      "step": 3060
    },
    {
      "epoch": 3.07,
      "learning_rate": 9.197999999999998e-05,
      "loss": 0.2415,
      "step": 3070
    },
    {
      "epoch": 3.08,
      "learning_rate": 9.227999999999999e-05,
      "loss": 0.2811,
      "step": 3080
    },
    {
      "epoch": 3.09,
      "learning_rate": 9.257999999999998e-05,
      "loss": 0.3032,
      "step": 3090
    },
    {
      "epoch": 3.1,
      "learning_rate": 9.287999999999999e-05,
      "loss": 0.3255,
      "step": 3100
    },
    {
      "epoch": 3.11,
      "learning_rate": 9.317999999999999e-05,
      "loss": 0.2069,
      "step": 3110
    },
    {
      "epoch": 3.12,
      "learning_rate": 9.347999999999999e-05,
      "loss": 0.3955,
      "step": 3120
    },
    {
      "epoch": 3.13,
      "learning_rate": 9.377999999999999e-05,
      "loss": 0.3174,
      "step": 3130
    },
    {
      "epoch": 3.14,
      "learning_rate": 9.408e-05,
      "loss": 0.294,
      "step": 3140
    },
    {
      "epoch": 3.15,
      "learning_rate": 9.437999999999999e-05,
      "loss": 0.2427,
      "step": 3150
    },
    {
      "epoch": 3.16,
      "learning_rate": 9.468e-05,
      "loss": 0.2781,
      "step": 3160
    },
    {
      "epoch": 3.17,
      "learning_rate": 9.497999999999999e-05,
      "loss": 0.2794,
      "step": 3170
    },
    {
      "epoch": 3.18,
      "learning_rate": 9.528e-05,
      "loss": 0.3226,
      "step": 3180
    },
    {
      "epoch": 3.19,
      "learning_rate": 9.557999999999999e-05,
      "loss": 0.304,
      "step": 3190
    },
    {
      "epoch": 3.2,
      "learning_rate": 9.588e-05,
      "loss": 0.3223,
      "step": 3200
    },
    {
      "epoch": 3.21,
      "learning_rate": 9.617999999999999e-05,
      "loss": 0.3055,
      "step": 3210
    },
    {
      "epoch": 3.22,
      "learning_rate": 9.647999999999998e-05,
      "loss": 0.326,
      "step": 3220
    },
    {
      "epoch": 3.23,
      "learning_rate": 9.677999999999999e-05,
      "loss": 0.2829,
      "step": 3230
    },
    {
      "epoch": 3.24,
      "learning_rate": 9.707999999999999e-05,
      "loss": 0.234,
      "step": 3240
    },
    {
      "epoch": 3.25,
      "learning_rate": 9.737999999999999e-05,
      "loss": 0.2396,
      "step": 3250
    },
    {
      "epoch": 3.26,
      "learning_rate": 9.767999999999999e-05,
      "loss": 0.2947,
      "step": 3260
    },
    {
      "epoch": 3.27,
      "learning_rate": 9.798e-05,
      "loss": 0.2851,
      "step": 3270
    },
    {
      "epoch": 3.28,
      "learning_rate": 9.827999999999999e-05,
      "loss": 0.2699,
      "step": 3280
    },
    {
      "epoch": 3.29,
      "learning_rate": 9.858e-05,
      "loss": 0.2535,
      "step": 3290
    },
    {
      "epoch": 3.3,
      "learning_rate": 9.887999999999999e-05,
      "loss": 0.2614,
      "step": 3300
    },
    {
      "epoch": 3.31,
      "learning_rate": 9.918e-05,
      "loss": 0.2775,
      "step": 3310
    },
    {
      "epoch": 3.32,
      "learning_rate": 9.947999999999999e-05,
      "loss": 0.2966,
      "step": 3320
    },
    {
      "epoch": 3.33,
      "learning_rate": 9.978e-05,
      "loss": 0.31,
      "step": 3330
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00010007999999999999,
      "loss": 0.395,
      "step": 3340
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00010038,
      "loss": 0.273,
      "step": 3350
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00010067999999999999,
      "loss": 0.2641,
      "step": 3360
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00010098,
      "loss": 0.3775,
      "step": 3370
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00010127999999999999,
      "loss": 0.3017,
      "step": 3380
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00010158,
      "loss": 0.4365,
      "step": 3390
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00010188,
      "loss": 0.3267,
      "step": 3400
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00010218,
      "loss": 0.2294,
      "step": 3410
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00010248,
      "loss": 0.2818,
      "step": 3420
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00010278,
      "loss": 0.3028,
      "step": 3430
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00010308,
      "loss": 0.2208,
      "step": 3440
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00010338,
      "loss": 0.3219,
      "step": 3450
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00010368,
      "loss": 0.27,
      "step": 3460
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00010397999999999999,
      "loss": 0.3025,
      "step": 3470
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.00010428,
      "loss": 0.2589,
      "step": 3480
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00010457999999999999,
      "loss": 0.295,
      "step": 3490
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00010488,
      "loss": 0.2714,
      "step": 3500
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00010517999999999999,
      "loss": 0.2784,
      "step": 3510
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00010548,
      "loss": 0.2622,
      "step": 3520
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00010578,
      "loss": 0.25,
      "step": 3530
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00010608,
      "loss": 0.2949,
      "step": 3540
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00010638,
      "loss": 0.2934,
      "step": 3550
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00010668,
      "loss": 0.2551,
      "step": 3560
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00010697999999999998,
      "loss": 0.3511,
      "step": 3570
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00010727999999999999,
      "loss": 0.2836,
      "step": 3580
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00010757999999999998,
      "loss": 0.2846,
      "step": 3590
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00010787999999999998,
      "loss": 0.2183,
      "step": 3600
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00010817999999999998,
      "loss": 0.262,
      "step": 3610
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00010847999999999998,
      "loss": 0.2774,
      "step": 3620
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00010877999999999999,
      "loss": 0.2307,
      "step": 3630
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00010907999999999998,
      "loss": 0.2125,
      "step": 3640
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00010937999999999999,
      "loss": 0.2725,
      "step": 3650
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00010967999999999998,
      "loss": 0.3039,
      "step": 3660
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00010997999999999999,
      "loss": 0.3027,
      "step": 3670
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00011027999999999998,
      "loss": 0.218,
      "step": 3680
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00011057999999999999,
      "loss": 0.2956,
      "step": 3690
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00011087999999999998,
      "loss": 0.2846,
      "step": 3700
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00011117999999999999,
      "loss": 0.2763,
      "step": 3710
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00011147999999999998,
      "loss": 0.3188,
      "step": 3720
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00011177999999999999,
      "loss": 0.296,
      "step": 3730
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00011207999999999998,
      "loss": 0.2896,
      "step": 3740
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00011237999999999999,
      "loss": 0.2618,
      "step": 3750
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00011267999999999999,
      "loss": 0.2027,
      "step": 3760
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00011297999999999999,
      "loss": 0.3543,
      "step": 3770
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00011327999999999999,
      "loss": 0.3883,
      "step": 3780
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00011358,
      "loss": 0.3288,
      "step": 3790
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00011387999999999999,
      "loss": 0.2857,
      "step": 3800
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00011418,
      "loss": 0.3173,
      "step": 3810
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00011447999999999999,
      "loss": 0.3474,
      "step": 3820
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00011477999999999998,
      "loss": 0.2588,
      "step": 3830
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00011507999999999999,
      "loss": 0.4266,
      "step": 3840
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00011537999999999998,
      "loss": 0.3788,
      "step": 3850
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00011567999999999999,
      "loss": 0.1989,
      "step": 3860
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00011597999999999998,
      "loss": 0.3682,
      "step": 3870
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00011627999999999999,
      "loss": 0.227,
      "step": 3880
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00011657999999999998,
      "loss": 0.3309,
      "step": 3890
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00011687999999999999,
      "loss": 0.2526,
      "step": 3900
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00011717999999999999,
      "loss": 0.2848,
      "step": 3910
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00011748,
      "loss": 0.3389,
      "step": 3920
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00011777999999999999,
      "loss": 0.2653,
      "step": 3930
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00011808,
      "loss": 0.3201,
      "step": 3940
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00011837999999999999,
      "loss": 0.2855,
      "step": 3950
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00011868,
      "loss": 0.2153,
      "step": 3960
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00011897999999999999,
      "loss": 0.2666,
      "step": 3970
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00011928,
      "loss": 0.3134,
      "step": 3980
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00011957999999999999,
      "loss": 0.3206,
      "step": 3990
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00011988,
      "loss": 0.289,
      "step": 4000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8005,
      "eval_loss": 0.27321934700012207,
      "eval_runtime": 14.9907,
      "eval_samples_per_second": 133.416,
      "eval_steps_per_second": 16.677,
      "step": 4000
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00012017999999999999,
      "loss": 0.2766,
      "step": 4010
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00012048,
      "loss": 0.3161,
      "step": 4020
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00012077999999999999,
      "loss": 0.2885,
      "step": 4030
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00012108,
      "loss": 0.324,
      "step": 4040
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00012137999999999999,
      "loss": 0.2633,
      "step": 4050
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00012168,
      "loss": 0.3343,
      "step": 4060
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00012198,
      "loss": 0.3566,
      "step": 4070
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00012228,
      "loss": 0.2631,
      "step": 4080
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00012257999999999998,
      "loss": 0.2485,
      "step": 4090
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00012288,
      "loss": 0.2901,
      "step": 4100
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00012318,
      "loss": 0.2812,
      "step": 4110
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00012348,
      "loss": 0.2104,
      "step": 4120
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00012377999999999998,
      "loss": 0.2882,
      "step": 4130
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00012408,
      "loss": 0.2801,
      "step": 4140
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00012438,
      "loss": 0.2453,
      "step": 4150
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00012468,
      "loss": 0.288,
      "step": 4160
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00012497999999999999,
      "loss": 0.265,
      "step": 4170
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00012528,
      "loss": 0.272,
      "step": 4180
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00012558,
      "loss": 0.2464,
      "step": 4190
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00012587999999999998,
      "loss": 0.2669,
      "step": 4200
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00012618,
      "loss": 0.2401,
      "step": 4210
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00012647999999999997,
      "loss": 0.3246,
      "step": 4220
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00012677999999999998,
      "loss": 0.2457,
      "step": 4230
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00012707999999999998,
      "loss": 0.3312,
      "step": 4240
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00012738,
      "loss": 0.2747,
      "step": 4250
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00012767999999999997,
      "loss": 0.3217,
      "step": 4260
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00012797999999999998,
      "loss": 0.3128,
      "step": 4270
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00012827999999999998,
      "loss": 0.3081,
      "step": 4280
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00012858,
      "loss": 0.2848,
      "step": 4290
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00012887999999999997,
      "loss": 0.3104,
      "step": 4300
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00012917999999999998,
      "loss": 0.2623,
      "step": 4310
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00012948,
      "loss": 0.2672,
      "step": 4320
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00012978,
      "loss": 0.2825,
      "step": 4330
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00013007999999999997,
      "loss": 0.338,
      "step": 4340
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00013037999999999998,
      "loss": 0.3118,
      "step": 4350
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00013064999999999998,
      "loss": 0.3284,
      "step": 4360
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00013094999999999998,
      "loss": 0.3349,
      "step": 4370
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00013125,
      "loss": 0.242,
      "step": 4380
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00013155,
      "loss": 0.254,
      "step": 4390
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00013184999999999998,
      "loss": 0.2938,
      "step": 4400
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00013215,
      "loss": 0.2443,
      "step": 4410
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00013245,
      "loss": 0.2404,
      "step": 4420
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00013275,
      "loss": 0.2314,
      "step": 4430
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00013304999999999998,
      "loss": 0.2876,
      "step": 4440
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00013335,
      "loss": 0.2591,
      "step": 4450
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00013365,
      "loss": 0.2452,
      "step": 4460
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00013395,
      "loss": 0.309,
      "step": 4470
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00013424999999999998,
      "loss": 0.2457,
      "step": 4480
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00013455,
      "loss": 0.3532,
      "step": 4490
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00013485,
      "loss": 0.394,
      "step": 4500
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00013514999999999998,
      "loss": 0.4151,
      "step": 4510
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00013544999999999999,
      "loss": 0.3973,
      "step": 4520
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00013575,
      "loss": 0.8534,
      "step": 4530
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00013605,
      "loss": 0.3193,
      "step": 4540
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00013634999999999998,
      "loss": 0.3094,
      "step": 4550
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00013665,
      "loss": 0.2531,
      "step": 4560
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00013695,
      "loss": 0.2914,
      "step": 4570
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00013725,
      "loss": 0.2302,
      "step": 4580
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.00013754999999999998,
      "loss": 0.3676,
      "step": 4590
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00013785,
      "loss": 0.302,
      "step": 4600
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00013815,
      "loss": 0.2646,
      "step": 4610
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00013845,
      "loss": 0.2348,
      "step": 4620
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00013874999999999998,
      "loss": 0.237,
      "step": 4630
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00013905,
      "loss": 0.3236,
      "step": 4640
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00013935,
      "loss": 0.3352,
      "step": 4650
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00013965,
      "loss": 0.2915,
      "step": 4660
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00013995,
      "loss": 0.2629,
      "step": 4670
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00014025,
      "loss": 0.2699,
      "step": 4680
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00014055,
      "loss": 0.233,
      "step": 4690
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00014084999999999998,
      "loss": 0.2209,
      "step": 4700
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00014115,
      "loss": 0.2057,
      "step": 4710
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00014144999999999997,
      "loss": 0.2857,
      "step": 4720
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00014174999999999998,
      "loss": 0.3289,
      "step": 4730
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00014204999999999998,
      "loss": 0.2296,
      "step": 4740
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00014235,
      "loss": 0.3536,
      "step": 4750
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00014264999999999997,
      "loss": 0.3442,
      "step": 4760
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00014294999999999998,
      "loss": 0.265,
      "step": 4770
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00014324999999999999,
      "loss": 0.2362,
      "step": 4780
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00014355,
      "loss": 0.3033,
      "step": 4790
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00014384999999999997,
      "loss": 0.3174,
      "step": 4800
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00014414999999999998,
      "loss": 0.2375,
      "step": 4810
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00014445,
      "loss": 0.2906,
      "step": 4820
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00014475,
      "loss": 0.3989,
      "step": 4830
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00014504999999999997,
      "loss": 0.2779,
      "step": 4840
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00014534999999999998,
      "loss": 0.341,
      "step": 4850
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00014565,
      "loss": 0.2858,
      "step": 4860
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00014595,
      "loss": 0.2482,
      "step": 4870
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00014624999999999998,
      "loss": 0.2352,
      "step": 4880
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00014654999999999998,
      "loss": 0.3404,
      "step": 4890
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00014685,
      "loss": 0.2763,
      "step": 4900
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00014714999999999997,
      "loss": 0.2781,
      "step": 4910
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00014744999999999998,
      "loss": 0.2605,
      "step": 4920
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00014774999999999999,
      "loss": 0.2999,
      "step": 4930
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00014805,
      "loss": 0.2445,
      "step": 4940
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00014834999999999997,
      "loss": 0.3064,
      "step": 4950
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00014864999999999998,
      "loss": 0.2968,
      "step": 4960
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00014895,
      "loss": 0.3574,
      "step": 4970
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00014925,
      "loss": 0.2425,
      "step": 4980
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00014954999999999998,
      "loss": 0.2717,
      "step": 4990
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00014984999999999998,
      "loss": 0.282,
      "step": 5000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27421727776527405,
      "eval_runtime": 15.5161,
      "eval_samples_per_second": 128.898,
      "eval_steps_per_second": 16.112,
      "step": 5000
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00014999999897476407,
      "loss": 0.2733,
      "step": 5010
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00014999999077287696,
      "loss": 0.3175,
      "step": 5020
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00014999997436910357,
      "loss": 0.2912,
      "step": 5030
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.0001499999497634458,
      "loss": 0.254,
      "step": 5040
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00014999991695590625,
      "loss": 0.2862,
      "step": 5050
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00014999987594648855,
      "loss": 0.3017,
      "step": 5060
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.00014999982673519717,
      "loss": 0.2587,
      "step": 5070
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00014999976932203752,
      "loss": 0.2663,
      "step": 5080
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00014999970370701586,
      "loss": 0.3525,
      "step": 5090
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00014999962989013937,
      "loss": 0.2898,
      "step": 5100
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.0001499995478714161,
      "loss": 0.304,
      "step": 5110
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00014999945765085498,
      "loss": 0.2796,
      "step": 5120
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.000149999359228466,
      "loss": 0.2959,
      "step": 5130
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00014999925260425983,
      "loss": 0.3168,
      "step": 5140
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00014999913777824817,
      "loss": 0.2627,
      "step": 5150
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00014999901475044354,
      "loss": 0.303,
      "step": 5160
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.00014999888352085946,
      "loss": 0.2821,
      "step": 5170
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.0001499987440895102,
      "loss": 0.3054,
      "step": 5180
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.00014999859645641105,
      "loss": 0.3055,
      "step": 5190
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00014999844062157816,
      "loss": 0.2542,
      "step": 5200
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00014999827658502854,
      "loss": 0.2693,
      "step": 5210
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00014999810434678017,
      "loss": 0.3063,
      "step": 5220
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.00014999792390685187,
      "loss": 0.1748,
      "step": 5230
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00014999773526526335,
      "loss": 0.2719,
      "step": 5240
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.00014999753842203528,
      "loss": 0.2547,
      "step": 5250
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.00014999733337718916,
      "loss": 0.2786,
      "step": 5260
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.0001499971201307474,
      "loss": 0.2625,
      "step": 5270
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.00014999689868273335,
      "loss": 0.285,
      "step": 5280
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00014999666903317124,
      "loss": 0.2373,
      "step": 5290
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.00014999643118208613,
      "loss": 0.2682,
      "step": 5300
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.00014999618512950404,
      "loss": 0.3072,
      "step": 5310
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.00014999593087545193,
      "loss": 0.3725,
      "step": 5320
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0001499956684199576,
      "loss": 0.2463,
      "step": 5330
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.0001499953977630497,
      "loss": 0.33,
      "step": 5340
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.00014999511890475786,
      "loss": 0.2785,
      "step": 5350
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00014999483184511257,
      "loss": 0.2654,
      "step": 5360
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.0001499945365841452,
      "loss": 0.2294,
      "step": 5370
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.0001499942331218881,
      "loss": 0.2224,
      "step": 5380
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.00014999392145837438,
      "loss": 0.2282,
      "step": 5390
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00014999360159363817,
      "loss": 0.2834,
      "step": 5400
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00014999327352771446,
      "loss": 0.2893,
      "step": 5410
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.0001499929372606391,
      "loss": 0.3412,
      "step": 5420
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00014999259279244886,
      "loss": 0.2621,
      "step": 5430
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00014999224012318143,
      "loss": 0.3201,
      "step": 5440
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.00014999187925287538,
      "loss": 0.3157,
      "step": 5450
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00014999151018157015,
      "loss": 0.2952,
      "step": 5460
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00014999113290930613,
      "loss": 0.2432,
      "step": 5470
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.00014999074743612454,
      "loss": 0.2658,
      "step": 5480
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00014999035376206756,
      "loss": 0.3248,
      "step": 5490
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00014998995188717824,
      "loss": 0.2338,
      "step": 5500
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.00014998954181150054,
      "loss": 0.2675,
      "step": 5510
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00014998912353507928,
      "loss": 0.2794,
      "step": 5520
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00014998869705796022,
      "loss": 0.2571,
      "step": 5530
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00014998826238019,
      "loss": 0.2978,
      "step": 5540
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.00014998781950181615,
      "loss": 0.289,
      "step": 5550
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.0001499873684228871,
      "loss": 0.3299,
      "step": 5560
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00014998690914345215,
      "loss": 0.3725,
      "step": 5570
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.0001499864416635616,
      "loss": 0.3418,
      "step": 5580
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.00014998596598326652,
      "loss": 0.3196,
      "step": 5590
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00014998548210261892,
      "loss": 0.3085,
      "step": 5600
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00014998499002167175,
      "loss": 0.272,
      "step": 5610
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.0001499844897404788,
      "loss": 0.3015,
      "step": 5620
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.00014998398125909483,
      "loss": 0.3281,
      "step": 5630
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00014998346457757535,
      "loss": 0.3112,
      "step": 5640
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00014998293969597696,
      "loss": 0.2458,
      "step": 5650
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.000149982406614357,
      "loss": 0.2929,
      "step": 5660
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.0001499818653327738,
      "loss": 0.3337,
      "step": 5670
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00014998131585128652,
      "loss": 0.3224,
      "step": 5680
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00014998075816995528,
      "loss": 0.1646,
      "step": 5690
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00014998019228884107,
      "loss": 0.2961,
      "step": 5700
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.00014997961820800576,
      "loss": 0.25,
      "step": 5710
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.0001499790359275121,
      "loss": 0.3246,
      "step": 5720
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00014997844544742387,
      "loss": 0.2928,
      "step": 5730
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.0001499778467678055,
      "loss": 0.305,
      "step": 5740
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.00014997723988872258,
      "loss": 0.2462,
      "step": 5750
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.0001499766248102414,
      "loss": 0.2584,
      "step": 5760
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00014997600153242928,
      "loss": 0.2689,
      "step": 5770
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00014997537005535436,
      "loss": 0.3216,
      "step": 5780
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.0001499747303790857,
      "loss": 0.2632,
      "step": 5790
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00014997408250369323,
      "loss": 0.2886,
      "step": 5800
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.0001499734264292478,
      "loss": 0.2893,
      "step": 5810
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00014997276215582124,
      "loss": 0.2399,
      "step": 5820
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00014997208968348607,
      "loss": 0.2757,
      "step": 5830
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.00014997140901231592,
      "loss": 0.2465,
      "step": 5840
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00014997072014238518,
      "loss": 0.2144,
      "step": 5850
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00014997002307376922,
      "loss": 0.3085,
      "step": 5860
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00014996931780654425,
      "loss": 0.3365,
      "step": 5870
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.0001499686043407874,
      "loss": 0.2582,
      "step": 5880
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.0001499678826765767,
      "loss": 0.3329,
      "step": 5890
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00014996715281399104,
      "loss": 0.3312,
      "step": 5900
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.00014996641475311027,
      "loss": 0.2679,
      "step": 5910
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.0001499656684940151,
      "loss": 0.246,
      "step": 5920
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.0001499649140367871,
      "loss": 0.2784,
      "step": 5930
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00014996415138150885,
      "loss": 0.2431,
      "step": 5940
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.0001499633805282637,
      "loss": 0.3118,
      "step": 5950
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00014996260147713596,
      "loss": 0.2498,
      "step": 5960
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.0001499618142282108,
      "loss": 0.2533,
      "step": 5970
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.00014996101878157438,
      "loss": 0.2733,
      "step": 5980
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00014996021513731365,
      "loss": 0.3056,
      "step": 5990
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.00014995940329551647,
      "loss": 0.2691,
      "step": 6000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.27327650785446167,
      "eval_runtime": 14.5942,
      "eval_samples_per_second": 137.041,
      "eval_steps_per_second": 17.13,
      "step": 6000
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00014995858325627165,
      "loss": 0.2877,
      "step": 6010
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00014995775501966887,
      "loss": 0.3037,
      "step": 6020
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00014995691858579868,
      "loss": 0.3053,
      "step": 6030
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.0001499560739547526,
      "loss": 0.303,
      "step": 6040
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00014995522112662296,
      "loss": 0.2545,
      "step": 6050
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.00014995436010150303,
      "loss": 0.2735,
      "step": 6060
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.00014995349087948694,
      "loss": 0.3061,
      "step": 6070
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.0001499526134606698,
      "loss": 0.3242,
      "step": 6080
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00014995172784514754,
      "loss": 0.2953,
      "step": 6090
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00014995083403301703,
      "loss": 0.3168,
      "step": 6100
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00014994993202437597,
      "loss": 0.3486,
      "step": 6110
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00014994902181932304,
      "loss": 0.2173,
      "step": 6120
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.00014994810341795777,
      "loss": 0.3553,
      "step": 6130
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00014994717682038062,
      "loss": 0.2863,
      "step": 6140
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00014994624202669285,
      "loss": 0.3666,
      "step": 6150
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00014994529903699676,
      "loss": 0.2339,
      "step": 6160
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00014994434785139542,
      "loss": 0.3113,
      "step": 6170
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.0001499433884699929,
      "loss": 0.3105,
      "step": 6180
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.00014994242089289407,
      "loss": 0.2346,
      "step": 6190
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.0001499414451202048,
      "loss": 0.2754,
      "step": 6200
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00014994046115203173,
      "loss": 0.3483,
      "step": 6210
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.0001499394689884825,
      "loss": 0.2486,
      "step": 6220
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00014993846862966563,
      "loss": 0.338,
      "step": 6230
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.0001499374600756905,
      "loss": 0.2675,
      "step": 6240
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.0001499364433266674,
      "loss": 0.2521,
      "step": 6250
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.00014993541838270751,
      "loss": 0.2755,
      "step": 6260
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00014993438524392295,
      "loss": 0.2704,
      "step": 6270
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00014993334391042666,
      "loss": 0.258,
      "step": 6280
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.00014993229438233256,
      "loss": 0.2216,
      "step": 6290
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.0001499312366597554,
      "loss": 0.3317,
      "step": 6300
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.00014993017074281084,
      "loss": 0.319,
      "step": 6310
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00014992909663161548,
      "loss": 0.2612,
      "step": 6320
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.00014992801432628676,
      "loss": 0.2521,
      "step": 6330
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.00014992692382694305,
      "loss": 0.1847,
      "step": 6340
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.0001499258251337036,
      "loss": 0.2825,
      "step": 6350
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00014992471824668853,
      "loss": 0.2673,
      "step": 6360
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00014992360316601897,
      "loss": 0.2675,
      "step": 6370
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.0001499224798918168,
      "loss": 0.2169,
      "step": 6380
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00014992134842420487,
      "loss": 0.2866,
      "step": 6390
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.0001499202087633069,
      "loss": 0.2338,
      "step": 6400
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00014991906090924757,
      "loss": 0.247,
      "step": 6410
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.0001499179048621524,
      "loss": 0.2689,
      "step": 6420
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00014991674062214775,
      "loss": 0.2629,
      "step": 6430
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00014991556818936096,
      "loss": 0.313,
      "step": 6440
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00014991438756392032,
      "loss": 0.2093,
      "step": 6450
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00014991319874595483,
      "loss": 0.2169,
      "step": 6460
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00014991200173559462,
      "loss": 0.2513,
      "step": 6470
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.0001499107965329705,
      "loss": 0.2597,
      "step": 6480
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.0001499095831382143,
      "loss": 0.373,
      "step": 6490
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.0001499083615514587,
      "loss": 0.2741,
      "step": 6500
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.0001499071317728373,
      "loss": 0.3247,
      "step": 6510
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.00014990589380248462,
      "loss": 0.2177,
      "step": 6520
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.000149904647640536,
      "loss": 0.3326,
      "step": 6530
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.00014990339328712772,
      "loss": 0.245,
      "step": 6540
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.000149902130742397,
      "loss": 0.2992,
      "step": 6550
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.00014990086000648184,
      "loss": 0.3202,
      "step": 6560
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00014989958107952122,
      "loss": 0.2693,
      "step": 6570
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00014989829396165507,
      "loss": 0.2727,
      "step": 6580
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00014989699865302408,
      "loss": 0.2393,
      "step": 6590
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.00014989569515376993,
      "loss": 0.2918,
      "step": 6600
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00014989438346403515,
      "loss": 0.27,
      "step": 6610
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00014989306358396322,
      "loss": 0.2278,
      "step": 6620
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00014989173551369845,
      "loss": 0.3185,
      "step": 6630
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00014989039925338607,
      "loss": 0.2646,
      "step": 6640
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.00014988905480317223,
      "loss": 0.339,
      "step": 6650
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00014988770216320393,
      "loss": 0.2866,
      "step": 6660
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00014988634133362912,
      "loss": 0.2502,
      "step": 6670
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.00014988497231459665,
      "loss": 0.3568,
      "step": 6680
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.00014988359510625617,
      "loss": 0.2884,
      "step": 6690
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.0001498822097087583,
      "loss": 0.2772,
      "step": 6700
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00014988081612225457,
      "loss": 0.2864,
      "step": 6710
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00014987941434689738,
      "loss": 0.2755,
      "step": 6720
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.00014987800438284003,
      "loss": 0.3036,
      "step": 6730
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00014987658623023668,
      "loss": 0.2985,
      "step": 6740
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00014987515988924244,
      "loss": 0.2482,
      "step": 6750
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.00014987372536001328,
      "loss": 0.2577,
      "step": 6760
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.0001498722826427061,
      "loss": 0.2553,
      "step": 6770
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00014987083173747861,
      "loss": 0.3359,
      "step": 6780
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.0001498693726444896,
      "loss": 0.2503,
      "step": 6790
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.0001498679053638985,
      "loss": 0.2794,
      "step": 6800
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00014986642989586589,
      "loss": 0.2459,
      "step": 6810
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.000149864946240553,
      "loss": 0.2291,
      "step": 6820
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.0001498634543981222,
      "loss": 0.3096,
      "step": 6830
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.00014986195436873657,
      "loss": 0.3399,
      "step": 6840
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.00014986044615256016,
      "loss": 0.2318,
      "step": 6850
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.0001498589297497579,
      "loss": 0.2014,
      "step": 6860
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.00014985740516049563,
      "loss": 0.2691,
      "step": 6870
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.0001498558723849401,
      "loss": 0.347,
      "step": 6880
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.0001498543314232589,
      "loss": 0.3036,
      "step": 6890
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.00014985278227562054,
      "loss": 0.2831,
      "step": 6900
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00014985122494219448,
      "loss": 0.2662,
      "step": 6910
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00014984965942315098,
      "loss": 0.2914,
      "step": 6920
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00014984808571866126,
      "loss": 0.2863,
      "step": 6930
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00014984650382889741,
      "loss": 0.2786,
      "step": 6940
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.00014984491375403245,
      "loss": 0.3131,
      "step": 6950
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00014984331549424025,
      "loss": 0.3161,
      "step": 6960
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00014984170904969556,
      "loss": 0.2384,
      "step": 6970
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.00014984009442057413,
      "loss": 0.2798,
      "step": 6980
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.0001498384716070525,
      "loss": 0.3067,
      "step": 6990
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.0001498368406093081,
      "loss": 0.3493,
      "step": 7000
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27725109457969666,
      "eval_runtime": 14.7462,
      "eval_samples_per_second": 135.628,
      "eval_steps_per_second": 16.954,
      "step": 7000
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.00014983520142751935,
      "loss": 0.2849,
      "step": 7010
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00014983355406186547,
      "loss": 0.2431,
      "step": 7020
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.00014983189851252662,
      "loss": 0.1836,
      "step": 7030
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.00014983023477968386,
      "loss": 0.2265,
      "step": 7040
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00014982856286351916,
      "loss": 0.2494,
      "step": 7050
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.0001498268827642153,
      "loss": 0.2712,
      "step": 7060
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.00014982519448195603,
      "loss": 0.2662,
      "step": 7070
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.00014982349801692603,
      "loss": 0.3057,
      "step": 7080
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.00014982179336931077,
      "loss": 0.2897,
      "step": 7090
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.00014982008053929667,
      "loss": 0.266,
      "step": 7100
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00014981835952707103,
      "loss": 0.3117,
      "step": 7110
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.00014981663033282212,
      "loss": 0.2511,
      "step": 7120
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00014981489295673897,
      "loss": 0.3248,
      "step": 7130
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00014981314739901164,
      "loss": 0.2945,
      "step": 7140
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.000149811393659831,
      "loss": 0.2192,
      "step": 7150
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00014980963173938876,
      "loss": 0.2777,
      "step": 7160
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.00014980786163787773,
      "loss": 0.3123,
      "step": 7170
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.0001498060833554914,
      "loss": 0.2157,
      "step": 7180
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00014980429689242426,
      "loss": 0.2552,
      "step": 7190
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00014980250224887168,
      "loss": 0.235,
      "step": 7200
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.00014980069942502995,
      "loss": 0.2801,
      "step": 7210
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.00014979888842109616,
      "loss": 0.239,
      "step": 7220
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.0001497970692372684,
      "loss": 0.2521,
      "step": 7230
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00014979524187374557,
      "loss": 0.2493,
      "step": 7240
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.0001497934063307276,
      "loss": 0.3307,
      "step": 7250
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.0001497915626084151,
      "loss": 0.2817,
      "step": 7260
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00014978971070700982,
      "loss": 0.267,
      "step": 7270
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.0001497878506267142,
      "loss": 0.2625,
      "step": 7280
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00014978598236773167,
      "loss": 0.2954,
      "step": 7290
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00014978410593026654,
      "loss": 0.2719,
      "step": 7300
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00014978222131452402,
      "loss": 0.2705,
      "step": 7310
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00014978032852071022,
      "loss": 0.2689,
      "step": 7320
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00014977842754903214,
      "loss": 0.2503,
      "step": 7330
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00014977651839969764,
      "loss": 0.3131,
      "step": 7340
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.0001497746010729155,
      "loss": 0.3343,
      "step": 7350
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00014977267556889542,
      "loss": 0.3154,
      "step": 7360
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.00014977074188784797,
      "loss": 0.2421,
      "step": 7370
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00014976880002998458,
      "loss": 0.2695,
      "step": 7380
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00014976684999551764,
      "loss": 0.3404,
      "step": 7390
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.0001497648917846604,
      "loss": 0.3243,
      "step": 7400
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.000149762925397627,
      "loss": 0.3061,
      "step": 7410
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.00014976095083463247,
      "loss": 0.2539,
      "step": 7420
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00014975896809589278,
      "loss": 0.3029,
      "step": 7430
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00014975697718162473,
      "loss": 0.3114,
      "step": 7440
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00014975497809204607,
      "loss": 0.2819,
      "step": 7450
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.00014975297082737534,
      "loss": 0.2936,
      "step": 7460
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00014975095538783217,
      "loss": 0.2479,
      "step": 7470
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00014974893177363688,
      "loss": 0.3025,
      "step": 7480
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.0001497468999850108,
      "loss": 0.2943,
      "step": 7490
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.0001497448600221761,
      "loss": 0.3273,
      "step": 7500
    },
    {
      "epoch": 7.51,
      "learning_rate": 0.00014974281188535592,
      "loss": 0.2941,
      "step": 7510
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.00014974075557477417,
      "loss": 0.338,
      "step": 7520
    },
    {
      "epoch": 7.53,
      "learning_rate": 0.0001497386910906558,
      "loss": 0.2863,
      "step": 7530
    },
    {
      "epoch": 7.54,
      "learning_rate": 0.0001497366184332265,
      "loss": 0.2627,
      "step": 7540
    },
    {
      "epoch": 7.55,
      "learning_rate": 0.000149734537602713,
      "loss": 0.2427,
      "step": 7550
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.0001497324485993428,
      "loss": 0.2856,
      "step": 7560
    },
    {
      "epoch": 7.57,
      "learning_rate": 0.0001497303514233444,
      "loss": 0.2123,
      "step": 7570
    },
    {
      "epoch": 7.58,
      "learning_rate": 0.00014972824607494714,
      "loss": 0.2471,
      "step": 7580
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.00014972613255438122,
      "loss": 0.1957,
      "step": 7590
    },
    {
      "epoch": 7.6,
      "learning_rate": 0.0001497240108618778,
      "loss": 0.1984,
      "step": 7600
    },
    {
      "epoch": 7.61,
      "learning_rate": 0.0001497218809976689,
      "loss": 0.2485,
      "step": 7610
    },
    {
      "epoch": 7.62,
      "learning_rate": 0.00014971974296198743,
      "loss": 0.3141,
      "step": 7620
    },
    {
      "epoch": 7.63,
      "learning_rate": 0.00014971759675506724,
      "loss": 0.3295,
      "step": 7630
    },
    {
      "epoch": 7.64,
      "learning_rate": 0.00014971544237714295,
      "loss": 0.2148,
      "step": 7640
    },
    {
      "epoch": 7.65,
      "learning_rate": 0.00014971327982845026,
      "loss": 0.2731,
      "step": 7650
    },
    {
      "epoch": 7.66,
      "learning_rate": 0.00014971110910922558,
      "loss": 0.3492,
      "step": 7660
    },
    {
      "epoch": 7.67,
      "learning_rate": 0.00014970893021970638,
      "loss": 0.2357,
      "step": 7670
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.00014970674316013087,
      "loss": 0.2996,
      "step": 7680
    },
    {
      "epoch": 7.69,
      "learning_rate": 0.00014970454793073823,
      "loss": 0.2762,
      "step": 7690
    },
    {
      "epoch": 7.7,
      "learning_rate": 0.00014970234453176855,
      "loss": 0.3871,
      "step": 7700
    },
    {
      "epoch": 7.71,
      "learning_rate": 0.00014970013296346278,
      "loss": 0.2449,
      "step": 7710
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.00014969791322606282,
      "loss": 0.3214,
      "step": 7720
    },
    {
      "epoch": 7.73,
      "learning_rate": 0.00014969568531981135,
      "loss": 0.2681,
      "step": 7730
    },
    {
      "epoch": 7.74,
      "learning_rate": 0.00014969344924495203,
      "loss": 0.2808,
      "step": 7740
    },
    {
      "epoch": 7.75,
      "learning_rate": 0.00014969120500172943,
      "loss": 0.2862,
      "step": 7750
    },
    {
      "epoch": 7.76,
      "learning_rate": 0.0001496889525903889,
      "loss": 0.3739,
      "step": 7760
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.00014968669201117685,
      "loss": 0.2704,
      "step": 7770
    },
    {
      "epoch": 7.78,
      "learning_rate": 0.00014968442326434043,
      "loss": 0.3087,
      "step": 7780
    },
    {
      "epoch": 7.79,
      "learning_rate": 0.00014968214635012778,
      "loss": 0.2748,
      "step": 7790
    },
    {
      "epoch": 7.8,
      "learning_rate": 0.00014967986126878787,
      "loss": 0.3066,
      "step": 7800
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.00014967756802057063,
      "loss": 0.3196,
      "step": 7810
    },
    {
      "epoch": 7.82,
      "learning_rate": 0.00014967526660572683,
      "loss": 0.3111,
      "step": 7820
    },
    {
      "epoch": 7.83,
      "learning_rate": 0.00014967295702450812,
      "loss": 0.3144,
      "step": 7830
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.0001496706392771671,
      "loss": 0.2081,
      "step": 7840
    },
    {
      "epoch": 7.85,
      "learning_rate": 0.00014966831336395728,
      "loss": 0.3114,
      "step": 7850
    },
    {
      "epoch": 7.86,
      "learning_rate": 0.00014966597928513294,
      "loss": 0.2546,
      "step": 7860
    },
    {
      "epoch": 7.87,
      "learning_rate": 0.00014966363704094936,
      "loss": 0.2895,
      "step": 7870
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.0001496612866316627,
      "loss": 0.2471,
      "step": 7880
    },
    {
      "epoch": 7.89,
      "learning_rate": 0.00014965892805753,
      "loss": 0.2848,
      "step": 7890
    },
    {
      "epoch": 7.9,
      "learning_rate": 0.00014965656131880913,
      "loss": 0.3485,
      "step": 7900
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.000149654186415759,
      "loss": 0.3758,
      "step": 7910
    },
    {
      "epoch": 7.92,
      "learning_rate": 0.0001496518033486393,
      "loss": 0.305,
      "step": 7920
    },
    {
      "epoch": 7.93,
      "learning_rate": 0.00014964941211771055,
      "loss": 0.2193,
      "step": 7930
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.00014964701272323437,
      "loss": 0.2459,
      "step": 7940
    },
    {
      "epoch": 7.95,
      "learning_rate": 0.00014964460516547312,
      "loss": 0.2955,
      "step": 7950
    },
    {
      "epoch": 7.96,
      "learning_rate": 0.00014964218944469004,
      "loss": 0.3221,
      "step": 7960
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.00014963976556114938,
      "loss": 0.3218,
      "step": 7970
    },
    {
      "epoch": 7.98,
      "learning_rate": 0.00014963733351511618,
      "loss": 0.3266,
      "step": 7980
    },
    {
      "epoch": 7.99,
      "learning_rate": 0.00014963489330685638,
      "loss": 0.2237,
      "step": 7990
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.00014963244493663687,
      "loss": 0.2695,
      "step": 8000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2821389138698578,
      "eval_runtime": 14.7089,
      "eval_samples_per_second": 135.972,
      "eval_steps_per_second": 16.997,
      "step": 8000
    },
    {
      "epoch": 8.01,
      "learning_rate": 0.00014962998840472536,
      "loss": 0.247,
      "step": 8010
    },
    {
      "epoch": 8.02,
      "learning_rate": 0.00014962752371139057,
      "loss": 0.2586,
      "step": 8020
    },
    {
      "epoch": 8.03,
      "learning_rate": 0.00014962505085690196,
      "loss": 0.2058,
      "step": 8030
    },
    {
      "epoch": 8.04,
      "learning_rate": 0.00014962256984153,
      "loss": 0.3925,
      "step": 8040
    },
    {
      "epoch": 8.05,
      "learning_rate": 0.00014962008066554596,
      "loss": 0.2808,
      "step": 8050
    },
    {
      "epoch": 8.06,
      "learning_rate": 0.00014961758332922214,
      "loss": 0.2646,
      "step": 8060
    },
    {
      "epoch": 8.07,
      "learning_rate": 0.00014961507783283157,
      "loss": 0.2692,
      "step": 8070
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.00014961256417664825,
      "loss": 0.2417,
      "step": 8080
    },
    {
      "epoch": 8.09,
      "learning_rate": 0.0001496100423609471,
      "loss": 0.3588,
      "step": 8090
    },
    {
      "epoch": 8.1,
      "learning_rate": 0.0001496075123860039,
      "loss": 0.2804,
      "step": 8100
    },
    {
      "epoch": 8.11,
      "learning_rate": 0.00014960497425209533,
      "loss": 0.3907,
      "step": 8110
    },
    {
      "epoch": 8.12,
      "learning_rate": 0.00014960242795949896,
      "loss": 0.2258,
      "step": 8120
    },
    {
      "epoch": 8.13,
      "learning_rate": 0.00014959987350849317,
      "loss": 0.2008,
      "step": 8130
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.0001495973108993574,
      "loss": 0.2515,
      "step": 8140
    },
    {
      "epoch": 8.15,
      "learning_rate": 0.00014959474013237189,
      "loss": 0.2506,
      "step": 8150
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.00014959216120781773,
      "loss": 0.263,
      "step": 8160
    },
    {
      "epoch": 8.17,
      "learning_rate": 0.00014958957412597695,
      "loss": 0.2971,
      "step": 8170
    },
    {
      "epoch": 8.18,
      "learning_rate": 0.0001495869788871325,
      "loss": 0.2509,
      "step": 8180
    },
    {
      "epoch": 8.19,
      "learning_rate": 0.0001495843754915682,
      "loss": 0.2682,
      "step": 8190
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.0001495817639395687,
      "loss": 0.2707,
      "step": 8200
    },
    {
      "epoch": 8.21,
      "learning_rate": 0.00014957914423141967,
      "loss": 0.215,
      "step": 8210
    },
    {
      "epoch": 8.22,
      "learning_rate": 0.0001495765163674075,
      "loss": 0.2428,
      "step": 8220
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.00014957388034781967,
      "loss": 0.2497,
      "step": 8230
    },
    {
      "epoch": 8.24,
      "learning_rate": 0.00014957123617294438,
      "loss": 0.2796,
      "step": 8240
    },
    {
      "epoch": 8.25,
      "learning_rate": 0.00014956858384307086,
      "loss": 0.291,
      "step": 8250
    },
    {
      "epoch": 8.26,
      "learning_rate": 0.00014956592335848908,
      "loss": 0.3305,
      "step": 8260
    },
    {
      "epoch": 8.27,
      "learning_rate": 0.00014956325471949,
      "loss": 0.3053,
      "step": 8270
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.00014956057792636556,
      "loss": 0.2805,
      "step": 8280
    },
    {
      "epoch": 8.29,
      "learning_rate": 0.00014955789297940836,
      "loss": 0.2772,
      "step": 8290
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.00014955519987891211,
      "loss": 0.2582,
      "step": 8300
    },
    {
      "epoch": 8.31,
      "learning_rate": 0.0001495524986251713,
      "loss": 0.2534,
      "step": 8310
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.00014954978921848133,
      "loss": 0.226,
      "step": 8320
    },
    {
      "epoch": 8.33,
      "learning_rate": 0.00014954707165913849,
      "loss": 0.2795,
      "step": 8330
    },
    {
      "epoch": 8.34,
      "learning_rate": 0.00014954434594743996,
      "loss": 0.2927,
      "step": 8340
    },
    {
      "epoch": 8.35,
      "learning_rate": 0.0001495416120836838,
      "loss": 0.2352,
      "step": 8350
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.00014953887006816907,
      "loss": 0.2452,
      "step": 8360
    },
    {
      "epoch": 8.37,
      "learning_rate": 0.00014953611990119555,
      "loss": 0.277,
      "step": 8370
    },
    {
      "epoch": 8.38,
      "learning_rate": 0.00014953336158306406,
      "loss": 0.3638,
      "step": 8380
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.00014953059511407617,
      "loss": 0.3023,
      "step": 8390
    },
    {
      "epoch": 8.4,
      "learning_rate": 0.00014952782049453442,
      "loss": 0.2683,
      "step": 8400
    },
    {
      "epoch": 8.41,
      "learning_rate": 0.00014952503772474235,
      "loss": 0.3555,
      "step": 8410
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.00014952224680500416,
      "loss": 0.3124,
      "step": 8420
    },
    {
      "epoch": 8.43,
      "learning_rate": 0.00014951944773562508,
      "loss": 0.2874,
      "step": 8430
    },
    {
      "epoch": 8.44,
      "learning_rate": 0.00014951664051691128,
      "loss": 0.2882,
      "step": 8440
    },
    {
      "epoch": 8.45,
      "learning_rate": 0.00014951382514916968,
      "loss": 0.2276,
      "step": 8450
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.0001495110016327082,
      "loss": 0.2943,
      "step": 8460
    },
    {
      "epoch": 8.47,
      "learning_rate": 0.0001495081699678356,
      "loss": 0.2351,
      "step": 8470
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.00014950533015486157,
      "loss": 0.237,
      "step": 8480
    },
    {
      "epoch": 8.49,
      "learning_rate": 0.00014950248219409662,
      "loss": 0.2652,
      "step": 8490
    },
    {
      "epoch": 8.5,
      "learning_rate": 0.00014949962608585226,
      "loss": 0.3508,
      "step": 8500
    },
    {
      "epoch": 8.51,
      "learning_rate": 0.0001494967618304408,
      "loss": 0.2982,
      "step": 8510
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.00014949388942817545,
      "loss": 0.216,
      "step": 8520
    },
    {
      "epoch": 8.53,
      "learning_rate": 0.00014949100887937035,
      "loss": 0.3493,
      "step": 8530
    },
    {
      "epoch": 8.54,
      "learning_rate": 0.00014948812018434054,
      "loss": 0.2999,
      "step": 8540
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.0001494852233434019,
      "loss": 0.2799,
      "step": 8550
    },
    {
      "epoch": 8.56,
      "learning_rate": 0.00014948231835687118,
      "loss": 0.2984,
      "step": 8560
    },
    {
      "epoch": 8.57,
      "learning_rate": 0.00014947940522506615,
      "loss": 0.2613,
      "step": 8570
    },
    {
      "epoch": 8.58,
      "learning_rate": 0.00014947648394830532,
      "loss": 0.2949,
      "step": 8580
    },
    {
      "epoch": 8.59,
      "learning_rate": 0.00014947355452690818,
      "loss": 0.2173,
      "step": 8590
    },
    {
      "epoch": 8.6,
      "learning_rate": 0.00014947061696119507,
      "loss": 0.3547,
      "step": 8600
    },
    {
      "epoch": 8.61,
      "learning_rate": 0.00014946767125148728,
      "loss": 0.2827,
      "step": 8610
    },
    {
      "epoch": 8.62,
      "learning_rate": 0.00014946471739810693,
      "loss": 0.2466,
      "step": 8620
    },
    {
      "epoch": 8.63,
      "learning_rate": 0.00014946175540137704,
      "loss": 0.3029,
      "step": 8630
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.0001494587852616215,
      "loss": 0.2516,
      "step": 8640
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.00014945580697916518,
      "loss": 0.299,
      "step": 8650
    },
    {
      "epoch": 8.66,
      "learning_rate": 0.00014945282055433374,
      "loss": 0.2653,
      "step": 8660
    },
    {
      "epoch": 8.67,
      "learning_rate": 0.00014944982598745377,
      "loss": 0.3678,
      "step": 8670
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.0001494468232788528,
      "loss": 0.2691,
      "step": 8680
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.00014944381242885913,
      "loss": 0.2797,
      "step": 8690
    },
    {
      "epoch": 8.7,
      "learning_rate": 0.00014944079343780207,
      "loss": 0.2681,
      "step": 8700
    },
    {
      "epoch": 8.71,
      "learning_rate": 0.00014943776630601177,
      "loss": 0.2788,
      "step": 8710
    },
    {
      "epoch": 8.72,
      "learning_rate": 0.00014943473103381925,
      "loss": 0.2679,
      "step": 8720
    },
    {
      "epoch": 8.73,
      "learning_rate": 0.00014943168762155646,
      "loss": 0.2175,
      "step": 8730
    },
    {
      "epoch": 8.74,
      "learning_rate": 0.00014942863606955622,
      "loss": 0.2601,
      "step": 8740
    },
    {
      "epoch": 8.75,
      "learning_rate": 0.00014942557637815222,
      "loss": 0.3287,
      "step": 8750
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.0001494225085476791,
      "loss": 0.3185,
      "step": 8760
    },
    {
      "epoch": 8.77,
      "learning_rate": 0.00014941943257847236,
      "loss": 0.2433,
      "step": 8770
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.00014941634847086833,
      "loss": 0.3042,
      "step": 8780
    },
    {
      "epoch": 8.79,
      "learning_rate": 0.00014941325622520432,
      "loss": 0.2277,
      "step": 8790
    },
    {
      "epoch": 8.8,
      "learning_rate": 0.0001494101558418185,
      "loss": 0.2867,
      "step": 8800
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.0001494070473210499,
      "loss": 0.2779,
      "step": 8810
    },
    {
      "epoch": 8.82,
      "learning_rate": 0.00014940393066323847,
      "loss": 0.2497,
      "step": 8820
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.00014940080586872508,
      "loss": 0.3048,
      "step": 8830
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.00014939767293785136,
      "loss": 0.2428,
      "step": 8840
    },
    {
      "epoch": 8.85,
      "learning_rate": 0.00014939453187096005,
      "loss": 0.2394,
      "step": 8850
    },
    {
      "epoch": 8.86,
      "learning_rate": 0.00014939138266839455,
      "loss": 0.2943,
      "step": 8860
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.0001493882253304993,
      "loss": 0.2569,
      "step": 8870
    },
    {
      "epoch": 8.88,
      "learning_rate": 0.00014938505985761955,
      "loss": 0.3572,
      "step": 8880
    },
    {
      "epoch": 8.89,
      "learning_rate": 0.0001493818862501015,
      "loss": 0.3072,
      "step": 8890
    },
    {
      "epoch": 8.9,
      "learning_rate": 0.0001493787045082922,
      "loss": 0.2347,
      "step": 8900
    },
    {
      "epoch": 8.91,
      "learning_rate": 0.0001493755146325396,
      "loss": 0.3089,
      "step": 8910
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.00014937231662319255,
      "loss": 0.3213,
      "step": 8920
    },
    {
      "epoch": 8.93,
      "learning_rate": 0.00014936911048060077,
      "loss": 0.2998,
      "step": 8930
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.00014936589620511488,
      "loss": 0.234,
      "step": 8940
    },
    {
      "epoch": 8.95,
      "learning_rate": 0.00014936267379708637,
      "loss": 0.2369,
      "step": 8950
    },
    {
      "epoch": 8.96,
      "learning_rate": 0.00014935944325686768,
      "loss": 0.3835,
      "step": 8960
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.00014935620458481205,
      "loss": 0.3441,
      "step": 8970
    },
    {
      "epoch": 8.98,
      "learning_rate": 0.0001493529577812737,
      "loss": 0.2696,
      "step": 8980
    },
    {
      "epoch": 8.99,
      "learning_rate": 0.00014934970284660767,
      "loss": 0.2738,
      "step": 8990
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.0001493464397811699,
      "loss": 0.32,
      "step": 9000
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.804,
      "eval_loss": 0.27320173382759094,
      "eval_runtime": 15.1836,
      "eval_samples_per_second": 131.721,
      "eval_steps_per_second": 16.465,
      "step": 9000
    },
    {
      "epoch": 9.01,
      "learning_rate": 0.00014934316858531728,
      "loss": 0.2606,
      "step": 9010
    },
    {
      "epoch": 9.02,
      "learning_rate": 0.00014933988925940753,
      "loss": 0.2706,
      "step": 9020
    },
    {
      "epoch": 9.03,
      "learning_rate": 0.00014933660180379923,
      "loss": 0.2595,
      "step": 9030
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.00014933330621885193,
      "loss": 0.2269,
      "step": 9040
    },
    {
      "epoch": 9.05,
      "learning_rate": 0.00014933000250492602,
      "loss": 0.2978,
      "step": 9050
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.00014932669066238278,
      "loss": 0.2612,
      "step": 9060
    },
    {
      "epoch": 9.07,
      "learning_rate": 0.00014932337069158442,
      "loss": 0.2326,
      "step": 9070
    },
    {
      "epoch": 9.08,
      "learning_rate": 0.00014932004259289396,
      "loss": 0.2768,
      "step": 9080
    },
    {
      "epoch": 9.09,
      "learning_rate": 0.0001493167063666754,
      "loss": 0.243,
      "step": 9090
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.00014931336201329354,
      "loss": 0.2594,
      "step": 9100
    },
    {
      "epoch": 9.11,
      "learning_rate": 0.00014931000953311417,
      "loss": 0.3257,
      "step": 9110
    },
    {
      "epoch": 9.12,
      "learning_rate": 0.00014930664892650385,
      "loss": 0.2346,
      "step": 9120
    },
    {
      "epoch": 9.13,
      "learning_rate": 0.00014930328019383015,
      "loss": 0.2786,
      "step": 9130
    },
    {
      "epoch": 9.14,
      "learning_rate": 0.00014929990333546143,
      "loss": 0.2992,
      "step": 9140
    },
    {
      "epoch": 9.15,
      "learning_rate": 0.000149296518351767,
      "loss": 0.2265,
      "step": 9150
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.000149293125243117,
      "loss": 0.4163,
      "step": 9160
    },
    {
      "epoch": 9.17,
      "learning_rate": 0.00014928972400988255,
      "loss": 0.3035,
      "step": 9170
    },
    {
      "epoch": 9.18,
      "learning_rate": 0.00014928631465243556,
      "loss": 0.2691,
      "step": 9180
    },
    {
      "epoch": 9.19,
      "learning_rate": 0.00014928289717114888,
      "loss": 0.3185,
      "step": 9190
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.00014927947156639625,
      "loss": 0.3231,
      "step": 9200
    },
    {
      "epoch": 9.21,
      "learning_rate": 0.0001492760378385523,
      "loss": 0.3062,
      "step": 9210
    },
    {
      "epoch": 9.22,
      "learning_rate": 0.0001492725959879925,
      "loss": 0.2905,
      "step": 9220
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.0001492691460150933,
      "loss": 0.2458,
      "step": 9230
    },
    {
      "epoch": 9.24,
      "learning_rate": 0.00014926568792023194,
      "loss": 0.3176,
      "step": 9240
    },
    {
      "epoch": 9.25,
      "learning_rate": 0.00014926222170378662,
      "loss": 0.2943,
      "step": 9250
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.00014925874736613636,
      "loss": 0.4772,
      "step": 9260
    },
    {
      "epoch": 9.27,
      "learning_rate": 0.00014925526490766115,
      "loss": 1.0193,
      "step": 9270
    },
    {
      "epoch": 9.28,
      "learning_rate": 0.0001492517743287418,
      "loss": 0.5561,
      "step": 9280
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.00014924862586505015,
      "loss": 0.3171,
      "step": 9290
    },
    {
      "epoch": 9.3,
      "learning_rate": 0.00014924547082438683,
      "loss": 0.4306,
      "step": 9300
    },
    {
      "epoch": 9.31,
      "learning_rate": 0.00014924195751025751,
      "loss": 0.22,
      "step": 9310
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.00014923843607713937,
      "loss": 0.2746,
      "step": 9320
    },
    {
      "epoch": 9.33,
      "learning_rate": 0.00014923490652541746,
      "loss": 0.2236,
      "step": 9330
    },
    {
      "epoch": 9.34,
      "learning_rate": 0.0001492313688554778,
      "loss": 0.2083,
      "step": 9340
    },
    {
      "epoch": 9.35,
      "learning_rate": 0.00014922782306770724,
      "loss": 0.3991,
      "step": 9350
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.00014922426916249356,
      "loss": 0.2975,
      "step": 9360
    },
    {
      "epoch": 9.37,
      "learning_rate": 0.00014922070714022537,
      "loss": 0.2782,
      "step": 9370
    },
    {
      "epoch": 9.38,
      "learning_rate": 0.00014921713700129227,
      "loss": 0.2455,
      "step": 9380
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.00014921355874608462,
      "loss": 0.3012,
      "step": 9390
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.00014920997237499378,
      "loss": 0.2992,
      "step": 9400
    },
    {
      "epoch": 9.41,
      "learning_rate": 0.00014920637788841195,
      "loss": 0.2687,
      "step": 9410
    },
    {
      "epoch": 9.42,
      "learning_rate": 0.0001492027752867322,
      "loss": 0.2606,
      "step": 9420
    },
    {
      "epoch": 9.43,
      "learning_rate": 0.00014919916457034848,
      "loss": 0.2701,
      "step": 9430
    },
    {
      "epoch": 9.44,
      "learning_rate": 0.0001491955457396557,
      "loss": 0.3203,
      "step": 9440
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.00014919191879504955,
      "loss": 0.2853,
      "step": 9450
    },
    {
      "epoch": 9.46,
      "learning_rate": 0.00014918828373692674,
      "loss": 0.2746,
      "step": 9460
    },
    {
      "epoch": 9.47,
      "learning_rate": 0.00014918464056568476,
      "loss": 0.2421,
      "step": 9470
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.00014918098928172203,
      "loss": 0.2942,
      "step": 9480
    },
    {
      "epoch": 9.49,
      "learning_rate": 0.00014917732988543785,
      "loss": 0.2526,
      "step": 9490
    },
    {
      "epoch": 9.5,
      "learning_rate": 0.00014917366237723236,
      "loss": 0.2261,
      "step": 9500
    },
    {
      "epoch": 9.51,
      "learning_rate": 0.0001491699867575067,
      "loss": 0.3044,
      "step": 9510
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.0001491663030266628,
      "loss": 0.2554,
      "step": 9520
    },
    {
      "epoch": 9.53,
      "learning_rate": 0.0001491626111851035,
      "loss": 0.2974,
      "step": 9530
    },
    {
      "epoch": 9.54,
      "learning_rate": 0.00014915891123323254,
      "loss": 0.2605,
      "step": 9540
    },
    {
      "epoch": 9.55,
      "learning_rate": 0.00014915520317145453,
      "loss": 0.263,
      "step": 9550
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.00014915148700017503,
      "loss": 0.2593,
      "step": 9560
    },
    {
      "epoch": 9.57,
      "learning_rate": 0.00014914776271980038,
      "loss": 0.2717,
      "step": 9570
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.00014914403033073787,
      "loss": 0.2573,
      "step": 9580
    },
    {
      "epoch": 9.59,
      "learning_rate": 0.00014914028983339567,
      "loss": 0.3418,
      "step": 9590
    },
    {
      "epoch": 9.6,
      "learning_rate": 0.00014913654122818287,
      "loss": 0.3176,
      "step": 9600
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.00014913278451550934,
      "loss": 0.246,
      "step": 9610
    },
    {
      "epoch": 9.62,
      "learning_rate": 0.000149129019695786,
      "loss": 0.3189,
      "step": 9620
    },
    {
      "epoch": 9.63,
      "learning_rate": 0.0001491252467694245,
      "loss": 0.2666,
      "step": 9630
    },
    {
      "epoch": 9.64,
      "learning_rate": 0.00014912146573683744,
      "loss": 0.3252,
      "step": 9640
    },
    {
      "epoch": 9.65,
      "learning_rate": 0.00014911767659843834,
      "loss": 0.2743,
      "step": 9650
    },
    {
      "epoch": 9.66,
      "learning_rate": 0.00014911387935464157,
      "loss": 0.24,
      "step": 9660
    },
    {
      "epoch": 9.67,
      "learning_rate": 0.00014911007400586238,
      "loss": 0.3774,
      "step": 9670
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.00014910626055251693,
      "loss": 0.3535,
      "step": 9680
    },
    {
      "epoch": 9.69,
      "learning_rate": 0.00014910243899502222,
      "loss": 0.2651,
      "step": 9690
    },
    {
      "epoch": 9.7,
      "learning_rate": 0.0001490986093337962,
      "loss": 0.2604,
      "step": 9700
    },
    {
      "epoch": 9.71,
      "learning_rate": 0.00014909477156925766,
      "loss": 0.278,
      "step": 9710
    },
    {
      "epoch": 9.72,
      "learning_rate": 0.0001490909257018263,
      "loss": 0.2611,
      "step": 9720
    },
    {
      "epoch": 9.73,
      "learning_rate": 0.00014908707173192273,
      "loss": 0.2358,
      "step": 9730
    },
    {
      "epoch": 9.74,
      "learning_rate": 0.00014908320965996836,
      "loss": 0.2802,
      "step": 9740
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.00014907933948638558,
      "loss": 0.3041,
      "step": 9750
    },
    {
      "epoch": 9.76,
      "learning_rate": 0.0001490754612115976,
      "loss": 0.2868,
      "step": 9760
    },
    {
      "epoch": 9.77,
      "learning_rate": 0.00014907157483602855,
      "loss": 0.2087,
      "step": 9770
    },
    {
      "epoch": 9.78,
      "learning_rate": 0.00014906768036010345,
      "loss": 0.338,
      "step": 9780
    },
    {
      "epoch": 9.79,
      "learning_rate": 0.00014906377778424817,
      "loss": 0.3473,
      "step": 9790
    },
    {
      "epoch": 9.8,
      "learning_rate": 0.00014905986710888952,
      "loss": 0.2761,
      "step": 9800
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.00014905594833445511,
      "loss": 0.1858,
      "step": 9810
    },
    {
      "epoch": 9.82,
      "learning_rate": 0.00014905202146137358,
      "loss": 0.2939,
      "step": 9820
    },
    {
      "epoch": 9.83,
      "learning_rate": 0.0001490480864900743,
      "loss": 0.2447,
      "step": 9830
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.00014904414342098763,
      "loss": 0.2769,
      "step": 9840
    },
    {
      "epoch": 9.85,
      "learning_rate": 0.00014904019225454475,
      "loss": 0.2179,
      "step": 9850
    },
    {
      "epoch": 9.86,
      "learning_rate": 0.00014903623299117774,
      "loss": 0.322,
      "step": 9860
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.00014903226563131963,
      "loss": 0.2521,
      "step": 9870
    },
    {
      "epoch": 9.88,
      "learning_rate": 0.00014902829017540424,
      "loss": 0.28,
      "step": 9880
    },
    {
      "epoch": 9.89,
      "learning_rate": 0.00014902430662386634,
      "loss": 0.3226,
      "step": 9890
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.00014902031497714157,
      "loss": 0.3203,
      "step": 9900
    },
    {
      "epoch": 9.91,
      "learning_rate": 0.00014901631523566643,
      "loss": 0.2513,
      "step": 9910
    },
    {
      "epoch": 9.92,
      "learning_rate": 0.00014901230739987833,
      "loss": 0.2204,
      "step": 9920
    },
    {
      "epoch": 9.93,
      "learning_rate": 0.0001490082914702156,
      "loss": 0.3806,
      "step": 9930
    },
    {
      "epoch": 9.94,
      "learning_rate": 0.00014900426744711735,
      "loss": 0.2477,
      "step": 9940
    },
    {
      "epoch": 9.95,
      "learning_rate": 0.0001490002353310237,
      "loss": 0.4033,
      "step": 9950
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.00014899619512237557,
      "loss": 0.308,
      "step": 9960
    },
    {
      "epoch": 9.97,
      "learning_rate": 0.0001489921468216148,
      "loss": 0.261,
      "step": 9970
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.00014898809042918407,
      "loss": 0.2407,
      "step": 9980
    },
    {
      "epoch": 9.99,
      "learning_rate": 0.000148984025945527,
      "loss": 0.2746,
      "step": 9990
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.00014897995337108814,
      "loss": 0.3248,
      "step": 10000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2760428190231323,
      "eval_runtime": 15.0687,
      "eval_samples_per_second": 132.725,
      "eval_steps_per_second": 16.591,
      "step": 10000
    },
    {
      "epoch": 10.01,
      "learning_rate": 0.00014897587270631276,
      "loss": 0.3107,
      "step": 10010
    },
    {
      "epoch": 10.02,
      "learning_rate": 0.00014897178395164716,
      "loss": 0.3223,
      "step": 10020
    },
    {
      "epoch": 10.03,
      "learning_rate": 0.00014896768710753852,
      "loss": 0.2318,
      "step": 10030
    },
    {
      "epoch": 10.04,
      "learning_rate": 0.0001489635821744348,
      "loss": 0.2169,
      "step": 10040
    },
    {
      "epoch": 10.05,
      "learning_rate": 0.00014895946915278495,
      "loss": 0.265,
      "step": 10050
    },
    {
      "epoch": 10.06,
      "learning_rate": 0.00014895534804303877,
      "loss": 0.3643,
      "step": 10060
    },
    {
      "epoch": 10.07,
      "learning_rate": 0.00014895121884564688,
      "loss": 0.3216,
      "step": 10070
    },
    {
      "epoch": 10.08,
      "learning_rate": 0.00014894708156106088,
      "loss": 0.2971,
      "step": 10080
    },
    {
      "epoch": 10.09,
      "learning_rate": 0.00014894293618973324,
      "loss": 0.2877,
      "step": 10090
    },
    {
      "epoch": 10.1,
      "learning_rate": 0.00014893878273211726,
      "loss": 0.2526,
      "step": 10100
    },
    {
      "epoch": 10.11,
      "learning_rate": 0.00014893462118866716,
      "loss": 0.2448,
      "step": 10110
    },
    {
      "epoch": 10.12,
      "learning_rate": 0.00014893045155983805,
      "loss": 0.2457,
      "step": 10120
    },
    {
      "epoch": 10.13,
      "learning_rate": 0.0001489262738460859,
      "loss": 0.3637,
      "step": 10130
    },
    {
      "epoch": 10.14,
      "learning_rate": 0.00014892208804786762,
      "loss": 0.225,
      "step": 10140
    },
    {
      "epoch": 10.15,
      "learning_rate": 0.00014891789416564093,
      "loss": 0.2495,
      "step": 10150
    },
    {
      "epoch": 10.16,
      "learning_rate": 0.00014891369219986443,
      "loss": 0.2929,
      "step": 10160
    },
    {
      "epoch": 10.17,
      "learning_rate": 0.0001489094821509977,
      "loss": 0.3243,
      "step": 10170
    },
    {
      "epoch": 10.18,
      "learning_rate": 0.00014890526401950112,
      "loss": 0.2099,
      "step": 10180
    },
    {
      "epoch": 10.19,
      "learning_rate": 0.000148901037805836,
      "loss": 0.2524,
      "step": 10190
    },
    {
      "epoch": 10.2,
      "learning_rate": 0.00014889680351046447,
      "loss": 0.2612,
      "step": 10200
    },
    {
      "epoch": 10.21,
      "learning_rate": 0.00014889256113384961,
      "loss": 0.3386,
      "step": 10210
    },
    {
      "epoch": 10.22,
      "learning_rate": 0.0001488883106764554,
      "loss": 0.295,
      "step": 10220
    },
    {
      "epoch": 10.23,
      "learning_rate": 0.00014888405213874656,
      "loss": 0.3327,
      "step": 10230
    },
    {
      "epoch": 10.24,
      "learning_rate": 0.0001488797855211889,
      "loss": 0.2107,
      "step": 10240
    },
    {
      "epoch": 10.25,
      "learning_rate": 0.00014887551082424898,
      "loss": 0.255,
      "step": 10250
    },
    {
      "epoch": 10.26,
      "learning_rate": 0.00014887122804839426,
      "loss": 0.2778,
      "step": 10260
    },
    {
      "epoch": 10.27,
      "learning_rate": 0.00014886693719409308,
      "loss": 0.2859,
      "step": 10270
    },
    {
      "epoch": 10.28,
      "learning_rate": 0.00014886263826181472,
      "loss": 0.2877,
      "step": 10280
    },
    {
      "epoch": 10.29,
      "learning_rate": 0.0001488583312520293,
      "loss": 0.2258,
      "step": 10290
    },
    {
      "epoch": 10.3,
      "learning_rate": 0.0001488540161652078,
      "loss": 0.3594,
      "step": 10300
    },
    {
      "epoch": 10.31,
      "learning_rate": 0.00014884969300182216,
      "loss": 0.2792,
      "step": 10310
    },
    {
      "epoch": 10.32,
      "learning_rate": 0.00014884536176234509,
      "loss": 0.2862,
      "step": 10320
    },
    {
      "epoch": 10.33,
      "learning_rate": 0.0001488410224472503,
      "loss": 0.2431,
      "step": 10330
    },
    {
      "epoch": 10.34,
      "learning_rate": 0.0001488366750570123,
      "loss": 0.3086,
      "step": 10340
    },
    {
      "epoch": 10.35,
      "learning_rate": 0.00014883231959210655,
      "loss": 0.2782,
      "step": 10350
    },
    {
      "epoch": 10.36,
      "learning_rate": 0.00014882795605300933,
      "loss": 0.2693,
      "step": 10360
    },
    {
      "epoch": 10.37,
      "learning_rate": 0.00014882358444019784,
      "loss": 0.3181,
      "step": 10370
    },
    {
      "epoch": 10.38,
      "learning_rate": 0.00014881920475415014,
      "loss": 0.294,
      "step": 10380
    },
    {
      "epoch": 10.39,
      "learning_rate": 0.0001488148169953452,
      "loss": 0.3057,
      "step": 10390
    },
    {
      "epoch": 10.4,
      "learning_rate": 0.00014881042116426281,
      "loss": 0.2441,
      "step": 10400
    },
    {
      "epoch": 10.41,
      "learning_rate": 0.00014880601726138378,
      "loss": 0.2602,
      "step": 10410
    },
    {
      "epoch": 10.42,
      "learning_rate": 0.00014880160528718967,
      "loss": 0.3036,
      "step": 10420
    },
    {
      "epoch": 10.43,
      "learning_rate": 0.00014879718524216294,
      "loss": 0.2941,
      "step": 10430
    },
    {
      "epoch": 10.44,
      "learning_rate": 0.000148792757126787,
      "loss": 0.2596,
      "step": 10440
    },
    {
      "epoch": 10.45,
      "learning_rate": 0.00014878832094154608,
      "loss": 0.3226,
      "step": 10450
    },
    {
      "epoch": 10.46,
      "learning_rate": 0.0001487838766869253,
      "loss": 0.2092,
      "step": 10460
    },
    {
      "epoch": 10.47,
      "learning_rate": 0.00014877942436341074,
      "loss": 0.2334,
      "step": 10470
    },
    {
      "epoch": 10.48,
      "learning_rate": 0.00014877496397148923,
      "loss": 0.2956,
      "step": 10480
    },
    {
      "epoch": 10.49,
      "learning_rate": 0.00014877049551164859,
      "loss": 0.2342,
      "step": 10490
    },
    {
      "epoch": 10.5,
      "learning_rate": 0.00014876601898437746,
      "loss": 0.2326,
      "step": 10500
    },
    {
      "epoch": 10.51,
      "learning_rate": 0.00014876153439016541,
      "loss": 0.2813,
      "step": 10510
    },
    {
      "epoch": 10.52,
      "learning_rate": 0.00014875704172950287,
      "loss": 0.258,
      "step": 10520
    },
    {
      "epoch": 10.53,
      "learning_rate": 0.00014875254100288113,
      "loss": 0.305,
      "step": 10530
    },
    {
      "epoch": 10.54,
      "learning_rate": 0.0001487480322107924,
      "loss": 0.327,
      "step": 10540
    },
    {
      "epoch": 10.55,
      "learning_rate": 0.0001487435153537297,
      "loss": 0.2708,
      "step": 10550
    },
    {
      "epoch": 10.56,
      "learning_rate": 0.00014873899043218707,
      "loss": 0.2596,
      "step": 10560
    },
    {
      "epoch": 10.57,
      "learning_rate": 0.0001487344574466593,
      "loss": 0.2655,
      "step": 10570
    },
    {
      "epoch": 10.58,
      "learning_rate": 0.00014872991639764213,
      "loss": 0.3118,
      "step": 10580
    },
    {
      "epoch": 10.59,
      "learning_rate": 0.00014872536728563216,
      "loss": 0.2527,
      "step": 10590
    },
    {
      "epoch": 10.6,
      "learning_rate": 0.00014872081011112683,
      "loss": 0.2344,
      "step": 10600
    },
    {
      "epoch": 10.61,
      "learning_rate": 0.00014871624487462458,
      "loss": 0.2256,
      "step": 10610
    },
    {
      "epoch": 10.62,
      "learning_rate": 0.00014871167157662463,
      "loss": 0.2179,
      "step": 10620
    },
    {
      "epoch": 10.63,
      "learning_rate": 0.00014870709021762708,
      "loss": 0.2964,
      "step": 10630
    },
    {
      "epoch": 10.64,
      "learning_rate": 0.00014870250079813298,
      "loss": 0.3302,
      "step": 10640
    },
    {
      "epoch": 10.65,
      "learning_rate": 0.00014869790331864419,
      "loss": 0.1621,
      "step": 10650
    },
    {
      "epoch": 10.66,
      "learning_rate": 0.00014869329777966348,
      "loss": 0.3106,
      "step": 10660
    },
    {
      "epoch": 10.67,
      "learning_rate": 0.00014868868418169455,
      "loss": 0.3285,
      "step": 10670
    },
    {
      "epoch": 10.68,
      "learning_rate": 0.00014868406252524188,
      "loss": 0.3701,
      "step": 10680
    },
    {
      "epoch": 10.69,
      "learning_rate": 0.00014867943281081093,
      "loss": 0.2833,
      "step": 10690
    },
    {
      "epoch": 10.7,
      "learning_rate": 0.00014867479503890798,
      "loss": 0.2871,
      "step": 10700
    },
    {
      "epoch": 10.71,
      "learning_rate": 0.00014867014921004024,
      "loss": 0.2915,
      "step": 10710
    },
    {
      "epoch": 10.72,
      "learning_rate": 0.0001486654953247157,
      "loss": 0.2469,
      "step": 10720
    },
    {
      "epoch": 10.73,
      "learning_rate": 0.00014866083338344337,
      "loss": 0.3702,
      "step": 10730
    },
    {
      "epoch": 10.74,
      "learning_rate": 0.000148656163386733,
      "loss": 0.2816,
      "step": 10740
    },
    {
      "epoch": 10.75,
      "learning_rate": 0.00014865148533509543,
      "loss": 0.3046,
      "step": 10750
    },
    {
      "epoch": 10.76,
      "learning_rate": 0.00014864679922904208,
      "loss": 0.2657,
      "step": 10760
    },
    {
      "epoch": 10.77,
      "learning_rate": 0.00014864210506908556,
      "loss": 0.2509,
      "step": 10770
    },
    {
      "epoch": 10.78,
      "learning_rate": 0.00014863740285573908,
      "loss": 0.2544,
      "step": 10780
    },
    {
      "epoch": 10.79,
      "learning_rate": 0.00014863269258951698,
      "loss": 0.2773,
      "step": 10790
    },
    {
      "epoch": 10.8,
      "learning_rate": 0.00014862797427093433,
      "loss": 0.2781,
      "step": 10800
    },
    {
      "epoch": 10.81,
      "learning_rate": 0.00014862324790050708,
      "loss": 0.338,
      "step": 10810
    },
    {
      "epoch": 10.82,
      "learning_rate": 0.00014861851347875213,
      "loss": 0.3128,
      "step": 10820
    },
    {
      "epoch": 10.83,
      "learning_rate": 0.00014861377100618725,
      "loss": 0.3739,
      "step": 10830
    },
    {
      "epoch": 10.84,
      "learning_rate": 0.00014860902048333105,
      "loss": 0.2523,
      "step": 10840
    },
    {
      "epoch": 10.85,
      "learning_rate": 0.00014860426191070302,
      "loss": 0.2764,
      "step": 10850
    },
    {
      "epoch": 10.86,
      "learning_rate": 0.0001485994952888236,
      "loss": 0.2655,
      "step": 10860
    },
    {
      "epoch": 10.87,
      "learning_rate": 0.000148594720618214,
      "loss": 0.2398,
      "step": 10870
    },
    {
      "epoch": 10.88,
      "learning_rate": 0.0001485899378993964,
      "loss": 0.2538,
      "step": 10880
    },
    {
      "epoch": 10.89,
      "learning_rate": 0.00014858514713289388,
      "loss": 0.2821,
      "step": 10890
    },
    {
      "epoch": 10.9,
      "learning_rate": 0.00014858034831923027,
      "loss": 0.2797,
      "step": 10900
    },
    {
      "epoch": 10.91,
      "learning_rate": 0.00014857554145893037,
      "loss": 0.2868,
      "step": 10910
    },
    {
      "epoch": 10.92,
      "learning_rate": 0.0001485707265525199,
      "loss": 0.2993,
      "step": 10920
    },
    {
      "epoch": 10.93,
      "learning_rate": 0.0001485659036005254,
      "loss": 0.2864,
      "step": 10930
    },
    {
      "epoch": 10.94,
      "learning_rate": 0.00014856107260347427,
      "loss": 0.2949,
      "step": 10940
    },
    {
      "epoch": 10.95,
      "learning_rate": 0.00014855623356189483,
      "loss": 0.2589,
      "step": 10950
    },
    {
      "epoch": 10.96,
      "learning_rate": 0.0001485513864763163,
      "loss": 0.2754,
      "step": 10960
    },
    {
      "epoch": 10.97,
      "learning_rate": 0.0001485465313472687,
      "loss": 0.2837,
      "step": 10970
    },
    {
      "epoch": 10.98,
      "learning_rate": 0.00014854166817528303,
      "loss": 0.2681,
      "step": 10980
    },
    {
      "epoch": 10.99,
      "learning_rate": 0.0001485367969608911,
      "loss": 0.2801,
      "step": 10990
    },
    {
      "epoch": 11.0,
      "learning_rate": 0.0001485319177046256,
      "loss": 0.341,
      "step": 11000
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27402862906455994,
      "eval_runtime": 14.9304,
      "eval_samples_per_second": 133.955,
      "eval_steps_per_second": 16.744,
      "step": 11000
    },
    {
      "epoch": 11.01,
      "learning_rate": 0.00014852703040702013,
      "loss": 0.2832,
      "step": 11010
    },
    {
      "epoch": 11.02,
      "learning_rate": 0.00014852213506860918,
      "loss": 0.3575,
      "step": 11020
    },
    {
      "epoch": 11.03,
      "learning_rate": 0.00014851723168992807,
      "loss": 0.3368,
      "step": 11030
    },
    {
      "epoch": 11.04,
      "learning_rate": 0.00014851232027151304,
      "loss": 0.275,
      "step": 11040
    },
    {
      "epoch": 11.05,
      "learning_rate": 0.00014850740081390117,
      "loss": 0.2866,
      "step": 11050
    },
    {
      "epoch": 11.06,
      "learning_rate": 0.00014850247331763046,
      "loss": 0.3054,
      "step": 11060
    },
    {
      "epoch": 11.07,
      "learning_rate": 0.0001484975377832398,
      "loss": 0.3021,
      "step": 11070
    },
    {
      "epoch": 11.08,
      "learning_rate": 0.00014849259421126888,
      "loss": 0.3094,
      "step": 11080
    },
    {
      "epoch": 11.09,
      "learning_rate": 0.0001484876426022584,
      "loss": 0.2893,
      "step": 11090
    },
    {
      "epoch": 11.1,
      "learning_rate": 0.0001484826829567498,
      "loss": 0.2197,
      "step": 11100
    },
    {
      "epoch": 11.11,
      "learning_rate": 0.00014847771527528545,
      "loss": 0.2696,
      "step": 11110
    },
    {
      "epoch": 11.12,
      "learning_rate": 0.00014847273955840862,
      "loss": 0.2224,
      "step": 11120
    },
    {
      "epoch": 11.13,
      "learning_rate": 0.00014846775580666348,
      "loss": 0.3065,
      "step": 11130
    },
    {
      "epoch": 11.14,
      "learning_rate": 0.000148462764020595,
      "loss": 0.2181,
      "step": 11140
    },
    {
      "epoch": 11.15,
      "learning_rate": 0.00014845776420074913,
      "loss": 0.2558,
      "step": 11150
    },
    {
      "epoch": 11.16,
      "learning_rate": 0.00014845275634767257,
      "loss": 0.3091,
      "step": 11160
    },
    {
      "epoch": 11.17,
      "learning_rate": 0.00014844774046191304,
      "loss": 0.2523,
      "step": 11170
    },
    {
      "epoch": 11.18,
      "learning_rate": 0.00014844271654401904,
      "loss": 0.2855,
      "step": 11180
    },
    {
      "epoch": 11.19,
      "learning_rate": 0.00014843768459453995,
      "loss": 0.3121,
      "step": 11190
    },
    {
      "epoch": 11.2,
      "learning_rate": 0.0001484326446140261,
      "loss": 0.3144,
      "step": 11200
    },
    {
      "epoch": 11.21,
      "learning_rate": 0.00014842759660302866,
      "loss": 0.2719,
      "step": 11210
    },
    {
      "epoch": 11.22,
      "learning_rate": 0.00014842254056209964,
      "loss": 0.2331,
      "step": 11220
    },
    {
      "epoch": 11.23,
      "learning_rate": 0.00014841747649179196,
      "loss": 0.2677,
      "step": 11230
    },
    {
      "epoch": 11.24,
      "learning_rate": 0.00014841240439265944,
      "loss": 0.2632,
      "step": 11240
    },
    {
      "epoch": 11.25,
      "learning_rate": 0.00014840732426525677,
      "loss": 0.2654,
      "step": 11250
    },
    {
      "epoch": 11.26,
      "learning_rate": 0.00014840223611013945,
      "loss": 0.2896,
      "step": 11260
    },
    {
      "epoch": 11.27,
      "learning_rate": 0.00014839713992786393,
      "loss": 0.3032,
      "step": 11270
    },
    {
      "epoch": 11.28,
      "learning_rate": 0.00014839203571898757,
      "loss": 0.2945,
      "step": 11280
    },
    {
      "epoch": 11.29,
      "learning_rate": 0.00014838692348406857,
      "loss": 0.2781,
      "step": 11290
    },
    {
      "epoch": 11.3,
      "learning_rate": 0.00014838180322366588,
      "loss": 0.2036,
      "step": 11300
    },
    {
      "epoch": 11.31,
      "learning_rate": 0.00014837667493833957,
      "loss": 0.2248,
      "step": 11310
    },
    {
      "epoch": 11.32,
      "learning_rate": 0.00014837153862865037,
      "loss": 0.2268,
      "step": 11320
    },
    {
      "epoch": 11.33,
      "learning_rate": 0.00014836639429516003,
      "loss": 0.2496,
      "step": 11330
    },
    {
      "epoch": 11.34,
      "learning_rate": 0.00014836124193843113,
      "loss": 0.299,
      "step": 11340
    },
    {
      "epoch": 11.35,
      "learning_rate": 0.0001483560815590271,
      "loss": 0.2761,
      "step": 11350
    },
    {
      "epoch": 11.36,
      "learning_rate": 0.00014835091315751228,
      "loss": 0.3153,
      "step": 11360
    },
    {
      "epoch": 11.37,
      "learning_rate": 0.00014834573673445188,
      "loss": 0.2159,
      "step": 11370
    },
    {
      "epoch": 11.38,
      "learning_rate": 0.00014834055229041198,
      "loss": 0.1904,
      "step": 11380
    },
    {
      "epoch": 11.39,
      "learning_rate": 0.00014833535982595954,
      "loss": 0.338,
      "step": 11390
    },
    {
      "epoch": 11.4,
      "learning_rate": 0.0001483301593416624,
      "loss": 0.2564,
      "step": 11400
    },
    {
      "epoch": 11.41,
      "learning_rate": 0.00014832495083808933,
      "loss": 0.3302,
      "step": 11410
    },
    {
      "epoch": 11.42,
      "learning_rate": 0.00014831973431580985,
      "loss": 0.2866,
      "step": 11420
    },
    {
      "epoch": 11.43,
      "learning_rate": 0.00014831450977539445,
      "loss": 0.2429,
      "step": 11430
    },
    {
      "epoch": 11.44,
      "learning_rate": 0.0001483092772174145,
      "loss": 0.2382,
      "step": 11440
    },
    {
      "epoch": 11.45,
      "learning_rate": 0.0001483040366424422,
      "loss": 0.2415,
      "step": 11450
    },
    {
      "epoch": 11.46,
      "learning_rate": 0.00014829878805105068,
      "loss": 0.2294,
      "step": 11460
    },
    {
      "epoch": 11.47,
      "learning_rate": 0.0001482935314438139,
      "loss": 0.2676,
      "step": 11470
    },
    {
      "epoch": 11.48,
      "learning_rate": 0.00014828826682130672,
      "loss": 0.3399,
      "step": 11480
    },
    {
      "epoch": 11.49,
      "learning_rate": 0.00014828299418410485,
      "loss": 0.3775,
      "step": 11490
    },
    {
      "epoch": 11.5,
      "learning_rate": 0.0001482777135327849,
      "loss": 0.2831,
      "step": 11500
    },
    {
      "epoch": 11.51,
      "learning_rate": 0.00014827242486792442,
      "loss": 0.2479,
      "step": 11510
    },
    {
      "epoch": 11.52,
      "learning_rate": 0.0001482671281901017,
      "loss": 0.3431,
      "step": 11520
    },
    {
      "epoch": 11.53,
      "learning_rate": 0.00014826182349989597,
      "loss": 0.3724,
      "step": 11530
    },
    {
      "epoch": 11.54,
      "learning_rate": 0.0001482565107978874,
      "loss": 0.2153,
      "step": 11540
    },
    {
      "epoch": 11.55,
      "learning_rate": 0.00014825119008465693,
      "loss": 0.3445,
      "step": 11550
    },
    {
      "epoch": 11.56,
      "learning_rate": 0.00014824586136078646,
      "loss": 0.3244,
      "step": 11560
    },
    {
      "epoch": 11.57,
      "learning_rate": 0.0001482405246268587,
      "loss": 0.3583,
      "step": 11570
    },
    {
      "epoch": 11.58,
      "learning_rate": 0.0001482351798834573,
      "loss": 0.2525,
      "step": 11580
    },
    {
      "epoch": 11.59,
      "learning_rate": 0.00014822982713116675,
      "loss": 0.2166,
      "step": 11590
    },
    {
      "epoch": 11.6,
      "learning_rate": 0.00014822446637057236,
      "loss": 0.3128,
      "step": 11600
    },
    {
      "epoch": 11.61,
      "learning_rate": 0.00014821909760226045,
      "loss": 0.3117,
      "step": 11610
    },
    {
      "epoch": 11.62,
      "learning_rate": 0.00014821372082681806,
      "loss": 0.2794,
      "step": 11620
    },
    {
      "epoch": 11.63,
      "learning_rate": 0.0001482083360448333,
      "loss": 0.2609,
      "step": 11630
    },
    {
      "epoch": 11.64,
      "learning_rate": 0.00014820294325689496,
      "loss": 0.3043,
      "step": 11640
    },
    {
      "epoch": 11.65,
      "learning_rate": 0.00014819754246359277,
      "loss": 0.3046,
      "step": 11650
    },
    {
      "epoch": 11.66,
      "learning_rate": 0.0001481921336655174,
      "loss": 0.2683,
      "step": 11660
    },
    {
      "epoch": 11.67,
      "learning_rate": 0.00014818671686326037,
      "loss": 0.3182,
      "step": 11670
    },
    {
      "epoch": 11.68,
      "learning_rate": 0.000148181292057414,
      "loss": 0.3487,
      "step": 11680
    },
    {
      "epoch": 11.69,
      "learning_rate": 0.00014817585924857156,
      "loss": 0.2142,
      "step": 11690
    },
    {
      "epoch": 11.7,
      "learning_rate": 0.00014817041843732717,
      "loss": 0.317,
      "step": 11700
    },
    {
      "epoch": 11.71,
      "learning_rate": 0.0001481649696242758,
      "loss": 0.2629,
      "step": 11710
    },
    {
      "epoch": 11.72,
      "learning_rate": 0.0001481595128100134,
      "loss": 0.3337,
      "step": 11720
    },
    {
      "epoch": 11.73,
      "learning_rate": 0.00014815404799513665,
      "loss": 0.2655,
      "step": 11730
    },
    {
      "epoch": 11.74,
      "learning_rate": 0.0001481485751802432,
      "loss": 0.3445,
      "step": 11740
    },
    {
      "epoch": 11.75,
      "learning_rate": 0.00014814309436593154,
      "loss": 0.2469,
      "step": 11750
    },
    {
      "epoch": 11.76,
      "learning_rate": 0.00014813760555280105,
      "loss": 0.2796,
      "step": 11760
    },
    {
      "epoch": 11.77,
      "learning_rate": 0.00014813210874145197,
      "loss": 0.3495,
      "step": 11770
    },
    {
      "epoch": 11.78,
      "learning_rate": 0.00014812660393248543,
      "loss": 0.3299,
      "step": 11780
    },
    {
      "epoch": 11.79,
      "learning_rate": 0.00014812109112650345,
      "loss": 0.2911,
      "step": 11790
    },
    {
      "epoch": 11.8,
      "learning_rate": 0.00014811557032410886,
      "loss": 0.2447,
      "step": 11800
    },
    {
      "epoch": 11.81,
      "learning_rate": 0.00014811004152590545,
      "loss": 0.2371,
      "step": 11810
    },
    {
      "epoch": 11.82,
      "learning_rate": 0.0001481045047324978,
      "loss": 0.3068,
      "step": 11820
    },
    {
      "epoch": 11.83,
      "learning_rate": 0.0001480989599444914,
      "loss": 0.2471,
      "step": 11830
    },
    {
      "epoch": 11.84,
      "learning_rate": 0.00014809340716249268,
      "loss": 0.2642,
      "step": 11840
    },
    {
      "epoch": 11.85,
      "learning_rate": 0.00014808784638710884,
      "loss": 0.2241,
      "step": 11850
    },
    {
      "epoch": 11.86,
      "learning_rate": 0.00014808227761894802,
      "loss": 0.2486,
      "step": 11860
    },
    {
      "epoch": 11.87,
      "learning_rate": 0.00014807670085861918,
      "loss": 0.3008,
      "step": 11870
    },
    {
      "epoch": 11.88,
      "learning_rate": 0.0001480711161067322,
      "loss": 0.3179,
      "step": 11880
    },
    {
      "epoch": 11.89,
      "learning_rate": 0.00014806552336389783,
      "loss": 0.3098,
      "step": 11890
    },
    {
      "epoch": 11.9,
      "learning_rate": 0.00014805992263072765,
      "loss": 0.2896,
      "step": 11900
    },
    {
      "epoch": 11.91,
      "learning_rate": 0.00014805431390783422,
      "loss": 0.2387,
      "step": 11910
    },
    {
      "epoch": 11.92,
      "learning_rate": 0.00014804869719583082,
      "loss": 0.2407,
      "step": 11920
    },
    {
      "epoch": 11.93,
      "learning_rate": 0.00014804307249533175,
      "loss": 0.306,
      "step": 11930
    },
    {
      "epoch": 11.94,
      "learning_rate": 0.00014803743980695207,
      "loss": 0.2794,
      "step": 11940
    },
    {
      "epoch": 11.95,
      "learning_rate": 0.00014803179913130778,
      "loss": 0.2263,
      "step": 11950
    },
    {
      "epoch": 11.96,
      "learning_rate": 0.00014802615046901577,
      "loss": 0.3039,
      "step": 11960
    },
    {
      "epoch": 11.97,
      "learning_rate": 0.0001480204938206937,
      "loss": 0.2933,
      "step": 11970
    },
    {
      "epoch": 11.98,
      "learning_rate": 0.00014801482918696022,
      "loss": 0.2657,
      "step": 11980
    },
    {
      "epoch": 11.99,
      "learning_rate": 0.0001480091565684348,
      "loss": 0.2012,
      "step": 11990
    },
    {
      "epoch": 12.0,
      "learning_rate": 0.0001480034759657378,
      "loss": 0.2536,
      "step": 12000
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2732619643211365,
      "eval_runtime": 15.1193,
      "eval_samples_per_second": 132.281,
      "eval_steps_per_second": 16.535,
      "step": 12000
    },
    {
      "epoch": 12.01,
      "learning_rate": 0.00014799778737949044,
      "loss": 0.2651,
      "step": 12010
    },
    {
      "epoch": 12.02,
      "learning_rate": 0.00014799209081031475,
      "loss": 0.3614,
      "step": 12020
    },
    {
      "epoch": 12.03,
      "learning_rate": 0.00014798638625883377,
      "loss": 0.2998,
      "step": 12030
    },
    {
      "epoch": 12.04,
      "learning_rate": 0.00014798067372567134,
      "loss": 0.2162,
      "step": 12040
    },
    {
      "epoch": 12.05,
      "learning_rate": 0.00014797495321145217,
      "loss": 0.3105,
      "step": 12050
    },
    {
      "epoch": 12.06,
      "learning_rate": 0.0001479692247168018,
      "loss": 0.291,
      "step": 12060
    },
    {
      "epoch": 12.07,
      "learning_rate": 0.0001479634882423467,
      "loss": 0.3435,
      "step": 12070
    },
    {
      "epoch": 12.08,
      "learning_rate": 0.0001479577437887143,
      "loss": 0.2604,
      "step": 12080
    },
    {
      "epoch": 12.09,
      "learning_rate": 0.00014795199135653268,
      "loss": 0.3204,
      "step": 12090
    },
    {
      "epoch": 12.1,
      "learning_rate": 0.00014794623094643096,
      "loss": 0.2675,
      "step": 12100
    },
    {
      "epoch": 12.11,
      "learning_rate": 0.0001479404625590391,
      "loss": 0.2067,
      "step": 12110
    },
    {
      "epoch": 12.12,
      "learning_rate": 0.00014793468619498797,
      "loss": 0.2427,
      "step": 12120
    },
    {
      "epoch": 12.13,
      "learning_rate": 0.00014792890185490916,
      "loss": 0.2693,
      "step": 12130
    },
    {
      "epoch": 12.14,
      "learning_rate": 0.0001479231095394353,
      "loss": 0.2656,
      "step": 12140
    },
    {
      "epoch": 12.15,
      "learning_rate": 0.0001479173092491998,
      "loss": 0.3251,
      "step": 12150
    },
    {
      "epoch": 12.16,
      "learning_rate": 0.00014791150098483703,
      "loss": 0.3373,
      "step": 12160
    },
    {
      "epoch": 12.17,
      "learning_rate": 0.00014790568474698214,
      "loss": 0.3239,
      "step": 12170
    },
    {
      "epoch": 12.18,
      "learning_rate": 0.00014789986053627115,
      "loss": 0.24,
      "step": 12180
    },
    {
      "epoch": 12.19,
      "learning_rate": 0.000147894028353341,
      "loss": 0.2641,
      "step": 12190
    },
    {
      "epoch": 12.2,
      "learning_rate": 0.00014788818819882953,
      "loss": 0.2868,
      "step": 12200
    },
    {
      "epoch": 12.21,
      "learning_rate": 0.0001478823400733754,
      "loss": 0.3025,
      "step": 12210
    },
    {
      "epoch": 12.22,
      "learning_rate": 0.0001478764839776181,
      "loss": 0.3299,
      "step": 12220
    },
    {
      "epoch": 12.23,
      "learning_rate": 0.0001478706199121981,
      "loss": 0.2964,
      "step": 12230
    },
    {
      "epoch": 12.24,
      "learning_rate": 0.00014786474787775665,
      "loss": 0.2175,
      "step": 12240
    },
    {
      "epoch": 12.25,
      "learning_rate": 0.00014785886787493593,
      "loss": 0.2939,
      "step": 12250
    },
    {
      "epoch": 12.26,
      "learning_rate": 0.00014785297990437896,
      "loss": 0.3033,
      "step": 12260
    },
    {
      "epoch": 12.27,
      "learning_rate": 0.00014784708396672964,
      "loss": 0.2349,
      "step": 12270
    },
    {
      "epoch": 12.28,
      "learning_rate": 0.00014784118006263276,
      "loss": 0.2518,
      "step": 12280
    },
    {
      "epoch": 12.29,
      "learning_rate": 0.00014783526819273391,
      "loss": 0.3032,
      "step": 12290
    },
    {
      "epoch": 12.3,
      "learning_rate": 0.00014782934835767965,
      "loss": 0.3247,
      "step": 12300
    },
    {
      "epoch": 12.31,
      "learning_rate": 0.00014782342055811738,
      "loss": 0.3033,
      "step": 12310
    },
    {
      "epoch": 12.32,
      "learning_rate": 0.00014781748479469528,
      "loss": 0.2968,
      "step": 12320
    },
    {
      "epoch": 12.33,
      "learning_rate": 0.00014781154106806256,
      "loss": 0.1909,
      "step": 12330
    },
    {
      "epoch": 12.34,
      "learning_rate": 0.00014780558937886918,
      "loss": 0.3211,
      "step": 12340
    },
    {
      "epoch": 12.35,
      "learning_rate": 0.00014779962972776597,
      "loss": 0.2175,
      "step": 12350
    },
    {
      "epoch": 12.36,
      "learning_rate": 0.00014779366211540473,
      "loss": 0.33,
      "step": 12360
    },
    {
      "epoch": 12.37,
      "learning_rate": 0.00014778768654243805,
      "loss": 0.2596,
      "step": 12370
    },
    {
      "epoch": 12.38,
      "learning_rate": 0.0001477817030095194,
      "loss": 0.2821,
      "step": 12380
    },
    {
      "epoch": 12.39,
      "learning_rate": 0.0001477757115173031,
      "loss": 0.3027,
      "step": 12390
    },
    {
      "epoch": 12.4,
      "learning_rate": 0.00014776971206644445,
      "loss": 0.2258,
      "step": 12400
    },
    {
      "epoch": 12.41,
      "learning_rate": 0.0001477637046575995,
      "loss": 0.2542,
      "step": 12410
    },
    {
      "epoch": 12.42,
      "learning_rate": 0.0001477576892914252,
      "loss": 0.2667,
      "step": 12420
    },
    {
      "epoch": 12.43,
      "learning_rate": 0.00014775166596857936,
      "loss": 0.2746,
      "step": 12430
    },
    {
      "epoch": 12.44,
      "learning_rate": 0.00014774563468972072,
      "loss": 0.2859,
      "step": 12440
    },
    {
      "epoch": 12.45,
      "learning_rate": 0.00014773959545550885,
      "loss": 0.2516,
      "step": 12450
    },
    {
      "epoch": 12.46,
      "learning_rate": 0.00014773354826660417,
      "loss": 0.2511,
      "step": 12460
    },
    {
      "epoch": 12.47,
      "learning_rate": 0.00014772749312366804,
      "loss": 0.2889,
      "step": 12470
    },
    {
      "epoch": 12.48,
      "learning_rate": 0.00014772143002736256,
      "loss": 0.3116,
      "step": 12480
    },
    {
      "epoch": 12.49,
      "learning_rate": 0.00014771535897835087,
      "loss": 0.2772,
      "step": 12490
    },
    {
      "epoch": 12.5,
      "learning_rate": 0.00014770927997729682,
      "loss": 0.3361,
      "step": 12500
    },
    {
      "epoch": 12.51,
      "learning_rate": 0.00014770319302486525,
      "loss": 0.2794,
      "step": 12510
    },
    {
      "epoch": 12.52,
      "learning_rate": 0.00014769709812172176,
      "loss": 0.3109,
      "step": 12520
    },
    {
      "epoch": 12.53,
      "learning_rate": 0.00014769099526853297,
      "loss": 0.2605,
      "step": 12530
    },
    {
      "epoch": 12.54,
      "learning_rate": 0.0001476848844659662,
      "loss": 0.2973,
      "step": 12540
    },
    {
      "epoch": 12.55,
      "learning_rate": 0.00014767876571468972,
      "loss": 0.2859,
      "step": 12550
    },
    {
      "epoch": 12.56,
      "learning_rate": 0.00014767263901537274,
      "loss": 0.2329,
      "step": 12560
    },
    {
      "epoch": 12.57,
      "learning_rate": 0.0001476665043686852,
      "loss": 0.3146,
      "step": 12570
    },
    {
      "epoch": 12.58,
      "learning_rate": 0.00014766036177529798,
      "loss": 0.3284,
      "step": 12580
    },
    {
      "epoch": 12.59,
      "learning_rate": 0.00014765421123588286,
      "loss": 0.3112,
      "step": 12590
    },
    {
      "epoch": 12.6,
      "learning_rate": 0.0001476480527511124,
      "loss": 0.248,
      "step": 12600
    },
    {
      "epoch": 12.61,
      "learning_rate": 0.00014764188632166014,
      "loss": 0.2429,
      "step": 12610
    },
    {
      "epoch": 12.62,
      "learning_rate": 0.00014763571194820042,
      "loss": 0.3224,
      "step": 12620
    },
    {
      "epoch": 12.63,
      "learning_rate": 0.00014762952963140845,
      "loss": 0.2806,
      "step": 12630
    },
    {
      "epoch": 12.64,
      "learning_rate": 0.0001476233393719603,
      "loss": 0.3602,
      "step": 12640
    },
    {
      "epoch": 12.65,
      "learning_rate": 0.00014761714117053293,
      "loss": 0.2869,
      "step": 12650
    },
    {
      "epoch": 12.66,
      "learning_rate": 0.0001476109350278042,
      "loss": 0.3271,
      "step": 12660
    },
    {
      "epoch": 12.67,
      "learning_rate": 0.00014760472094445278,
      "loss": 0.3203,
      "step": 12670
    },
    {
      "epoch": 12.68,
      "learning_rate": 0.00014759849892115822,
      "loss": 0.2488,
      "step": 12680
    },
    {
      "epoch": 12.69,
      "learning_rate": 0.000147592268958601,
      "loss": 0.3048,
      "step": 12690
    },
    {
      "epoch": 12.7,
      "learning_rate": 0.00014758603105746238,
      "loss": 0.2289,
      "step": 12700
    },
    {
      "epoch": 12.71,
      "learning_rate": 0.00014757978521842452,
      "loss": 0.3571,
      "step": 12710
    },
    {
      "epoch": 12.72,
      "learning_rate": 0.00014757353144217048,
      "loss": 0.3036,
      "step": 12720
    },
    {
      "epoch": 12.73,
      "learning_rate": 0.00014756726972938415,
      "loss": 0.2063,
      "step": 12730
    },
    {
      "epoch": 12.74,
      "learning_rate": 0.0001475610000807503,
      "loss": 0.274,
      "step": 12740
    },
    {
      "epoch": 12.75,
      "learning_rate": 0.0001475547224969546,
      "loss": 0.2431,
      "step": 12750
    },
    {
      "epoch": 12.76,
      "learning_rate": 0.00014754843697868352,
      "loss": 0.2642,
      "step": 12760
    },
    {
      "epoch": 12.77,
      "learning_rate": 0.00014754214352662441,
      "loss": 0.2522,
      "step": 12770
    },
    {
      "epoch": 12.78,
      "learning_rate": 0.0001475358421414656,
      "loss": 0.3266,
      "step": 12780
    },
    {
      "epoch": 12.79,
      "learning_rate": 0.00014752953282389612,
      "loss": 0.2972,
      "step": 12790
    },
    {
      "epoch": 12.8,
      "learning_rate": 0.000147523215574606,
      "loss": 0.235,
      "step": 12800
    },
    {
      "epoch": 12.81,
      "learning_rate": 0.00014751689039428604,
      "loss": 0.3186,
      "step": 12810
    },
    {
      "epoch": 12.82,
      "learning_rate": 0.000147510557283628,
      "loss": 0.2425,
      "step": 12820
    },
    {
      "epoch": 12.83,
      "learning_rate": 0.0001475042162433244,
      "loss": 0.3057,
      "step": 12830
    },
    {
      "epoch": 12.84,
      "learning_rate": 0.00014749786727406874,
      "loss": 0.3074,
      "step": 12840
    },
    {
      "epoch": 12.85,
      "learning_rate": 0.0001474915103765553,
      "loss": 0.2393,
      "step": 12850
    },
    {
      "epoch": 12.86,
      "learning_rate": 0.0001474851455514793,
      "loss": 0.2597,
      "step": 12860
    },
    {
      "epoch": 12.87,
      "learning_rate": 0.00014747877279953675,
      "loss": 0.3263,
      "step": 12870
    },
    {
      "epoch": 12.88,
      "learning_rate": 0.00014747239212142458,
      "loss": 0.3059,
      "step": 12880
    },
    {
      "epoch": 12.89,
      "learning_rate": 0.00014746600351784055,
      "loss": 0.2895,
      "step": 12890
    },
    {
      "epoch": 12.9,
      "learning_rate": 0.00014745960698948335,
      "loss": 0.2247,
      "step": 12900
    },
    {
      "epoch": 12.91,
      "learning_rate": 0.00014745320253705245,
      "loss": 0.2608,
      "step": 12910
    },
    {
      "epoch": 12.92,
      "learning_rate": 0.00014744679016124825,
      "loss": 0.2514,
      "step": 12920
    },
    {
      "epoch": 12.93,
      "learning_rate": 0.000147440369862772,
      "loss": 0.2851,
      "step": 12930
    },
    {
      "epoch": 12.94,
      "learning_rate": 0.00014743394164232586,
      "loss": 0.2512,
      "step": 12940
    },
    {
      "epoch": 12.95,
      "learning_rate": 0.00014742750550061272,
      "loss": 0.2656,
      "step": 12950
    },
    {
      "epoch": 12.96,
      "learning_rate": 0.00014742106143833647,
      "loss": 0.2439,
      "step": 12960
    },
    {
      "epoch": 12.97,
      "learning_rate": 0.00014741460945620185,
      "loss": 0.3082,
      "step": 12970
    },
    {
      "epoch": 12.98,
      "learning_rate": 0.0001474081495549144,
      "loss": 0.1792,
      "step": 12980
    },
    {
      "epoch": 12.99,
      "learning_rate": 0.0001474016817351806,
      "loss": 0.2233,
      "step": 12990
    },
    {
      "epoch": 13.0,
      "learning_rate": 0.0001473952059977077,
      "loss": 0.2655,
      "step": 13000
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2739758789539337,
      "eval_runtime": 14.5675,
      "eval_samples_per_second": 137.292,
      "eval_steps_per_second": 17.161,
      "step": 13000
    },
    {
      "epoch": 13.01,
      "learning_rate": 0.00014738872234320395,
      "loss": 0.2307,
      "step": 13010
    },
    {
      "epoch": 13.02,
      "learning_rate": 0.00014738223077237833,
      "loss": 0.3432,
      "step": 13020
    },
    {
      "epoch": 13.03,
      "learning_rate": 0.00014737573128594078,
      "loss": 0.2287,
      "step": 13030
    },
    {
      "epoch": 13.04,
      "learning_rate": 0.0001473692238846021,
      "loss": 0.2704,
      "step": 13040
    },
    {
      "epoch": 13.05,
      "learning_rate": 0.0001473627085690739,
      "loss": 0.3201,
      "step": 13050
    },
    {
      "epoch": 13.06,
      "learning_rate": 0.00014735618534006867,
      "loss": 0.3027,
      "step": 13060
    },
    {
      "epoch": 13.07,
      "learning_rate": 0.0001473496541982998,
      "loss": 0.2748,
      "step": 13070
    },
    {
      "epoch": 13.08,
      "learning_rate": 0.00014734311514448152,
      "loss": 0.2735,
      "step": 13080
    },
    {
      "epoch": 13.09,
      "learning_rate": 0.00014733656817932894,
      "loss": 0.2079,
      "step": 13090
    },
    {
      "epoch": 13.1,
      "learning_rate": 0.000147330013303558,
      "loss": 0.298,
      "step": 13100
    },
    {
      "epoch": 13.11,
      "learning_rate": 0.00014732345051788557,
      "loss": 0.291,
      "step": 13110
    },
    {
      "epoch": 13.12,
      "learning_rate": 0.00014731687982302933,
      "loss": 0.2593,
      "step": 13120
    },
    {
      "epoch": 13.13,
      "learning_rate": 0.00014731030121970784,
      "loss": 0.2791,
      "step": 13130
    },
    {
      "epoch": 13.14,
      "learning_rate": 0.00014730371470864052,
      "loss": 0.3083,
      "step": 13140
    },
    {
      "epoch": 13.15,
      "learning_rate": 0.00014729712029054766,
      "loss": 0.2286,
      "step": 13150
    },
    {
      "epoch": 13.16,
      "learning_rate": 0.00014729051796615045,
      "loss": 0.2438,
      "step": 13160
    },
    {
      "epoch": 13.17,
      "learning_rate": 0.00014728390773617088,
      "loss": 0.3172,
      "step": 13170
    },
    {
      "epoch": 13.18,
      "learning_rate": 0.00014727728960133179,
      "loss": 0.2815,
      "step": 13180
    },
    {
      "epoch": 13.19,
      "learning_rate": 0.00014727066356235702,
      "loss": 0.2562,
      "step": 13190
    },
    {
      "epoch": 13.2,
      "learning_rate": 0.0001472640296199711,
      "loss": 0.2072,
      "step": 13200
    },
    {
      "epoch": 13.21,
      "learning_rate": 0.0001472573877748996,
      "loss": 0.2002,
      "step": 13210
    },
    {
      "epoch": 13.22,
      "learning_rate": 0.00014725073802786877,
      "loss": 0.2685,
      "step": 13220
    },
    {
      "epoch": 13.23,
      "learning_rate": 0.0001472440803796059,
      "loss": 0.2497,
      "step": 13230
    },
    {
      "epoch": 13.24,
      "learning_rate": 0.000147237414830839,
      "loss": 0.3086,
      "step": 13240
    },
    {
      "epoch": 13.25,
      "learning_rate": 0.00014723074138229698,
      "loss": 0.3288,
      "step": 13250
    },
    {
      "epoch": 13.26,
      "learning_rate": 0.00014722406003470973,
      "loss": 0.2629,
      "step": 13260
    },
    {
      "epoch": 13.27,
      "learning_rate": 0.00014721737078880783,
      "loss": 0.3417,
      "step": 13270
    },
    {
      "epoch": 13.28,
      "learning_rate": 0.00014721067364532284,
      "loss": 0.2935,
      "step": 13280
    },
    {
      "epoch": 13.29,
      "learning_rate": 0.00014720396860498717,
      "loss": 0.3387,
      "step": 13290
    },
    {
      "epoch": 13.3,
      "learning_rate": 0.00014719725566853404,
      "loss": 0.3243,
      "step": 13300
    },
    {
      "epoch": 13.31,
      "learning_rate": 0.00014719053483669756,
      "loss": 0.2692,
      "step": 13310
    },
    {
      "epoch": 13.32,
      "learning_rate": 0.00014718380611021274,
      "loss": 0.2383,
      "step": 13320
    },
    {
      "epoch": 13.33,
      "learning_rate": 0.00014717706948981542,
      "loss": 0.3059,
      "step": 13330
    },
    {
      "epoch": 13.34,
      "learning_rate": 0.00014717032497624228,
      "loss": 0.2038,
      "step": 13340
    },
    {
      "epoch": 13.35,
      "learning_rate": 0.00014716357257023093,
      "loss": 0.2541,
      "step": 13350
    },
    {
      "epoch": 13.36,
      "learning_rate": 0.00014715681227251977,
      "loss": 0.3217,
      "step": 13360
    },
    {
      "epoch": 13.37,
      "learning_rate": 0.00014715004408384812,
      "loss": 0.3163,
      "step": 13370
    },
    {
      "epoch": 13.38,
      "learning_rate": 0.0001471432680049561,
      "loss": 0.2675,
      "step": 13380
    },
    {
      "epoch": 13.39,
      "learning_rate": 0.00014713648403658476,
      "loss": 0.2904,
      "step": 13390
    },
    {
      "epoch": 13.4,
      "learning_rate": 0.00014712969217947597,
      "loss": 0.2943,
      "step": 13400
    },
    {
      "epoch": 13.41,
      "learning_rate": 0.00014712289243437251,
      "loss": 0.3537,
      "step": 13410
    },
    {
      "epoch": 13.42,
      "learning_rate": 0.00014711608480201795,
      "loss": 0.2464,
      "step": 13420
    },
    {
      "epoch": 13.43,
      "learning_rate": 0.0001471092692831568,
      "loss": 0.29,
      "step": 13430
    },
    {
      "epoch": 13.44,
      "learning_rate": 0.00014710244587853437,
      "loss": 0.2587,
      "step": 13440
    },
    {
      "epoch": 13.45,
      "learning_rate": 0.0001470956145888969,
      "loss": 0.3737,
      "step": 13450
    },
    {
      "epoch": 13.46,
      "learning_rate": 0.00014708877541499136,
      "loss": 0.2931,
      "step": 13460
    },
    {
      "epoch": 13.47,
      "learning_rate": 0.00014708192835756573,
      "loss": 0.2101,
      "step": 13470
    },
    {
      "epoch": 13.48,
      "learning_rate": 0.0001470750734173688,
      "loss": 0.3,
      "step": 13480
    },
    {
      "epoch": 13.49,
      "learning_rate": 0.0001470682105951502,
      "loss": 0.2824,
      "step": 13490
    },
    {
      "epoch": 13.5,
      "learning_rate": 0.00014706133989166042,
      "loss": 0.2313,
      "step": 13500
    },
    {
      "epoch": 13.51,
      "learning_rate": 0.0001470544613076509,
      "loss": 0.293,
      "step": 13510
    },
    {
      "epoch": 13.52,
      "learning_rate": 0.00014704757484387379,
      "loss": 0.2511,
      "step": 13520
    },
    {
      "epoch": 13.53,
      "learning_rate": 0.00014704068050108224,
      "loss": 0.2422,
      "step": 13530
    },
    {
      "epoch": 13.54,
      "learning_rate": 0.00014703377828003016,
      "loss": 0.1904,
      "step": 13540
    },
    {
      "epoch": 13.55,
      "learning_rate": 0.0001470268681814724,
      "loss": 0.3393,
      "step": 13550
    },
    {
      "epoch": 13.56,
      "learning_rate": 0.00014701995020616462,
      "loss": 0.2277,
      "step": 13560
    },
    {
      "epoch": 13.57,
      "learning_rate": 0.00014701302435486338,
      "loss": 0.2963,
      "step": 13570
    },
    {
      "epoch": 13.58,
      "learning_rate": 0.00014700609062832606,
      "loss": 0.3781,
      "step": 13580
    },
    {
      "epoch": 13.59,
      "learning_rate": 0.00014699914902731092,
      "loss": 0.2536,
      "step": 13590
    },
    {
      "epoch": 13.6,
      "learning_rate": 0.0001469921995525771,
      "loss": 0.2576,
      "step": 13600
    },
    {
      "epoch": 13.61,
      "learning_rate": 0.00014698524220488457,
      "loss": 0.2842,
      "step": 13610
    },
    {
      "epoch": 13.62,
      "learning_rate": 0.0001469782769849942,
      "loss": 0.2393,
      "step": 13620
    },
    {
      "epoch": 13.63,
      "learning_rate": 0.00014697130389366766,
      "loss": 0.2958,
      "step": 13630
    },
    {
      "epoch": 13.64,
      "learning_rate": 0.00014696432293166752,
      "loss": 0.3242,
      "step": 13640
    },
    {
      "epoch": 13.65,
      "learning_rate": 0.00014695733409975724,
      "loss": 0.3423,
      "step": 13650
    },
    {
      "epoch": 13.66,
      "learning_rate": 0.00014695033739870107,
      "loss": 0.2607,
      "step": 13660
    },
    {
      "epoch": 13.67,
      "learning_rate": 0.0001469433328292642,
      "loss": 0.2003,
      "step": 13670
    },
    {
      "epoch": 13.68,
      "learning_rate": 0.00014693632039221262,
      "loss": 0.3021,
      "step": 13680
    },
    {
      "epoch": 13.69,
      "learning_rate": 0.00014692930008831316,
      "loss": 0.3037,
      "step": 13690
    },
    {
      "epoch": 13.7,
      "learning_rate": 0.00014692227191833362,
      "loss": 0.3299,
      "step": 13700
    },
    {
      "epoch": 13.71,
      "learning_rate": 0.00014691523588304255,
      "loss": 0.2167,
      "step": 13710
    },
    {
      "epoch": 13.72,
      "learning_rate": 0.00014690819198320942,
      "loss": 0.2701,
      "step": 13720
    },
    {
      "epoch": 13.73,
      "learning_rate": 0.0001469011402196045,
      "loss": 0.3301,
      "step": 13730
    },
    {
      "epoch": 13.74,
      "learning_rate": 0.000146894080592999,
      "loss": 0.2729,
      "step": 13740
    },
    {
      "epoch": 13.75,
      "learning_rate": 0.00014688701310416492,
      "loss": 0.2952,
      "step": 13750
    },
    {
      "epoch": 13.76,
      "learning_rate": 0.0001468799377538752,
      "loss": 0.3139,
      "step": 13760
    },
    {
      "epoch": 13.77,
      "learning_rate": 0.00014687285454290355,
      "loss": 0.2606,
      "step": 13770
    },
    {
      "epoch": 13.78,
      "learning_rate": 0.00014686576347202457,
      "loss": 0.2949,
      "step": 13780
    },
    {
      "epoch": 13.79,
      "learning_rate": 0.00014685866454201374,
      "loss": 0.2555,
      "step": 13790
    },
    {
      "epoch": 13.8,
      "learning_rate": 0.00014685155775364742,
      "loss": 0.253,
      "step": 13800
    },
    {
      "epoch": 13.81,
      "learning_rate": 0.00014684444310770277,
      "loss": 0.2893,
      "step": 13810
    },
    {
      "epoch": 13.82,
      "learning_rate": 0.0001468373206049578,
      "loss": 0.2994,
      "step": 13820
    },
    {
      "epoch": 13.83,
      "learning_rate": 0.0001468301902461915,
      "loss": 0.3672,
      "step": 13830
    },
    {
      "epoch": 13.84,
      "learning_rate": 0.00014682305203218355,
      "loss": 0.2852,
      "step": 13840
    },
    {
      "epoch": 13.85,
      "learning_rate": 0.00014681590596371465,
      "loss": 0.3152,
      "step": 13850
    },
    {
      "epoch": 13.86,
      "learning_rate": 0.0001468087520415662,
      "loss": 0.3128,
      "step": 13860
    },
    {
      "epoch": 13.87,
      "learning_rate": 0.00014680159026652064,
      "loss": 0.2742,
      "step": 13870
    },
    {
      "epoch": 13.88,
      "learning_rate": 0.0001467944206393611,
      "loss": 0.2616,
      "step": 13880
    },
    {
      "epoch": 13.89,
      "learning_rate": 0.00014678724316087165,
      "loss": 0.2318,
      "step": 13890
    },
    {
      "epoch": 13.9,
      "learning_rate": 0.00014678005783183725,
      "loss": 0.2194,
      "step": 13900
    },
    {
      "epoch": 13.91,
      "learning_rate": 0.00014677286465304362,
      "loss": 0.2464,
      "step": 13910
    },
    {
      "epoch": 13.92,
      "learning_rate": 0.00014676566362527743,
      "loss": 0.2563,
      "step": 13920
    },
    {
      "epoch": 13.93,
      "learning_rate": 0.00014675845474932615,
      "loss": 0.2184,
      "step": 13930
    },
    {
      "epoch": 13.94,
      "learning_rate": 0.00014675123802597816,
      "loss": 0.2307,
      "step": 13940
    },
    {
      "epoch": 13.95,
      "learning_rate": 0.00014674401345602265,
      "loss": 0.3031,
      "step": 13950
    },
    {
      "epoch": 13.96,
      "learning_rate": 0.0001467367810402497,
      "loss": 0.2673,
      "step": 13960
    },
    {
      "epoch": 13.97,
      "learning_rate": 0.00014672954077945023,
      "loss": 0.3101,
      "step": 13970
    },
    {
      "epoch": 13.98,
      "learning_rate": 0.00014672229267441602,
      "loss": 0.3058,
      "step": 13980
    },
    {
      "epoch": 13.99,
      "learning_rate": 0.0001467150367259397,
      "loss": 0.3745,
      "step": 13990
    },
    {
      "epoch": 14.0,
      "learning_rate": 0.00014670777293481483,
      "loss": 0.2503,
      "step": 14000
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2731021046638489,
      "eval_runtime": 14.9463,
      "eval_samples_per_second": 133.812,
      "eval_steps_per_second": 16.727,
      "step": 14000
    },
    {
      "epoch": 14.01,
      "learning_rate": 0.00014670050130183567,
      "loss": 0.2577,
      "step": 14010
    },
    {
      "epoch": 14.02,
      "learning_rate": 0.00014669322182779752,
      "loss": 0.2507,
      "step": 14020
    },
    {
      "epoch": 14.03,
      "learning_rate": 0.0001466859345134964,
      "loss": 0.2885,
      "step": 14030
    },
    {
      "epoch": 14.04,
      "learning_rate": 0.00014667863935972927,
      "loss": 0.2715,
      "step": 14040
    },
    {
      "epoch": 14.05,
      "learning_rate": 0.0001466713363672939,
      "loss": 0.3045,
      "step": 14050
    },
    {
      "epoch": 14.06,
      "learning_rate": 0.00014666402553698896,
      "loss": 0.2105,
      "step": 14060
    },
    {
      "epoch": 14.07,
      "learning_rate": 0.00014665670686961395,
      "loss": 0.3157,
      "step": 14070
    },
    {
      "epoch": 14.08,
      "learning_rate": 0.00014664938036596916,
      "loss": 0.3112,
      "step": 14080
    },
    {
      "epoch": 14.09,
      "learning_rate": 0.00014664204602685588,
      "loss": 0.3579,
      "step": 14090
    },
    {
      "epoch": 14.1,
      "learning_rate": 0.00014663470385307617,
      "loss": 0.2886,
      "step": 14100
    },
    {
      "epoch": 14.11,
      "learning_rate": 0.00014662735384543294,
      "loss": 0.2909,
      "step": 14110
    },
    {
      "epoch": 14.12,
      "learning_rate": 0.00014661999600472999,
      "loss": 0.2973,
      "step": 14120
    },
    {
      "epoch": 14.13,
      "learning_rate": 0.00014661263033177192,
      "loss": 0.315,
      "step": 14130
    },
    {
      "epoch": 14.14,
      "learning_rate": 0.0001466052568273643,
      "loss": 0.2989,
      "step": 14140
    },
    {
      "epoch": 14.15,
      "learning_rate": 0.00014659787549231343,
      "loss": 0.2713,
      "step": 14150
    },
    {
      "epoch": 14.16,
      "learning_rate": 0.00014659048632742656,
      "loss": 0.2863,
      "step": 14160
    },
    {
      "epoch": 14.17,
      "learning_rate": 0.00014658308933351174,
      "loss": 0.198,
      "step": 14170
    },
    {
      "epoch": 14.18,
      "learning_rate": 0.0001465756845113779,
      "loss": 0.286,
      "step": 14180
    },
    {
      "epoch": 14.19,
      "learning_rate": 0.00014656827186183477,
      "loss": 0.2878,
      "step": 14190
    },
    {
      "epoch": 14.2,
      "learning_rate": 0.00014656085138569307,
      "loss": 0.2461,
      "step": 14200
    },
    {
      "epoch": 14.21,
      "learning_rate": 0.00014655342308376423,
      "loss": 0.26,
      "step": 14210
    },
    {
      "epoch": 14.22,
      "learning_rate": 0.00014654598695686063,
      "loss": 0.2687,
      "step": 14220
    },
    {
      "epoch": 14.23,
      "learning_rate": 0.00014653854300579548,
      "loss": 0.2684,
      "step": 14230
    },
    {
      "epoch": 14.24,
      "learning_rate": 0.00014653109123138284,
      "loss": 0.2956,
      "step": 14240
    },
    {
      "epoch": 14.25,
      "learning_rate": 0.00014652363163443756,
      "loss": 0.3222,
      "step": 14250
    },
    {
      "epoch": 14.26,
      "learning_rate": 0.0001465161642157755,
      "loss": 0.3214,
      "step": 14260
    },
    {
      "epoch": 14.27,
      "learning_rate": 0.0001465086889762132,
      "loss": 0.2158,
      "step": 14270
    },
    {
      "epoch": 14.28,
      "learning_rate": 0.00014650120591656822,
      "loss": 0.2837,
      "step": 14280
    },
    {
      "epoch": 14.29,
      "learning_rate": 0.00014649371503765884,
      "loss": 0.25,
      "step": 14290
    },
    {
      "epoch": 14.3,
      "learning_rate": 0.0001464862163403043,
      "loss": 0.2631,
      "step": 14300
    },
    {
      "epoch": 14.31,
      "learning_rate": 0.0001464787098253246,
      "loss": 0.2478,
      "step": 14310
    },
    {
      "epoch": 14.32,
      "learning_rate": 0.00014647119549354064,
      "loss": 0.3473,
      "step": 14320
    },
    {
      "epoch": 14.33,
      "learning_rate": 0.00014646367334577424,
      "loss": 0.3208,
      "step": 14330
    },
    {
      "epoch": 14.34,
      "learning_rate": 0.00014645614338284793,
      "loss": 0.2505,
      "step": 14340
    },
    {
      "epoch": 14.35,
      "learning_rate": 0.00014644860560558522,
      "loss": 0.3286,
      "step": 14350
    },
    {
      "epoch": 14.36,
      "learning_rate": 0.00014644106001481045,
      "loss": 0.2794,
      "step": 14360
    },
    {
      "epoch": 14.37,
      "learning_rate": 0.00014643350661134875,
      "loss": 0.2923,
      "step": 14370
    },
    {
      "epoch": 14.38,
      "learning_rate": 0.00014642594539602613,
      "loss": 0.2839,
      "step": 14380
    },
    {
      "epoch": 14.39,
      "learning_rate": 0.00014641837636966955,
      "loss": 0.2373,
      "step": 14390
    },
    {
      "epoch": 14.4,
      "learning_rate": 0.00014641079953310672,
      "loss": 0.302,
      "step": 14400
    },
    {
      "epoch": 14.41,
      "learning_rate": 0.0001464032148871662,
      "loss": 0.2665,
      "step": 14410
    },
    {
      "epoch": 14.42,
      "learning_rate": 0.00014639562243267743,
      "loss": 0.3353,
      "step": 14420
    },
    {
      "epoch": 14.43,
      "learning_rate": 0.00014638802217047076,
      "loss": 0.3168,
      "step": 14430
    },
    {
      "epoch": 14.44,
      "learning_rate": 0.0001463804141013773,
      "loss": 0.3153,
      "step": 14440
    },
    {
      "epoch": 14.45,
      "learning_rate": 0.0001463727982262291,
      "loss": 0.2639,
      "step": 14450
    },
    {
      "epoch": 14.46,
      "learning_rate": 0.00014636517454585897,
      "loss": 0.2522,
      "step": 14460
    },
    {
      "epoch": 14.47,
      "learning_rate": 0.00014635754306110063,
      "loss": 0.3257,
      "step": 14470
    },
    {
      "epoch": 14.48,
      "learning_rate": 0.0001463499037727887,
      "loss": 0.2901,
      "step": 14480
    },
    {
      "epoch": 14.49,
      "learning_rate": 0.00014634225668175855,
      "loss": 0.3026,
      "step": 14490
    },
    {
      "epoch": 14.5,
      "learning_rate": 0.00014633460178884646,
      "loss": 0.2766,
      "step": 14500
    },
    {
      "epoch": 14.51,
      "learning_rate": 0.0001463269390948896,
      "loss": 0.2406,
      "step": 14510
    },
    {
      "epoch": 14.52,
      "learning_rate": 0.00014631926860072587,
      "loss": 0.3101,
      "step": 14520
    },
    {
      "epoch": 14.53,
      "learning_rate": 0.0001463115903071942,
      "loss": 0.2923,
      "step": 14530
    },
    {
      "epoch": 14.54,
      "learning_rate": 0.00014630390421513422,
      "loss": 0.2292,
      "step": 14540
    },
    {
      "epoch": 14.55,
      "learning_rate": 0.00014629621032538647,
      "loss": 0.2596,
      "step": 14550
    },
    {
      "epoch": 14.56,
      "learning_rate": 0.00014628850863879233,
      "loss": 0.2045,
      "step": 14560
    },
    {
      "epoch": 14.57,
      "learning_rate": 0.0001462807991561941,
      "loss": 0.3379,
      "step": 14570
    },
    {
      "epoch": 14.58,
      "learning_rate": 0.00014627308187843482,
      "loss": 0.3168,
      "step": 14580
    },
    {
      "epoch": 14.59,
      "learning_rate": 0.0001462653568063585,
      "loss": 0.3308,
      "step": 14590
    },
    {
      "epoch": 14.6,
      "learning_rate": 0.00014625762394080986,
      "loss": 0.2573,
      "step": 14600
    },
    {
      "epoch": 14.61,
      "learning_rate": 0.00014624988328263463,
      "loss": 0.3269,
      "step": 14610
    },
    {
      "epoch": 14.62,
      "learning_rate": 0.00014624213483267927,
      "loss": 0.2313,
      "step": 14620
    },
    {
      "epoch": 14.63,
      "learning_rate": 0.00014623437859179116,
      "loss": 0.3269,
      "step": 14630
    },
    {
      "epoch": 14.64,
      "learning_rate": 0.0001462266145608185,
      "loss": 0.2353,
      "step": 14640
    },
    {
      "epoch": 14.65,
      "learning_rate": 0.00014621884274061038,
      "loss": 0.3308,
      "step": 14650
    },
    {
      "epoch": 14.66,
      "learning_rate": 0.0001462110631320167,
      "loss": 0.1912,
      "step": 14660
    },
    {
      "epoch": 14.67,
      "learning_rate": 0.0001462032757358882,
      "loss": 0.2394,
      "step": 14670
    },
    {
      "epoch": 14.68,
      "learning_rate": 0.0001461954805530765,
      "loss": 0.2958,
      "step": 14680
    },
    {
      "epoch": 14.69,
      "learning_rate": 0.0001461876775844341,
      "loss": 0.2748,
      "step": 14690
    },
    {
      "epoch": 14.7,
      "learning_rate": 0.00014617986683081432,
      "loss": 0.2322,
      "step": 14700
    },
    {
      "epoch": 14.71,
      "learning_rate": 0.00014617204829307133,
      "loss": 0.3022,
      "step": 14710
    },
    {
      "epoch": 14.72,
      "learning_rate": 0.00014616422197206012,
      "loss": 0.34,
      "step": 14720
    },
    {
      "epoch": 14.73,
      "learning_rate": 0.0001461563878686366,
      "loss": 0.2258,
      "step": 14730
    },
    {
      "epoch": 14.74,
      "learning_rate": 0.00014614854598365748,
      "loss": 0.2839,
      "step": 14740
    },
    {
      "epoch": 14.75,
      "learning_rate": 0.00014614069631798036,
      "loss": 0.2794,
      "step": 14750
    },
    {
      "epoch": 14.76,
      "learning_rate": 0.00014613283887246362,
      "loss": 0.2267,
      "step": 14760
    },
    {
      "epoch": 14.77,
      "learning_rate": 0.00014612497364796658,
      "loss": 0.2659,
      "step": 14770
    },
    {
      "epoch": 14.78,
      "learning_rate": 0.0001461171006453494,
      "loss": 0.2643,
      "step": 14780
    },
    {
      "epoch": 14.79,
      "learning_rate": 0.00014610921986547295,
      "loss": 0.3063,
      "step": 14790
    },
    {
      "epoch": 14.8,
      "learning_rate": 0.00014610133130919917,
      "loss": 0.233,
      "step": 14800
    },
    {
      "epoch": 14.81,
      "learning_rate": 0.00014609343497739067,
      "loss": 0.281,
      "step": 14810
    },
    {
      "epoch": 14.82,
      "learning_rate": 0.00014608553087091101,
      "loss": 0.3131,
      "step": 14820
    },
    {
      "epoch": 14.83,
      "learning_rate": 0.0001460776189906246,
      "loss": 0.201,
      "step": 14830
    },
    {
      "epoch": 14.84,
      "learning_rate": 0.00014606969933739661,
      "loss": 0.3586,
      "step": 14840
    },
    {
      "epoch": 14.85,
      "learning_rate": 0.00014606177191209315,
      "loss": 0.2415,
      "step": 14850
    },
    {
      "epoch": 14.86,
      "learning_rate": 0.00014605383671558117,
      "loss": 0.2681,
      "step": 14860
    },
    {
      "epoch": 14.87,
      "learning_rate": 0.0001460458937487284,
      "loss": 0.36,
      "step": 14870
    },
    {
      "epoch": 14.88,
      "learning_rate": 0.00014603794301240355,
      "loss": 0.245,
      "step": 14880
    },
    {
      "epoch": 14.89,
      "learning_rate": 0.00014602998450747605,
      "loss": 0.2704,
      "step": 14890
    },
    {
      "epoch": 14.9,
      "learning_rate": 0.00014602201823481624,
      "loss": 0.2996,
      "step": 14900
    },
    {
      "epoch": 14.91,
      "learning_rate": 0.00014601404419529527,
      "loss": 0.3059,
      "step": 14910
    },
    {
      "epoch": 14.92,
      "learning_rate": 0.00014600606238978522,
      "loss": 0.2884,
      "step": 14920
    },
    {
      "epoch": 14.93,
      "learning_rate": 0.00014599807281915893,
      "loss": 0.2351,
      "step": 14930
    },
    {
      "epoch": 14.94,
      "learning_rate": 0.00014599007548429013,
      "loss": 0.2724,
      "step": 14940
    },
    {
      "epoch": 14.95,
      "learning_rate": 0.00014598207038605342,
      "loss": 0.2745,
      "step": 14950
    },
    {
      "epoch": 14.96,
      "learning_rate": 0.0001459740575253242,
      "loss": 0.2312,
      "step": 14960
    },
    {
      "epoch": 14.97,
      "learning_rate": 0.00014596603690297878,
      "loss": 0.2898,
      "step": 14970
    },
    {
      "epoch": 14.98,
      "learning_rate": 0.00014595800851989425,
      "loss": 0.2581,
      "step": 14980
    },
    {
      "epoch": 14.99,
      "learning_rate": 0.00014594997237694858,
      "loss": 0.3211,
      "step": 14990
    },
    {
      "epoch": 15.0,
      "learning_rate": 0.0001459419284750206,
      "loss": 0.2268,
      "step": 15000
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2731403708457947,
      "eval_runtime": 14.9623,
      "eval_samples_per_second": 133.669,
      "eval_steps_per_second": 16.709,
      "step": 15000
    },
    {
      "epoch": 15.01,
      "learning_rate": 0.00014593387681499,
      "loss": 0.3307,
      "step": 15010
    },
    {
      "epoch": 15.02,
      "learning_rate": 0.00014592581739773726,
      "loss": 0.252,
      "step": 15020
    },
    {
      "epoch": 15.03,
      "learning_rate": 0.0001459177502241438,
      "loss": 0.3629,
      "step": 15030
    },
    {
      "epoch": 15.04,
      "learning_rate": 0.00014590967529509177,
      "loss": 0.2812,
      "step": 15040
    },
    {
      "epoch": 15.05,
      "learning_rate": 0.00014590159261146428,
      "loss": 0.3137,
      "step": 15050
    },
    {
      "epoch": 15.06,
      "learning_rate": 0.0001458935021741452,
      "loss": 0.204,
      "step": 15060
    },
    {
      "epoch": 15.07,
      "learning_rate": 0.0001458854039840193,
      "loss": 0.2656,
      "step": 15070
    },
    {
      "epoch": 15.08,
      "learning_rate": 0.00014587729804197222,
      "loss": 0.3237,
      "step": 15080
    },
    {
      "epoch": 15.09,
      "learning_rate": 0.0001458691843488904,
      "loss": 0.2512,
      "step": 15090
    },
    {
      "epoch": 15.1,
      "learning_rate": 0.0001458610629056611,
      "loss": 0.2961,
      "step": 15100
    },
    {
      "epoch": 15.11,
      "learning_rate": 0.0001458529337131725,
      "loss": 0.2875,
      "step": 15110
    },
    {
      "epoch": 15.12,
      "learning_rate": 0.0001458447967723136,
      "loss": 0.2644,
      "step": 15120
    },
    {
      "epoch": 15.13,
      "learning_rate": 0.00014583665208397426,
      "loss": 0.3201,
      "step": 15130
    },
    {
      "epoch": 15.14,
      "learning_rate": 0.00014582849964904512,
      "loss": 0.2675,
      "step": 15140
    },
    {
      "epoch": 15.15,
      "learning_rate": 0.00014582033946841777,
      "loss": 0.2547,
      "step": 15150
    },
    {
      "epoch": 15.16,
      "learning_rate": 0.00014581217154298454,
      "loss": 0.2816,
      "step": 15160
    },
    {
      "epoch": 15.17,
      "learning_rate": 0.00014580399587363872,
      "loss": 0.3012,
      "step": 15170
    },
    {
      "epoch": 15.18,
      "learning_rate": 0.0001457958124612744,
      "loss": 0.3245,
      "step": 15180
    },
    {
      "epoch": 15.19,
      "learning_rate": 0.0001457876213067864,
      "loss": 0.2546,
      "step": 15190
    },
    {
      "epoch": 15.2,
      "learning_rate": 0.0001457794224110706,
      "loss": 0.2981,
      "step": 15200
    },
    {
      "epoch": 15.21,
      "learning_rate": 0.00014577121577502358,
      "loss": 0.2858,
      "step": 15210
    },
    {
      "epoch": 15.22,
      "learning_rate": 0.0001457630013995428,
      "loss": 0.2754,
      "step": 15220
    },
    {
      "epoch": 15.23,
      "learning_rate": 0.00014575477928552654,
      "loss": 0.2367,
      "step": 15230
    },
    {
      "epoch": 15.24,
      "learning_rate": 0.00014574654943387403,
      "loss": 0.2702,
      "step": 15240
    },
    {
      "epoch": 15.25,
      "learning_rate": 0.00014573831184548525,
      "loss": 0.2792,
      "step": 15250
    },
    {
      "epoch": 15.26,
      "learning_rate": 0.00014573006652126102,
      "loss": 0.3024,
      "step": 15260
    },
    {
      "epoch": 15.27,
      "learning_rate": 0.00014572181346210307,
      "loss": 0.2802,
      "step": 15270
    },
    {
      "epoch": 15.28,
      "learning_rate": 0.00014571355266891392,
      "loss": 0.3234,
      "step": 15280
    },
    {
      "epoch": 15.29,
      "learning_rate": 0.00014570528414259697,
      "loss": 0.3337,
      "step": 15290
    },
    {
      "epoch": 15.3,
      "learning_rate": 0.0001456978358578348,
      "loss": 0.2925,
      "step": 15300
    },
    {
      "epoch": 15.31,
      "learning_rate": 0.00014568955264106687,
      "loss": 0.2564,
      "step": 15310
    },
    {
      "epoch": 15.32,
      "learning_rate": 0.00014568126169379577,
      "loss": 0.322,
      "step": 15320
    },
    {
      "epoch": 15.33,
      "learning_rate": 0.00014567296301692815,
      "loss": 0.196,
      "step": 15330
    },
    {
      "epoch": 15.34,
      "learning_rate": 0.00014566465661137152,
      "loss": 0.2508,
      "step": 15340
    },
    {
      "epoch": 15.35,
      "learning_rate": 0.00014565634247803435,
      "loss": 0.3339,
      "step": 15350
    },
    {
      "epoch": 15.36,
      "learning_rate": 0.00014564802061782574,
      "loss": 0.2796,
      "step": 15360
    },
    {
      "epoch": 15.37,
      "learning_rate": 0.00014563969103165584,
      "loss": 0.2628,
      "step": 15370
    },
    {
      "epoch": 15.38,
      "learning_rate": 0.00014563135372043553,
      "loss": 0.2699,
      "step": 15380
    },
    {
      "epoch": 15.39,
      "learning_rate": 0.00014562300868507655,
      "loss": 0.2911,
      "step": 15390
    },
    {
      "epoch": 15.4,
      "learning_rate": 0.00014561465592649155,
      "loss": 0.2606,
      "step": 15400
    },
    {
      "epoch": 15.41,
      "learning_rate": 0.00014560629544559394,
      "loss": 0.2077,
      "step": 15410
    },
    {
      "epoch": 15.42,
      "learning_rate": 0.000145597927243298,
      "loss": 0.3213,
      "step": 15420
    },
    {
      "epoch": 15.43,
      "learning_rate": 0.0001455895513205189,
      "loss": 0.208,
      "step": 15430
    },
    {
      "epoch": 15.44,
      "learning_rate": 0.00014558116767817258,
      "loss": 0.2475,
      "step": 15440
    },
    {
      "epoch": 15.45,
      "learning_rate": 0.0001455727763171759,
      "loss": 0.2879,
      "step": 15450
    },
    {
      "epoch": 15.46,
      "learning_rate": 0.00014556437723844647,
      "loss": 0.2743,
      "step": 15460
    },
    {
      "epoch": 15.47,
      "learning_rate": 0.00014555597044290286,
      "loss": 0.276,
      "step": 15470
    },
    {
      "epoch": 15.48,
      "learning_rate": 0.0001455475559314644,
      "loss": 0.2562,
      "step": 15480
    },
    {
      "epoch": 15.49,
      "learning_rate": 0.0001455391337050513,
      "loss": 0.2416,
      "step": 15490
    },
    {
      "epoch": 15.5,
      "learning_rate": 0.00014553070376458458,
      "loss": 0.2355,
      "step": 15500
    },
    {
      "epoch": 15.51,
      "learning_rate": 0.00014552226611098615,
      "loss": 0.2245,
      "step": 15510
    },
    {
      "epoch": 15.52,
      "learning_rate": 0.00014551382074517872,
      "loss": 0.2849,
      "step": 15520
    },
    {
      "epoch": 15.53,
      "learning_rate": 0.00014550536766808585,
      "loss": 0.3092,
      "step": 15530
    },
    {
      "epoch": 15.54,
      "learning_rate": 0.00014549690688063198,
      "loss": 0.2586,
      "step": 15540
    },
    {
      "epoch": 15.55,
      "learning_rate": 0.00014548843838374238,
      "loss": 0.2227,
      "step": 15550
    },
    {
      "epoch": 15.56,
      "learning_rate": 0.00014547996217834314,
      "loss": 0.2492,
      "step": 15560
    },
    {
      "epoch": 15.57,
      "learning_rate": 0.0001454714782653612,
      "loss": 0.3104,
      "step": 15570
    },
    {
      "epoch": 15.58,
      "learning_rate": 0.00014546298664572433,
      "loss": 0.3022,
      "step": 15580
    },
    {
      "epoch": 15.59,
      "learning_rate": 0.00014545448732036117,
      "loss": 0.3059,
      "step": 15590
    },
    {
      "epoch": 15.6,
      "learning_rate": 0.00014544598029020124,
      "loss": 0.2787,
      "step": 15600
    },
    {
      "epoch": 15.61,
      "learning_rate": 0.00014543746555617483,
      "loss": 0.2517,
      "step": 15610
    },
    {
      "epoch": 15.62,
      "learning_rate": 0.00014542894311921303,
      "loss": 0.2507,
      "step": 15620
    },
    {
      "epoch": 15.63,
      "learning_rate": 0.00014542041298024795,
      "loss": 0.2187,
      "step": 15630
    },
    {
      "epoch": 15.64,
      "learning_rate": 0.00014541187514021235,
      "loss": 0.3255,
      "step": 15640
    },
    {
      "epoch": 15.65,
      "learning_rate": 0.00014540332960003997,
      "loss": 0.2177,
      "step": 15650
    },
    {
      "epoch": 15.66,
      "learning_rate": 0.00014539477636066531,
      "loss": 0.2494,
      "step": 15660
    },
    {
      "epoch": 15.67,
      "learning_rate": 0.00014538621542302372,
      "loss": 0.3808,
      "step": 15670
    },
    {
      "epoch": 15.68,
      "learning_rate": 0.00014537764678805145,
      "loss": 0.3225,
      "step": 15680
    },
    {
      "epoch": 15.69,
      "learning_rate": 0.00014536907045668555,
      "loss": 0.2991,
      "step": 15690
    },
    {
      "epoch": 15.7,
      "learning_rate": 0.0001453604864298639,
      "loss": 0.2165,
      "step": 15700
    },
    {
      "epoch": 15.71,
      "learning_rate": 0.00014535189470852523,
      "loss": 0.2984,
      "step": 15710
    },
    {
      "epoch": 15.72,
      "learning_rate": 0.00014534329529360915,
      "loss": 0.2776,
      "step": 15720
    },
    {
      "epoch": 15.73,
      "learning_rate": 0.00014533468818605605,
      "loss": 0.2299,
      "step": 15730
    },
    {
      "epoch": 15.74,
      "learning_rate": 0.00014532607338680717,
      "loss": 0.3555,
      "step": 15740
    },
    {
      "epoch": 15.75,
      "learning_rate": 0.00014531745089680465,
      "loss": 0.2614,
      "step": 15750
    },
    {
      "epoch": 15.76,
      "learning_rate": 0.00014530882071699144,
      "loss": 0.2775,
      "step": 15760
    },
    {
      "epoch": 15.77,
      "learning_rate": 0.0001453001828483113,
      "loss": 0.233,
      "step": 15770
    },
    {
      "epoch": 15.78,
      "learning_rate": 0.00014529153729170885,
      "loss": 0.2686,
      "step": 15780
    },
    {
      "epoch": 15.79,
      "learning_rate": 0.00014528288404812954,
      "loss": 0.2707,
      "step": 15790
    },
    {
      "epoch": 15.8,
      "learning_rate": 0.0001452742231185197,
      "loss": 0.2776,
      "step": 15800
    },
    {
      "epoch": 15.81,
      "learning_rate": 0.0001452655545038265,
      "loss": 0.3462,
      "step": 15810
    },
    {
      "epoch": 15.82,
      "learning_rate": 0.00014525687820499792,
      "loss": 0.2958,
      "step": 15820
    },
    {
      "epoch": 15.83,
      "learning_rate": 0.00014524819422298272,
      "loss": 0.326,
      "step": 15830
    },
    {
      "epoch": 15.84,
      "learning_rate": 0.00014523950255873066,
      "loss": 0.3023,
      "step": 15840
    },
    {
      "epoch": 15.85,
      "learning_rate": 0.00014523080321319218,
      "loss": 0.2392,
      "step": 15850
    },
    {
      "epoch": 15.86,
      "learning_rate": 0.00014522209618731866,
      "loss": 0.3627,
      "step": 15860
    },
    {
      "epoch": 15.87,
      "learning_rate": 0.00014521338148206227,
      "loss": 0.2665,
      "step": 15870
    },
    {
      "epoch": 15.88,
      "learning_rate": 0.00014520465909837604,
      "loss": 0.2457,
      "step": 15880
    },
    {
      "epoch": 15.89,
      "learning_rate": 0.00014519592903721387,
      "loss": 0.3037,
      "step": 15890
    },
    {
      "epoch": 15.9,
      "learning_rate": 0.00014518719129953043,
      "loss": 0.2685,
      "step": 15900
    },
    {
      "epoch": 15.91,
      "learning_rate": 0.00014517844588628128,
      "loss": 0.3091,
      "step": 15910
    },
    {
      "epoch": 15.92,
      "learning_rate": 0.00014516969279842278,
      "loss": 0.3072,
      "step": 15920
    },
    {
      "epoch": 15.93,
      "learning_rate": 0.00014516093203691217,
      "loss": 0.2181,
      "step": 15930
    },
    {
      "epoch": 15.94,
      "learning_rate": 0.0001451521636027075,
      "loss": 0.2747,
      "step": 15940
    },
    {
      "epoch": 15.95,
      "learning_rate": 0.00014514338749676775,
      "loss": 0.3484,
      "step": 15950
    },
    {
      "epoch": 15.96,
      "learning_rate": 0.00014513460372005257,
      "loss": 0.2793,
      "step": 15960
    },
    {
      "epoch": 15.97,
      "learning_rate": 0.00014512581227352258,
      "loss": 0.2695,
      "step": 15970
    },
    {
      "epoch": 15.98,
      "learning_rate": 0.00014511701315813918,
      "loss": 0.2649,
      "step": 15980
    },
    {
      "epoch": 15.99,
      "learning_rate": 0.00014510820637486465,
      "loss": 0.2845,
      "step": 15990
    },
    {
      "epoch": 16.0,
      "learning_rate": 0.0001450993919246621,
      "loss": 0.3237,
      "step": 16000
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2749080955982208,
      "eval_runtime": 15.3246,
      "eval_samples_per_second": 130.51,
      "eval_steps_per_second": 16.314,
      "step": 16000
    },
    {
      "epoch": 16.01,
      "learning_rate": 0.00014509056980849537,
      "loss": 0.238,
      "step": 16010
    },
    {
      "epoch": 16.02,
      "learning_rate": 0.00014508174002732938,
      "loss": 0.3074,
      "step": 16020
    },
    {
      "epoch": 16.03,
      "learning_rate": 0.0001450729025821296,
      "loss": 0.2706,
      "step": 16030
    },
    {
      "epoch": 16.04,
      "learning_rate": 0.00014506405747386262,
      "loss": 0.2896,
      "step": 16040
    },
    {
      "epoch": 16.05,
      "learning_rate": 0.0001450552047034956,
      "loss": 0.2433,
      "step": 16050
    },
    {
      "epoch": 16.06,
      "learning_rate": 0.00014504634427199675,
      "loss": 0.3123,
      "step": 16060
    },
    {
      "epoch": 16.07,
      "learning_rate": 0.00014503747618033498,
      "loss": 0.3043,
      "step": 16070
    },
    {
      "epoch": 16.08,
      "learning_rate": 0.00014502860042948012,
      "loss": 0.2889,
      "step": 16080
    },
    {
      "epoch": 16.09,
      "learning_rate": 0.00014501971702040282,
      "loss": 0.3466,
      "step": 16090
    },
    {
      "epoch": 16.1,
      "learning_rate": 0.00014501082595407453,
      "loss": 0.3104,
      "step": 16100
    },
    {
      "epoch": 16.11,
      "learning_rate": 0.0001450019272314676,
      "loss": 0.3064,
      "step": 16110
    },
    {
      "epoch": 16.12,
      "learning_rate": 0.0001449930208535551,
      "loss": 0.2648,
      "step": 16120
    },
    {
      "epoch": 16.13,
      "learning_rate": 0.00014498410682131112,
      "loss": 0.3146,
      "step": 16130
    },
    {
      "epoch": 16.14,
      "learning_rate": 0.0001449751851357104,
      "loss": 0.243,
      "step": 16140
    },
    {
      "epoch": 16.15,
      "learning_rate": 0.00014496625579772866,
      "loss": 0.2615,
      "step": 16150
    },
    {
      "epoch": 16.16,
      "learning_rate": 0.00014495731880834238,
      "loss": 0.3643,
      "step": 16160
    },
    {
      "epoch": 16.17,
      "learning_rate": 0.0001449483741685289,
      "loss": 0.2423,
      "step": 16170
    },
    {
      "epoch": 16.18,
      "learning_rate": 0.00014493942187926635,
      "loss": 0.2875,
      "step": 16180
    },
    {
      "epoch": 16.19,
      "learning_rate": 0.0001449304619415338,
      "loss": 0.2113,
      "step": 16190
    },
    {
      "epoch": 16.2,
      "learning_rate": 0.0001449214943563111,
      "loss": 0.2781,
      "step": 16200
    },
    {
      "epoch": 16.21,
      "learning_rate": 0.00014491251912457888,
      "loss": 0.3291,
      "step": 16210
    },
    {
      "epoch": 16.22,
      "learning_rate": 0.00014490353624731868,
      "loss": 0.2848,
      "step": 16220
    },
    {
      "epoch": 16.23,
      "learning_rate": 0.00014489454572551283,
      "loss": 0.312,
      "step": 16230
    },
    {
      "epoch": 16.24,
      "learning_rate": 0.00014488554756014458,
      "loss": 0.2879,
      "step": 16240
    },
    {
      "epoch": 16.25,
      "learning_rate": 0.0001448765417521979,
      "loss": 0.2523,
      "step": 16250
    },
    {
      "epoch": 16.26,
      "learning_rate": 0.0001448675283026577,
      "loss": 0.3026,
      "step": 16260
    },
    {
      "epoch": 16.27,
      "learning_rate": 0.0001448585072125096,
      "loss": 0.3055,
      "step": 16270
    },
    {
      "epoch": 16.28,
      "learning_rate": 0.0001448494784827402,
      "loss": 0.2258,
      "step": 16280
    },
    {
      "epoch": 16.29,
      "learning_rate": 0.00014484044211433687,
      "loss": 0.3297,
      "step": 16290
    },
    {
      "epoch": 16.3,
      "learning_rate": 0.0001448313981082878,
      "loss": 0.3373,
      "step": 16300
    },
    {
      "epoch": 16.31,
      "learning_rate": 0.000144822346465582,
      "loss": 0.2694,
      "step": 16310
    },
    {
      "epoch": 16.32,
      "learning_rate": 0.00014481328718720935,
      "loss": 0.2928,
      "step": 16320
    },
    {
      "epoch": 16.33,
      "learning_rate": 0.00014480422027416062,
      "loss": 0.2438,
      "step": 16330
    },
    {
      "epoch": 16.34,
      "learning_rate": 0.00014479514572742728,
      "loss": 0.2642,
      "step": 16340
    },
    {
      "epoch": 16.35,
      "learning_rate": 0.00014478606354800176,
      "loss": 0.2414,
      "step": 16350
    },
    {
      "epoch": 16.36,
      "learning_rate": 0.00014477697373687723,
      "loss": 0.3107,
      "step": 16360
    },
    {
      "epoch": 16.37,
      "learning_rate": 0.00014476787629504777,
      "loss": 0.3509,
      "step": 16370
    },
    {
      "epoch": 16.38,
      "learning_rate": 0.00014475877122350825,
      "loss": 0.2677,
      "step": 16380
    },
    {
      "epoch": 16.39,
      "learning_rate": 0.0001447496585232544,
      "loss": 0.2515,
      "step": 16390
    },
    {
      "epoch": 16.4,
      "learning_rate": 0.00014474053819528275,
      "loss": 0.2336,
      "step": 16400
    },
    {
      "epoch": 16.41,
      "learning_rate": 0.0001447314102405907,
      "loss": 0.2789,
      "step": 16410
    },
    {
      "epoch": 16.42,
      "learning_rate": 0.00014472227466017648,
      "loss": 0.28,
      "step": 16420
    },
    {
      "epoch": 16.43,
      "learning_rate": 0.0001447131314550391,
      "loss": 0.2669,
      "step": 16430
    },
    {
      "epoch": 16.44,
      "learning_rate": 0.00014470398062617847,
      "loss": 0.3006,
      "step": 16440
    },
    {
      "epoch": 16.45,
      "learning_rate": 0.00014469482217459537,
      "loss": 0.2506,
      "step": 16450
    },
    {
      "epoch": 16.46,
      "learning_rate": 0.00014468565610129127,
      "loss": 0.3282,
      "step": 16460
    },
    {
      "epoch": 16.47,
      "learning_rate": 0.00014467648240726859,
      "loss": 0.3459,
      "step": 16470
    },
    {
      "epoch": 16.48,
      "learning_rate": 0.00014466730109353052,
      "loss": 0.2359,
      "step": 16480
    },
    {
      "epoch": 16.49,
      "learning_rate": 0.0001446581121610812,
      "loss": 0.286,
      "step": 16490
    },
    {
      "epoch": 16.5,
      "learning_rate": 0.00014464891561092545,
      "loss": 0.2876,
      "step": 16500
    },
    {
      "epoch": 16.51,
      "learning_rate": 0.00014463971144406898,
      "loss": 0.2768,
      "step": 16510
    },
    {
      "epoch": 16.52,
      "learning_rate": 0.00014463049966151838,
      "loss": 0.2688,
      "step": 16520
    },
    {
      "epoch": 16.53,
      "learning_rate": 0.00014462128026428104,
      "loss": 0.2806,
      "step": 16530
    },
    {
      "epoch": 16.54,
      "learning_rate": 0.00014461205325336514,
      "loss": 0.2138,
      "step": 16540
    },
    {
      "epoch": 16.55,
      "learning_rate": 0.00014460281862977976,
      "loss": 0.3257,
      "step": 16550
    },
    {
      "epoch": 16.56,
      "learning_rate": 0.0001445935763945348,
      "loss": 0.2954,
      "step": 16560
    },
    {
      "epoch": 16.57,
      "learning_rate": 0.00014458432654864095,
      "loss": 0.2951,
      "step": 16570
    },
    {
      "epoch": 16.58,
      "learning_rate": 0.00014457506909310976,
      "loss": 0.3033,
      "step": 16580
    },
    {
      "epoch": 16.59,
      "learning_rate": 0.00014456580402895361,
      "loss": 0.2594,
      "step": 16590
    },
    {
      "epoch": 16.6,
      "learning_rate": 0.00014455653135718574,
      "loss": 0.2865,
      "step": 16600
    },
    {
      "epoch": 16.61,
      "learning_rate": 0.00014454725107882017,
      "loss": 0.2107,
      "step": 16610
    },
    {
      "epoch": 16.62,
      "learning_rate": 0.0001445379631948718,
      "loss": 0.2262,
      "step": 16620
    },
    {
      "epoch": 16.63,
      "learning_rate": 0.0001445286677063563,
      "loss": 0.2276,
      "step": 16630
    },
    {
      "epoch": 16.64,
      "learning_rate": 0.00014451936461429025,
      "loss": 0.2526,
      "step": 16640
    },
    {
      "epoch": 16.65,
      "learning_rate": 0.000144510053919691,
      "loss": 0.2957,
      "step": 16650
    },
    {
      "epoch": 16.66,
      "learning_rate": 0.00014450073562357674,
      "loss": 0.2938,
      "step": 16660
    },
    {
      "epoch": 16.67,
      "learning_rate": 0.00014449140972696656,
      "loss": 0.3924,
      "step": 16670
    },
    {
      "epoch": 16.68,
      "learning_rate": 0.00014448207623088025,
      "loss": 0.3289,
      "step": 16680
    },
    {
      "epoch": 16.69,
      "learning_rate": 0.00014447273513633858,
      "loss": 0.3089,
      "step": 16690
    },
    {
      "epoch": 16.7,
      "learning_rate": 0.00014446338644436306,
      "loss": 0.3257,
      "step": 16700
    },
    {
      "epoch": 16.71,
      "learning_rate": 0.00014445403015597602,
      "loss": 0.2605,
      "step": 16710
    },
    {
      "epoch": 16.72,
      "learning_rate": 0.00014444466627220066,
      "loss": 0.2689,
      "step": 16720
    },
    {
      "epoch": 16.73,
      "learning_rate": 0.00014443529479406098,
      "loss": 0.2517,
      "step": 16730
    },
    {
      "epoch": 16.74,
      "learning_rate": 0.0001444259157225819,
      "loss": 0.2866,
      "step": 16740
    },
    {
      "epoch": 16.75,
      "learning_rate": 0.00014441652905878904,
      "loss": 0.2248,
      "step": 16750
    },
    {
      "epoch": 16.76,
      "learning_rate": 0.00014440713480370893,
      "loss": 0.2617,
      "step": 16760
    },
    {
      "epoch": 16.77,
      "learning_rate": 0.0001443977329583689,
      "loss": 0.2693,
      "step": 16770
    },
    {
      "epoch": 16.78,
      "learning_rate": 0.00014438832352379715,
      "loss": 0.2665,
      "step": 16780
    },
    {
      "epoch": 16.79,
      "learning_rate": 0.00014437890650102265,
      "loss": 0.2273,
      "step": 16790
    },
    {
      "epoch": 16.8,
      "learning_rate": 0.00014436948189107523,
      "loss": 0.2853,
      "step": 16800
    },
    {
      "epoch": 16.81,
      "learning_rate": 0.0001443600496949856,
      "loss": 0.293,
      "step": 16810
    },
    {
      "epoch": 16.82,
      "learning_rate": 0.00014435060991378518,
      "loss": 0.2572,
      "step": 16820
    },
    {
      "epoch": 16.83,
      "learning_rate": 0.00014434116254850635,
      "loss": 0.2577,
      "step": 16830
    },
    {
      "epoch": 16.84,
      "learning_rate": 0.00014433170760018224,
      "loss": 0.2671,
      "step": 16840
    },
    {
      "epoch": 16.85,
      "learning_rate": 0.0001443222450698468,
      "loss": 0.2677,
      "step": 16850
    },
    {
      "epoch": 16.86,
      "learning_rate": 0.0001443127749585349,
      "loss": 0.2168,
      "step": 16860
    },
    {
      "epoch": 16.87,
      "learning_rate": 0.00014430329726728214,
      "loss": 0.3021,
      "step": 16870
    },
    {
      "epoch": 16.88,
      "learning_rate": 0.00014429381199712493,
      "loss": 0.2636,
      "step": 16880
    },
    {
      "epoch": 16.89,
      "learning_rate": 0.00014428431914910068,
      "loss": 0.2344,
      "step": 16890
    },
    {
      "epoch": 16.9,
      "learning_rate": 0.00014427481872424745,
      "loss": 0.2811,
      "step": 16900
    },
    {
      "epoch": 16.91,
      "learning_rate": 0.00014426531072360416,
      "loss": 0.2853,
      "step": 16910
    },
    {
      "epoch": 16.92,
      "learning_rate": 0.00014425579514821066,
      "loss": 0.2872,
      "step": 16920
    },
    {
      "epoch": 16.93,
      "learning_rate": 0.0001442462719991075,
      "loss": 0.2952,
      "step": 16930
    },
    {
      "epoch": 16.94,
      "learning_rate": 0.00014423674127733618,
      "loss": 0.2797,
      "step": 16940
    },
    {
      "epoch": 16.95,
      "learning_rate": 0.0001442272029839389,
      "loss": 0.2686,
      "step": 16950
    },
    {
      "epoch": 16.96,
      "learning_rate": 0.00014421765711995882,
      "loss": 0.2751,
      "step": 16960
    },
    {
      "epoch": 16.97,
      "learning_rate": 0.0001442081036864398,
      "loss": 0.2627,
      "step": 16970
    },
    {
      "epoch": 16.98,
      "learning_rate": 0.00014419854268442662,
      "loss": 0.281,
      "step": 16980
    },
    {
      "epoch": 16.99,
      "learning_rate": 0.00014418897411496483,
      "loss": 0.2712,
      "step": 16990
    },
    {
      "epoch": 17.0,
      "learning_rate": 0.00014417939797910088,
      "loss": 0.2558,
      "step": 17000
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27476000785827637,
      "eval_runtime": 15.2894,
      "eval_samples_per_second": 130.81,
      "eval_steps_per_second": 16.351,
      "step": 17000
    },
    {
      "epoch": 17.01,
      "learning_rate": 0.00014416981427788195,
      "loss": 0.3129,
      "step": 17010
    },
    {
      "epoch": 17.02,
      "learning_rate": 0.00014416022301235614,
      "loss": 0.3061,
      "step": 17020
    },
    {
      "epoch": 17.03,
      "learning_rate": 0.00014415062418357232,
      "loss": 0.2835,
      "step": 17030
    },
    {
      "epoch": 17.04,
      "learning_rate": 0.0001441410177925802,
      "loss": 0.2253,
      "step": 17040
    },
    {
      "epoch": 17.05,
      "learning_rate": 0.00014413140384043037,
      "loss": 0.3475,
      "step": 17050
    },
    {
      "epoch": 17.06,
      "learning_rate": 0.00014412178232817412,
      "loss": 0.3436,
      "step": 17060
    },
    {
      "epoch": 17.07,
      "learning_rate": 0.00014411215325686367,
      "loss": 0.298,
      "step": 17070
    },
    {
      "epoch": 17.08,
      "learning_rate": 0.00014410251662755206,
      "loss": 0.2292,
      "step": 17080
    },
    {
      "epoch": 17.09,
      "learning_rate": 0.0001440928724412931,
      "loss": 0.207,
      "step": 17090
    },
    {
      "epoch": 17.1,
      "learning_rate": 0.00014408322069914153,
      "loss": 0.2646,
      "step": 17100
    },
    {
      "epoch": 17.11,
      "learning_rate": 0.00014407356140215278,
      "loss": 0.2519,
      "step": 17110
    },
    {
      "epoch": 17.12,
      "learning_rate": 0.00014406389455138324,
      "loss": 0.3521,
      "step": 17120
    },
    {
      "epoch": 17.13,
      "learning_rate": 0.00014405422014788998,
      "loss": 0.2275,
      "step": 17130
    },
    {
      "epoch": 17.14,
      "learning_rate": 0.00014404453819273104,
      "loss": 0.2987,
      "step": 17140
    },
    {
      "epoch": 17.15,
      "learning_rate": 0.00014403484868696524,
      "loss": 0.2615,
      "step": 17150
    },
    {
      "epoch": 17.16,
      "learning_rate": 0.00014402515163165216,
      "loss": 0.2601,
      "step": 17160
    },
    {
      "epoch": 17.17,
      "learning_rate": 0.00014401544702785229,
      "loss": 0.3549,
      "step": 17170
    },
    {
      "epoch": 17.18,
      "learning_rate": 0.00014400573487662686,
      "loss": 0.2232,
      "step": 17180
    },
    {
      "epoch": 17.19,
      "learning_rate": 0.00014399601517903806,
      "loss": 0.2834,
      "step": 17190
    },
    {
      "epoch": 17.2,
      "learning_rate": 0.00014398628793614872,
      "loss": 0.1937,
      "step": 17200
    },
    {
      "epoch": 17.21,
      "learning_rate": 0.00014397655314902269,
      "loss": 0.2909,
      "step": 17210
    },
    {
      "epoch": 17.22,
      "learning_rate": 0.00014396681081872448,
      "loss": 0.2529,
      "step": 17220
    },
    {
      "epoch": 17.23,
      "learning_rate": 0.00014395706094631956,
      "loss": 0.3182,
      "step": 17230
    },
    {
      "epoch": 17.24,
      "learning_rate": 0.00014394730353287414,
      "loss": 0.2655,
      "step": 17240
    },
    {
      "epoch": 17.25,
      "learning_rate": 0.00014393753857945525,
      "loss": 0.2937,
      "step": 17250
    },
    {
      "epoch": 17.26,
      "learning_rate": 0.00014392776608713076,
      "loss": 0.2434,
      "step": 17260
    },
    {
      "epoch": 17.27,
      "learning_rate": 0.00014391798605696942,
      "loss": 0.268,
      "step": 17270
    },
    {
      "epoch": 17.28,
      "learning_rate": 0.00014390819849004075,
      "loss": 0.2589,
      "step": 17280
    },
    {
      "epoch": 17.29,
      "learning_rate": 0.0001438984033874151,
      "loss": 0.2894,
      "step": 17290
    },
    {
      "epoch": 17.3,
      "learning_rate": 0.00014388860075016362,
      "loss": 0.2577,
      "step": 17300
    },
    {
      "epoch": 17.31,
      "learning_rate": 0.00014387879057935836,
      "loss": 0.2819,
      "step": 17310
    },
    {
      "epoch": 17.32,
      "learning_rate": 0.00014386897287607211,
      "loss": 0.2664,
      "step": 17320
    },
    {
      "epoch": 17.33,
      "learning_rate": 0.0001438601305037306,
      "loss": 0.2991,
      "step": 17330
    },
    {
      "epoch": 17.34,
      "learning_rate": 0.00014385029849168908,
      "loss": 0.3119,
      "step": 17340
    },
    {
      "epoch": 17.35,
      "learning_rate": 0.0001438404589502824,
      "loss": 0.296,
      "step": 17350
    },
    {
      "epoch": 17.36,
      "learning_rate": 0.00014383061188058665,
      "loss": 0.2376,
      "step": 17360
    },
    {
      "epoch": 17.37,
      "learning_rate": 0.0001438207572836787,
      "loss": 0.2845,
      "step": 17370
    },
    {
      "epoch": 17.38,
      "learning_rate": 0.00014381089516063618,
      "loss": 0.2723,
      "step": 17380
    },
    {
      "epoch": 17.39,
      "learning_rate": 0.0001438010255125376,
      "loss": 0.2991,
      "step": 17390
    },
    {
      "epoch": 17.4,
      "learning_rate": 0.00014379114834046233,
      "loss": 0.2785,
      "step": 17400
    },
    {
      "epoch": 17.41,
      "learning_rate": 0.00014378126364549053,
      "loss": 0.1705,
      "step": 17410
    },
    {
      "epoch": 17.42,
      "learning_rate": 0.00014377137142870312,
      "loss": 0.2697,
      "step": 17420
    },
    {
      "epoch": 17.43,
      "learning_rate": 0.00014376147169118192,
      "loss": 0.2978,
      "step": 17430
    },
    {
      "epoch": 17.44,
      "learning_rate": 0.00014375156443400955,
      "loss": 0.2531,
      "step": 17440
    },
    {
      "epoch": 17.45,
      "learning_rate": 0.00014374164965826947,
      "loss": 0.2729,
      "step": 17450
    },
    {
      "epoch": 17.46,
      "learning_rate": 0.00014373172736504596,
      "loss": 0.2555,
      "step": 17460
    },
    {
      "epoch": 17.47,
      "learning_rate": 0.00014372179755542405,
      "loss": 0.2228,
      "step": 17470
    },
    {
      "epoch": 17.48,
      "learning_rate": 0.00014371186023048969,
      "loss": 0.26,
      "step": 17480
    },
    {
      "epoch": 17.49,
      "learning_rate": 0.00014370191539132962,
      "loss": 0.2918,
      "step": 17490
    },
    {
      "epoch": 17.5,
      "learning_rate": 0.00014369196303903135,
      "loss": 0.2487,
      "step": 17500
    },
    {
      "epoch": 17.51,
      "learning_rate": 0.0001436820031746833,
      "loss": 0.2131,
      "step": 17510
    },
    {
      "epoch": 17.52,
      "learning_rate": 0.00014367203579937463,
      "loss": 0.2476,
      "step": 17520
    },
    {
      "epoch": 17.53,
      "learning_rate": 0.00014366206091419537,
      "loss": 0.2913,
      "step": 17530
    },
    {
      "epoch": 17.54,
      "learning_rate": 0.00014365207852023635,
      "loss": 0.2379,
      "step": 17540
    },
    {
      "epoch": 17.55,
      "learning_rate": 0.00014364208861858928,
      "loss": 0.3166,
      "step": 17550
    },
    {
      "epoch": 17.56,
      "learning_rate": 0.00014363209121034655,
      "loss": 0.305,
      "step": 17560
    },
    {
      "epoch": 17.57,
      "learning_rate": 0.00014362208629660153,
      "loss": 0.2399,
      "step": 17570
    },
    {
      "epoch": 17.58,
      "learning_rate": 0.00014361207387844836,
      "loss": 0.2798,
      "step": 17580
    },
    {
      "epoch": 17.59,
      "learning_rate": 0.0001436020539569819,
      "loss": 0.2862,
      "step": 17590
    },
    {
      "epoch": 17.6,
      "learning_rate": 0.00014359202653329797,
      "loss": 0.2694,
      "step": 17600
    },
    {
      "epoch": 17.61,
      "learning_rate": 0.00014358199160849317,
      "loss": 0.3331,
      "step": 17610
    },
    {
      "epoch": 17.62,
      "learning_rate": 0.00014357194918366488,
      "loss": 0.3399,
      "step": 17620
    },
    {
      "epoch": 17.63,
      "learning_rate": 0.00014356189925991128,
      "loss": 0.2557,
      "step": 17630
    },
    {
      "epoch": 17.64,
      "learning_rate": 0.0001435518418383315,
      "loss": 0.3117,
      "step": 17640
    },
    {
      "epoch": 17.65,
      "learning_rate": 0.00014354177692002534,
      "loss": 0.3189,
      "step": 17650
    },
    {
      "epoch": 17.66,
      "learning_rate": 0.0001435317045060935,
      "loss": 0.2173,
      "step": 17660
    },
    {
      "epoch": 17.67,
      "learning_rate": 0.00014352162459763752,
      "loss": 0.3018,
      "step": 17670
    },
    {
      "epoch": 17.68,
      "learning_rate": 0.0001435115371957597,
      "loss": 0.2654,
      "step": 17680
    },
    {
      "epoch": 17.69,
      "learning_rate": 0.00014350144230156314,
      "loss": 0.2789,
      "step": 17690
    },
    {
      "epoch": 17.7,
      "learning_rate": 0.00014349133991615188,
      "loss": 0.285,
      "step": 17700
    },
    {
      "epoch": 17.71,
      "learning_rate": 0.00014348123004063063,
      "loss": 0.3325,
      "step": 17710
    },
    {
      "epoch": 17.72,
      "learning_rate": 0.00014347111267610501,
      "loss": 0.3578,
      "step": 17720
    },
    {
      "epoch": 17.73,
      "learning_rate": 0.0001434609878236815,
      "loss": 0.3024,
      "step": 17730
    },
    {
      "epoch": 17.74,
      "learning_rate": 0.00014345085548446727,
      "loss": 0.2741,
      "step": 17740
    },
    {
      "epoch": 17.75,
      "learning_rate": 0.0001434407156595704,
      "loss": 0.2177,
      "step": 17750
    },
    {
      "epoch": 17.76,
      "learning_rate": 0.00014343056835009976,
      "loss": 0.2736,
      "step": 17760
    },
    {
      "epoch": 17.77,
      "learning_rate": 0.00014342041355716505,
      "loss": 0.2785,
      "step": 17770
    },
    {
      "epoch": 17.78,
      "learning_rate": 0.00014341025128187677,
      "loss": 0.2354,
      "step": 17780
    },
    {
      "epoch": 17.79,
      "learning_rate": 0.00014340008152534628,
      "loss": 0.2411,
      "step": 17790
    },
    {
      "epoch": 17.8,
      "learning_rate": 0.0001433899042886857,
      "loss": 0.3149,
      "step": 17800
    },
    {
      "epoch": 17.81,
      "learning_rate": 0.00014337971957300801,
      "loss": 0.3147,
      "step": 17810
    },
    {
      "epoch": 17.82,
      "learning_rate": 0.00014336952737942704,
      "loss": 0.3423,
      "step": 17820
    },
    {
      "epoch": 17.83,
      "learning_rate": 0.00014335932770905729,
      "loss": 0.2126,
      "step": 17830
    },
    {
      "epoch": 17.84,
      "learning_rate": 0.00014334912056301424,
      "loss": 0.2463,
      "step": 17840
    },
    {
      "epoch": 17.85,
      "learning_rate": 0.00014333890594241417,
      "loss": 0.3128,
      "step": 17850
    },
    {
      "epoch": 17.86,
      "learning_rate": 0.00014332868384837405,
      "loss": 0.2923,
      "step": 17860
    },
    {
      "epoch": 17.87,
      "learning_rate": 0.00014331845428201183,
      "loss": 0.3351,
      "step": 17870
    },
    {
      "epoch": 17.88,
      "learning_rate": 0.00014330821724444615,
      "loss": 0.3522,
      "step": 17880
    },
    {
      "epoch": 17.89,
      "learning_rate": 0.00014329797273679651,
      "loss": 0.2546,
      "step": 17890
    },
    {
      "epoch": 17.9,
      "learning_rate": 0.00014328772076018328,
      "loss": 0.2854,
      "step": 17900
    },
    {
      "epoch": 17.91,
      "learning_rate": 0.00014327746131572757,
      "loss": 0.2625,
      "step": 17910
    },
    {
      "epoch": 17.92,
      "learning_rate": 0.00014326719440455136,
      "loss": 0.2819,
      "step": 17920
    },
    {
      "epoch": 17.93,
      "learning_rate": 0.00014325692002777738,
      "loss": 0.2927,
      "step": 17930
    },
    {
      "epoch": 17.94,
      "learning_rate": 0.00014324663818652926,
      "loss": 0.3335,
      "step": 17940
    },
    {
      "epoch": 17.95,
      "learning_rate": 0.0001432363488819314,
      "loss": 0.3318,
      "step": 17950
    },
    {
      "epoch": 17.96,
      "learning_rate": 0.000143226052115109,
      "loss": 0.2905,
      "step": 17960
    },
    {
      "epoch": 17.97,
      "learning_rate": 0.00014321574788718814,
      "loss": 0.2494,
      "step": 17970
    },
    {
      "epoch": 17.98,
      "learning_rate": 0.00014320543619929566,
      "loss": 0.29,
      "step": 17980
    },
    {
      "epoch": 17.99,
      "learning_rate": 0.00014319511705255923,
      "loss": 0.2335,
      "step": 17990
    },
    {
      "epoch": 18.0,
      "learning_rate": 0.00014318479044810728,
      "loss": 0.2846,
      "step": 18000
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2733036279678345,
      "eval_runtime": 15.1355,
      "eval_samples_per_second": 132.14,
      "eval_steps_per_second": 16.517,
      "step": 18000
    },
    {
      "epoch": 18.01,
      "learning_rate": 0.0001431744563870692,
      "loss": 0.284,
      "step": 18010
    },
    {
      "epoch": 18.02,
      "learning_rate": 0.00014316411487057506,
      "loss": 0.2618,
      "step": 18020
    },
    {
      "epoch": 18.03,
      "learning_rate": 0.00014315376589975578,
      "loss": 0.3234,
      "step": 18030
    },
    {
      "epoch": 18.04,
      "learning_rate": 0.00014314340947574314,
      "loss": 0.2519,
      "step": 18040
    },
    {
      "epoch": 18.05,
      "learning_rate": 0.0001431330455996697,
      "loss": 0.2188,
      "step": 18050
    },
    {
      "epoch": 18.06,
      "learning_rate": 0.00014312267427266882,
      "loss": 0.3202,
      "step": 18060
    },
    {
      "epoch": 18.07,
      "learning_rate": 0.00014311229549587474,
      "loss": 0.2564,
      "step": 18070
    },
    {
      "epoch": 18.08,
      "learning_rate": 0.00014310190927042238,
      "loss": 0.2808,
      "step": 18080
    },
    {
      "epoch": 18.09,
      "learning_rate": 0.00014309151559744763,
      "loss": 0.3423,
      "step": 18090
    },
    {
      "epoch": 18.1,
      "learning_rate": 0.0001430811144780871,
      "loss": 0.2834,
      "step": 18100
    },
    {
      "epoch": 18.11,
      "learning_rate": 0.00014307070591347828,
      "loss": 0.3108,
      "step": 18110
    },
    {
      "epoch": 18.12,
      "learning_rate": 0.00014306028990475938,
      "loss": 0.2348,
      "step": 18120
    },
    {
      "epoch": 18.13,
      "learning_rate": 0.0001430498664530695,
      "loss": 0.2524,
      "step": 18130
    },
    {
      "epoch": 18.14,
      "learning_rate": 0.00014303943555954855,
      "loss": 0.2941,
      "step": 18140
    },
    {
      "epoch": 18.15,
      "learning_rate": 0.0001430289972253372,
      "loss": 0.2601,
      "step": 18150
    },
    {
      "epoch": 18.16,
      "learning_rate": 0.00014301855145157702,
      "loss": 0.2421,
      "step": 18160
    },
    {
      "epoch": 18.17,
      "learning_rate": 0.0001430080982394103,
      "loss": 0.2568,
      "step": 18170
    },
    {
      "epoch": 18.18,
      "learning_rate": 0.00014299763758998023,
      "loss": 0.2637,
      "step": 18180
    },
    {
      "epoch": 18.19,
      "learning_rate": 0.00014298716950443072,
      "loss": 0.2608,
      "step": 18190
    },
    {
      "epoch": 18.2,
      "learning_rate": 0.00014297669398390656,
      "loss": 0.2767,
      "step": 18200
    },
    {
      "epoch": 18.21,
      "learning_rate": 0.00014296621102955336,
      "loss": 0.2747,
      "step": 18210
    },
    {
      "epoch": 18.22,
      "learning_rate": 0.00014295572064251753,
      "loss": 0.2921,
      "step": 18220
    },
    {
      "epoch": 18.23,
      "learning_rate": 0.00014294522282394623,
      "loss": 0.3195,
      "step": 18230
    },
    {
      "epoch": 18.24,
      "learning_rate": 0.00014293471757498752,
      "loss": 0.2424,
      "step": 18240
    },
    {
      "epoch": 18.25,
      "learning_rate": 0.00014292420489679027,
      "loss": 0.2504,
      "step": 18250
    },
    {
      "epoch": 18.26,
      "learning_rate": 0.00014291368479050405,
      "loss": 0.2447,
      "step": 18260
    },
    {
      "epoch": 18.27,
      "learning_rate": 0.00014290315725727938,
      "loss": 0.2435,
      "step": 18270
    },
    {
      "epoch": 18.28,
      "learning_rate": 0.00014289262229826754,
      "loss": 0.2613,
      "step": 18280
    },
    {
      "epoch": 18.29,
      "learning_rate": 0.0001428820799146206,
      "loss": 0.3205,
      "step": 18290
    },
    {
      "epoch": 18.3,
      "learning_rate": 0.00014287153010749144,
      "loss": 0.2865,
      "step": 18300
    },
    {
      "epoch": 18.31,
      "learning_rate": 0.0001428609728780338,
      "loss": 0.2943,
      "step": 18310
    },
    {
      "epoch": 18.32,
      "learning_rate": 0.0001428504082274022,
      "loss": 0.3517,
      "step": 18320
    },
    {
      "epoch": 18.33,
      "learning_rate": 0.00014283983615675196,
      "loss": 0.3479,
      "step": 18330
    },
    {
      "epoch": 18.34,
      "learning_rate": 0.00014282925666723924,
      "loss": 0.2717,
      "step": 18340
    },
    {
      "epoch": 18.35,
      "learning_rate": 0.00014281866976002098,
      "loss": 0.2824,
      "step": 18350
    },
    {
      "epoch": 18.36,
      "learning_rate": 0.00014280807543625497,
      "loss": 0.3062,
      "step": 18360
    },
    {
      "epoch": 18.37,
      "learning_rate": 0.00014279747369709978,
      "loss": 0.2465,
      "step": 18370
    },
    {
      "epoch": 18.38,
      "learning_rate": 0.00014278686454371477,
      "loss": 0.3227,
      "step": 18380
    },
    {
      "epoch": 18.39,
      "learning_rate": 0.0001427762479772602,
      "loss": 0.2779,
      "step": 18390
    },
    {
      "epoch": 18.4,
      "learning_rate": 0.00014276562399889703,
      "loss": 0.2951,
      "step": 18400
    },
    {
      "epoch": 18.41,
      "learning_rate": 0.00014275499260978713,
      "loss": 0.313,
      "step": 18410
    },
    {
      "epoch": 18.42,
      "learning_rate": 0.0001427443538110931,
      "loss": 0.3223,
      "step": 18420
    },
    {
      "epoch": 18.43,
      "learning_rate": 0.00014273370760397837,
      "loss": 0.2603,
      "step": 18430
    },
    {
      "epoch": 18.44,
      "learning_rate": 0.00014272305398960723,
      "loss": 0.2962,
      "step": 18440
    },
    {
      "epoch": 18.45,
      "learning_rate": 0.00014271239296914472,
      "loss": 0.2868,
      "step": 18450
    },
    {
      "epoch": 18.46,
      "learning_rate": 0.0001427017245437567,
      "loss": 0.2262,
      "step": 18460
    },
    {
      "epoch": 18.47,
      "learning_rate": 0.00014269104871460992,
      "loss": 0.1557,
      "step": 18470
    },
    {
      "epoch": 18.48,
      "learning_rate": 0.0001426803654828718,
      "loss": 0.26,
      "step": 18480
    },
    {
      "epoch": 18.49,
      "learning_rate": 0.00014266967484971064,
      "loss": 0.2789,
      "step": 18490
    },
    {
      "epoch": 18.5,
      "learning_rate": 0.0001426589768162956,
      "loss": 0.2452,
      "step": 18500
    },
    {
      "epoch": 18.51,
      "learning_rate": 0.00014264827138379659,
      "loss": 0.2868,
      "step": 18510
    },
    {
      "epoch": 18.52,
      "learning_rate": 0.00014263755855338433,
      "loss": 0.2831,
      "step": 18520
    },
    {
      "epoch": 18.53,
      "learning_rate": 0.00014262683832623035,
      "loss": 0.2775,
      "step": 18530
    },
    {
      "epoch": 18.54,
      "learning_rate": 0.000142616110703507,
      "loss": 0.3395,
      "step": 18540
    },
    {
      "epoch": 18.55,
      "learning_rate": 0.00014260537568638743,
      "loss": 0.3114,
      "step": 18550
    },
    {
      "epoch": 18.56,
      "learning_rate": 0.00014259463327604563,
      "loss": 0.2613,
      "step": 18560
    },
    {
      "epoch": 18.57,
      "learning_rate": 0.00014258388347365637,
      "loss": 0.2423,
      "step": 18570
    },
    {
      "epoch": 18.58,
      "learning_rate": 0.00014257312628039522,
      "loss": 0.3059,
      "step": 18580
    },
    {
      "epoch": 18.59,
      "learning_rate": 0.00014256236169743857,
      "loss": 0.2336,
      "step": 18590
    },
    {
      "epoch": 18.6,
      "learning_rate": 0.00014255158972596366,
      "loss": 0.2784,
      "step": 18600
    },
    {
      "epoch": 18.61,
      "learning_rate": 0.00014254081036714839,
      "loss": 0.2863,
      "step": 18610
    },
    {
      "epoch": 18.62,
      "learning_rate": 0.0001425300236221717,
      "loss": 0.2602,
      "step": 18620
    },
    {
      "epoch": 18.63,
      "learning_rate": 0.00014251922949221315,
      "loss": 0.2428,
      "step": 18630
    },
    {
      "epoch": 18.64,
      "learning_rate": 0.00014250842797845314,
      "loss": 0.3464,
      "step": 18640
    },
    {
      "epoch": 18.65,
      "learning_rate": 0.00014249761908207296,
      "loss": 0.2423,
      "step": 18650
    },
    {
      "epoch": 18.66,
      "learning_rate": 0.00014248680280425465,
      "loss": 0.2138,
      "step": 18660
    },
    {
      "epoch": 18.67,
      "learning_rate": 0.00014247597914618105,
      "loss": 0.2991,
      "step": 18670
    },
    {
      "epoch": 18.68,
      "learning_rate": 0.00014246514810903582,
      "loss": 0.2417,
      "step": 18680
    },
    {
      "epoch": 18.69,
      "learning_rate": 0.0001424543096940034,
      "loss": 0.2874,
      "step": 18690
    },
    {
      "epoch": 18.7,
      "learning_rate": 0.00014244346390226913,
      "loss": 0.3211,
      "step": 18700
    },
    {
      "epoch": 18.71,
      "learning_rate": 0.00014243261073501902,
      "loss": 0.2493,
      "step": 18710
    },
    {
      "epoch": 18.72,
      "learning_rate": 0.00014242175019344,
      "loss": 0.2748,
      "step": 18720
    },
    {
      "epoch": 18.73,
      "learning_rate": 0.00014241088227871974,
      "loss": 0.2355,
      "step": 18730
    },
    {
      "epoch": 18.74,
      "learning_rate": 0.00014240000699204674,
      "loss": 0.286,
      "step": 18740
    },
    {
      "epoch": 18.75,
      "learning_rate": 0.0001423891243346103,
      "loss": 0.3205,
      "step": 18750
    },
    {
      "epoch": 18.76,
      "learning_rate": 0.00014237823430760058,
      "loss": 0.3076,
      "step": 18760
    },
    {
      "epoch": 18.77,
      "learning_rate": 0.0001423673369122084,
      "loss": 0.273,
      "step": 18770
    },
    {
      "epoch": 18.78,
      "learning_rate": 0.00014235643214962558,
      "loss": 0.2683,
      "step": 18780
    },
    {
      "epoch": 18.79,
      "learning_rate": 0.0001423455200210446,
      "loss": 0.3036,
      "step": 18790
    },
    {
      "epoch": 18.8,
      "learning_rate": 0.0001423346005276588,
      "loss": 0.2795,
      "step": 18800
    },
    {
      "epoch": 18.81,
      "learning_rate": 0.00014232367367066233,
      "loss": 0.3209,
      "step": 18810
    },
    {
      "epoch": 18.82,
      "learning_rate": 0.0001423127394512501,
      "loss": 0.2764,
      "step": 18820
    },
    {
      "epoch": 18.83,
      "learning_rate": 0.00014230179787061791,
      "loss": 0.2065,
      "step": 18830
    },
    {
      "epoch": 18.84,
      "learning_rate": 0.0001422908489299623,
      "loss": 0.3471,
      "step": 18840
    },
    {
      "epoch": 18.85,
      "learning_rate": 0.00014227989263048064,
      "loss": 0.2761,
      "step": 18850
    },
    {
      "epoch": 18.86,
      "learning_rate": 0.00014226892897337102,
      "loss": 0.2702,
      "step": 18860
    },
    {
      "epoch": 18.87,
      "learning_rate": 0.0001422579579598325,
      "loss": 0.3043,
      "step": 18870
    },
    {
      "epoch": 18.88,
      "learning_rate": 0.00014224697959106482,
      "loss": 0.3212,
      "step": 18880
    },
    {
      "epoch": 18.89,
      "learning_rate": 0.00014223599386826852,
      "loss": 0.2703,
      "step": 18890
    },
    {
      "epoch": 18.9,
      "learning_rate": 0.00014222500079264506,
      "loss": 0.3204,
      "step": 18900
    },
    {
      "epoch": 18.91,
      "learning_rate": 0.00014221400036539656,
      "loss": 0.2762,
      "step": 18910
    },
    {
      "epoch": 18.92,
      "learning_rate": 0.00014220299258772606,
      "loss": 0.2696,
      "step": 18920
    },
    {
      "epoch": 18.93,
      "learning_rate": 0.0001421919774608373,
      "loss": 0.2691,
      "step": 18930
    },
    {
      "epoch": 18.94,
      "learning_rate": 0.00014218095498593492,
      "loss": 0.2429,
      "step": 18940
    },
    {
      "epoch": 18.95,
      "learning_rate": 0.0001421699251642243,
      "loss": 0.2159,
      "step": 18950
    },
    {
      "epoch": 18.96,
      "learning_rate": 0.00014215888799691168,
      "loss": 0.3261,
      "step": 18960
    },
    {
      "epoch": 18.97,
      "learning_rate": 0.000142147843485204,
      "loss": 0.2949,
      "step": 18970
    },
    {
      "epoch": 18.98,
      "learning_rate": 0.00014213679163030914,
      "loss": 0.2823,
      "step": 18980
    },
    {
      "epoch": 18.99,
      "learning_rate": 0.00014212573243343568,
      "loss": 0.3105,
      "step": 18990
    },
    {
      "epoch": 19.0,
      "learning_rate": 0.00014211466589579303,
      "loss": 0.3395,
      "step": 19000
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2733384370803833,
      "eval_runtime": 14.8286,
      "eval_samples_per_second": 134.875,
      "eval_steps_per_second": 16.859,
      "step": 19000
    },
    {
      "epoch": 19.01,
      "learning_rate": 0.00014210359201859144,
      "loss": 0.2788,
      "step": 19010
    },
    {
      "epoch": 19.02,
      "learning_rate": 0.0001420925108030419,
      "loss": 0.3033,
      "step": 19020
    },
    {
      "epoch": 19.03,
      "learning_rate": 0.00014208142225035627,
      "loss": 0.2711,
      "step": 19030
    },
    {
      "epoch": 19.04,
      "learning_rate": 0.00014207032636174714,
      "loss": 0.2173,
      "step": 19040
    },
    {
      "epoch": 19.05,
      "learning_rate": 0.000142059223138428,
      "loss": 0.2695,
      "step": 19050
    },
    {
      "epoch": 19.06,
      "learning_rate": 0.00014204811258161298,
      "loss": 0.3391,
      "step": 19060
    },
    {
      "epoch": 19.07,
      "learning_rate": 0.0001420369946925172,
      "loss": 0.2307,
      "step": 19070
    },
    {
      "epoch": 19.08,
      "learning_rate": 0.00014202586947235647,
      "loss": 0.3016,
      "step": 19080
    },
    {
      "epoch": 19.09,
      "learning_rate": 0.00014201473692234743,
      "loss": 0.261,
      "step": 19090
    },
    {
      "epoch": 19.1,
      "learning_rate": 0.0001420035970437075,
      "loss": 0.3319,
      "step": 19100
    },
    {
      "epoch": 19.11,
      "learning_rate": 0.00014199244983765494,
      "loss": 0.2448,
      "step": 19110
    },
    {
      "epoch": 19.12,
      "learning_rate": 0.0001419812953054088,
      "loss": 0.2519,
      "step": 19120
    },
    {
      "epoch": 19.13,
      "learning_rate": 0.0001419701334481889,
      "loss": 0.3191,
      "step": 19130
    },
    {
      "epoch": 19.14,
      "learning_rate": 0.0001419589642672159,
      "loss": 0.2478,
      "step": 19140
    },
    {
      "epoch": 19.15,
      "learning_rate": 0.00014194778776371124,
      "loss": 0.2133,
      "step": 19150
    },
    {
      "epoch": 19.16,
      "learning_rate": 0.0001419366039388972,
      "loss": 0.2865,
      "step": 19160
    },
    {
      "epoch": 19.17,
      "learning_rate": 0.0001419254127939967,
      "loss": 0.3479,
      "step": 19170
    },
    {
      "epoch": 19.18,
      "learning_rate": 0.00014191421433023372,
      "loss": 0.2295,
      "step": 19180
    },
    {
      "epoch": 19.19,
      "learning_rate": 0.00014190300854883292,
      "loss": 0.2644,
      "step": 19190
    },
    {
      "epoch": 19.2,
      "learning_rate": 0.00014189179545101962,
      "loss": 0.3069,
      "step": 19200
    },
    {
      "epoch": 19.21,
      "learning_rate": 0.00014188057503802017,
      "loss": 0.2351,
      "step": 19210
    },
    {
      "epoch": 19.22,
      "learning_rate": 0.0001418693473110616,
      "loss": 0.2389,
      "step": 19220
    },
    {
      "epoch": 19.23,
      "learning_rate": 0.00014185811227137172,
      "loss": 0.3763,
      "step": 19230
    },
    {
      "epoch": 19.24,
      "learning_rate": 0.0001418468699201792,
      "loss": 0.2363,
      "step": 19240
    },
    {
      "epoch": 19.25,
      "learning_rate": 0.00014183562025871352,
      "loss": 0.2691,
      "step": 19250
    },
    {
      "epoch": 19.26,
      "learning_rate": 0.00014182436328820486,
      "loss": 0.2535,
      "step": 19260
    },
    {
      "epoch": 19.27,
      "learning_rate": 0.0001418130990098843,
      "loss": 0.2499,
      "step": 19270
    },
    {
      "epoch": 19.28,
      "learning_rate": 0.00014180182742498372,
      "loss": 0.2547,
      "step": 19280
    },
    {
      "epoch": 19.29,
      "learning_rate": 0.00014179054853473568,
      "loss": 0.3254,
      "step": 19290
    },
    {
      "epoch": 19.3,
      "learning_rate": 0.0001417792623403737,
      "loss": 0.2444,
      "step": 19300
    },
    {
      "epoch": 19.31,
      "learning_rate": 0.000141767968843132,
      "loss": 0.2644,
      "step": 19310
    },
    {
      "epoch": 19.32,
      "learning_rate": 0.0001417566680442456,
      "loss": 0.2748,
      "step": 19320
    },
    {
      "epoch": 19.33,
      "learning_rate": 0.00014174535994495034,
      "loss": 0.2384,
      "step": 19330
    },
    {
      "epoch": 19.34,
      "learning_rate": 0.00014173404454648287,
      "loss": 0.2681,
      "step": 19340
    },
    {
      "epoch": 19.35,
      "learning_rate": 0.00014172272185008063,
      "loss": 0.3081,
      "step": 19350
    },
    {
      "epoch": 19.36,
      "learning_rate": 0.00014171139185698183,
      "loss": 0.3019,
      "step": 19360
    },
    {
      "epoch": 19.37,
      "learning_rate": 0.00014170005456842555,
      "loss": 0.2592,
      "step": 19370
    },
    {
      "epoch": 19.38,
      "learning_rate": 0.00014168870998565157,
      "loss": 0.2819,
      "step": 19380
    },
    {
      "epoch": 19.39,
      "learning_rate": 0.0001416784936256242,
      "loss": 0.2707,
      "step": 19390
    },
    {
      "epoch": 19.4,
      "learning_rate": 0.00014166713518725519,
      "loss": 0.2767,
      "step": 19400
    },
    {
      "epoch": 19.41,
      "learning_rate": 0.0001416557694582685,
      "loss": 0.2866,
      "step": 19410
    },
    {
      "epoch": 19.42,
      "learning_rate": 0.0001416443964399071,
      "loss": 0.374,
      "step": 19420
    },
    {
      "epoch": 19.43,
      "learning_rate": 0.0001416330161334147,
      "loss": 0.2942,
      "step": 19430
    },
    {
      "epoch": 19.44,
      "learning_rate": 0.00014162162854003583,
      "loss": 0.2087,
      "step": 19440
    },
    {
      "epoch": 19.45,
      "learning_rate": 0.00014161023366101582,
      "loss": 0.2358,
      "step": 19450
    },
    {
      "epoch": 19.46,
      "learning_rate": 0.0001415988314976008,
      "loss": 0.2187,
      "step": 19460
    },
    {
      "epoch": 19.47,
      "learning_rate": 0.00014158742205103774,
      "loss": 0.2793,
      "step": 19470
    },
    {
      "epoch": 19.48,
      "learning_rate": 0.00014157600532257428,
      "loss": 0.285,
      "step": 19480
    },
    {
      "epoch": 19.49,
      "learning_rate": 0.000141564581313459,
      "loss": 0.3227,
      "step": 19490
    },
    {
      "epoch": 19.5,
      "learning_rate": 0.00014155315002494114,
      "loss": 0.3434,
      "step": 19500
    },
    {
      "epoch": 19.51,
      "learning_rate": 0.00014154171145827087,
      "loss": 0.3124,
      "step": 19510
    },
    {
      "epoch": 19.52,
      "learning_rate": 0.00014153026561469908,
      "loss": 0.2867,
      "step": 19520
    },
    {
      "epoch": 19.53,
      "learning_rate": 0.00014151881249547748,
      "loss": 0.2948,
      "step": 19530
    },
    {
      "epoch": 19.54,
      "learning_rate": 0.00014150735210185857,
      "loss": 0.2671,
      "step": 19540
    },
    {
      "epoch": 19.55,
      "learning_rate": 0.0001414958844350956,
      "loss": 0.2531,
      "step": 19550
    },
    {
      "epoch": 19.56,
      "learning_rate": 0.00014148440949644268,
      "loss": 0.2079,
      "step": 19560
    },
    {
      "epoch": 19.57,
      "learning_rate": 0.0001414729272871547,
      "loss": 0.311,
      "step": 19570
    },
    {
      "epoch": 19.58,
      "learning_rate": 0.00014146143780848736,
      "loss": 0.2639,
      "step": 19580
    },
    {
      "epoch": 19.59,
      "learning_rate": 0.00014144994106169708,
      "loss": 0.2784,
      "step": 19590
    },
    {
      "epoch": 19.6,
      "learning_rate": 0.00014143843704804115,
      "loss": 0.2607,
      "step": 19600
    },
    {
      "epoch": 19.61,
      "learning_rate": 0.00014142692576877763,
      "loss": 0.2397,
      "step": 19610
    },
    {
      "epoch": 19.62,
      "learning_rate": 0.00014141540722516541,
      "loss": 0.313,
      "step": 19620
    },
    {
      "epoch": 19.63,
      "learning_rate": 0.00014140388141846408,
      "loss": 0.2621,
      "step": 19630
    },
    {
      "epoch": 19.64,
      "learning_rate": 0.00014139234834993413,
      "loss": 0.1852,
      "step": 19640
    },
    {
      "epoch": 19.65,
      "learning_rate": 0.00014138080802083677,
      "loss": 0.2802,
      "step": 19650
    },
    {
      "epoch": 19.66,
      "learning_rate": 0.00014136926043243405,
      "loss": 0.3194,
      "step": 19660
    },
    {
      "epoch": 19.67,
      "learning_rate": 0.0001413577055859888,
      "loss": 0.288,
      "step": 19670
    },
    {
      "epoch": 19.68,
      "learning_rate": 0.00014134614348276466,
      "loss": 0.3578,
      "step": 19680
    },
    {
      "epoch": 19.69,
      "learning_rate": 0.00014133457412402598,
      "loss": 0.3573,
      "step": 19690
    },
    {
      "epoch": 19.7,
      "learning_rate": 0.000141322997511038,
      "loss": 0.2603,
      "step": 19700
    },
    {
      "epoch": 19.71,
      "learning_rate": 0.00014131141364506674,
      "loss": 0.2595,
      "step": 19710
    },
    {
      "epoch": 19.72,
      "learning_rate": 0.000141299822527379,
      "loss": 0.2307,
      "step": 19720
    },
    {
      "epoch": 19.73,
      "learning_rate": 0.00014128822415924235,
      "loss": 0.2696,
      "step": 19730
    },
    {
      "epoch": 19.74,
      "learning_rate": 0.00014127661854192514,
      "loss": 0.2434,
      "step": 19740
    },
    {
      "epoch": 19.75,
      "learning_rate": 0.0001412650056766966,
      "loss": 0.2866,
      "step": 19750
    },
    {
      "epoch": 19.76,
      "learning_rate": 0.00014125338556482663,
      "loss": 0.2602,
      "step": 19760
    },
    {
      "epoch": 19.77,
      "learning_rate": 0.00014124175820758603,
      "loss": 0.2778,
      "step": 19770
    },
    {
      "epoch": 19.78,
      "learning_rate": 0.0001412301236062464,
      "loss": 0.3004,
      "step": 19780
    },
    {
      "epoch": 19.79,
      "learning_rate": 0.00014121848176207997,
      "loss": 0.2621,
      "step": 19790
    },
    {
      "epoch": 19.8,
      "learning_rate": 0.00014120683267635997,
      "loss": 0.9562,
      "step": 19800
    },
    {
      "epoch": 19.81,
      "learning_rate": 0.00014119517635036025,
      "loss": 0.7632,
      "step": 19810
    },
    {
      "epoch": 19.82,
      "learning_rate": 0.00014118467946757493,
      "loss": 0.8693,
      "step": 19820
    },
    {
      "epoch": 19.83,
      "learning_rate": 0.00014117300938855634,
      "loss": 1.0927,
      "step": 19830
    },
    {
      "epoch": 19.84,
      "learning_rate": 0.00014116133207295694,
      "loss": 0.346,
      "step": 19840
    },
    {
      "epoch": 19.85,
      "learning_rate": 0.00014114964752205374,
      "loss": 0.4052,
      "step": 19850
    },
    {
      "epoch": 19.86,
      "learning_rate": 0.00014113795573712453,
      "loss": 0.4306,
      "step": 19860
    },
    {
      "epoch": 19.87,
      "learning_rate": 0.0001411262567194479,
      "loss": 0.2536,
      "step": 19870
    },
    {
      "epoch": 19.88,
      "learning_rate": 0.0001411145504703033,
      "loss": 0.3415,
      "step": 19880
    },
    {
      "epoch": 19.89,
      "learning_rate": 0.00014110283699097083,
      "loss": 0.3205,
      "step": 19890
    },
    {
      "epoch": 19.9,
      "learning_rate": 0.0001410911162827315,
      "loss": 0.3058,
      "step": 19900
    },
    {
      "epoch": 19.91,
      "learning_rate": 0.00014107938834686707,
      "loss": 0.3177,
      "step": 19910
    },
    {
      "epoch": 19.92,
      "learning_rate": 0.00014106765318466004,
      "loss": 0.3177,
      "step": 19920
    },
    {
      "epoch": 19.93,
      "learning_rate": 0.00014105591079739384,
      "loss": 0.2857,
      "step": 19930
    },
    {
      "epoch": 19.94,
      "learning_rate": 0.00014104416118635251,
      "loss": 0.3158,
      "step": 19940
    },
    {
      "epoch": 19.95,
      "learning_rate": 0.000141032404352821,
      "loss": 0.2996,
      "step": 19950
    },
    {
      "epoch": 19.96,
      "learning_rate": 0.00014102064029808506,
      "loss": 0.3498,
      "step": 19960
    },
    {
      "epoch": 19.97,
      "learning_rate": 0.00014100886902343115,
      "loss": 0.2592,
      "step": 19970
    },
    {
      "epoch": 19.98,
      "learning_rate": 0.00014099709053014658,
      "loss": 0.2598,
      "step": 19980
    },
    {
      "epoch": 19.99,
      "learning_rate": 0.00014098530481951942,
      "loss": 0.2179,
      "step": 19990
    },
    {
      "epoch": 20.0,
      "learning_rate": 0.0001409735118928385,
      "loss": 0.2198,
      "step": 20000
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2774011194705963,
      "eval_runtime": 14.8933,
      "eval_samples_per_second": 134.288,
      "eval_steps_per_second": 16.786,
      "step": 20000
    },
    {
      "epoch": 20.01,
      "learning_rate": 0.00014096171175139352,
      "loss": 0.2664,
      "step": 20010
    },
    {
      "epoch": 20.02,
      "learning_rate": 0.00014094990439647491,
      "loss": 0.3475,
      "step": 20020
    },
    {
      "epoch": 20.03,
      "learning_rate": 0.0001409380898293739,
      "loss": 0.3138,
      "step": 20030
    },
    {
      "epoch": 20.04,
      "learning_rate": 0.00014092626805138256,
      "loss": 0.2664,
      "step": 20040
    },
    {
      "epoch": 20.05,
      "learning_rate": 0.00014091443906379364,
      "loss": 0.1971,
      "step": 20050
    },
    {
      "epoch": 20.06,
      "learning_rate": 0.00014090260286790077,
      "loss": 0.1358,
      "step": 20060
    },
    {
      "epoch": 20.07,
      "learning_rate": 0.0001408907594649983,
      "loss": 0.3112,
      "step": 20070
    },
    {
      "epoch": 20.08,
      "learning_rate": 0.0001408789088563815,
      "loss": 0.2185,
      "step": 20080
    },
    {
      "epoch": 20.09,
      "learning_rate": 0.00014086705104334626,
      "loss": 0.2008,
      "step": 20090
    },
    {
      "epoch": 20.1,
      "learning_rate": 0.00014085518602718932,
      "loss": 0.2129,
      "step": 20100
    },
    {
      "epoch": 20.11,
      "learning_rate": 0.00014084331380920828,
      "loss": 0.247,
      "step": 20110
    },
    {
      "epoch": 20.12,
      "learning_rate": 0.0001408314343907014,
      "loss": 0.253,
      "step": 20120
    },
    {
      "epoch": 20.13,
      "learning_rate": 0.00014081954777296784,
      "loss": 0.3502,
      "step": 20130
    },
    {
      "epoch": 20.14,
      "learning_rate": 0.00014080765395730753,
      "loss": 0.3114,
      "step": 20140
    },
    {
      "epoch": 20.15,
      "learning_rate": 0.00014079575294502107,
      "loss": 0.3023,
      "step": 20150
    },
    {
      "epoch": 20.16,
      "learning_rate": 0.00014078384473741002,
      "loss": 0.2605,
      "step": 20160
    },
    {
      "epoch": 20.17,
      "learning_rate": 0.0001407719293357766,
      "loss": 0.2248,
      "step": 20170
    },
    {
      "epoch": 20.18,
      "learning_rate": 0.00014076000674142388,
      "loss": 0.3175,
      "step": 20180
    },
    {
      "epoch": 20.19,
      "learning_rate": 0.00014074807695565572,
      "loss": 0.2814,
      "step": 20190
    },
    {
      "epoch": 20.2,
      "learning_rate": 0.0001407361399797767,
      "loss": 0.3171,
      "step": 20200
    },
    {
      "epoch": 20.21,
      "learning_rate": 0.0001407241958150922,
      "loss": 0.348,
      "step": 20210
    },
    {
      "epoch": 20.22,
      "learning_rate": 0.0001407122444629085,
      "loss": 0.2522,
      "step": 20220
    },
    {
      "epoch": 20.23,
      "learning_rate": 0.00014070028592453256,
      "loss": 0.2529,
      "step": 20230
    },
    {
      "epoch": 20.24,
      "learning_rate": 0.0001406883202012721,
      "loss": 0.2966,
      "step": 20240
    },
    {
      "epoch": 20.25,
      "learning_rate": 0.0001406763472944357,
      "loss": 0.3039,
      "step": 20250
    },
    {
      "epoch": 20.26,
      "learning_rate": 0.00014066436720533274,
      "loss": 0.3127,
      "step": 20260
    },
    {
      "epoch": 20.27,
      "learning_rate": 0.00014065237993527327,
      "loss": 0.3126,
      "step": 20270
    },
    {
      "epoch": 20.28,
      "learning_rate": 0.00014064038548556825,
      "loss": 0.2689,
      "step": 20280
    },
    {
      "epoch": 20.29,
      "learning_rate": 0.00014062838385752938,
      "loss": 0.2679,
      "step": 20290
    },
    {
      "epoch": 20.3,
      "learning_rate": 0.0001406163750524691,
      "loss": 0.3142,
      "step": 20300
    },
    {
      "epoch": 20.31,
      "learning_rate": 0.0001406043590717007,
      "loss": 0.3164,
      "step": 20310
    },
    {
      "epoch": 20.32,
      "learning_rate": 0.00014059233591653822,
      "loss": 0.3527,
      "step": 20320
    },
    {
      "epoch": 20.33,
      "learning_rate": 0.00014058030558829652,
      "loss": 0.3003,
      "step": 20330
    },
    {
      "epoch": 20.34,
      "learning_rate": 0.0001405682680882912,
      "loss": 0.2501,
      "step": 20340
    },
    {
      "epoch": 20.35,
      "learning_rate": 0.00014055622341783863,
      "loss": 0.2598,
      "step": 20350
    },
    {
      "epoch": 20.36,
      "learning_rate": 0.00014054417157825607,
      "loss": 0.2801,
      "step": 20360
    },
    {
      "epoch": 20.37,
      "learning_rate": 0.00014053211257086142,
      "loss": 0.267,
      "step": 20370
    },
    {
      "epoch": 20.38,
      "learning_rate": 0.00014052004639697347,
      "loss": 0.285,
      "step": 20380
    },
    {
      "epoch": 20.39,
      "learning_rate": 0.00014050797305791175,
      "loss": 0.2272,
      "step": 20390
    },
    {
      "epoch": 20.4,
      "learning_rate": 0.0001404958925549966,
      "loss": 0.2439,
      "step": 20400
    },
    {
      "epoch": 20.41,
      "learning_rate": 0.0001404838048895491,
      "loss": 0.3207,
      "step": 20410
    },
    {
      "epoch": 20.42,
      "learning_rate": 0.00014047171006289117,
      "loss": 0.2447,
      "step": 20420
    },
    {
      "epoch": 20.43,
      "learning_rate": 0.00014045960807634544,
      "loss": 0.3636,
      "step": 20430
    },
    {
      "epoch": 20.44,
      "learning_rate": 0.00014044749893123542,
      "loss": 0.2549,
      "step": 20440
    },
    {
      "epoch": 20.45,
      "learning_rate": 0.0001404353826288853,
      "loss": 0.2927,
      "step": 20450
    },
    {
      "epoch": 20.46,
      "learning_rate": 0.00014042325917062009,
      "loss": 0.1993,
      "step": 20460
    },
    {
      "epoch": 20.47,
      "learning_rate": 0.00014041112855776562,
      "loss": 0.2852,
      "step": 20470
    },
    {
      "epoch": 20.48,
      "learning_rate": 0.00014039899079164853,
      "loss": 0.2553,
      "step": 20480
    },
    {
      "epoch": 20.49,
      "learning_rate": 0.0001403868458735961,
      "loss": 0.257,
      "step": 20490
    },
    {
      "epoch": 20.5,
      "learning_rate": 0.00014037469380493648,
      "loss": 0.2463,
      "step": 20500
    },
    {
      "epoch": 20.51,
      "learning_rate": 0.0001403625345869987,
      "loss": 0.2644,
      "step": 20510
    },
    {
      "epoch": 20.52,
      "learning_rate": 0.00014035036822111234,
      "loss": 0.3114,
      "step": 20520
    },
    {
      "epoch": 20.53,
      "learning_rate": 0.000140338194708608,
      "loss": 0.3086,
      "step": 20530
    },
    {
      "epoch": 20.54,
      "learning_rate": 0.00014032601405081693,
      "loss": 0.3324,
      "step": 20540
    },
    {
      "epoch": 20.55,
      "learning_rate": 0.00014031382624907118,
      "loss": 0.2893,
      "step": 20550
    },
    {
      "epoch": 20.56,
      "learning_rate": 0.00014030163130470357,
      "loss": 0.2837,
      "step": 20560
    },
    {
      "epoch": 20.57,
      "learning_rate": 0.00014028942921904777,
      "loss": 0.26,
      "step": 20570
    },
    {
      "epoch": 20.58,
      "learning_rate": 0.0001402772199934381,
      "loss": 0.3554,
      "step": 20580
    },
    {
      "epoch": 20.59,
      "learning_rate": 0.00014026500362920982,
      "loss": 0.3035,
      "step": 20590
    },
    {
      "epoch": 20.6,
      "learning_rate": 0.00014025278012769888,
      "loss": 0.3213,
      "step": 20600
    },
    {
      "epoch": 20.61,
      "learning_rate": 0.00014024054949024202,
      "loss": 0.2428,
      "step": 20610
    },
    {
      "epoch": 20.62,
      "learning_rate": 0.00014022831171817672,
      "loss": 0.2861,
      "step": 20620
    },
    {
      "epoch": 20.63,
      "learning_rate": 0.00014021606681284134,
      "loss": 0.1901,
      "step": 20630
    },
    {
      "epoch": 20.64,
      "learning_rate": 0.00014020381477557496,
      "loss": 0.2515,
      "step": 20640
    },
    {
      "epoch": 20.65,
      "learning_rate": 0.0001401915556077174,
      "loss": 0.2973,
      "step": 20650
    },
    {
      "epoch": 20.66,
      "learning_rate": 0.00014017928931060936,
      "loss": 0.2227,
      "step": 20660
    },
    {
      "epoch": 20.67,
      "learning_rate": 0.00014016701588559223,
      "loss": 0.3141,
      "step": 20670
    },
    {
      "epoch": 20.68,
      "learning_rate": 0.0001401547353340082,
      "loss": 0.2849,
      "step": 20680
    },
    {
      "epoch": 20.69,
      "learning_rate": 0.0001401424476572003,
      "loss": 0.3327,
      "step": 20690
    },
    {
      "epoch": 20.7,
      "learning_rate": 0.00014013015285651223,
      "loss": 0.2961,
      "step": 20700
    },
    {
      "epoch": 20.71,
      "learning_rate": 0.00014011785093328858,
      "loss": 0.284,
      "step": 20710
    },
    {
      "epoch": 20.72,
      "learning_rate": 0.00014010554188887466,
      "loss": 0.2546,
      "step": 20720
    },
    {
      "epoch": 20.73,
      "learning_rate": 0.00014009322572461656,
      "loss": 0.304,
      "step": 20730
    },
    {
      "epoch": 20.74,
      "learning_rate": 0.00014008090244186118,
      "loss": 0.3137,
      "step": 20740
    },
    {
      "epoch": 20.75,
      "learning_rate": 0.00014006857204195615,
      "loss": 0.2255,
      "step": 20750
    },
    {
      "epoch": 20.76,
      "learning_rate": 0.00014005623452624988,
      "loss": 0.3156,
      "step": 20760
    },
    {
      "epoch": 20.77,
      "learning_rate": 0.00014004388989609162,
      "loss": 0.2631,
      "step": 20770
    },
    {
      "epoch": 20.78,
      "learning_rate": 0.0001400315381528314,
      "loss": 0.2199,
      "step": 20780
    },
    {
      "epoch": 20.79,
      "learning_rate": 0.00014001917929781988,
      "loss": 0.2639,
      "step": 20790
    },
    {
      "epoch": 20.8,
      "learning_rate": 0.0001400068133324087,
      "loss": 0.2148,
      "step": 20800
    },
    {
      "epoch": 20.81,
      "learning_rate": 0.00013999444025795013,
      "loss": 0.2505,
      "step": 20810
    },
    {
      "epoch": 20.82,
      "learning_rate": 0.0001399820600757973,
      "loss": 0.2818,
      "step": 20820
    },
    {
      "epoch": 20.83,
      "learning_rate": 0.00013996967278730413,
      "loss": 0.3097,
      "step": 20830
    },
    {
      "epoch": 20.84,
      "learning_rate": 0.00013995727839382518,
      "loss": 0.298,
      "step": 20840
    },
    {
      "epoch": 20.85,
      "learning_rate": 0.00013994487689671589,
      "loss": 0.2809,
      "step": 20850
    },
    {
      "epoch": 20.86,
      "learning_rate": 0.00013993246829733255,
      "loss": 0.3203,
      "step": 20860
    },
    {
      "epoch": 20.87,
      "learning_rate": 0.0001399200525970321,
      "loss": 0.3034,
      "step": 20870
    },
    {
      "epoch": 20.88,
      "learning_rate": 0.0001399076297971723,
      "loss": 0.2102,
      "step": 20880
    },
    {
      "epoch": 20.89,
      "learning_rate": 0.0001398951998991117,
      "loss": 0.286,
      "step": 20890
    },
    {
      "epoch": 20.9,
      "learning_rate": 0.0001398827629042096,
      "loss": 0.3065,
      "step": 20900
    },
    {
      "epoch": 20.91,
      "learning_rate": 0.0001398703188138261,
      "loss": 0.2882,
      "step": 20910
    },
    {
      "epoch": 20.92,
      "learning_rate": 0.00013985786762932205,
      "loss": 0.2674,
      "step": 20920
    },
    {
      "epoch": 20.93,
      "learning_rate": 0.00013984540935205913,
      "loss": 0.2718,
      "step": 20930
    },
    {
      "epoch": 20.94,
      "learning_rate": 0.0001398329439833997,
      "loss": 0.3124,
      "step": 20940
    },
    {
      "epoch": 20.95,
      "learning_rate": 0.00013982047152470703,
      "loss": 0.33,
      "step": 20950
    },
    {
      "epoch": 20.96,
      "learning_rate": 0.00013980799197734503,
      "loss": 0.3275,
      "step": 20960
    },
    {
      "epoch": 20.97,
      "learning_rate": 0.0001397955053426785,
      "loss": 0.2678,
      "step": 20970
    },
    {
      "epoch": 20.98,
      "learning_rate": 0.00013978301162207286,
      "loss": 0.2512,
      "step": 20980
    },
    {
      "epoch": 20.99,
      "learning_rate": 0.00013977051081689453,
      "loss": 0.2605,
      "step": 20990
    },
    {
      "epoch": 21.0,
      "learning_rate": 0.0001397580029285105,
      "loss": 0.3243,
      "step": 21000
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2732864320278168,
      "eval_runtime": 14.8471,
      "eval_samples_per_second": 134.706,
      "eval_steps_per_second": 16.838,
      "step": 21000
    },
    {
      "epoch": 21.01,
      "learning_rate": 0.00013974548795828861,
      "loss": 0.2455,
      "step": 21010
    },
    {
      "epoch": 21.02,
      "learning_rate": 0.00013973296590759753,
      "loss": 0.2865,
      "step": 21020
    },
    {
      "epoch": 21.03,
      "learning_rate": 0.0001397204367778066,
      "loss": 0.2606,
      "step": 21030
    },
    {
      "epoch": 21.04,
      "learning_rate": 0.00013970790057028602,
      "loss": 0.2601,
      "step": 21040
    },
    {
      "epoch": 21.05,
      "learning_rate": 0.00013969535728640672,
      "loss": 0.3294,
      "step": 21050
    },
    {
      "epoch": 21.06,
      "learning_rate": 0.0001396828069275404,
      "loss": 0.3198,
      "step": 21060
    },
    {
      "epoch": 21.07,
      "learning_rate": 0.0001396702494950596,
      "loss": 0.1842,
      "step": 21070
    },
    {
      "epoch": 21.08,
      "learning_rate": 0.00013965768499033752,
      "loss": 0.3036,
      "step": 21080
    },
    {
      "epoch": 21.09,
      "learning_rate": 0.00013964511341474822,
      "loss": 0.2757,
      "step": 21090
    },
    {
      "epoch": 21.1,
      "learning_rate": 0.0001396325347696665,
      "loss": 0.2608,
      "step": 21100
    },
    {
      "epoch": 21.11,
      "learning_rate": 0.00013961994905646797,
      "loss": 0.2514,
      "step": 21110
    },
    {
      "epoch": 21.12,
      "learning_rate": 0.00013960735627652896,
      "loss": 0.2743,
      "step": 21120
    },
    {
      "epoch": 21.13,
      "learning_rate": 0.00013959475643122662,
      "loss": 0.2957,
      "step": 21130
    },
    {
      "epoch": 21.14,
      "learning_rate": 0.00013958214952193882,
      "loss": 0.2537,
      "step": 21140
    },
    {
      "epoch": 21.15,
      "learning_rate": 0.00013956953555004423,
      "loss": 0.2667,
      "step": 21150
    },
    {
      "epoch": 21.16,
      "learning_rate": 0.00013955691451692233,
      "loss": 0.256,
      "step": 21160
    },
    {
      "epoch": 21.17,
      "learning_rate": 0.0001395442864239533,
      "loss": 0.2077,
      "step": 21170
    },
    {
      "epoch": 21.18,
      "learning_rate": 0.00013953165127251815,
      "loss": 0.3319,
      "step": 21180
    },
    {
      "epoch": 21.19,
      "learning_rate": 0.00013951900906399866,
      "loss": 0.2347,
      "step": 21190
    },
    {
      "epoch": 21.2,
      "learning_rate": 0.00013950635979977734,
      "loss": 0.261,
      "step": 21200
    },
    {
      "epoch": 21.21,
      "learning_rate": 0.00013949370348123748,
      "loss": 0.2424,
      "step": 21210
    },
    {
      "epoch": 21.22,
      "learning_rate": 0.00013948104010976317,
      "loss": 0.3051,
      "step": 21220
    },
    {
      "epoch": 21.23,
      "learning_rate": 0.0001394683696867393,
      "loss": 0.2702,
      "step": 21230
    },
    {
      "epoch": 21.24,
      "learning_rate": 0.0001394556922135514,
      "loss": 0.2956,
      "step": 21240
    },
    {
      "epoch": 21.25,
      "learning_rate": 0.00013944300769158592,
      "loss": 0.2351,
      "step": 21250
    },
    {
      "epoch": 21.26,
      "learning_rate": 0.00013943031612223002,
      "loss": 0.3471,
      "step": 21260
    },
    {
      "epoch": 21.27,
      "learning_rate": 0.00013941761750687162,
      "loss": 0.2776,
      "step": 21270
    },
    {
      "epoch": 21.28,
      "learning_rate": 0.0001394049118468994,
      "loss": 0.2255,
      "step": 21280
    },
    {
      "epoch": 21.29,
      "learning_rate": 0.00013939219914370284,
      "loss": 0.3206,
      "step": 21290
    },
    {
      "epoch": 21.3,
      "learning_rate": 0.00013937947939867223,
      "loss": 0.222,
      "step": 21300
    },
    {
      "epoch": 21.31,
      "learning_rate": 0.00013936675261319852,
      "loss": 0.3262,
      "step": 21310
    },
    {
      "epoch": 21.32,
      "learning_rate": 0.00013935401878867353,
      "loss": 0.2376,
      "step": 21320
    },
    {
      "epoch": 21.33,
      "learning_rate": 0.0001393412779264898,
      "loss": 0.3003,
      "step": 21330
    },
    {
      "epoch": 21.34,
      "learning_rate": 0.00013932853002804067,
      "loss": 0.2929,
      "step": 21340
    },
    {
      "epoch": 21.35,
      "learning_rate": 0.00013931577509472017,
      "loss": 0.1761,
      "step": 21350
    },
    {
      "epoch": 21.36,
      "learning_rate": 0.00013930301312792325,
      "loss": 0.2999,
      "step": 21360
    },
    {
      "epoch": 21.37,
      "learning_rate": 0.00013929024412904546,
      "loss": 0.3564,
      "step": 21370
    },
    {
      "epoch": 21.38,
      "learning_rate": 0.00013927746809948324,
      "loss": 0.2748,
      "step": 21380
    },
    {
      "epoch": 21.39,
      "learning_rate": 0.00013926468504063376,
      "loss": 0.3177,
      "step": 21390
    },
    {
      "epoch": 21.4,
      "learning_rate": 0.0001392518949538949,
      "loss": 0.2777,
      "step": 21400
    },
    {
      "epoch": 21.41,
      "learning_rate": 0.00013923909784066546,
      "loss": 0.2139,
      "step": 21410
    },
    {
      "epoch": 21.42,
      "learning_rate": 0.00013922629370234483,
      "loss": 0.299,
      "step": 21420
    },
    {
      "epoch": 21.43,
      "learning_rate": 0.00013921348254033333,
      "loss": 0.2456,
      "step": 21430
    },
    {
      "epoch": 21.44,
      "learning_rate": 0.00013920066435603185,
      "loss": 0.2949,
      "step": 21440
    },
    {
      "epoch": 21.45,
      "learning_rate": 0.0001391878391508423,
      "loss": 0.2721,
      "step": 21450
    },
    {
      "epoch": 21.46,
      "learning_rate": 0.00013917500692616714,
      "loss": 0.29,
      "step": 21460
    },
    {
      "epoch": 21.47,
      "learning_rate": 0.0001391621676834097,
      "loss": 0.199,
      "step": 21470
    },
    {
      "epoch": 21.48,
      "learning_rate": 0.0001391493214239741,
      "loss": 0.2681,
      "step": 21480
    },
    {
      "epoch": 21.49,
      "learning_rate": 0.00013913646814926514,
      "loss": 0.2947,
      "step": 21490
    },
    {
      "epoch": 21.5,
      "learning_rate": 0.00013912360786068846,
      "loss": 0.3306,
      "step": 21500
    },
    {
      "epoch": 21.51,
      "learning_rate": 0.00013911074055965043,
      "loss": 0.2874,
      "step": 21510
    },
    {
      "epoch": 21.52,
      "learning_rate": 0.0001390978662475582,
      "loss": 0.2939,
      "step": 21520
    },
    {
      "epoch": 21.53,
      "learning_rate": 0.00013908498492581968,
      "loss": 0.2937,
      "step": 21530
    },
    {
      "epoch": 21.54,
      "learning_rate": 0.00013907209659584353,
      "loss": 0.352,
      "step": 21540
    },
    {
      "epoch": 21.55,
      "learning_rate": 0.00013905920125903927,
      "loss": 0.316,
      "step": 21550
    },
    {
      "epoch": 21.56,
      "learning_rate": 0.00013904629891681706,
      "loss": 0.2692,
      "step": 21560
    },
    {
      "epoch": 21.57,
      "learning_rate": 0.00013903338957058791,
      "loss": 0.3076,
      "step": 21570
    },
    {
      "epoch": 21.58,
      "learning_rate": 0.0001390204732217635,
      "loss": 0.3104,
      "step": 21580
    },
    {
      "epoch": 21.59,
      "learning_rate": 0.00013900754987175644,
      "loss": 0.2054,
      "step": 21590
    },
    {
      "epoch": 21.6,
      "learning_rate": 0.00013899461952197994,
      "loss": 0.2166,
      "step": 21600
    },
    {
      "epoch": 21.61,
      "learning_rate": 0.00013898168217384808,
      "loss": 0.2949,
      "step": 21610
    },
    {
      "epoch": 21.62,
      "learning_rate": 0.00013896873782877564,
      "loss": 0.2852,
      "step": 21620
    },
    {
      "epoch": 21.63,
      "learning_rate": 0.0001389557864881782,
      "loss": 0.304,
      "step": 21630
    },
    {
      "epoch": 21.64,
      "learning_rate": 0.00013894282815347212,
      "loss": 0.2184,
      "step": 21640
    },
    {
      "epoch": 21.65,
      "learning_rate": 0.00013892986282607446,
      "loss": 0.2345,
      "step": 21650
    },
    {
      "epoch": 21.66,
      "learning_rate": 0.00013891689050740314,
      "loss": 0.312,
      "step": 21660
    },
    {
      "epoch": 21.67,
      "learning_rate": 0.00013890391119887678,
      "loss": 0.2778,
      "step": 21670
    },
    {
      "epoch": 21.68,
      "learning_rate": 0.00013889092490191476,
      "loss": 0.3123,
      "step": 21680
    },
    {
      "epoch": 21.69,
      "learning_rate": 0.00013887793161793726,
      "loss": 0.2689,
      "step": 21690
    },
    {
      "epoch": 21.7,
      "learning_rate": 0.00013886493134836517,
      "loss": 0.2692,
      "step": 21700
    },
    {
      "epoch": 21.71,
      "learning_rate": 0.00013885192409462024,
      "loss": 0.3385,
      "step": 21710
    },
    {
      "epoch": 21.72,
      "learning_rate": 0.0001388389098581249,
      "loss": 0.3208,
      "step": 21720
    },
    {
      "epoch": 21.73,
      "learning_rate": 0.00013882588864030232,
      "loss": 0.364,
      "step": 21730
    },
    {
      "epoch": 21.74,
      "learning_rate": 0.00013881286044257652,
      "loss": 0.2595,
      "step": 21740
    },
    {
      "epoch": 21.75,
      "learning_rate": 0.00013879982526637227,
      "loss": 0.2544,
      "step": 21750
    },
    {
      "epoch": 21.76,
      "learning_rate": 0.00013878678311311503,
      "loss": 0.257,
      "step": 21760
    },
    {
      "epoch": 21.77,
      "learning_rate": 0.0001387737339842311,
      "loss": 0.2482,
      "step": 21770
    },
    {
      "epoch": 21.78,
      "learning_rate": 0.00013876067788114752,
      "loss": 0.3437,
      "step": 21780
    },
    {
      "epoch": 21.79,
      "learning_rate": 0.00013874761480529204,
      "loss": 0.2712,
      "step": 21790
    },
    {
      "epoch": 21.8,
      "learning_rate": 0.00013873454475809327,
      "loss": 0.2519,
      "step": 21800
    },
    {
      "epoch": 21.81,
      "learning_rate": 0.00013872146774098048,
      "loss": 0.2427,
      "step": 21810
    },
    {
      "epoch": 21.82,
      "learning_rate": 0.00013870838375538384,
      "loss": 0.2255,
      "step": 21820
    },
    {
      "epoch": 21.83,
      "learning_rate": 0.00013869529280273408,
      "loss": 0.3209,
      "step": 21830
    },
    {
      "epoch": 21.84,
      "learning_rate": 0.0001386821948844629,
      "loss": 0.2859,
      "step": 21840
    },
    {
      "epoch": 21.85,
      "learning_rate": 0.00013866909000200258,
      "loss": 0.3311,
      "step": 21850
    },
    {
      "epoch": 21.86,
      "learning_rate": 0.00013865597815678634,
      "loss": 0.2859,
      "step": 21860
    },
    {
      "epoch": 21.87,
      "learning_rate": 0.00013864285935024804,
      "loss": 0.2691,
      "step": 21870
    },
    {
      "epoch": 21.88,
      "learning_rate": 0.0001386297335838223,
      "loss": 0.2429,
      "step": 21880
    },
    {
      "epoch": 21.89,
      "learning_rate": 0.0001386166008589446,
      "loss": 0.3125,
      "step": 21890
    },
    {
      "epoch": 21.9,
      "learning_rate": 0.00013860346117705106,
      "loss": 0.2501,
      "step": 21900
    },
    {
      "epoch": 21.91,
      "learning_rate": 0.00013859031453957861,
      "loss": 0.2186,
      "step": 21910
    },
    {
      "epoch": 21.92,
      "learning_rate": 0.000138577160947965,
      "loss": 0.338,
      "step": 21920
    },
    {
      "epoch": 21.93,
      "learning_rate": 0.00013856400040364861,
      "loss": 0.2422,
      "step": 21930
    },
    {
      "epoch": 21.94,
      "learning_rate": 0.00013855083290806875,
      "loss": 0.3403,
      "step": 21940
    },
    {
      "epoch": 21.95,
      "learning_rate": 0.00013853765846266533,
      "loss": 0.2889,
      "step": 21950
    },
    {
      "epoch": 21.96,
      "learning_rate": 0.00013852447706887912,
      "loss": 0.2514,
      "step": 21960
    },
    {
      "epoch": 21.97,
      "learning_rate": 0.0001385112887281516,
      "loss": 0.3272,
      "step": 21970
    },
    {
      "epoch": 21.98,
      "learning_rate": 0.00013849809344192502,
      "loss": 0.2921,
      "step": 21980
    },
    {
      "epoch": 21.99,
      "learning_rate": 0.00013848489121164243,
      "loss": 0.2947,
      "step": 21990
    },
    {
      "epoch": 22.0,
      "learning_rate": 0.00013847168203874756,
      "loss": 0.3382,
      "step": 22000
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2731655538082123,
      "eval_runtime": 14.9772,
      "eval_samples_per_second": 133.536,
      "eval_steps_per_second": 16.692,
      "step": 22000
    },
    {
      "epoch": 22.01,
      "learning_rate": 0.00013845846592468498,
      "loss": 0.2254,
      "step": 22010
    },
    {
      "epoch": 22.02,
      "learning_rate": 0.0001384452428709,
      "loss": 0.311,
      "step": 22020
    },
    {
      "epoch": 22.03,
      "learning_rate": 0.0001384320128788386,
      "loss": 0.229,
      "step": 22030
    },
    {
      "epoch": 22.04,
      "learning_rate": 0.00013841877594994768,
      "loss": 0.3381,
      "step": 22040
    },
    {
      "epoch": 22.05,
      "learning_rate": 0.00013840553208567478,
      "loss": 0.208,
      "step": 22050
    },
    {
      "epoch": 22.06,
      "learning_rate": 0.00013839228128746818,
      "loss": 0.2847,
      "step": 22060
    },
    {
      "epoch": 22.07,
      "learning_rate": 0.00013837902355677702,
      "loss": 0.2305,
      "step": 22070
    },
    {
      "epoch": 22.08,
      "learning_rate": 0.00013836575889505115,
      "loss": 0.2667,
      "step": 22080
    },
    {
      "epoch": 22.09,
      "learning_rate": 0.00013835248730374115,
      "loss": 0.2971,
      "step": 22090
    },
    {
      "epoch": 22.1,
      "learning_rate": 0.00013833920878429838,
      "loss": 0.251,
      "step": 22100
    },
    {
      "epoch": 22.11,
      "learning_rate": 0.00013832592333817495,
      "loss": 0.3291,
      "step": 22110
    },
    {
      "epoch": 22.12,
      "learning_rate": 0.00013831263096682377,
      "loss": 0.3184,
      "step": 22120
    },
    {
      "epoch": 22.13,
      "learning_rate": 0.00013829933167169847,
      "loss": 0.3026,
      "step": 22130
    },
    {
      "epoch": 22.14,
      "learning_rate": 0.00013828602545425342,
      "loss": 0.2394,
      "step": 22140
    },
    {
      "epoch": 22.15,
      "learning_rate": 0.00013827271231594377,
      "loss": 0.2788,
      "step": 22150
    },
    {
      "epoch": 22.16,
      "learning_rate": 0.00013825939225822545,
      "loss": 0.2684,
      "step": 22160
    },
    {
      "epoch": 22.17,
      "learning_rate": 0.00013824606528255507,
      "loss": 0.2074,
      "step": 22170
    },
    {
      "epoch": 22.18,
      "learning_rate": 0.00013823273139039008,
      "loss": 0.2444,
      "step": 22180
    },
    {
      "epoch": 22.19,
      "learning_rate": 0.00013821939058318868,
      "loss": 0.3293,
      "step": 22190
    },
    {
      "epoch": 22.2,
      "learning_rate": 0.00013820604286240976,
      "loss": 0.3014,
      "step": 22200
    },
    {
      "epoch": 22.21,
      "learning_rate": 0.00013819268822951302,
      "loss": 0.2367,
      "step": 22210
    },
    {
      "epoch": 22.22,
      "learning_rate": 0.0001381793266859589,
      "loss": 0.3134,
      "step": 22220
    },
    {
      "epoch": 22.23,
      "learning_rate": 0.00013816595823320862,
      "loss": 0.2336,
      "step": 22230
    },
    {
      "epoch": 22.24,
      "learning_rate": 0.0001381525828727241,
      "loss": 0.2849,
      "step": 22240
    },
    {
      "epoch": 22.25,
      "learning_rate": 0.0001381392006059681,
      "loss": 0.2768,
      "step": 22250
    },
    {
      "epoch": 22.26,
      "learning_rate": 0.000138125811434404,
      "loss": 0.296,
      "step": 22260
    },
    {
      "epoch": 22.27,
      "learning_rate": 0.0001381124153594961,
      "loss": 0.2895,
      "step": 22270
    },
    {
      "epoch": 22.28,
      "learning_rate": 0.00013809901238270934,
      "loss": 0.3289,
      "step": 22280
    },
    {
      "epoch": 22.29,
      "learning_rate": 0.00013808560250550944,
      "loss": 0.3025,
      "step": 22290
    },
    {
      "epoch": 22.3,
      "learning_rate": 0.0001380721857293629,
      "loss": 0.2604,
      "step": 22300
    },
    {
      "epoch": 22.31,
      "learning_rate": 0.00013805876205573697,
      "loss": 0.3066,
      "step": 22310
    },
    {
      "epoch": 22.32,
      "learning_rate": 0.00013804533148609963,
      "loss": 0.2723,
      "step": 22320
    },
    {
      "epoch": 22.33,
      "learning_rate": 0.0001380318940219196,
      "loss": 0.2945,
      "step": 22330
    },
    {
      "epoch": 22.34,
      "learning_rate": 0.00013801844966466643,
      "loss": 0.2028,
      "step": 22340
    },
    {
      "epoch": 22.35,
      "learning_rate": 0.00013800499841581037,
      "loss": 0.2882,
      "step": 22350
    },
    {
      "epoch": 22.36,
      "learning_rate": 0.00013799154027682237,
      "loss": 0.2348,
      "step": 22360
    },
    {
      "epoch": 22.37,
      "learning_rate": 0.00013797807524917427,
      "loss": 0.2818,
      "step": 22370
    },
    {
      "epoch": 22.38,
      "learning_rate": 0.00013796460333433849,
      "loss": 0.2967,
      "step": 22380
    },
    {
      "epoch": 22.39,
      "learning_rate": 0.0001379511245337884,
      "loss": 0.3069,
      "step": 22390
    },
    {
      "epoch": 22.4,
      "learning_rate": 0.00013793763884899796,
      "loss": 0.3254,
      "step": 22400
    },
    {
      "epoch": 22.41,
      "learning_rate": 0.00013792414628144197,
      "loss": 0.2151,
      "step": 22410
    },
    {
      "epoch": 22.42,
      "learning_rate": 0.00013791064683259596,
      "loss": 0.2592,
      "step": 22420
    },
    {
      "epoch": 22.43,
      "learning_rate": 0.00013789714050393617,
      "loss": 0.3051,
      "step": 22430
    },
    {
      "epoch": 22.44,
      "learning_rate": 0.00013788362729693967,
      "loss": 0.2125,
      "step": 22440
    },
    {
      "epoch": 22.45,
      "learning_rate": 0.00013787010721308423,
      "loss": 0.2678,
      "step": 22450
    },
    {
      "epoch": 22.46,
      "learning_rate": 0.0001378565802538484,
      "loss": 0.2691,
      "step": 22460
    },
    {
      "epoch": 22.47,
      "learning_rate": 0.00013784304642071145,
      "loss": 0.1992,
      "step": 22470
    },
    {
      "epoch": 22.48,
      "learning_rate": 0.00013782950571515344,
      "loss": 0.2768,
      "step": 22480
    },
    {
      "epoch": 22.49,
      "learning_rate": 0.00013781595813865512,
      "loss": 0.2612,
      "step": 22490
    },
    {
      "epoch": 22.5,
      "learning_rate": 0.00013780240369269808,
      "loss": 0.3475,
      "step": 22500
    },
    {
      "epoch": 22.51,
      "learning_rate": 0.0001377888423787646,
      "loss": 0.225,
      "step": 22510
    },
    {
      "epoch": 22.52,
      "learning_rate": 0.0001377752741983377,
      "loss": 0.2593,
      "step": 22520
    },
    {
      "epoch": 22.53,
      "learning_rate": 0.0001377616991529012,
      "loss": 0.2398,
      "step": 22530
    },
    {
      "epoch": 22.54,
      "learning_rate": 0.00013774811724393964,
      "loss": 0.2988,
      "step": 22540
    },
    {
      "epoch": 22.55,
      "learning_rate": 0.00013773452847293835,
      "loss": 0.2469,
      "step": 22550
    },
    {
      "epoch": 22.56,
      "learning_rate": 0.00013772093284138332,
      "loss": 0.321,
      "step": 22560
    },
    {
      "epoch": 22.57,
      "learning_rate": 0.00013770733035076138,
      "loss": 0.3133,
      "step": 22570
    },
    {
      "epoch": 22.58,
      "learning_rate": 0.00013769372100256005,
      "loss": 0.269,
      "step": 22580
    },
    {
      "epoch": 22.59,
      "learning_rate": 0.00013768010479826766,
      "loss": 0.3408,
      "step": 22590
    },
    {
      "epoch": 22.6,
      "learning_rate": 0.00013766648173937324,
      "loss": 0.3566,
      "step": 22600
    },
    {
      "epoch": 22.61,
      "learning_rate": 0.0001376528518273666,
      "loss": 0.3019,
      "step": 22610
    },
    {
      "epoch": 22.62,
      "learning_rate": 0.0001376392150637383,
      "loss": 0.3305,
      "step": 22620
    },
    {
      "epoch": 22.63,
      "learning_rate": 0.00013762557144997962,
      "loss": 0.2984,
      "step": 22630
    },
    {
      "epoch": 22.64,
      "learning_rate": 0.00013761192098758258,
      "loss": 0.3239,
      "step": 22640
    },
    {
      "epoch": 22.65,
      "learning_rate": 0.00013759826367804002,
      "loss": 0.2793,
      "step": 22650
    },
    {
      "epoch": 22.66,
      "learning_rate": 0.0001375845995228454,
      "loss": 0.2492,
      "step": 22660
    },
    {
      "epoch": 22.67,
      "learning_rate": 0.00013757092852349315,
      "loss": 0.3531,
      "step": 22670
    },
    {
      "epoch": 22.68,
      "learning_rate": 0.0001375572506814782,
      "loss": 0.2419,
      "step": 22680
    },
    {
      "epoch": 22.69,
      "learning_rate": 0.00013754356599829633,
      "loss": 0.2882,
      "step": 22690
    },
    {
      "epoch": 22.7,
      "learning_rate": 0.00013752987447544418,
      "loss": 0.2882,
      "step": 22700
    },
    {
      "epoch": 22.71,
      "learning_rate": 0.00013751617611441894,
      "loss": 0.2512,
      "step": 22710
    },
    {
      "epoch": 22.72,
      "learning_rate": 0.00013750247091671866,
      "loss": 0.2698,
      "step": 22720
    },
    {
      "epoch": 22.73,
      "learning_rate": 0.00013748875888384214,
      "loss": 0.2522,
      "step": 22730
    },
    {
      "epoch": 22.74,
      "learning_rate": 0.00013747504001728893,
      "loss": 0.2111,
      "step": 22740
    },
    {
      "epoch": 22.75,
      "learning_rate": 0.00013746131431855924,
      "loss": 0.3105,
      "step": 22750
    },
    {
      "epoch": 22.76,
      "learning_rate": 0.0001374475817891541,
      "loss": 0.2797,
      "step": 22760
    },
    {
      "epoch": 22.77,
      "learning_rate": 0.00013743384243057534,
      "loss": 0.33,
      "step": 22770
    },
    {
      "epoch": 22.78,
      "learning_rate": 0.00013742009624432544,
      "loss": 0.2923,
      "step": 22780
    },
    {
      "epoch": 22.79,
      "learning_rate": 0.00013740634323190765,
      "loss": 0.2726,
      "step": 22790
    },
    {
      "epoch": 22.8,
      "learning_rate": 0.000137392583394826,
      "loss": 0.3118,
      "step": 22800
    },
    {
      "epoch": 22.81,
      "learning_rate": 0.00013737881673458522,
      "loss": 0.3142,
      "step": 22810
    },
    {
      "epoch": 22.82,
      "learning_rate": 0.00013736504325269087,
      "loss": 0.2341,
      "step": 22820
    },
    {
      "epoch": 22.83,
      "learning_rate": 0.00013735126295064912,
      "loss": 0.3146,
      "step": 22830
    },
    {
      "epoch": 22.84,
      "learning_rate": 0.000137337475829967,
      "loss": 0.262,
      "step": 22840
    },
    {
      "epoch": 22.85,
      "learning_rate": 0.00013732368189215224,
      "loss": 0.2907,
      "step": 22850
    },
    {
      "epoch": 22.86,
      "learning_rate": 0.00013730988113871333,
      "loss": 0.2557,
      "step": 22860
    },
    {
      "epoch": 22.87,
      "learning_rate": 0.00013729607357115952,
      "loss": 0.2855,
      "step": 22870
    },
    {
      "epoch": 22.88,
      "learning_rate": 0.00013728225919100074,
      "loss": 0.2775,
      "step": 22880
    },
    {
      "epoch": 22.89,
      "learning_rate": 0.00013726843799974776,
      "loss": 0.3294,
      "step": 22890
    },
    {
      "epoch": 22.9,
      "learning_rate": 0.000137254609998912,
      "loss": 0.3448,
      "step": 22900
    },
    {
      "epoch": 22.91,
      "learning_rate": 0.0001372407751900057,
      "loss": 0.2449,
      "step": 22910
    },
    {
      "epoch": 22.92,
      "learning_rate": 0.0001372269335745418,
      "loss": 0.2596,
      "step": 22920
    },
    {
      "epoch": 22.93,
      "learning_rate": 0.00013721308515403401,
      "loss": 0.3165,
      "step": 22930
    },
    {
      "epoch": 22.94,
      "learning_rate": 0.00013719922992999674,
      "loss": 0.2606,
      "step": 22940
    },
    {
      "epoch": 22.95,
      "learning_rate": 0.00013718536790394522,
      "loss": 0.2596,
      "step": 22950
    },
    {
      "epoch": 22.96,
      "learning_rate": 0.00013717149907739536,
      "loss": 0.3018,
      "step": 22960
    },
    {
      "epoch": 22.97,
      "learning_rate": 0.0001371576234518638,
      "loss": 0.3071,
      "step": 22970
    },
    {
      "epoch": 22.98,
      "learning_rate": 0.00013714374102886804,
      "loss": 0.2235,
      "step": 22980
    },
    {
      "epoch": 22.99,
      "learning_rate": 0.00013712985180992616,
      "loss": 0.2788,
      "step": 22990
    },
    {
      "epoch": 23.0,
      "learning_rate": 0.0001371159557965571,
      "loss": 0.2411,
      "step": 23000
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27378448843955994,
      "eval_runtime": 15.2086,
      "eval_samples_per_second": 131.505,
      "eval_steps_per_second": 16.438,
      "step": 23000
    },
    {
      "epoch": 23.01,
      "learning_rate": 0.00013710205299028054,
      "loss": 0.2993,
      "step": 23010
    },
    {
      "epoch": 23.02,
      "learning_rate": 0.00013708814339261682,
      "loss": 0.2999,
      "step": 23020
    },
    {
      "epoch": 23.03,
      "learning_rate": 0.00013707422700508706,
      "loss": 0.278,
      "step": 23030
    },
    {
      "epoch": 23.04,
      "learning_rate": 0.00013706030382921316,
      "loss": 0.2653,
      "step": 23040
    },
    {
      "epoch": 23.05,
      "learning_rate": 0.00013704637386651776,
      "loss": 0.2865,
      "step": 23050
    },
    {
      "epoch": 23.06,
      "learning_rate": 0.0001370324371185242,
      "loss": 0.2879,
      "step": 23060
    },
    {
      "epoch": 23.07,
      "learning_rate": 0.0001370184935867566,
      "loss": 0.2349,
      "step": 23070
    },
    {
      "epoch": 23.08,
      "learning_rate": 0.00013700454327273973,
      "loss": 0.3165,
      "step": 23080
    },
    {
      "epoch": 23.09,
      "learning_rate": 0.0001369905861779993,
      "loss": 0.2162,
      "step": 23090
    },
    {
      "epoch": 23.1,
      "learning_rate": 0.00013697662230406152,
      "loss": 0.2347,
      "step": 23100
    },
    {
      "epoch": 23.11,
      "learning_rate": 0.0001369626516524535,
      "loss": 0.2761,
      "step": 23110
    },
    {
      "epoch": 23.12,
      "learning_rate": 0.00013694867422470308,
      "loss": 0.3167,
      "step": 23120
    },
    {
      "epoch": 23.13,
      "learning_rate": 0.00013693469002233876,
      "loss": 0.2364,
      "step": 23130
    },
    {
      "epoch": 23.14,
      "learning_rate": 0.00013692069904688988,
      "loss": 0.3063,
      "step": 23140
    },
    {
      "epoch": 23.15,
      "learning_rate": 0.00013690670129988644,
      "loss": 0.2924,
      "step": 23150
    },
    {
      "epoch": 23.16,
      "learning_rate": 0.00013689269678285922,
      "loss": 0.3697,
      "step": 23160
    },
    {
      "epoch": 23.17,
      "learning_rate": 0.00013687868549733975,
      "loss": 0.2825,
      "step": 23170
    },
    {
      "epoch": 23.18,
      "learning_rate": 0.00013686466744486025,
      "loss": 0.2268,
      "step": 23180
    },
    {
      "epoch": 23.19,
      "learning_rate": 0.00013685064262695373,
      "loss": 0.2752,
      "step": 23190
    },
    {
      "epoch": 23.2,
      "learning_rate": 0.00013683661104515392,
      "loss": 0.3213,
      "step": 23200
    },
    {
      "epoch": 23.21,
      "learning_rate": 0.0001368225727009953,
      "loss": 0.3217,
      "step": 23210
    },
    {
      "epoch": 23.22,
      "learning_rate": 0.00013680852759601308,
      "loss": 0.2874,
      "step": 23220
    },
    {
      "epoch": 23.23,
      "learning_rate": 0.0001367944757317432,
      "loss": 0.2679,
      "step": 23230
    },
    {
      "epoch": 23.24,
      "learning_rate": 0.00013678041710972236,
      "loss": 0.2341,
      "step": 23240
    },
    {
      "epoch": 23.25,
      "learning_rate": 0.000136766351731488,
      "loss": 0.3266,
      "step": 23250
    },
    {
      "epoch": 23.26,
      "learning_rate": 0.00013675227959857828,
      "loss": 0.2848,
      "step": 23260
    },
    {
      "epoch": 23.27,
      "learning_rate": 0.00013673820071253212,
      "loss": 0.2667,
      "step": 23270
    },
    {
      "epoch": 23.28,
      "learning_rate": 0.00013672411507488914,
      "loss": 0.2663,
      "step": 23280
    },
    {
      "epoch": 23.29,
      "learning_rate": 0.00013671002268718973,
      "loss": 0.2778,
      "step": 23290
    },
    {
      "epoch": 23.3,
      "learning_rate": 0.00013669592355097503,
      "loss": 0.3038,
      "step": 23300
    },
    {
      "epoch": 23.31,
      "learning_rate": 0.00013668181766778687,
      "loss": 0.2966,
      "step": 23310
    },
    {
      "epoch": 23.32,
      "learning_rate": 0.00013666770503916787,
      "loss": 0.2561,
      "step": 23320
    },
    {
      "epoch": 23.33,
      "learning_rate": 0.0001366535856666614,
      "loss": 0.3126,
      "step": 23330
    },
    {
      "epoch": 23.34,
      "learning_rate": 0.00013663945955181146,
      "loss": 0.3032,
      "step": 23340
    },
    {
      "epoch": 23.35,
      "learning_rate": 0.00013662532669616288,
      "loss": 0.2693,
      "step": 23350
    },
    {
      "epoch": 23.36,
      "learning_rate": 0.00013661118710126127,
      "loss": 0.2529,
      "step": 23360
    },
    {
      "epoch": 23.37,
      "learning_rate": 0.00013659704076865285,
      "loss": 0.3273,
      "step": 23370
    },
    {
      "epoch": 23.38,
      "learning_rate": 0.00013658288769988466,
      "loss": 0.3358,
      "step": 23380
    },
    {
      "epoch": 23.39,
      "learning_rate": 0.00013656872789650446,
      "loss": 0.2592,
      "step": 23390
    },
    {
      "epoch": 23.4,
      "learning_rate": 0.00013655456136006072,
      "loss": 0.2871,
      "step": 23400
    },
    {
      "epoch": 23.41,
      "learning_rate": 0.00013654038809210277,
      "loss": 0.2565,
      "step": 23410
    },
    {
      "epoch": 23.42,
      "learning_rate": 0.00013652620809418044,
      "loss": 0.3175,
      "step": 23420
    },
    {
      "epoch": 23.43,
      "learning_rate": 0.0001365120213678445,
      "loss": 0.2789,
      "step": 23430
    },
    {
      "epoch": 23.44,
      "learning_rate": 0.0001364978279146464,
      "loss": 0.3075,
      "step": 23440
    },
    {
      "epoch": 23.45,
      "learning_rate": 0.00013648362773613829,
      "loss": 0.222,
      "step": 23450
    },
    {
      "epoch": 23.46,
      "learning_rate": 0.00013646942083387308,
      "loss": 0.2717,
      "step": 23460
    },
    {
      "epoch": 23.47,
      "learning_rate": 0.00013645520720940445,
      "loss": 0.298,
      "step": 23470
    },
    {
      "epoch": 23.48,
      "learning_rate": 0.00013644098686428673,
      "loss": 0.2596,
      "step": 23480
    },
    {
      "epoch": 23.49,
      "learning_rate": 0.0001364267598000751,
      "loss": 0.2807,
      "step": 23490
    },
    {
      "epoch": 23.5,
      "learning_rate": 0.00013641252601832534,
      "loss": 0.1992,
      "step": 23500
    },
    {
      "epoch": 23.51,
      "learning_rate": 0.00013639828552059407,
      "loss": 0.2597,
      "step": 23510
    },
    {
      "epoch": 23.52,
      "learning_rate": 0.00013638403830843864,
      "loss": 0.2545,
      "step": 23520
    },
    {
      "epoch": 23.53,
      "learning_rate": 0.00013636978438341703,
      "loss": 0.291,
      "step": 23530
    },
    {
      "epoch": 23.54,
      "learning_rate": 0.00013635552374708808,
      "loss": 0.2845,
      "step": 23540
    },
    {
      "epoch": 23.55,
      "learning_rate": 0.0001363412564010113,
      "loss": 0.3364,
      "step": 23550
    },
    {
      "epoch": 23.56,
      "learning_rate": 0.00013632698234674695,
      "loss": 0.3266,
      "step": 23560
    },
    {
      "epoch": 23.57,
      "learning_rate": 0.000136312701585856,
      "loss": 0.2872,
      "step": 23570
    },
    {
      "epoch": 23.58,
      "learning_rate": 0.00013629841411990018,
      "loss": 0.2933,
      "step": 23580
    },
    {
      "epoch": 23.59,
      "learning_rate": 0.000136284119950442,
      "loss": 0.2665,
      "step": 23590
    },
    {
      "epoch": 23.6,
      "learning_rate": 0.00013626981907904456,
      "loss": 0.2723,
      "step": 23600
    },
    {
      "epoch": 23.61,
      "learning_rate": 0.00013625551150727184,
      "loss": 0.2221,
      "step": 23610
    },
    {
      "epoch": 23.62,
      "learning_rate": 0.00013624119723668846,
      "loss": 0.2257,
      "step": 23620
    },
    {
      "epoch": 23.63,
      "learning_rate": 0.00013622687626885986,
      "loss": 0.2688,
      "step": 23630
    },
    {
      "epoch": 23.64,
      "learning_rate": 0.0001362125486053521,
      "loss": 0.3194,
      "step": 23640
    },
    {
      "epoch": 23.65,
      "learning_rate": 0.00013619821424773205,
      "loss": 0.275,
      "step": 23650
    },
    {
      "epoch": 23.66,
      "learning_rate": 0.00013618387319756732,
      "loss": 0.2306,
      "step": 23660
    },
    {
      "epoch": 23.67,
      "learning_rate": 0.00013616952545642618,
      "loss": 0.2771,
      "step": 23670
    },
    {
      "epoch": 23.68,
      "learning_rate": 0.0001361551710258777,
      "loss": 0.2607,
      "step": 23680
    },
    {
      "epoch": 23.69,
      "learning_rate": 0.0001361408099074917,
      "loss": 0.3113,
      "step": 23690
    },
    {
      "epoch": 23.7,
      "learning_rate": 0.00013612644210283864,
      "loss": 0.2499,
      "step": 23700
    },
    {
      "epoch": 23.71,
      "learning_rate": 0.00013611206761348976,
      "loss": 0.2988,
      "step": 23710
    },
    {
      "epoch": 23.72,
      "learning_rate": 0.00013609768644101705,
      "loss": 0.218,
      "step": 23720
    },
    {
      "epoch": 23.73,
      "learning_rate": 0.00013608329858699322,
      "loss": 0.3136,
      "step": 23730
    },
    {
      "epoch": 23.74,
      "learning_rate": 0.0001360689040529917,
      "loss": 0.295,
      "step": 23740
    },
    {
      "epoch": 23.75,
      "learning_rate": 0.00013605450284058662,
      "loss": 0.2688,
      "step": 23750
    },
    {
      "epoch": 23.76,
      "learning_rate": 0.0001360400949513529,
      "loss": 0.3041,
      "step": 23760
    },
    {
      "epoch": 23.77,
      "learning_rate": 0.0001360256803868662,
      "loss": 0.2947,
      "step": 23770
    },
    {
      "epoch": 23.78,
      "learning_rate": 0.0001360112591487028,
      "loss": 0.3252,
      "step": 23780
    },
    {
      "epoch": 23.79,
      "learning_rate": 0.0001359968312384399,
      "loss": 0.2733,
      "step": 23790
    },
    {
      "epoch": 23.8,
      "learning_rate": 0.00013598239665765517,
      "loss": 0.2342,
      "step": 23800
    },
    {
      "epoch": 23.81,
      "learning_rate": 0.00013596795540792725,
      "loss": 0.2719,
      "step": 23810
    },
    {
      "epoch": 23.82,
      "learning_rate": 0.00013595350749083542,
      "loss": 0.2347,
      "step": 23820
    },
    {
      "epoch": 23.83,
      "learning_rate": 0.0001359390529079596,
      "loss": 0.2953,
      "step": 23830
    },
    {
      "epoch": 23.84,
      "learning_rate": 0.00013592459166088063,
      "loss": 0.3041,
      "step": 23840
    },
    {
      "epoch": 23.85,
      "learning_rate": 0.0001359101237511799,
      "loss": 0.226,
      "step": 23850
    },
    {
      "epoch": 23.86,
      "learning_rate": 0.0001358956491804396,
      "loss": 0.2601,
      "step": 23860
    },
    {
      "epoch": 23.87,
      "learning_rate": 0.00013588116795024266,
      "loss": 0.2333,
      "step": 23870
    },
    {
      "epoch": 23.88,
      "learning_rate": 0.00013586812915053885,
      "loss": 0.2656,
      "step": 23880
    },
    {
      "epoch": 23.89,
      "learning_rate": 0.00013585363527173784,
      "loss": 0.2687,
      "step": 23890
    },
    {
      "epoch": 23.9,
      "learning_rate": 0.0001358391347380748,
      "loss": 0.3298,
      "step": 23900
    },
    {
      "epoch": 23.91,
      "learning_rate": 0.00013582462755113543,
      "loss": 0.2861,
      "step": 23910
    },
    {
      "epoch": 23.92,
      "learning_rate": 0.00013581011371250622,
      "loss": 0.2944,
      "step": 23920
    },
    {
      "epoch": 23.93,
      "learning_rate": 0.00013579559322377443,
      "loss": 0.3352,
      "step": 23930
    },
    {
      "epoch": 23.94,
      "learning_rate": 0.00013578106608652798,
      "loss": 0.2288,
      "step": 23940
    },
    {
      "epoch": 23.95,
      "learning_rate": 0.0001357665323023555,
      "loss": 0.2672,
      "step": 23950
    },
    {
      "epoch": 23.96,
      "learning_rate": 0.00013575199187284642,
      "loss": 0.321,
      "step": 23960
    },
    {
      "epoch": 23.97,
      "learning_rate": 0.00013573744479959083,
      "loss": 0.2783,
      "step": 23970
    },
    {
      "epoch": 23.98,
      "learning_rate": 0.00013572289108417963,
      "loss": 0.3374,
      "step": 23980
    },
    {
      "epoch": 23.99,
      "learning_rate": 0.0001357083307282043,
      "loss": 0.2495,
      "step": 23990
    },
    {
      "epoch": 24.0,
      "learning_rate": 0.00013569376373325726,
      "loss": 0.2717,
      "step": 24000
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.27308452129364014,
      "eval_runtime": 14.9777,
      "eval_samples_per_second": 133.532,
      "eval_steps_per_second": 16.692,
      "step": 24000
    },
    {
      "epoch": 24.01,
      "learning_rate": 0.00013567919010093143,
      "loss": 0.2689,
      "step": 24010
    },
    {
      "epoch": 24.02,
      "learning_rate": 0.0001356646098328206,
      "loss": 0.2872,
      "step": 24020
    },
    {
      "epoch": 24.03,
      "learning_rate": 0.00013565002293051926,
      "loss": 0.2428,
      "step": 24030
    },
    {
      "epoch": 24.04,
      "learning_rate": 0.0001356354293956226,
      "loss": 0.2951,
      "step": 24040
    },
    {
      "epoch": 24.05,
      "learning_rate": 0.00013562082922972653,
      "loss": 0.2608,
      "step": 24050
    },
    {
      "epoch": 24.06,
      "learning_rate": 0.00013560622243442773,
      "loss": 0.2508,
      "step": 24060
    },
    {
      "epoch": 24.07,
      "learning_rate": 0.00013559160901132356,
      "loss": 0.2411,
      "step": 24070
    },
    {
      "epoch": 24.08,
      "learning_rate": 0.00013557698896201213,
      "loss": 0.3263,
      "step": 24080
    },
    {
      "epoch": 24.09,
      "learning_rate": 0.00013556236228809225,
      "loss": 0.2569,
      "step": 24090
    },
    {
      "epoch": 24.1,
      "learning_rate": 0.0001355477289911635,
      "loss": 0.231,
      "step": 24100
    },
    {
      "epoch": 24.11,
      "learning_rate": 0.00013553308907282615,
      "loss": 0.3037,
      "step": 24110
    },
    {
      "epoch": 24.12,
      "learning_rate": 0.00013551844253468118,
      "loss": 0.3869,
      "step": 24120
    },
    {
      "epoch": 24.13,
      "learning_rate": 0.00013550378937833031,
      "loss": 0.3574,
      "step": 24130
    },
    {
      "epoch": 24.14,
      "learning_rate": 0.00013548912960537602,
      "loss": 0.2974,
      "step": 24140
    },
    {
      "epoch": 24.15,
      "learning_rate": 0.00013547446321742144,
      "loss": 0.2661,
      "step": 24150
    },
    {
      "epoch": 24.16,
      "learning_rate": 0.00013545979021607047,
      "loss": 0.2574,
      "step": 24160
    },
    {
      "epoch": 24.17,
      "learning_rate": 0.00013544511060292776,
      "loss": 0.3183,
      "step": 24170
    },
    {
      "epoch": 24.18,
      "learning_rate": 0.00013543042437959865,
      "loss": 0.3307,
      "step": 24180
    },
    {
      "epoch": 24.19,
      "learning_rate": 0.00013541573154768918,
      "loss": 0.2993,
      "step": 24190
    },
    {
      "epoch": 24.2,
      "learning_rate": 0.00013540103210880612,
      "loss": 0.2392,
      "step": 24200
    },
    {
      "epoch": 24.21,
      "learning_rate": 0.00013538632606455704,
      "loss": 0.296,
      "step": 24210
    },
    {
      "epoch": 24.22,
      "learning_rate": 0.00013537161341655007,
      "loss": 0.2401,
      "step": 24220
    },
    {
      "epoch": 24.23,
      "learning_rate": 0.00013535689416639427,
      "loss": 0.3297,
      "step": 24230
    },
    {
      "epoch": 24.24,
      "learning_rate": 0.00013534216831569926,
      "loss": 0.2554,
      "step": 24240
    },
    {
      "epoch": 24.25,
      "learning_rate": 0.00013532743586607544,
      "loss": 0.297,
      "step": 24250
    },
    {
      "epoch": 24.26,
      "learning_rate": 0.00013531269681913395,
      "loss": 0.2256,
      "step": 24260
    },
    {
      "epoch": 24.27,
      "learning_rate": 0.0001352979511764866,
      "loss": 0.1993,
      "step": 24270
    },
    {
      "epoch": 24.28,
      "learning_rate": 0.00013528319893974598,
      "loss": 0.2498,
      "step": 24280
    },
    {
      "epoch": 24.29,
      "learning_rate": 0.00013526844011052533,
      "loss": 0.2487,
      "step": 24290
    },
    {
      "epoch": 24.3,
      "learning_rate": 0.0001352536746904387,
      "loss": 0.2833,
      "step": 24300
    },
    {
      "epoch": 24.31,
      "learning_rate": 0.0001352389026811008,
      "loss": 0.2249,
      "step": 24310
    },
    {
      "epoch": 24.32,
      "learning_rate": 0.00013522412408412707,
      "loss": 0.2698,
      "step": 24320
    },
    {
      "epoch": 24.33,
      "learning_rate": 0.00013520933890113368,
      "loss": 0.3102,
      "step": 24330
    },
    {
      "epoch": 24.34,
      "learning_rate": 0.0001351945471337375,
      "loss": 0.2355,
      "step": 24340
    },
    {
      "epoch": 24.35,
      "learning_rate": 0.00013517974878355613,
      "loss": 0.2188,
      "step": 24350
    },
    {
      "epoch": 24.36,
      "learning_rate": 0.00013516494385220793,
      "loss": 0.2547,
      "step": 24360
    },
    {
      "epoch": 24.37,
      "learning_rate": 0.00013515013234131193,
      "loss": 0.2338,
      "step": 24370
    },
    {
      "epoch": 24.38,
      "learning_rate": 0.0001351353142524879,
      "loss": 0.2258,
      "step": 24380
    },
    {
      "epoch": 24.39,
      "learning_rate": 0.0001351204895873563,
      "loss": 0.2917,
      "step": 24390
    },
    {
      "epoch": 24.4,
      "learning_rate": 0.00013510565834753835,
      "loss": 0.3006,
      "step": 24400
    },
    {
      "epoch": 24.41,
      "learning_rate": 0.000135090820534656,
      "loss": 0.2653,
      "step": 24410
    },
    {
      "epoch": 24.42,
      "learning_rate": 0.00013507597615033183,
      "loss": 0.2348,
      "step": 24420
    },
    {
      "epoch": 24.43,
      "learning_rate": 0.00013506112519618923,
      "loss": 0.3192,
      "step": 24430
    },
    {
      "epoch": 24.44,
      "learning_rate": 0.0001350462676738523,
      "loss": 0.3056,
      "step": 24440
    },
    {
      "epoch": 24.45,
      "learning_rate": 0.00013503140358494577,
      "loss": 0.3264,
      "step": 24450
    },
    {
      "epoch": 24.46,
      "learning_rate": 0.00013501653293109523,
      "loss": 0.2697,
      "step": 24460
    },
    {
      "epoch": 24.47,
      "learning_rate": 0.0001350016557139269,
      "loss": 0.2996,
      "step": 24470
    },
    {
      "epoch": 24.48,
      "learning_rate": 0.0001349867719350677,
      "loss": 0.2011,
      "step": 24480
    },
    {
      "epoch": 24.49,
      "learning_rate": 0.0001349718815961453,
      "loss": 0.3531,
      "step": 24490
    },
    {
      "epoch": 24.5,
      "learning_rate": 0.0001349569846987881,
      "loss": 0.2168,
      "step": 24500
    },
    {
      "epoch": 24.51,
      "learning_rate": 0.00013494208124462521,
      "loss": 0.3039,
      "step": 24510
    },
    {
      "epoch": 24.52,
      "learning_rate": 0.0001349271712352864,
      "loss": 0.3231,
      "step": 24520
    },
    {
      "epoch": 24.53,
      "learning_rate": 0.0001349122546724023,
      "loss": 0.2269,
      "step": 24530
    },
    {
      "epoch": 24.54,
      "learning_rate": 0.00013489733155760408,
      "loss": 0.2692,
      "step": 24540
    },
    {
      "epoch": 24.55,
      "learning_rate": 0.0001348824018925237,
      "loss": 0.3038,
      "step": 24550
    },
    {
      "epoch": 24.56,
      "learning_rate": 0.00013486746567879391,
      "loss": 0.338,
      "step": 24560
    },
    {
      "epoch": 24.57,
      "learning_rate": 0.00013485252291804808,
      "loss": 0.2437,
      "step": 24570
    },
    {
      "epoch": 24.58,
      "learning_rate": 0.00013483757361192034,
      "loss": 0.2681,
      "step": 24580
    },
    {
      "epoch": 24.59,
      "learning_rate": 0.0001348226177620455,
      "loss": 0.2572,
      "step": 24590
    },
    {
      "epoch": 24.6,
      "learning_rate": 0.00013480765537005914,
      "loss": 0.2992,
      "step": 24600
    },
    {
      "epoch": 24.61,
      "learning_rate": 0.0001347926864375975,
      "loss": 0.3297,
      "step": 24610
    },
    {
      "epoch": 24.62,
      "learning_rate": 0.00013477771096629757,
      "loss": 0.3316,
      "step": 24620
    },
    {
      "epoch": 24.63,
      "learning_rate": 0.00013476272895779703,
      "loss": 0.2843,
      "step": 24630
    },
    {
      "epoch": 24.64,
      "learning_rate": 0.00013474774041373431,
      "loss": 0.1941,
      "step": 24640
    },
    {
      "epoch": 24.65,
      "learning_rate": 0.00013473274533574853,
      "loss": 0.3565,
      "step": 24650
    },
    {
      "epoch": 24.66,
      "learning_rate": 0.00013471774372547955,
      "loss": 0.2943,
      "step": 24660
    },
    {
      "epoch": 24.67,
      "learning_rate": 0.00013470273558456787,
      "loss": 0.2781,
      "step": 24670
    },
    {
      "epoch": 24.68,
      "learning_rate": 0.0001346877209146548,
      "loss": 0.2768,
      "step": 24680
    },
    {
      "epoch": 24.69,
      "learning_rate": 0.0001346726997173823,
      "loss": 0.3115,
      "step": 24690
    },
    {
      "epoch": 24.7,
      "learning_rate": 0.0001346576719943931,
      "loss": 0.2969,
      "step": 24700
    },
    {
      "epoch": 24.71,
      "learning_rate": 0.00013464263774733053,
      "loss": 0.234,
      "step": 24710
    },
    {
      "epoch": 24.72,
      "learning_rate": 0.00013462759697783884,
      "loss": 0.3412,
      "step": 24720
    },
    {
      "epoch": 24.73,
      "learning_rate": 0.00013461254968756274,
      "loss": 0.3127,
      "step": 24730
    },
    {
      "epoch": 24.74,
      "learning_rate": 0.00013459749587814784,
      "loss": 0.2601,
      "step": 24740
    },
    {
      "epoch": 24.75,
      "learning_rate": 0.0001345824355512404,
      "loss": 0.2611,
      "step": 24750
    },
    {
      "epoch": 24.76,
      "learning_rate": 0.00013456736870848742,
      "loss": 0.2619,
      "step": 24760
    },
    {
      "epoch": 24.77,
      "learning_rate": 0.00013455229535153654,
      "loss": 0.3339,
      "step": 24770
    },
    {
      "epoch": 24.78,
      "learning_rate": 0.00013453721548203616,
      "loss": 0.2933,
      "step": 24780
    },
    {
      "epoch": 24.79,
      "learning_rate": 0.0001345221291016354,
      "loss": 0.2347,
      "step": 24790
    },
    {
      "epoch": 24.8,
      "learning_rate": 0.00013450703621198409,
      "loss": 0.2537,
      "step": 24800
    },
    {
      "epoch": 24.81,
      "learning_rate": 0.0001344919368147328,
      "loss": 0.2968,
      "step": 24810
    },
    {
      "epoch": 24.82,
      "learning_rate": 0.0001344768309115327,
      "loss": 0.267,
      "step": 24820
    },
    {
      "epoch": 24.83,
      "learning_rate": 0.00013446171850403584,
      "loss": 0.2362,
      "step": 24830
    },
    {
      "epoch": 24.84,
      "learning_rate": 0.0001344465995938948,
      "loss": 0.2251,
      "step": 24840
    },
    {
      "epoch": 24.85,
      "learning_rate": 0.00013443147418276306,
      "loss": 0.2702,
      "step": 24850
    },
    {
      "epoch": 24.86,
      "learning_rate": 0.00013441634227229462,
      "loss": 0.2462,
      "step": 24860
    },
    {
      "epoch": 24.87,
      "learning_rate": 0.00013440120386414432,
      "loss": 0.3284,
      "step": 24870
    },
    {
      "epoch": 24.88,
      "learning_rate": 0.0001343860589599677,
      "loss": 0.2611,
      "step": 24880
    },
    {
      "epoch": 24.89,
      "learning_rate": 0.00013437090756142093,
      "loss": 0.2774,
      "step": 24890
    },
    {
      "epoch": 24.9,
      "learning_rate": 0.00013435574967016097,
      "loss": 0.2523,
      "step": 24900
    },
    {
      "epoch": 24.91,
      "learning_rate": 0.00013434058528784547,
      "loss": 0.2688,
      "step": 24910
    },
    {
      "epoch": 24.92,
      "learning_rate": 0.00013432541441613278,
      "loss": 0.3121,
      "step": 24920
    },
    {
      "epoch": 24.93,
      "learning_rate": 0.000134310237056682,
      "loss": 0.2771,
      "step": 24930
    },
    {
      "epoch": 24.94,
      "learning_rate": 0.0001342950532111528,
      "loss": 0.2937,
      "step": 24940
    },
    {
      "epoch": 24.95,
      "learning_rate": 0.00013427986288120578,
      "loss": 0.3196,
      "step": 24950
    },
    {
      "epoch": 24.96,
      "learning_rate": 0.00013426466606850207,
      "loss": 0.3372,
      "step": 24960
    },
    {
      "epoch": 24.97,
      "learning_rate": 0.00013424946277470356,
      "loss": 0.1735,
      "step": 24970
    },
    {
      "epoch": 24.98,
      "learning_rate": 0.00013423425300147294,
      "loss": 0.3623,
      "step": 24980
    },
    {
      "epoch": 24.99,
      "learning_rate": 0.00013421903675047342,
      "loss": 0.2512,
      "step": 24990
    },
    {
      "epoch": 25.0,
      "learning_rate": 0.00013420381402336909,
      "loss": 0.3553,
      "step": 25000
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2732239365577698,
      "eval_runtime": 14.8074,
      "eval_samples_per_second": 135.068,
      "eval_steps_per_second": 16.883,
      "step": 25000
    },
    {
      "epoch": 25.01,
      "learning_rate": 0.00013418858482182466,
      "loss": 0.3735,
      "step": 25010
    },
    {
      "epoch": 25.02,
      "learning_rate": 0.0001341733491475056,
      "loss": 0.2556,
      "step": 25020
    },
    {
      "epoch": 25.03,
      "learning_rate": 0.00013415810700207801,
      "loss": 0.2419,
      "step": 25030
    },
    {
      "epoch": 25.04,
      "learning_rate": 0.00013414285838720882,
      "loss": 0.3074,
      "step": 25040
    },
    {
      "epoch": 25.05,
      "learning_rate": 0.0001341276033045655,
      "loss": 0.2895,
      "step": 25050
    },
    {
      "epoch": 25.06,
      "learning_rate": 0.00013411234175581644,
      "loss": 0.2593,
      "step": 25060
    },
    {
      "epoch": 25.07,
      "learning_rate": 0.00013409707374263056,
      "loss": 0.3649,
      "step": 25070
    },
    {
      "epoch": 25.08,
      "learning_rate": 0.0001340817992666775,
      "loss": 0.3089,
      "step": 25080
    },
    {
      "epoch": 25.09,
      "learning_rate": 0.00013406651832962774,
      "loss": 0.2431,
      "step": 25090
    },
    {
      "epoch": 25.1,
      "learning_rate": 0.00013405123093315232,
      "loss": 0.3401,
      "step": 25100
    },
    {
      "epoch": 25.11,
      "learning_rate": 0.00013403593707892307,
      "loss": 0.2265,
      "step": 25110
    },
    {
      "epoch": 25.12,
      "learning_rate": 0.00013402063676861252,
      "loss": 0.2725,
      "step": 25120
    },
    {
      "epoch": 25.13,
      "learning_rate": 0.00013400533000389384,
      "loss": 0.297,
      "step": 25130
    },
    {
      "epoch": 25.14,
      "learning_rate": 0.00013399001678644098,
      "loss": 0.3366,
      "step": 25140
    },
    {
      "epoch": 25.15,
      "learning_rate": 0.00013397469711792862,
      "loss": 0.2636,
      "step": 25150
    },
    {
      "epoch": 25.16,
      "learning_rate": 0.000133959371000032,
      "loss": 0.2612,
      "step": 25160
    },
    {
      "epoch": 25.17,
      "learning_rate": 0.00013394403843442723,
      "loss": 0.3491,
      "step": 25170
    },
    {
      "epoch": 25.18,
      "learning_rate": 0.00013392869942279107,
      "loss": 0.2649,
      "step": 25180
    },
    {
      "epoch": 25.19,
      "learning_rate": 0.00013391335396680087,
      "loss": 0.2953,
      "step": 25190
    },
    {
      "epoch": 25.2,
      "learning_rate": 0.00013389800206813494,
      "loss": 0.3083,
      "step": 25200
    },
    {
      "epoch": 25.21,
      "learning_rate": 0.000133882643728472,
      "loss": 0.3062,
      "step": 25210
    },
    {
      "epoch": 25.22,
      "learning_rate": 0.00013386727894949168,
      "loss": 0.2917,
      "step": 25220
    },
    {
      "epoch": 25.23,
      "learning_rate": 0.00013385190773287424,
      "loss": 0.2595,
      "step": 25230
    },
    {
      "epoch": 25.24,
      "learning_rate": 0.00013383653008030067,
      "loss": 0.335,
      "step": 25240
    },
    {
      "epoch": 25.25,
      "learning_rate": 0.0001338211459934526,
      "loss": 0.3172,
      "step": 25250
    },
    {
      "epoch": 25.26,
      "learning_rate": 0.00013380575547401245,
      "loss": 0.2714,
      "step": 25260
    },
    {
      "epoch": 25.27,
      "learning_rate": 0.0001337903585236633,
      "loss": 0.2781,
      "step": 25270
    },
    {
      "epoch": 25.28,
      "learning_rate": 0.00013377495514408893,
      "loss": 0.3121,
      "step": 25280
    },
    {
      "epoch": 25.29,
      "learning_rate": 0.00013375954533697383,
      "loss": 0.2486,
      "step": 25290
    },
    {
      "epoch": 25.3,
      "learning_rate": 0.0001337441291040032,
      "loss": 0.248,
      "step": 25300
    },
    {
      "epoch": 25.31,
      "learning_rate": 0.00013372870644686295,
      "loss": 0.2347,
      "step": 25310
    },
    {
      "epoch": 25.32,
      "learning_rate": 0.00013371327736723962,
      "loss": 0.3015,
      "step": 25320
    },
    {
      "epoch": 25.33,
      "learning_rate": 0.00013369784186682056,
      "loss": 0.2354,
      "step": 25330
    },
    {
      "epoch": 25.34,
      "learning_rate": 0.00013368239994729377,
      "loss": 0.3107,
      "step": 25340
    },
    {
      "epoch": 25.35,
      "learning_rate": 0.00013366695161034798,
      "loss": 0.2956,
      "step": 25350
    },
    {
      "epoch": 25.36,
      "learning_rate": 0.00013365149685767253,
      "loss": 0.2692,
      "step": 25360
    },
    {
      "epoch": 25.37,
      "learning_rate": 0.0001336360356909576,
      "loss": 0.2758,
      "step": 25370
    },
    {
      "epoch": 25.38,
      "learning_rate": 0.0001336205681118939,
      "loss": 0.2104,
      "step": 25380
    },
    {
      "epoch": 25.39,
      "learning_rate": 0.00013360509412217307,
      "loss": 0.3102,
      "step": 25390
    },
    {
      "epoch": 25.4,
      "learning_rate": 0.00013358961372348724,
      "loss": 0.198,
      "step": 25400
    },
    {
      "epoch": 25.41,
      "learning_rate": 0.00013357412691752932,
      "loss": 0.206,
      "step": 25410
    },
    {
      "epoch": 25.42,
      "learning_rate": 0.00013355863370599297,
      "loss": 0.2187,
      "step": 25420
    },
    {
      "epoch": 25.43,
      "learning_rate": 0.00013354313409057246,
      "loss": 0.2701,
      "step": 25430
    },
    {
      "epoch": 25.44,
      "learning_rate": 0.00013352762807296284,
      "loss": 0.2224,
      "step": 25440
    },
    {
      "epoch": 25.45,
      "learning_rate": 0.0001335121156548598,
      "loss": 0.2251,
      "step": 25450
    },
    {
      "epoch": 25.46,
      "learning_rate": 0.0001334965968379598,
      "loss": 0.2651,
      "step": 25460
    },
    {
      "epoch": 25.47,
      "learning_rate": 0.00013348107162395987,
      "loss": 0.2948,
      "step": 25470
    },
    {
      "epoch": 25.48,
      "learning_rate": 0.0001334655400145579,
      "loss": 0.2773,
      "step": 25480
    },
    {
      "epoch": 25.49,
      "learning_rate": 0.00013345000201145236,
      "loss": 0.2616,
      "step": 25490
    },
    {
      "epoch": 25.5,
      "learning_rate": 0.00013343445761634248,
      "loss": 0.3298,
      "step": 25500
    },
    {
      "epoch": 25.51,
      "learning_rate": 0.0001334189068309282,
      "loss": 0.3279,
      "step": 25510
    },
    {
      "epoch": 25.52,
      "learning_rate": 0.00013340334965691004,
      "loss": 0.3286,
      "step": 25520
    },
    {
      "epoch": 25.53,
      "learning_rate": 0.0001333877860959894,
      "loss": 0.2955,
      "step": 25530
    },
    {
      "epoch": 25.54,
      "learning_rate": 0.00013337221614986828,
      "loss": 0.2684,
      "step": 25540
    },
    {
      "epoch": 25.55,
      "learning_rate": 0.00013335663982024936,
      "loss": 0.1982,
      "step": 25550
    },
    {
      "epoch": 25.56,
      "learning_rate": 0.000133341057108836,
      "loss": 0.3251,
      "step": 25560
    },
    {
      "epoch": 25.57,
      "learning_rate": 0.00013332546801733238,
      "loss": 0.3152,
      "step": 25570
    },
    {
      "epoch": 25.58,
      "learning_rate": 0.00013330987254744328,
      "loss": 0.3149,
      "step": 25580
    },
    {
      "epoch": 25.59,
      "learning_rate": 0.00013329427070087418,
      "loss": 0.2998,
      "step": 25590
    },
    {
      "epoch": 25.6,
      "learning_rate": 0.00013327866247933126,
      "loss": 0.2715,
      "step": 25600
    },
    {
      "epoch": 25.61,
      "learning_rate": 0.00013326304788452146,
      "loss": 0.2426,
      "step": 25610
    },
    {
      "epoch": 25.62,
      "learning_rate": 0.0001332474269181523,
      "loss": 0.2515,
      "step": 25620
    },
    {
      "epoch": 25.63,
      "learning_rate": 0.00013323179958193214,
      "loss": 0.2695,
      "step": 25630
    },
    {
      "epoch": 25.64,
      "learning_rate": 0.00013321616587756992,
      "loss": 0.3104,
      "step": 25640
    },
    {
      "epoch": 25.65,
      "learning_rate": 0.00013320052580677533,
      "loss": 0.3138,
      "step": 25650
    },
    {
      "epoch": 25.66,
      "learning_rate": 0.00013318487937125876,
      "loss": 0.356,
      "step": 25660
    },
    {
      "epoch": 25.67,
      "learning_rate": 0.0001331692265727312,
      "loss": 0.2912,
      "step": 25670
    },
    {
      "epoch": 25.68,
      "learning_rate": 0.00013315356741290453,
      "loss": 0.1996,
      "step": 25680
    },
    {
      "epoch": 25.69,
      "learning_rate": 0.00013313790189349115,
      "loss": 0.2322,
      "step": 25690
    },
    {
      "epoch": 25.7,
      "learning_rate": 0.00013312223001620422,
      "loss": 0.2875,
      "step": 25700
    },
    {
      "epoch": 25.71,
      "learning_rate": 0.00013310655178275764,
      "loss": 0.2887,
      "step": 25710
    },
    {
      "epoch": 25.72,
      "learning_rate": 0.00013309086719486587,
      "loss": 0.2399,
      "step": 25720
    },
    {
      "epoch": 25.73,
      "learning_rate": 0.00013307517625424421,
      "loss": 0.2352,
      "step": 25730
    },
    {
      "epoch": 25.74,
      "learning_rate": 0.0001330594789626086,
      "loss": 0.2925,
      "step": 25740
    },
    {
      "epoch": 25.75,
      "learning_rate": 0.00013304377532167568,
      "loss": 0.3157,
      "step": 25750
    },
    {
      "epoch": 25.76,
      "learning_rate": 0.00013302806533316272,
      "loss": 0.276,
      "step": 25760
    },
    {
      "epoch": 25.77,
      "learning_rate": 0.0001330123489987878,
      "loss": 0.3158,
      "step": 25770
    },
    {
      "epoch": 25.78,
      "learning_rate": 0.0001329966263202696,
      "loss": 0.2587,
      "step": 25780
    },
    {
      "epoch": 25.79,
      "learning_rate": 0.00013298089729932755,
      "loss": 0.2789,
      "step": 25790
    },
    {
      "epoch": 25.8,
      "learning_rate": 0.00013296516193768177,
      "loss": 0.2228,
      "step": 25800
    },
    {
      "epoch": 25.81,
      "learning_rate": 0.000132949420237053,
      "loss": 0.2073,
      "step": 25810
    },
    {
      "epoch": 25.82,
      "learning_rate": 0.00013293367219916274,
      "loss": 0.3019,
      "step": 25820
    },
    {
      "epoch": 25.83,
      "learning_rate": 0.00013291791782573322,
      "loss": 0.2658,
      "step": 25830
    },
    {
      "epoch": 25.84,
      "learning_rate": 0.00013290215711848728,
      "loss": 0.2752,
      "step": 25840
    },
    {
      "epoch": 25.85,
      "learning_rate": 0.0001328863900791485,
      "loss": 0.2925,
      "step": 25850
    },
    {
      "epoch": 25.86,
      "learning_rate": 0.00013287061670944113,
      "loss": 0.249,
      "step": 25860
    },
    {
      "epoch": 25.87,
      "learning_rate": 0.00013285483701109012,
      "loss": 0.2764,
      "step": 25870
    },
    {
      "epoch": 25.88,
      "learning_rate": 0.0001328390509858211,
      "loss": 0.2761,
      "step": 25880
    },
    {
      "epoch": 25.89,
      "learning_rate": 0.00013282483815499092,
      "loss": 0.297,
      "step": 25890
    },
    {
      "epoch": 25.9,
      "learning_rate": 0.00013280904011333438,
      "loss": 0.2955,
      "step": 25900
    },
    {
      "epoch": 25.91,
      "learning_rate": 0.00013279323574976807,
      "loss": 0.3123,
      "step": 25910
    },
    {
      "epoch": 25.92,
      "learning_rate": 0.00013277742506602046,
      "loss": 0.2591,
      "step": 25920
    },
    {
      "epoch": 25.93,
      "learning_rate": 0.00013276160806382044,
      "loss": 0.226,
      "step": 25930
    },
    {
      "epoch": 25.94,
      "learning_rate": 0.00013274578474489787,
      "loss": 0.3306,
      "step": 25940
    },
    {
      "epoch": 25.95,
      "learning_rate": 0.00013272995511098306,
      "loss": 0.2868,
      "step": 25950
    },
    {
      "epoch": 25.96,
      "learning_rate": 0.00013271411916380716,
      "loss": 0.2773,
      "step": 25960
    },
    {
      "epoch": 25.97,
      "learning_rate": 0.00013269827690510198,
      "loss": 0.3037,
      "step": 25970
    },
    {
      "epoch": 25.98,
      "learning_rate": 0.00013268242833659995,
      "loss": 0.2948,
      "step": 25980
    },
    {
      "epoch": 25.99,
      "learning_rate": 0.00013266657346003432,
      "loss": 0.2693,
      "step": 25990
    },
    {
      "epoch": 26.0,
      "learning_rate": 0.0001326507122771389,
      "loss": 0.2602,
      "step": 26000
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2730797529220581,
      "eval_runtime": 15.1112,
      "eval_samples_per_second": 132.352,
      "eval_steps_per_second": 16.544,
      "step": 26000
    },
    {
      "epoch": 26.01,
      "learning_rate": 0.00013263484478964827,
      "loss": 0.2779,
      "step": 26010
    },
    {
      "epoch": 26.02,
      "learning_rate": 0.00013261897099929766,
      "loss": 0.2092,
      "step": 26020
    },
    {
      "epoch": 26.03,
      "learning_rate": 0.000132603090907823,
      "loss": 0.3114,
      "step": 26030
    },
    {
      "epoch": 26.04,
      "learning_rate": 0.00013258720451696097,
      "loss": 0.3027,
      "step": 26040
    },
    {
      "epoch": 26.05,
      "learning_rate": 0.00013257131182844878,
      "loss": 0.2502,
      "step": 26050
    },
    {
      "epoch": 26.06,
      "learning_rate": 0.0001325554128440245,
      "loss": 0.2927,
      "step": 26060
    },
    {
      "epoch": 26.07,
      "learning_rate": 0.0001325395075654268,
      "loss": 0.3052,
      "step": 26070
    },
    {
      "epoch": 26.08,
      "learning_rate": 0.00013252359599439506,
      "loss": 0.2814,
      "step": 26080
    },
    {
      "epoch": 26.09,
      "learning_rate": 0.00013250767813266937,
      "loss": 0.3479,
      "step": 26090
    },
    {
      "epoch": 26.1,
      "learning_rate": 0.00013249175398199044,
      "loss": 0.2341,
      "step": 26100
    },
    {
      "epoch": 26.11,
      "learning_rate": 0.00013247582354409976,
      "loss": 0.2516,
      "step": 26110
    },
    {
      "epoch": 26.12,
      "learning_rate": 0.0001324598868207394,
      "loss": 0.3221,
      "step": 26120
    },
    {
      "epoch": 26.13,
      "learning_rate": 0.00013244394381365222,
      "loss": 0.2515,
      "step": 26130
    },
    {
      "epoch": 26.14,
      "learning_rate": 0.0001324279945245817,
      "loss": 0.3206,
      "step": 26140
    },
    {
      "epoch": 26.15,
      "learning_rate": 0.00013241203895527208,
      "loss": 0.2685,
      "step": 26150
    },
    {
      "epoch": 26.16,
      "learning_rate": 0.00013239607710746815,
      "loss": 0.2691,
      "step": 26160
    },
    {
      "epoch": 26.17,
      "learning_rate": 0.00013238010898291555,
      "loss": 0.2854,
      "step": 26170
    },
    {
      "epoch": 26.18,
      "learning_rate": 0.00013236413458336048,
      "loss": 0.2778,
      "step": 26180
    },
    {
      "epoch": 26.19,
      "learning_rate": 0.0001323481539105499,
      "loss": 0.2258,
      "step": 26190
    },
    {
      "epoch": 26.2,
      "learning_rate": 0.00013233216696623146,
      "loss": 0.2594,
      "step": 26200
    },
    {
      "epoch": 26.21,
      "learning_rate": 0.0001323161737521534,
      "loss": 0.3044,
      "step": 26210
    },
    {
      "epoch": 26.22,
      "learning_rate": 0.00013230017427006476,
      "loss": 0.2426,
      "step": 26220
    },
    {
      "epoch": 26.23,
      "learning_rate": 0.00013228416852171523,
      "loss": 0.233,
      "step": 26230
    },
    {
      "epoch": 26.24,
      "learning_rate": 0.00013226815650885514,
      "loss": 0.2947,
      "step": 26240
    },
    {
      "epoch": 26.25,
      "learning_rate": 0.00013225213823323556,
      "loss": 0.2689,
      "step": 26250
    },
    {
      "epoch": 26.26,
      "learning_rate": 0.0001322361136966082,
      "loss": 0.3194,
      "step": 26260
    },
    {
      "epoch": 26.27,
      "learning_rate": 0.00013222008290072554,
      "loss": 0.3388,
      "step": 26270
    },
    {
      "epoch": 26.28,
      "learning_rate": 0.00013220404584734062,
      "loss": 0.253,
      "step": 26280
    },
    {
      "epoch": 26.29,
      "learning_rate": 0.00013218800253820726,
      "loss": 0.3218,
      "step": 26290
    },
    {
      "epoch": 26.3,
      "learning_rate": 0.00013217195297507992,
      "loss": 0.2594,
      "step": 26300
    },
    {
      "epoch": 26.31,
      "learning_rate": 0.00013215589715971375,
      "loss": 0.3222,
      "step": 26310
    },
    {
      "epoch": 26.32,
      "learning_rate": 0.00013213983509386461,
      "loss": 0.2597,
      "step": 26320
    },
    {
      "epoch": 26.33,
      "learning_rate": 0.000132123766779289,
      "loss": 0.2351,
      "step": 26330
    },
    {
      "epoch": 26.34,
      "learning_rate": 0.00013210769221774416,
      "loss": 0.261,
      "step": 26340
    },
    {
      "epoch": 26.35,
      "learning_rate": 0.00013209161141098795,
      "loss": 0.2442,
      "step": 26350
    },
    {
      "epoch": 26.36,
      "learning_rate": 0.00013207552436077894,
      "loss": 0.3671,
      "step": 26360
    },
    {
      "epoch": 26.37,
      "learning_rate": 0.0001320594310688764,
      "loss": 0.2507,
      "step": 26370
    },
    {
      "epoch": 26.38,
      "learning_rate": 0.00013204333153704026,
      "loss": 0.3565,
      "step": 26380
    },
    {
      "epoch": 26.39,
      "learning_rate": 0.00013202722576703118,
      "loss": 0.2226,
      "step": 26390
    },
    {
      "epoch": 26.4,
      "learning_rate": 0.0001320111137606104,
      "loss": 0.2434,
      "step": 26400
    },
    {
      "epoch": 26.41,
      "learning_rate": 0.00013199499551953996,
      "loss": 0.295,
      "step": 26410
    },
    {
      "epoch": 26.42,
      "learning_rate": 0.00013197887104558247,
      "loss": 0.3309,
      "step": 26420
    },
    {
      "epoch": 26.43,
      "learning_rate": 0.00013196274034050131,
      "loss": 0.2852,
      "step": 26430
    },
    {
      "epoch": 26.44,
      "learning_rate": 0.00013194660340606052,
      "loss": 0.3321,
      "step": 26440
    },
    {
      "epoch": 26.45,
      "learning_rate": 0.00013193046024402485,
      "loss": 0.2934,
      "step": 26450
    },
    {
      "epoch": 26.46,
      "learning_rate": 0.00013191431085615956,
      "loss": 0.2353,
      "step": 26460
    },
    {
      "epoch": 26.47,
      "learning_rate": 0.00013189815524423083,
      "loss": 0.2688,
      "step": 26470
    },
    {
      "epoch": 26.48,
      "learning_rate": 0.0001318819934100054,
      "loss": 0.2879,
      "step": 26480
    },
    {
      "epoch": 26.49,
      "learning_rate": 0.0001318658253552507,
      "loss": 0.2199,
      "step": 26490
    },
    {
      "epoch": 26.5,
      "learning_rate": 0.0001318496510817348,
      "loss": 0.3144,
      "step": 26500
    },
    {
      "epoch": 26.51,
      "learning_rate": 0.00013183347059122656,
      "loss": 0.3168,
      "step": 26510
    },
    {
      "epoch": 26.52,
      "learning_rate": 0.0001318172838854954,
      "loss": 0.2752,
      "step": 26520
    },
    {
      "epoch": 26.53,
      "learning_rate": 0.00013180109096631152,
      "loss": 0.354,
      "step": 26530
    },
    {
      "epoch": 26.54,
      "learning_rate": 0.00013178489183544574,
      "loss": 0.2472,
      "step": 26540
    },
    {
      "epoch": 26.55,
      "learning_rate": 0.00013176868649466953,
      "loss": 0.2659,
      "step": 26550
    },
    {
      "epoch": 26.56,
      "learning_rate": 0.00013175247494575515,
      "loss": 0.2961,
      "step": 26560
    },
    {
      "epoch": 26.57,
      "learning_rate": 0.0001317362571904754,
      "loss": 0.3244,
      "step": 26570
    },
    {
      "epoch": 26.58,
      "learning_rate": 0.0001317200332306039,
      "loss": 0.2897,
      "step": 26580
    },
    {
      "epoch": 26.59,
      "learning_rate": 0.00013170380306791482,
      "loss": 0.2612,
      "step": 26590
    },
    {
      "epoch": 26.6,
      "learning_rate": 0.0001316875667041831,
      "loss": 0.2335,
      "step": 26600
    },
    {
      "epoch": 26.61,
      "learning_rate": 0.0001316713241411843,
      "loss": 0.3044,
      "step": 26610
    },
    {
      "epoch": 26.62,
      "learning_rate": 0.00013165507538069471,
      "loss": 0.2303,
      "step": 26620
    },
    {
      "epoch": 26.63,
      "learning_rate": 0.00013163882042449123,
      "loss": 0.2656,
      "step": 26630
    },
    {
      "epoch": 26.64,
      "learning_rate": 0.00013162255927435157,
      "loss": 0.272,
      "step": 26640
    },
    {
      "epoch": 26.65,
      "learning_rate": 0.00013160629193205388,
      "loss": 0.3303,
      "step": 26650
    },
    {
      "epoch": 26.66,
      "learning_rate": 0.00013159001839937727,
      "loss": 0.2776,
      "step": 26660
    },
    {
      "epoch": 26.67,
      "learning_rate": 0.00013157373867810128,
      "loss": 0.2275,
      "step": 26670
    },
    {
      "epoch": 26.68,
      "learning_rate": 0.00013155745277000633,
      "loss": 0.2616,
      "step": 26680
    },
    {
      "epoch": 26.69,
      "learning_rate": 0.00013154116067687336,
      "loss": 0.2775,
      "step": 26690
    },
    {
      "epoch": 26.7,
      "learning_rate": 0.00013152486240048406,
      "loss": 0.2601,
      "step": 26700
    },
    {
      "epoch": 26.71,
      "learning_rate": 0.00013150855794262078,
      "loss": 0.2771,
      "step": 26710
    },
    {
      "epoch": 26.72,
      "learning_rate": 0.0001314922473050666,
      "loss": 0.2693,
      "step": 26720
    },
    {
      "epoch": 26.73,
      "learning_rate": 0.00013147593048960516,
      "loss": 0.303,
      "step": 26730
    },
    {
      "epoch": 26.74,
      "learning_rate": 0.00013145960749802089,
      "loss": 0.2952,
      "step": 26740
    },
    {
      "epoch": 26.75,
      "learning_rate": 0.00013144327833209882,
      "loss": 0.3388,
      "step": 26750
    },
    {
      "epoch": 26.76,
      "learning_rate": 0.0001314269429936247,
      "loss": 0.2856,
      "step": 26760
    },
    {
      "epoch": 26.77,
      "learning_rate": 0.0001314106014843849,
      "loss": 0.1988,
      "step": 26770
    },
    {
      "epoch": 26.78,
      "learning_rate": 0.00013139425380616658,
      "loss": 0.2862,
      "step": 26780
    },
    {
      "epoch": 26.79,
      "learning_rate": 0.0001313778999607574,
      "loss": 0.2773,
      "step": 26790
    },
    {
      "epoch": 26.8,
      "learning_rate": 0.0001313615399499459,
      "loss": 0.303,
      "step": 26800
    },
    {
      "epoch": 26.81,
      "learning_rate": 0.0001313451737755211,
      "loss": 0.3295,
      "step": 26810
    },
    {
      "epoch": 26.82,
      "learning_rate": 0.0001313288014392728,
      "loss": 0.2774,
      "step": 26820
    },
    {
      "epoch": 26.83,
      "learning_rate": 0.0001313124229429915,
      "loss": 0.3377,
      "step": 26830
    },
    {
      "epoch": 26.84,
      "learning_rate": 0.00013129603828846825,
      "loss": 0.3015,
      "step": 26840
    },
    {
      "epoch": 26.85,
      "learning_rate": 0.0001312796474774949,
      "loss": 0.2809,
      "step": 26850
    },
    {
      "epoch": 26.86,
      "learning_rate": 0.00013126325051186392,
      "loss": 0.2959,
      "step": 26860
    },
    {
      "epoch": 26.87,
      "learning_rate": 0.00013124684739336846,
      "loss": 0.2364,
      "step": 26870
    },
    {
      "epoch": 26.88,
      "learning_rate": 0.00013123043812380232,
      "loss": 0.2572,
      "step": 26880
    },
    {
      "epoch": 26.89,
      "learning_rate": 0.00013121402270496006,
      "loss": 0.278,
      "step": 26890
    },
    {
      "epoch": 26.9,
      "learning_rate": 0.00013119760113863675,
      "loss": 0.3033,
      "step": 26900
    },
    {
      "epoch": 26.91,
      "learning_rate": 0.00013118117342662827,
      "loss": 0.2373,
      "step": 26910
    },
    {
      "epoch": 26.92,
      "learning_rate": 0.00013116473957073115,
      "loss": 0.3028,
      "step": 26920
    },
    {
      "epoch": 26.93,
      "learning_rate": 0.00013114829957274252,
      "loss": 0.2418,
      "step": 26930
    },
    {
      "epoch": 26.94,
      "learning_rate": 0.0001311318534344603,
      "loss": 0.2071,
      "step": 26940
    },
    {
      "epoch": 26.95,
      "learning_rate": 0.00013111540115768298,
      "loss": 0.2541,
      "step": 26950
    },
    {
      "epoch": 26.96,
      "learning_rate": 0.00013109894274420975,
      "loss": 0.2993,
      "step": 26960
    },
    {
      "epoch": 26.97,
      "learning_rate": 0.00013108247819584049,
      "loss": 0.2766,
      "step": 26970
    },
    {
      "epoch": 26.98,
      "learning_rate": 0.0001310660075143757,
      "loss": 0.2514,
      "step": 26980
    },
    {
      "epoch": 26.99,
      "learning_rate": 0.00013104953070161666,
      "loss": 0.2312,
      "step": 26990
    },
    {
      "epoch": 27.0,
      "learning_rate": 0.0001310330477593652,
      "loss": 0.271,
      "step": 27000
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27421191334724426,
      "eval_runtime": 15.067,
      "eval_samples_per_second": 132.74,
      "eval_steps_per_second": 16.592,
      "step": 27000
    },
    {
      "epoch": 27.01,
      "learning_rate": 0.00013101655868942387,
      "loss": 0.2667,
      "step": 27010
    },
    {
      "epoch": 27.02,
      "learning_rate": 0.00013100006349359592,
      "loss": 0.2435,
      "step": 27020
    },
    {
      "epoch": 27.03,
      "learning_rate": 0.0001309835621736852,
      "loss": 0.2784,
      "step": 27030
    },
    {
      "epoch": 27.04,
      "learning_rate": 0.00013096705473149633,
      "loss": 0.2959,
      "step": 27040
    },
    {
      "epoch": 27.05,
      "learning_rate": 0.00013095054116883447,
      "loss": 0.2876,
      "step": 27050
    },
    {
      "epoch": 27.06,
      "learning_rate": 0.00013093402148750554,
      "loss": 0.27,
      "step": 27060
    },
    {
      "epoch": 27.07,
      "learning_rate": 0.00013091749568931615,
      "loss": 0.2779,
      "step": 27070
    },
    {
      "epoch": 27.08,
      "learning_rate": 0.00013090096377607347,
      "loss": 0.337,
      "step": 27080
    },
    {
      "epoch": 27.09,
      "learning_rate": 0.00013088442574958544,
      "loss": 0.2544,
      "step": 27090
    },
    {
      "epoch": 27.1,
      "learning_rate": 0.00013086788161166066,
      "loss": 0.2859,
      "step": 27100
    },
    {
      "epoch": 27.11,
      "learning_rate": 0.0001308513313641083,
      "loss": 0.3069,
      "step": 27110
    },
    {
      "epoch": 27.12,
      "learning_rate": 0.00013083477500873834,
      "loss": 0.255,
      "step": 27120
    },
    {
      "epoch": 27.13,
      "learning_rate": 0.00013081821254736132,
      "loss": 0.3423,
      "step": 27130
    },
    {
      "epoch": 27.14,
      "learning_rate": 0.00013080164398178852,
      "loss": 0.3289,
      "step": 27140
    },
    {
      "epoch": 27.15,
      "learning_rate": 0.00013078506931383182,
      "loss": 0.2445,
      "step": 27150
    },
    {
      "epoch": 27.16,
      "learning_rate": 0.0001307684885453038,
      "loss": 0.3647,
      "step": 27160
    },
    {
      "epoch": 27.17,
      "learning_rate": 0.00013075190167801773,
      "loss": 0.2961,
      "step": 27170
    },
    {
      "epoch": 27.18,
      "learning_rate": 0.0001307353087137875,
      "loss": 0.2774,
      "step": 27180
    },
    {
      "epoch": 27.19,
      "learning_rate": 0.00013071870965442771,
      "loss": 0.2522,
      "step": 27190
    },
    {
      "epoch": 27.2,
      "learning_rate": 0.00013070210450175361,
      "loss": 0.3553,
      "step": 27200
    },
    {
      "epoch": 27.21,
      "learning_rate": 0.00013068549325758112,
      "loss": 0.3177,
      "step": 27210
    },
    {
      "epoch": 27.22,
      "learning_rate": 0.0001306688759237268,
      "loss": 0.2837,
      "step": 27220
    },
    {
      "epoch": 27.23,
      "learning_rate": 0.0001306522525020079,
      "loss": 0.3096,
      "step": 27230
    },
    {
      "epoch": 27.24,
      "learning_rate": 0.00013063562299424233,
      "loss": 0.2854,
      "step": 27240
    },
    {
      "epoch": 27.25,
      "learning_rate": 0.00013061898740224868,
      "loss": 0.257,
      "step": 27250
    },
    {
      "epoch": 27.26,
      "learning_rate": 0.00013060234572784623,
      "loss": 0.179,
      "step": 27260
    },
    {
      "epoch": 27.27,
      "learning_rate": 0.00013058569797285482,
      "loss": 0.2518,
      "step": 27270
    },
    {
      "epoch": 27.28,
      "learning_rate": 0.00013056904413909502,
      "loss": 0.2667,
      "step": 27280
    },
    {
      "epoch": 27.29,
      "learning_rate": 0.00013055238422838813,
      "loss": 0.2836,
      "step": 27290
    },
    {
      "epoch": 27.3,
      "learning_rate": 0.00013053571824255604,
      "loss": 0.2215,
      "step": 27300
    },
    {
      "epoch": 27.31,
      "learning_rate": 0.00013051904618342124,
      "loss": 0.2253,
      "step": 27310
    },
    {
      "epoch": 27.32,
      "learning_rate": 0.0001305023680528071,
      "loss": 0.2972,
      "step": 27320
    },
    {
      "epoch": 27.33,
      "learning_rate": 0.00013048568385253738,
      "loss": 0.2721,
      "step": 27330
    },
    {
      "epoch": 27.34,
      "learning_rate": 0.00013046899358443672,
      "loss": 0.2407,
      "step": 27340
    },
    {
      "epoch": 27.35,
      "learning_rate": 0.0001304522972503303,
      "loss": 0.2421,
      "step": 27350
    },
    {
      "epoch": 27.36,
      "learning_rate": 0.00013043559485204404,
      "loss": 0.2638,
      "step": 27360
    },
    {
      "epoch": 27.37,
      "learning_rate": 0.00013041888639140446,
      "loss": 0.2714,
      "step": 27370
    },
    {
      "epoch": 27.38,
      "learning_rate": 0.00013040217187023877,
      "loss": 0.2965,
      "step": 27380
    },
    {
      "epoch": 27.39,
      "learning_rate": 0.0001303854512903749,
      "loss": 0.2771,
      "step": 27390
    },
    {
      "epoch": 27.4,
      "learning_rate": 0.00013036872465364133,
      "loss": 0.2971,
      "step": 27400
    },
    {
      "epoch": 27.41,
      "learning_rate": 0.0001303519919618673,
      "loss": 0.2419,
      "step": 27410
    },
    {
      "epoch": 27.42,
      "learning_rate": 0.0001303352532168826,
      "loss": 0.2483,
      "step": 27420
    },
    {
      "epoch": 27.43,
      "learning_rate": 0.00013031850842051783,
      "loss": 0.3559,
      "step": 27430
    },
    {
      "epoch": 27.44,
      "learning_rate": 0.00013030175757460416,
      "loss": 0.2759,
      "step": 27440
    },
    {
      "epoch": 27.45,
      "learning_rate": 0.0001302850006809734,
      "loss": 0.2979,
      "step": 27450
    },
    {
      "epoch": 27.46,
      "learning_rate": 0.0001302682377414581,
      "loss": 0.272,
      "step": 27460
    },
    {
      "epoch": 27.47,
      "learning_rate": 0.00013025146875789143,
      "loss": 0.2261,
      "step": 27470
    },
    {
      "epoch": 27.48,
      "learning_rate": 0.00013023469373210717,
      "loss": 0.2965,
      "step": 27480
    },
    {
      "epoch": 27.49,
      "learning_rate": 0.0001302179126659399,
      "loss": 0.2527,
      "step": 27490
    },
    {
      "epoch": 27.5,
      "learning_rate": 0.0001302011255612247,
      "loss": 0.3115,
      "step": 27500
    },
    {
      "epoch": 27.51,
      "learning_rate": 0.00013018433241979738,
      "loss": 0.2427,
      "step": 27510
    },
    {
      "epoch": 27.52,
      "learning_rate": 0.00013016753324349446,
      "loss": 0.2448,
      "step": 27520
    },
    {
      "epoch": 27.53,
      "learning_rate": 0.00013015072803415303,
      "loss": 0.2773,
      "step": 27530
    },
    {
      "epoch": 27.54,
      "learning_rate": 0.00013013391679361089,
      "loss": 0.2691,
      "step": 27540
    },
    {
      "epoch": 27.55,
      "learning_rate": 0.0001301170995237065,
      "loss": 0.2607,
      "step": 27550
    },
    {
      "epoch": 27.56,
      "learning_rate": 0.000130100276226279,
      "loss": 0.2867,
      "step": 27560
    },
    {
      "epoch": 27.57,
      "learning_rate": 0.00013008344690316814,
      "loss": 0.3032,
      "step": 27570
    },
    {
      "epoch": 27.58,
      "learning_rate": 0.00013006661155621433,
      "loss": 0.2954,
      "step": 27580
    },
    {
      "epoch": 27.59,
      "learning_rate": 0.00013004977018725867,
      "loss": 0.3075,
      "step": 27590
    },
    {
      "epoch": 27.6,
      "learning_rate": 0.0001300329227981429,
      "loss": 0.2859,
      "step": 27600
    },
    {
      "epoch": 27.61,
      "learning_rate": 0.00013001606939070946,
      "loss": 0.2638,
      "step": 27610
    },
    {
      "epoch": 27.62,
      "learning_rate": 0.00012999920996680135,
      "loss": 0.2458,
      "step": 27620
    },
    {
      "epoch": 27.63,
      "learning_rate": 0.00012998234452826234,
      "loss": 0.3167,
      "step": 27630
    },
    {
      "epoch": 27.64,
      "learning_rate": 0.00012996547307693682,
      "loss": 0.2938,
      "step": 27640
    },
    {
      "epoch": 27.65,
      "learning_rate": 0.00012994859561466976,
      "loss": 0.3119,
      "step": 27650
    },
    {
      "epoch": 27.66,
      "learning_rate": 0.00012993171214330693,
      "loss": 0.2691,
      "step": 27660
    },
    {
      "epoch": 27.67,
      "learning_rate": 0.00012991482266469466,
      "loss": 0.295,
      "step": 27670
    },
    {
      "epoch": 27.68,
      "learning_rate": 0.00012989792718067994,
      "loss": 0.27,
      "step": 27680
    },
    {
      "epoch": 27.69,
      "learning_rate": 0.0001298810256931104,
      "loss": 0.2869,
      "step": 27690
    },
    {
      "epoch": 27.7,
      "learning_rate": 0.00012986411820383446,
      "loss": 0.2687,
      "step": 27700
    },
    {
      "epoch": 27.71,
      "learning_rate": 0.00012984720471470102,
      "loss": 0.2415,
      "step": 27710
    },
    {
      "epoch": 27.72,
      "learning_rate": 0.00012983028522755972,
      "loss": 0.294,
      "step": 27720
    },
    {
      "epoch": 27.73,
      "learning_rate": 0.00012981335974426085,
      "loss": 0.3194,
      "step": 27730
    },
    {
      "epoch": 27.74,
      "learning_rate": 0.0001297964282666554,
      "loss": 0.2507,
      "step": 27740
    },
    {
      "epoch": 27.75,
      "learning_rate": 0.00012977949079659494,
      "loss": 0.3193,
      "step": 27750
    },
    {
      "epoch": 27.76,
      "learning_rate": 0.0001297625473359317,
      "loss": 0.3122,
      "step": 27760
    },
    {
      "epoch": 27.77,
      "learning_rate": 0.00012974559788651865,
      "loss": 0.2683,
      "step": 27770
    },
    {
      "epoch": 27.78,
      "learning_rate": 0.0001297286424502093,
      "loss": 0.2687,
      "step": 27780
    },
    {
      "epoch": 27.79,
      "learning_rate": 0.0001297116810288579,
      "loss": 0.2638,
      "step": 27790
    },
    {
      "epoch": 27.8,
      "learning_rate": 0.00012969471362431933,
      "loss": 0.3167,
      "step": 27800
    },
    {
      "epoch": 27.81,
      "learning_rate": 0.00012967774023844912,
      "loss": 0.245,
      "step": 27810
    },
    {
      "epoch": 27.82,
      "learning_rate": 0.00012966076087310343,
      "loss": 0.2372,
      "step": 27820
    },
    {
      "epoch": 27.83,
      "learning_rate": 0.00012964377553013908,
      "loss": 0.2572,
      "step": 27830
    },
    {
      "epoch": 27.84,
      "learning_rate": 0.00012962678421141364,
      "loss": 0.3195,
      "step": 27840
    },
    {
      "epoch": 27.85,
      "learning_rate": 0.0001296097869187852,
      "loss": 0.2715,
      "step": 27850
    },
    {
      "epoch": 27.86,
      "learning_rate": 0.00012959278365411256,
      "loss": 0.3578,
      "step": 27860
    },
    {
      "epoch": 27.87,
      "learning_rate": 0.00012957577441925517,
      "loss": 0.3011,
      "step": 27870
    },
    {
      "epoch": 27.88,
      "learning_rate": 0.00012955875921607317,
      "loss": 0.1991,
      "step": 27880
    },
    {
      "epoch": 27.89,
      "learning_rate": 0.00012954173804642725,
      "loss": 0.2427,
      "step": 27890
    },
    {
      "epoch": 27.9,
      "learning_rate": 0.0001295247109121789,
      "loss": 0.2957,
      "step": 27900
    },
    {
      "epoch": 27.91,
      "learning_rate": 0.00012950767781519013,
      "loss": 0.287,
      "step": 27910
    },
    {
      "epoch": 27.92,
      "learning_rate": 0.00012949063875732365,
      "loss": 0.2507,
      "step": 27920
    },
    {
      "epoch": 27.93,
      "learning_rate": 0.00012947359374044284,
      "loss": 0.2776,
      "step": 27930
    },
    {
      "epoch": 27.94,
      "learning_rate": 0.00012945824813183346,
      "loss": 0.3131,
      "step": 27940
    },
    {
      "epoch": 27.95,
      "learning_rate": 0.00012944119179796135,
      "loss": 0.2854,
      "step": 27950
    },
    {
      "epoch": 27.96,
      "learning_rate": 0.00012942412951048236,
      "loss": 0.2452,
      "step": 27960
    },
    {
      "epoch": 27.97,
      "learning_rate": 0.00012940706127126237,
      "loss": 0.3128,
      "step": 27970
    },
    {
      "epoch": 27.98,
      "learning_rate": 0.00012938998708216795,
      "loss": 0.2947,
      "step": 27980
    },
    {
      "epoch": 27.99,
      "learning_rate": 0.00012937290694506635,
      "loss": 0.2859,
      "step": 27990
    },
    {
      "epoch": 28.0,
      "learning_rate": 0.00012935582086182537,
      "loss": 0.2763,
      "step": 28000
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2733590602874756,
      "eval_runtime": 15.1732,
      "eval_samples_per_second": 131.812,
      "eval_steps_per_second": 16.476,
      "step": 28000
    },
    {
      "epoch": 28.01,
      "learning_rate": 0.00012933872883431357,
      "loss": 0.303,
      "step": 28010
    },
    {
      "epoch": 28.02,
      "learning_rate": 0.00012932163086440006,
      "loss": 0.2351,
      "step": 28020
    },
    {
      "epoch": 28.03,
      "learning_rate": 0.00012930452695395468,
      "loss": 0.3486,
      "step": 28030
    },
    {
      "epoch": 28.04,
      "learning_rate": 0.00012928741710484785,
      "loss": 0.235,
      "step": 28040
    },
    {
      "epoch": 28.05,
      "learning_rate": 0.00012927030131895073,
      "loss": 0.2966,
      "step": 28050
    },
    {
      "epoch": 28.06,
      "learning_rate": 0.00012925317959813505,
      "loss": 0.2179,
      "step": 28060
    },
    {
      "epoch": 28.07,
      "learning_rate": 0.00012923605194427323,
      "loss": 0.3213,
      "step": 28070
    },
    {
      "epoch": 28.08,
      "learning_rate": 0.0001292189183592383,
      "loss": 0.3036,
      "step": 28080
    },
    {
      "epoch": 28.09,
      "learning_rate": 0.00012920177884490395,
      "loss": 0.2776,
      "step": 28090
    },
    {
      "epoch": 28.1,
      "learning_rate": 0.0001291846334031446,
      "loss": 0.2448,
      "step": 28100
    },
    {
      "epoch": 28.11,
      "learning_rate": 0.00012916748203583518,
      "loss": 0.2503,
      "step": 28110
    },
    {
      "epoch": 28.12,
      "learning_rate": 0.00012915032474485137,
      "loss": 0.3463,
      "step": 28120
    },
    {
      "epoch": 28.13,
      "learning_rate": 0.00012913316153206946,
      "loss": 0.2521,
      "step": 28130
    },
    {
      "epoch": 28.14,
      "learning_rate": 0.00012911599239936642,
      "loss": 0.2786,
      "step": 28140
    },
    {
      "epoch": 28.15,
      "learning_rate": 0.00012909881734861977,
      "loss": 0.2356,
      "step": 28150
    },
    {
      "epoch": 28.16,
      "learning_rate": 0.00012908163638170782,
      "loss": 0.2785,
      "step": 28160
    },
    {
      "epoch": 28.17,
      "learning_rate": 0.0001290644495005094,
      "loss": 0.259,
      "step": 28170
    },
    {
      "epoch": 28.18,
      "learning_rate": 0.00012904725670690408,
      "loss": 0.2179,
      "step": 28180
    },
    {
      "epoch": 28.19,
      "learning_rate": 0.00012903005800277202,
      "loss": 0.3208,
      "step": 28190
    },
    {
      "epoch": 28.2,
      "learning_rate": 0.00012901285338999408,
      "loss": 0.2687,
      "step": 28200
    },
    {
      "epoch": 28.21,
      "learning_rate": 0.00012899564287045166,
      "loss": 0.2747,
      "step": 28210
    },
    {
      "epoch": 28.22,
      "learning_rate": 0.00012897842644602695,
      "loss": 0.2407,
      "step": 28220
    },
    {
      "epoch": 28.23,
      "learning_rate": 0.00012896120411860266,
      "loss": 0.2531,
      "step": 28230
    },
    {
      "epoch": 28.24,
      "learning_rate": 0.00012894397589006222,
      "loss": 0.2506,
      "step": 28240
    },
    {
      "epoch": 28.25,
      "learning_rate": 0.00012892674176228969,
      "loss": 0.2692,
      "step": 28250
    },
    {
      "epoch": 28.26,
      "learning_rate": 0.00012890950173716974,
      "loss": 0.2593,
      "step": 28260
    },
    {
      "epoch": 28.27,
      "learning_rate": 0.00012889225581658775,
      "loss": 0.3114,
      "step": 28270
    },
    {
      "epoch": 28.28,
      "learning_rate": 0.00012887500400242968,
      "loss": 0.1995,
      "step": 28280
    },
    {
      "epoch": 28.29,
      "learning_rate": 0.00012885774629658217,
      "loss": 0.277,
      "step": 28290
    },
    {
      "epoch": 28.3,
      "learning_rate": 0.0001288404827009325,
      "loss": 0.2917,
      "step": 28300
    },
    {
      "epoch": 28.31,
      "learning_rate": 0.0001288232132173686,
      "loss": 0.2738,
      "step": 28310
    },
    {
      "epoch": 28.32,
      "learning_rate": 0.000128805937847779,
      "loss": 0.3363,
      "step": 28320
    },
    {
      "epoch": 28.33,
      "learning_rate": 0.00012878865659405293,
      "loss": 0.294,
      "step": 28330
    },
    {
      "epoch": 28.34,
      "learning_rate": 0.00012877136945808028,
      "loss": 0.2391,
      "step": 28340
    },
    {
      "epoch": 28.35,
      "learning_rate": 0.0001287540764417515,
      "loss": 0.2787,
      "step": 28350
    },
    {
      "epoch": 28.36,
      "learning_rate": 0.00012873677754695774,
      "loss": 0.2889,
      "step": 28360
    },
    {
      "epoch": 28.37,
      "learning_rate": 0.00012871947277559077,
      "loss": 0.2687,
      "step": 28370
    },
    {
      "epoch": 28.38,
      "learning_rate": 0.00012870216212954302,
      "loss": 0.2948,
      "step": 28380
    },
    {
      "epoch": 28.39,
      "learning_rate": 0.00012868484561070754,
      "loss": 0.2515,
      "step": 28390
    },
    {
      "epoch": 28.4,
      "learning_rate": 0.0001286675232209781,
      "loss": 0.3212,
      "step": 28400
    },
    {
      "epoch": 28.41,
      "learning_rate": 0.000128650194962249,
      "loss": 0.2867,
      "step": 28410
    },
    {
      "epoch": 28.42,
      "learning_rate": 0.00012863286083641525,
      "loss": 0.2581,
      "step": 28420
    },
    {
      "epoch": 28.43,
      "learning_rate": 0.00012861552084537245,
      "loss": 0.2766,
      "step": 28430
    },
    {
      "epoch": 28.44,
      "learning_rate": 0.00012859817499101688,
      "loss": 0.2837,
      "step": 28440
    },
    {
      "epoch": 28.45,
      "learning_rate": 0.00012858082327524552,
      "loss": 0.2642,
      "step": 28450
    },
    {
      "epoch": 28.46,
      "learning_rate": 0.00012856346569995586,
      "loss": 0.324,
      "step": 28460
    },
    {
      "epoch": 28.47,
      "learning_rate": 0.00012854610226704612,
      "loss": 0.2659,
      "step": 28470
    },
    {
      "epoch": 28.48,
      "learning_rate": 0.00012852873297841517,
      "loss": 0.3196,
      "step": 28480
    },
    {
      "epoch": 28.49,
      "learning_rate": 0.00012851135783596243,
      "loss": 0.3328,
      "step": 28490
    },
    {
      "epoch": 28.5,
      "learning_rate": 0.00012849397684158806,
      "loss": 0.2596,
      "step": 28500
    },
    {
      "epoch": 28.51,
      "learning_rate": 0.00012847658999719285,
      "loss": 0.2986,
      "step": 28510
    },
    {
      "epoch": 28.52,
      "learning_rate": 0.0001284591973046781,
      "loss": 0.258,
      "step": 28520
    },
    {
      "epoch": 28.53,
      "learning_rate": 0.00012844179876594594,
      "loss": 0.2566,
      "step": 28530
    },
    {
      "epoch": 28.54,
      "learning_rate": 0.000128424394382899,
      "loss": 0.2545,
      "step": 28540
    },
    {
      "epoch": 28.55,
      "learning_rate": 0.00012840698415744062,
      "loss": 0.3613,
      "step": 28550
    },
    {
      "epoch": 28.56,
      "learning_rate": 0.00012838956809147473,
      "loss": 0.2867,
      "step": 28560
    },
    {
      "epoch": 28.57,
      "learning_rate": 0.00012837214618690597,
      "loss": 0.2763,
      "step": 28570
    },
    {
      "epoch": 28.58,
      "learning_rate": 0.00012835471844563953,
      "loss": 0.273,
      "step": 28580
    },
    {
      "epoch": 28.59,
      "learning_rate": 0.0001283372848695813,
      "loss": 0.2895,
      "step": 28590
    },
    {
      "epoch": 28.6,
      "learning_rate": 0.00012831984546063778,
      "loss": 0.2536,
      "step": 28600
    },
    {
      "epoch": 28.61,
      "learning_rate": 0.00012830240022071614,
      "loss": 0.2671,
      "step": 28610
    },
    {
      "epoch": 28.62,
      "learning_rate": 0.00012828494915172417,
      "loss": 0.2803,
      "step": 28620
    },
    {
      "epoch": 28.63,
      "learning_rate": 0.00012826749225557023,
      "loss": 0.2519,
      "step": 28630
    },
    {
      "epoch": 28.64,
      "learning_rate": 0.00012825002953416347,
      "loss": 0.2456,
      "step": 28640
    },
    {
      "epoch": 28.65,
      "learning_rate": 0.00012823256098941352,
      "loss": 0.2242,
      "step": 28650
    },
    {
      "epoch": 28.66,
      "learning_rate": 0.00012821508662323072,
      "loss": 0.2779,
      "step": 28660
    },
    {
      "epoch": 28.67,
      "learning_rate": 0.00012819760643752607,
      "loss": 0.2425,
      "step": 28670
    },
    {
      "epoch": 28.68,
      "learning_rate": 0.00012818012043421114,
      "loss": 0.3635,
      "step": 28680
    },
    {
      "epoch": 28.69,
      "learning_rate": 0.0001281626286151982,
      "loss": 0.2596,
      "step": 28690
    },
    {
      "epoch": 28.7,
      "learning_rate": 0.00012814513098240017,
      "loss": 0.2344,
      "step": 28700
    },
    {
      "epoch": 28.71,
      "learning_rate": 0.00012812762753773045,
      "loss": 0.2348,
      "step": 28710
    },
    {
      "epoch": 28.72,
      "learning_rate": 0.0001281101182831033,
      "loss": 0.3115,
      "step": 28720
    },
    {
      "epoch": 28.73,
      "learning_rate": 0.00012809260322043346,
      "loss": 0.3302,
      "step": 28730
    },
    {
      "epoch": 28.74,
      "learning_rate": 0.00012807508235163634,
      "loss": 0.2513,
      "step": 28740
    },
    {
      "epoch": 28.75,
      "learning_rate": 0.00012805755567862803,
      "loss": 0.2868,
      "step": 28750
    },
    {
      "epoch": 28.76,
      "learning_rate": 0.0001280400232033252,
      "loss": 0.2725,
      "step": 28760
    },
    {
      "epoch": 28.77,
      "learning_rate": 0.00012802248492764517,
      "loss": 0.3053,
      "step": 28770
    },
    {
      "epoch": 28.78,
      "learning_rate": 0.00012800494085350592,
      "loss": 0.3047,
      "step": 28780
    },
    {
      "epoch": 28.79,
      "learning_rate": 0.000127987390982826,
      "loss": 0.3039,
      "step": 28790
    },
    {
      "epoch": 28.8,
      "learning_rate": 0.0001279698353175247,
      "loss": 0.2814,
      "step": 28800
    },
    {
      "epoch": 28.81,
      "learning_rate": 0.00012795227385952184,
      "loss": 0.3013,
      "step": 28810
    },
    {
      "epoch": 28.82,
      "learning_rate": 0.0001279347066107379,
      "loss": 0.334,
      "step": 28820
    },
    {
      "epoch": 28.83,
      "learning_rate": 0.00012791713357309406,
      "loss": 0.2512,
      "step": 28830
    },
    {
      "epoch": 28.84,
      "learning_rate": 0.00012789955474851202,
      "loss": 0.2846,
      "step": 28840
    },
    {
      "epoch": 28.85,
      "learning_rate": 0.00012788197013891423,
      "loss": 0.2561,
      "step": 28850
    },
    {
      "epoch": 28.86,
      "learning_rate": 0.0001278643797462237,
      "loss": 0.258,
      "step": 28860
    },
    {
      "epoch": 28.87,
      "learning_rate": 0.00012784678357236407,
      "loss": 0.2604,
      "step": 28870
    },
    {
      "epoch": 28.88,
      "learning_rate": 0.00012782918161925963,
      "loss": 0.292,
      "step": 28880
    },
    {
      "epoch": 28.89,
      "learning_rate": 0.00012781157388883532,
      "loss": 0.2477,
      "step": 28890
    },
    {
      "epoch": 28.9,
      "learning_rate": 0.0001277939603830167,
      "loss": 0.2636,
      "step": 28900
    },
    {
      "epoch": 28.91,
      "learning_rate": 0.00012777634110372994,
      "loss": 0.2939,
      "step": 28910
    },
    {
      "epoch": 28.92,
      "learning_rate": 0.00012775871605290187,
      "loss": 0.2548,
      "step": 28920
    },
    {
      "epoch": 28.93,
      "learning_rate": 0.00012774108523245993,
      "loss": 0.3322,
      "step": 28930
    },
    {
      "epoch": 28.94,
      "learning_rate": 0.0001277234486443322,
      "loss": 0.2903,
      "step": 28940
    },
    {
      "epoch": 28.95,
      "learning_rate": 0.00012770580629044742,
      "loss": 0.2395,
      "step": 28950
    },
    {
      "epoch": 28.96,
      "learning_rate": 0.0001276881581727349,
      "loss": 0.3929,
      "step": 28960
    },
    {
      "epoch": 28.97,
      "learning_rate": 0.00012767050429312462,
      "loss": 0.2807,
      "step": 28970
    },
    {
      "epoch": 28.98,
      "learning_rate": 0.00012765284465354715,
      "loss": 0.3199,
      "step": 28980
    },
    {
      "epoch": 28.99,
      "learning_rate": 0.0001276351792559338,
      "loss": 0.3117,
      "step": 28990
    },
    {
      "epoch": 29.0,
      "learning_rate": 0.00012761750810221632,
      "loss": 0.254,
      "step": 29000
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2738175094127655,
      "eval_runtime": 15.1042,
      "eval_samples_per_second": 132.413,
      "eval_steps_per_second": 16.552,
      "step": 29000
    },
    {
      "epoch": 29.01,
      "learning_rate": 0.00012759983119432728,
      "loss": 0.2188,
      "step": 29010
    },
    {
      "epoch": 29.02,
      "learning_rate": 0.0001275821485341998,
      "loss": 0.2773,
      "step": 29020
    },
    {
      "epoch": 29.03,
      "learning_rate": 0.0001275644601237676,
      "loss": 0.2596,
      "step": 29030
    },
    {
      "epoch": 29.04,
      "learning_rate": 0.0001275467659649651,
      "loss": 0.3038,
      "step": 29040
    },
    {
      "epoch": 29.05,
      "learning_rate": 0.00012752906605972725,
      "loss": 0.2517,
      "step": 29050
    },
    {
      "epoch": 29.06,
      "learning_rate": 0.00012751136040998971,
      "loss": 0.2512,
      "step": 29060
    },
    {
      "epoch": 29.07,
      "learning_rate": 0.00012749364901768877,
      "loss": 0.3482,
      "step": 29070
    },
    {
      "epoch": 29.08,
      "learning_rate": 0.00012747593188476127,
      "loss": 0.3049,
      "step": 29080
    },
    {
      "epoch": 29.09,
      "learning_rate": 0.0001274582090131448,
      "loss": 0.2753,
      "step": 29090
    },
    {
      "epoch": 29.1,
      "learning_rate": 0.00012744048040477741,
      "loss": 0.2559,
      "step": 29100
    },
    {
      "epoch": 29.11,
      "learning_rate": 0.00012742274606159792,
      "loss": 0.2191,
      "step": 29110
    },
    {
      "epoch": 29.12,
      "learning_rate": 0.00012740500598554578,
      "loss": 0.3043,
      "step": 29120
    },
    {
      "epoch": 29.13,
      "learning_rate": 0.00012738726017856095,
      "loss": 0.2601,
      "step": 29130
    },
    {
      "epoch": 29.14,
      "learning_rate": 0.0001273695086425841,
      "loss": 0.2339,
      "step": 29140
    },
    {
      "epoch": 29.15,
      "learning_rate": 0.00012735175137955655,
      "loss": 0.2792,
      "step": 29150
    },
    {
      "epoch": 29.16,
      "learning_rate": 0.00012733398839142018,
      "loss": 0.2691,
      "step": 29160
    },
    {
      "epoch": 29.17,
      "learning_rate": 0.00012731621968011748,
      "loss": 0.312,
      "step": 29170
    },
    {
      "epoch": 29.18,
      "learning_rate": 0.0001272984452475917,
      "loss": 0.2951,
      "step": 29180
    },
    {
      "epoch": 29.19,
      "learning_rate": 0.00012728066509578654,
      "loss": 0.3545,
      "step": 29190
    },
    {
      "epoch": 29.2,
      "learning_rate": 0.00012726287922664646,
      "loss": 0.2697,
      "step": 29200
    },
    {
      "epoch": 29.21,
      "learning_rate": 0.0001272450876421165,
      "loss": 0.2586,
      "step": 29210
    },
    {
      "epoch": 29.22,
      "learning_rate": 0.0001272272903441423,
      "loss": 0.3101,
      "step": 29220
    },
    {
      "epoch": 29.23,
      "learning_rate": 0.00012720948733467016,
      "loss": 0.2748,
      "step": 29230
    },
    {
      "epoch": 29.24,
      "learning_rate": 0.00012719167861564696,
      "loss": 0.3123,
      "step": 29240
    },
    {
      "epoch": 29.25,
      "learning_rate": 0.00012717386418902024,
      "loss": 0.2596,
      "step": 29250
    },
    {
      "epoch": 29.26,
      "learning_rate": 0.0001271560440567382,
      "loss": 0.2353,
      "step": 29260
    },
    {
      "epoch": 29.27,
      "learning_rate": 0.0001271382182207496,
      "loss": 0.2672,
      "step": 29270
    },
    {
      "epoch": 29.28,
      "learning_rate": 0.00012712038668300383,
      "loss": 0.2408,
      "step": 29280
    },
    {
      "epoch": 29.29,
      "learning_rate": 0.00012710254944545095,
      "loss": 0.2431,
      "step": 29290
    },
    {
      "epoch": 29.3,
      "learning_rate": 0.00012708470651004157,
      "loss": 0.3065,
      "step": 29300
    },
    {
      "epoch": 29.31,
      "learning_rate": 0.00012706685787872702,
      "loss": 0.2678,
      "step": 29310
    },
    {
      "epoch": 29.32,
      "learning_rate": 0.00012704900355345916,
      "loss": 0.2247,
      "step": 29320
    },
    {
      "epoch": 29.33,
      "learning_rate": 0.00012703114353619055,
      "loss": 0.2742,
      "step": 29330
    },
    {
      "epoch": 29.34,
      "learning_rate": 0.00012701327782887428,
      "loss": 0.2602,
      "step": 29340
    },
    {
      "epoch": 29.35,
      "learning_rate": 0.00012699540643346417,
      "loss": 0.336,
      "step": 29350
    },
    {
      "epoch": 29.36,
      "learning_rate": 0.00012697752935191458,
      "loss": 0.2751,
      "step": 29360
    },
    {
      "epoch": 29.37,
      "learning_rate": 0.00012695964658618051,
      "loss": 0.2364,
      "step": 29370
    },
    {
      "epoch": 29.38,
      "learning_rate": 0.00012694175813821764,
      "loss": 0.2624,
      "step": 29380
    },
    {
      "epoch": 29.39,
      "learning_rate": 0.0001269238640099822,
      "loss": 0.1743,
      "step": 29390
    },
    {
      "epoch": 29.4,
      "learning_rate": 0.000126905964203431,
      "loss": 0.3138,
      "step": 29400
    },
    {
      "epoch": 29.41,
      "learning_rate": 0.00012688805872052163,
      "loss": 0.2592,
      "step": 29410
    },
    {
      "epoch": 29.42,
      "learning_rate": 0.00012687014756321217,
      "loss": 0.2705,
      "step": 29420
    },
    {
      "epoch": 29.43,
      "learning_rate": 0.00012685223073346136,
      "loss": 0.3271,
      "step": 29430
    },
    {
      "epoch": 29.44,
      "learning_rate": 0.00012683430823322859,
      "loss": 0.2998,
      "step": 29440
    },
    {
      "epoch": 29.45,
      "learning_rate": 0.00012681638006447374,
      "loss": 0.318,
      "step": 29450
    },
    {
      "epoch": 29.46,
      "learning_rate": 0.00012679844622915748,
      "loss": 0.3542,
      "step": 29460
    },
    {
      "epoch": 29.47,
      "learning_rate": 0.00012678050672924106,
      "loss": 0.2964,
      "step": 29470
    },
    {
      "epoch": 29.48,
      "learning_rate": 0.00012676256156668624,
      "loss": 0.2798,
      "step": 29480
    },
    {
      "epoch": 29.49,
      "learning_rate": 0.00012674461074345552,
      "loss": 0.3253,
      "step": 29490
    },
    {
      "epoch": 29.5,
      "learning_rate": 0.00012672665426151198,
      "loss": 0.276,
      "step": 29500
    },
    {
      "epoch": 29.51,
      "learning_rate": 0.0001267086921228193,
      "loss": 0.2922,
      "step": 29510
    },
    {
      "epoch": 29.52,
      "learning_rate": 0.00012669072432934175,
      "loss": 0.2603,
      "step": 29520
    },
    {
      "epoch": 29.53,
      "learning_rate": 0.00012667275088304434,
      "loss": 0.3579,
      "step": 29530
    },
    {
      "epoch": 29.54,
      "learning_rate": 0.00012665477178589257,
      "loss": 0.2422,
      "step": 29540
    },
    {
      "epoch": 29.55,
      "learning_rate": 0.00012663678703985263,
      "loss": 0.2349,
      "step": 29550
    },
    {
      "epoch": 29.56,
      "learning_rate": 0.0001266187966468913,
      "loss": 0.2968,
      "step": 29560
    },
    {
      "epoch": 29.57,
      "learning_rate": 0.00012660080060897594,
      "loss": 0.3247,
      "step": 29570
    },
    {
      "epoch": 29.58,
      "learning_rate": 0.00012658279892807466,
      "loss": 0.2343,
      "step": 29580
    },
    {
      "epoch": 29.59,
      "learning_rate": 0.000126564791606156,
      "loss": 0.322,
      "step": 29590
    },
    {
      "epoch": 29.6,
      "learning_rate": 0.00012654677864518926,
      "loss": 0.2636,
      "step": 29600
    },
    {
      "epoch": 29.61,
      "learning_rate": 0.00012652876004714433,
      "loss": 0.225,
      "step": 29610
    },
    {
      "epoch": 29.62,
      "learning_rate": 0.0001265107358139917,
      "loss": 0.3448,
      "step": 29620
    },
    {
      "epoch": 29.63,
      "learning_rate": 0.00012649270594770236,
      "loss": 0.2258,
      "step": 29630
    },
    {
      "epoch": 29.64,
      "learning_rate": 0.00012647467045024817,
      "loss": 0.3341,
      "step": 29640
    },
    {
      "epoch": 29.65,
      "learning_rate": 0.00012645662932360142,
      "loss": 0.269,
      "step": 29650
    },
    {
      "epoch": 29.66,
      "learning_rate": 0.00012643858256973503,
      "loss": 0.2672,
      "step": 29660
    },
    {
      "epoch": 29.67,
      "learning_rate": 0.0001264205301906226,
      "loss": 0.2354,
      "step": 29670
    },
    {
      "epoch": 29.68,
      "learning_rate": 0.00012640247218823828,
      "loss": 0.2109,
      "step": 29680
    },
    {
      "epoch": 29.69,
      "learning_rate": 0.00012638440856455692,
      "loss": 0.3196,
      "step": 29690
    },
    {
      "epoch": 29.7,
      "learning_rate": 0.00012636633932155384,
      "loss": 0.2556,
      "step": 29700
    },
    {
      "epoch": 29.71,
      "learning_rate": 0.00012634826446120516,
      "loss": 0.3049,
      "step": 29710
    },
    {
      "epoch": 29.72,
      "learning_rate": 0.00012633018398548745,
      "loss": 0.282,
      "step": 29720
    },
    {
      "epoch": 29.73,
      "learning_rate": 0.00012631209789637802,
      "loss": 0.2847,
      "step": 29730
    },
    {
      "epoch": 29.74,
      "learning_rate": 0.0001262940061958547,
      "loss": 0.2572,
      "step": 29740
    },
    {
      "epoch": 29.75,
      "learning_rate": 0.00012627590888589598,
      "loss": 0.2011,
      "step": 29750
    },
    {
      "epoch": 29.76,
      "learning_rate": 0.00012625780596848098,
      "loss": 0.3119,
      "step": 29760
    },
    {
      "epoch": 29.77,
      "learning_rate": 0.00012623969744558934,
      "loss": 0.3216,
      "step": 29770
    },
    {
      "epoch": 29.78,
      "learning_rate": 0.00012622158331920146,
      "loss": 0.2946,
      "step": 29780
    },
    {
      "epoch": 29.79,
      "learning_rate": 0.00012620346359129824,
      "loss": 0.3038,
      "step": 29790
    },
    {
      "epoch": 29.8,
      "learning_rate": 0.0001261853382638612,
      "loss": 0.3006,
      "step": 29800
    },
    {
      "epoch": 29.81,
      "learning_rate": 0.00012616720733887253,
      "loss": 0.2879,
      "step": 29810
    },
    {
      "epoch": 29.82,
      "learning_rate": 0.000126149070818315,
      "loss": 0.2511,
      "step": 29820
    },
    {
      "epoch": 29.83,
      "learning_rate": 0.00012613092870417198,
      "loss": 0.363,
      "step": 29830
    },
    {
      "epoch": 29.84,
      "learning_rate": 0.0001261127809984275,
      "loss": 0.2943,
      "step": 29840
    },
    {
      "epoch": 29.85,
      "learning_rate": 0.0001260946277030661,
      "loss": 0.2769,
      "step": 29850
    },
    {
      "epoch": 29.86,
      "learning_rate": 0.00012607646882007307,
      "loss": 0.254,
      "step": 29860
    },
    {
      "epoch": 29.87,
      "learning_rate": 0.00012605830435143416,
      "loss": 0.292,
      "step": 29870
    },
    {
      "epoch": 29.88,
      "learning_rate": 0.00012604013429913586,
      "loss": 0.2438,
      "step": 29880
    },
    {
      "epoch": 29.89,
      "learning_rate": 0.00012602195866516527,
      "loss": 0.2917,
      "step": 29890
    },
    {
      "epoch": 29.9,
      "learning_rate": 0.00012600377745150993,
      "loss": 0.2688,
      "step": 29900
    },
    {
      "epoch": 29.91,
      "learning_rate": 0.0001259855906601582,
      "loss": 0.2435,
      "step": 29910
    },
    {
      "epoch": 29.92,
      "learning_rate": 0.00012596739829309888,
      "loss": 0.3201,
      "step": 29920
    },
    {
      "epoch": 29.93,
      "learning_rate": 0.00012594920035232158,
      "loss": 0.2686,
      "step": 29930
    },
    {
      "epoch": 29.94,
      "learning_rate": 0.0001259309968398163,
      "loss": 0.2322,
      "step": 29940
    },
    {
      "epoch": 29.95,
      "learning_rate": 0.00012591278775757377,
      "loss": 0.2752,
      "step": 29950
    },
    {
      "epoch": 29.96,
      "learning_rate": 0.0001258945731075853,
      "loss": 0.2703,
      "step": 29960
    },
    {
      "epoch": 29.97,
      "learning_rate": 0.00012587817516381924,
      "loss": 0.3112,
      "step": 29970
    },
    {
      "epoch": 29.98,
      "learning_rate": 0.00012585994994060182,
      "loss": 0.3195,
      "step": 29980
    },
    {
      "epoch": 29.99,
      "learning_rate": 0.00012584171915541674,
      "loss": 0.278,
      "step": 29990
    },
    {
      "epoch": 30.0,
      "learning_rate": 0.00012582348281025765,
      "loss": 0.2765,
      "step": 30000
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2732310891151428,
      "eval_runtime": 14.8901,
      "eval_samples_per_second": 134.318,
      "eval_steps_per_second": 16.79,
      "step": 30000
    },
    {
      "epoch": 30.01,
      "learning_rate": 0.00012580524090711895,
      "loss": 0.2963,
      "step": 30010
    },
    {
      "epoch": 30.02,
      "learning_rate": 0.00012578699344799544,
      "loss": 0.2598,
      "step": 30020
    },
    {
      "epoch": 30.03,
      "learning_rate": 0.00012576874043488268,
      "loss": 0.3046,
      "step": 30030
    },
    {
      "epoch": 30.04,
      "learning_rate": 0.00012575048186977682,
      "loss": 0.2315,
      "step": 30040
    },
    {
      "epoch": 30.05,
      "learning_rate": 0.00012573221775467457,
      "loss": 0.3069,
      "step": 30050
    },
    {
      "epoch": 30.06,
      "learning_rate": 0.00012571394809157325,
      "loss": 0.2844,
      "step": 30060
    },
    {
      "epoch": 30.07,
      "learning_rate": 0.00012569567288247082,
      "loss": 0.2518,
      "step": 30070
    },
    {
      "epoch": 30.08,
      "learning_rate": 0.00012567739212936583,
      "loss": 0.2678,
      "step": 30080
    },
    {
      "epoch": 30.09,
      "learning_rate": 0.0001256591058342574,
      "loss": 0.2333,
      "step": 30090
    },
    {
      "epoch": 30.1,
      "learning_rate": 0.00012564081399914535,
      "loss": 0.2812,
      "step": 30100
    },
    {
      "epoch": 30.11,
      "learning_rate": 0.00012562251662603,
      "loss": 0.2298,
      "step": 30110
    },
    {
      "epoch": 30.12,
      "learning_rate": 0.00012560421371691233,
      "loss": 0.3234,
      "step": 30120
    },
    {
      "epoch": 30.13,
      "learning_rate": 0.00012558590527379397,
      "loss": 0.175,
      "step": 30130
    },
    {
      "epoch": 30.14,
      "learning_rate": 0.00012556759129867705,
      "loss": 0.2952,
      "step": 30140
    },
    {
      "epoch": 30.15,
      "learning_rate": 0.00012554927179356435,
      "loss": 0.2061,
      "step": 30150
    },
    {
      "epoch": 30.16,
      "learning_rate": 0.0001255309467604593,
      "loss": 0.3117,
      "step": 30160
    },
    {
      "epoch": 30.17,
      "learning_rate": 0.0001255126162013659,
      "loss": 0.2814,
      "step": 30170
    },
    {
      "epoch": 30.18,
      "learning_rate": 0.00012549428011828873,
      "loss": 0.2941,
      "step": 30180
    },
    {
      "epoch": 30.19,
      "learning_rate": 0.00012547593851323298,
      "loss": 0.2943,
      "step": 30190
    },
    {
      "epoch": 30.2,
      "learning_rate": 0.0001254575913882045,
      "loss": 0.2915,
      "step": 30200
    },
    {
      "epoch": 30.21,
      "learning_rate": 0.00012543923874520972,
      "loss": 0.327,
      "step": 30210
    },
    {
      "epoch": 30.22,
      "learning_rate": 0.00012542088058625558,
      "loss": 0.2844,
      "step": 30220
    },
    {
      "epoch": 30.23,
      "learning_rate": 0.00012540251691334976,
      "loss": 0.386,
      "step": 30230
    },
    {
      "epoch": 30.24,
      "learning_rate": 0.00012538414772850047,
      "loss": 0.2563,
      "step": 30240
    },
    {
      "epoch": 30.25,
      "learning_rate": 0.00012536577303371652,
      "loss": 0.2355,
      "step": 30250
    },
    {
      "epoch": 30.26,
      "learning_rate": 0.00012534739283100738,
      "loss": 0.2577,
      "step": 30260
    },
    {
      "epoch": 30.27,
      "learning_rate": 0.00012532900712238304,
      "loss": 0.2493,
      "step": 30270
    },
    {
      "epoch": 30.28,
      "learning_rate": 0.00012531061590985416,
      "loss": 0.2059,
      "step": 30280
    },
    {
      "epoch": 30.29,
      "learning_rate": 0.00012529221919543195,
      "loss": 0.2619,
      "step": 30290
    },
    {
      "epoch": 30.3,
      "learning_rate": 0.00012527381698112828,
      "loss": 0.2891,
      "step": 30300
    },
    {
      "epoch": 30.31,
      "learning_rate": 0.00012525540926895554,
      "loss": 0.2566,
      "step": 30310
    },
    {
      "epoch": 30.32,
      "learning_rate": 0.00012523699606092683,
      "loss": 0.2914,
      "step": 30320
    },
    {
      "epoch": 30.33,
      "learning_rate": 0.00012521857735905577,
      "loss": 0.2767,
      "step": 30330
    },
    {
      "epoch": 30.34,
      "learning_rate": 0.0001252001531653566,
      "loss": 0.234,
      "step": 30340
    },
    {
      "epoch": 30.35,
      "learning_rate": 0.0001251817234818441,
      "loss": 0.1998,
      "step": 30350
    },
    {
      "epoch": 30.36,
      "learning_rate": 0.0001251632883105338,
      "loss": 0.2773,
      "step": 30360
    },
    {
      "epoch": 30.37,
      "learning_rate": 0.0001251448476534417,
      "loss": 0.3214,
      "step": 30370
    },
    {
      "epoch": 30.38,
      "learning_rate": 0.00012512640151258447,
      "loss": 0.2946,
      "step": 30380
    },
    {
      "epoch": 30.39,
      "learning_rate": 0.00012510794988997932,
      "loss": 0.2777,
      "step": 30390
    },
    {
      "epoch": 30.4,
      "learning_rate": 0.00012508949278764413,
      "loss": 0.2601,
      "step": 30400
    },
    {
      "epoch": 30.41,
      "learning_rate": 0.00012507103020759726,
      "loss": 0.26,
      "step": 30410
    },
    {
      "epoch": 30.42,
      "learning_rate": 0.00012505256215185787,
      "loss": 0.3127,
      "step": 30420
    },
    {
      "epoch": 30.43,
      "learning_rate": 0.0001250340886224455,
      "loss": 0.2696,
      "step": 30430
    },
    {
      "epoch": 30.44,
      "learning_rate": 0.00012501560962138044,
      "loss": 0.3294,
      "step": 30440
    },
    {
      "epoch": 30.45,
      "learning_rate": 0.0001249971251506835,
      "loss": 0.3459,
      "step": 30450
    },
    {
      "epoch": 30.46,
      "learning_rate": 0.00012497863521237614,
      "loss": 0.266,
      "step": 30460
    },
    {
      "epoch": 30.47,
      "learning_rate": 0.00012496013980848035,
      "loss": 0.2526,
      "step": 30470
    },
    {
      "epoch": 30.48,
      "learning_rate": 0.0001249416389410188,
      "loss": 0.2658,
      "step": 30480
    },
    {
      "epoch": 30.49,
      "learning_rate": 0.00012492313261201472,
      "loss": 0.2407,
      "step": 30490
    },
    {
      "epoch": 30.5,
      "learning_rate": 0.00012490462082349185,
      "loss": 0.3043,
      "step": 30500
    },
    {
      "epoch": 30.51,
      "learning_rate": 0.00012488610357747475,
      "loss": 0.2783,
      "step": 30510
    },
    {
      "epoch": 30.52,
      "learning_rate": 0.00012486758087598834,
      "loss": 0.2859,
      "step": 30520
    },
    {
      "epoch": 30.53,
      "learning_rate": 0.00012484905272105824,
      "loss": 0.3402,
      "step": 30530
    },
    {
      "epoch": 30.54,
      "learning_rate": 0.0001248305191147107,
      "loss": 0.3382,
      "step": 30540
    },
    {
      "epoch": 30.55,
      "learning_rate": 0.00012481198005897252,
      "loss": 0.2958,
      "step": 30550
    },
    {
      "epoch": 30.56,
      "learning_rate": 0.00012479343555587107,
      "loss": 0.2195,
      "step": 30560
    },
    {
      "epoch": 30.57,
      "learning_rate": 0.0001247748856074344,
      "loss": 0.2705,
      "step": 30570
    },
    {
      "epoch": 30.58,
      "learning_rate": 0.00012475633021569104,
      "loss": 0.2786,
      "step": 30580
    },
    {
      "epoch": 30.59,
      "learning_rate": 0.00012473776938267024,
      "loss": 0.3089,
      "step": 30590
    },
    {
      "epoch": 30.6,
      "learning_rate": 0.00012471920311040173,
      "loss": 0.2483,
      "step": 30600
    },
    {
      "epoch": 30.61,
      "learning_rate": 0.00012470063140091595,
      "loss": 0.2616,
      "step": 30610
    },
    {
      "epoch": 30.62,
      "learning_rate": 0.00012468205425624382,
      "loss": 0.2517,
      "step": 30620
    },
    {
      "epoch": 30.63,
      "learning_rate": 0.00012466347167841696,
      "loss": 0.3038,
      "step": 30630
    },
    {
      "epoch": 30.64,
      "learning_rate": 0.00012464488366946747,
      "loss": 0.2769,
      "step": 30640
    },
    {
      "epoch": 30.65,
      "learning_rate": 0.0001246262902314282,
      "loss": 0.3438,
      "step": 30650
    },
    {
      "epoch": 30.66,
      "learning_rate": 0.00012460769136633237,
      "loss": 0.3237,
      "step": 30660
    },
    {
      "epoch": 30.67,
      "learning_rate": 0.00012458908707621403,
      "loss": 0.2511,
      "step": 30670
    },
    {
      "epoch": 30.68,
      "learning_rate": 0.0001245704773631077,
      "loss": 0.2959,
      "step": 30680
    },
    {
      "epoch": 30.69,
      "learning_rate": 0.00012455186222904848,
      "loss": 0.2815,
      "step": 30690
    },
    {
      "epoch": 30.7,
      "learning_rate": 0.0001245332416760721,
      "loss": 0.3179,
      "step": 30700
    },
    {
      "epoch": 30.71,
      "learning_rate": 0.00012451461570621487,
      "loss": 0.2408,
      "step": 30710
    },
    {
      "epoch": 30.72,
      "learning_rate": 0.00012449598432151375,
      "loss": 0.2874,
      "step": 30720
    },
    {
      "epoch": 30.73,
      "learning_rate": 0.00012447734752400616,
      "loss": 0.3294,
      "step": 30730
    },
    {
      "epoch": 30.74,
      "learning_rate": 0.00012445870531573025,
      "loss": 0.3213,
      "step": 30740
    },
    {
      "epoch": 30.75,
      "learning_rate": 0.0001244400576987247,
      "loss": 0.2259,
      "step": 30750
    },
    {
      "epoch": 30.76,
      "learning_rate": 0.00012442140467502878,
      "loss": 0.234,
      "step": 30760
    },
    {
      "epoch": 30.77,
      "learning_rate": 0.0001244027462466823,
      "loss": 0.3377,
      "step": 30770
    },
    {
      "epoch": 30.78,
      "learning_rate": 0.0001243840824157258,
      "loss": 0.2767,
      "step": 30780
    },
    {
      "epoch": 30.79,
      "learning_rate": 0.0001243654131842003,
      "loss": 0.3043,
      "step": 30790
    },
    {
      "epoch": 30.8,
      "learning_rate": 0.00012434673855414742,
      "loss": 0.3473,
      "step": 30800
    },
    {
      "epoch": 30.81,
      "learning_rate": 0.0001243280585276094,
      "loss": 0.3035,
      "step": 30810
    },
    {
      "epoch": 30.82,
      "learning_rate": 0.00012430937310662908,
      "loss": 0.312,
      "step": 30820
    },
    {
      "epoch": 30.83,
      "learning_rate": 0.00012429068229324983,
      "loss": 0.2946,
      "step": 30830
    },
    {
      "epoch": 30.84,
      "learning_rate": 0.0001242719860895157,
      "loss": 0.251,
      "step": 30840
    },
    {
      "epoch": 30.85,
      "learning_rate": 0.00012425328449747124,
      "loss": 0.2283,
      "step": 30850
    },
    {
      "epoch": 30.86,
      "learning_rate": 0.00012423457751916162,
      "loss": 0.226,
      "step": 30860
    },
    {
      "epoch": 30.87,
      "learning_rate": 0.00012421586515663264,
      "loss": 0.2521,
      "step": 30870
    },
    {
      "epoch": 30.88,
      "learning_rate": 0.00012419714741193063,
      "loss": 0.2253,
      "step": 30880
    },
    {
      "epoch": 30.89,
      "learning_rate": 0.00012417842428710257,
      "loss": 0.2876,
      "step": 30890
    },
    {
      "epoch": 30.9,
      "learning_rate": 0.00012415969578419595,
      "loss": 0.286,
      "step": 30900
    },
    {
      "epoch": 30.91,
      "learning_rate": 0.0001241409619052589,
      "loss": 0.2511,
      "step": 30910
    },
    {
      "epoch": 30.92,
      "learning_rate": 0.00012412222265234017,
      "loss": 0.2837,
      "step": 30920
    },
    {
      "epoch": 30.93,
      "learning_rate": 0.000124103478027489,
      "loss": 0.277,
      "step": 30930
    },
    {
      "epoch": 30.94,
      "learning_rate": 0.0001240847280327553,
      "loss": 0.291,
      "step": 30940
    },
    {
      "epoch": 30.95,
      "learning_rate": 0.00012406597267018956,
      "loss": 0.2682,
      "step": 30950
    },
    {
      "epoch": 30.96,
      "learning_rate": 0.00012404721194184283,
      "loss": 0.3399,
      "step": 30960
    },
    {
      "epoch": 30.97,
      "learning_rate": 0.0001240284458497667,
      "loss": 0.2495,
      "step": 30970
    },
    {
      "epoch": 30.98,
      "learning_rate": 0.00012400967439601346,
      "loss": 0.2994,
      "step": 30980
    },
    {
      "epoch": 30.99,
      "learning_rate": 0.0001239908975826359,
      "loss": 0.301,
      "step": 30990
    },
    {
      "epoch": 31.0,
      "learning_rate": 0.00012397211541168748,
      "loss": 0.3197,
      "step": 31000
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27552521228790283,
      "eval_runtime": 14.5861,
      "eval_samples_per_second": 137.117,
      "eval_steps_per_second": 17.14,
      "step": 31000
    },
    {
      "epoch": 31.01,
      "learning_rate": 0.00012395332788522212,
      "loss": 0.2422,
      "step": 31010
    },
    {
      "epoch": 31.02,
      "learning_rate": 0.00012393453500529443,
      "loss": 0.3026,
      "step": 31020
    },
    {
      "epoch": 31.03,
      "learning_rate": 0.00012391573677395955,
      "loss": 0.2871,
      "step": 31030
    },
    {
      "epoch": 31.04,
      "learning_rate": 0.00012389693319327327,
      "loss": 0.3267,
      "step": 31040
    },
    {
      "epoch": 31.05,
      "learning_rate": 0.00012387812426529183,
      "loss": 0.1979,
      "step": 31050
    },
    {
      "epoch": 31.06,
      "learning_rate": 0.00012385930999207228,
      "loss": 0.3304,
      "step": 31060
    },
    {
      "epoch": 31.07,
      "learning_rate": 0.00012384049037567201,
      "loss": 0.2658,
      "step": 31070
    },
    {
      "epoch": 31.08,
      "learning_rate": 0.00012382166541814914,
      "loss": 0.3327,
      "step": 31080
    },
    {
      "epoch": 31.09,
      "learning_rate": 0.00012380283512156235,
      "loss": 0.2071,
      "step": 31090
    },
    {
      "epoch": 31.1,
      "learning_rate": 0.00012378399948797088,
      "loss": 0.2791,
      "step": 31100
    },
    {
      "epoch": 31.11,
      "learning_rate": 0.0001237651585194346,
      "loss": 0.2432,
      "step": 31110
    },
    {
      "epoch": 31.12,
      "learning_rate": 0.00012374631221801386,
      "loss": 0.2268,
      "step": 31120
    },
    {
      "epoch": 31.13,
      "learning_rate": 0.0001237274605857697,
      "loss": 0.2577,
      "step": 31130
    },
    {
      "epoch": 31.14,
      "learning_rate": 0.00012370860362476374,
      "loss": 0.2971,
      "step": 31140
    },
    {
      "epoch": 31.15,
      "learning_rate": 0.00012368974133705813,
      "loss": 0.3038,
      "step": 31150
    },
    {
      "epoch": 31.16,
      "learning_rate": 0.0001236708737247156,
      "loss": 0.2958,
      "step": 31160
    },
    {
      "epoch": 31.17,
      "learning_rate": 0.0001236520007897995,
      "loss": 0.3048,
      "step": 31170
    },
    {
      "epoch": 31.18,
      "learning_rate": 0.00012363312253437373,
      "loss": 0.1388,
      "step": 31180
    },
    {
      "epoch": 31.19,
      "learning_rate": 0.0001236142389605028,
      "loss": 0.2197,
      "step": 31190
    },
    {
      "epoch": 31.2,
      "learning_rate": 0.00012359535007025178,
      "loss": 0.2505,
      "step": 31200
    },
    {
      "epoch": 31.21,
      "learning_rate": 0.00012357645586568634,
      "loss": 0.2267,
      "step": 31210
    },
    {
      "epoch": 31.22,
      "learning_rate": 0.00012355755634887273,
      "loss": 0.2602,
      "step": 31220
    },
    {
      "epoch": 31.23,
      "learning_rate": 0.00012353865152187778,
      "loss": 0.3111,
      "step": 31230
    },
    {
      "epoch": 31.24,
      "learning_rate": 0.00012351974138676884,
      "loss": 0.2842,
      "step": 31240
    },
    {
      "epoch": 31.25,
      "learning_rate": 0.00012350082594561395,
      "loss": 0.282,
      "step": 31250
    },
    {
      "epoch": 31.26,
      "learning_rate": 0.00012348190520048165,
      "loss": 0.2819,
      "step": 31260
    },
    {
      "epoch": 31.27,
      "learning_rate": 0.0001234629791534411,
      "loss": 0.333,
      "step": 31270
    },
    {
      "epoch": 31.28,
      "learning_rate": 0.000123444047806562,
      "loss": 0.3196,
      "step": 31280
    },
    {
      "epoch": 31.29,
      "learning_rate": 0.00012342511116191467,
      "loss": 0.3216,
      "step": 31290
    },
    {
      "epoch": 31.3,
      "learning_rate": 0.00012340616922156997,
      "loss": 0.3336,
      "step": 31300
    },
    {
      "epoch": 31.31,
      "learning_rate": 0.0001233872219875994,
      "loss": 0.2263,
      "step": 31310
    },
    {
      "epoch": 31.32,
      "learning_rate": 0.000123368269462075,
      "loss": 0.2606,
      "step": 31320
    },
    {
      "epoch": 31.33,
      "learning_rate": 0.00012334931164706934,
      "loss": 0.2338,
      "step": 31330
    },
    {
      "epoch": 31.34,
      "learning_rate": 0.00012333034854465568,
      "loss": 0.2439,
      "step": 31340
    },
    {
      "epoch": 31.35,
      "learning_rate": 0.00012331138015690774,
      "loss": 0.2689,
      "step": 31350
    },
    {
      "epoch": 31.36,
      "learning_rate": 0.00012329240648589992,
      "loss": 0.2947,
      "step": 31360
    },
    {
      "epoch": 31.37,
      "learning_rate": 0.0001232734275337071,
      "loss": 0.3032,
      "step": 31370
    },
    {
      "epoch": 31.38,
      "learning_rate": 0.00012325444330240487,
      "loss": 0.2248,
      "step": 31380
    },
    {
      "epoch": 31.39,
      "learning_rate": 0.00012323545379406924,
      "loss": 0.3074,
      "step": 31390
    },
    {
      "epoch": 31.4,
      "learning_rate": 0.0001232164590107769,
      "loss": 0.3056,
      "step": 31400
    },
    {
      "epoch": 31.41,
      "learning_rate": 0.00012319745895460513,
      "loss": 0.2541,
      "step": 31410
    },
    {
      "epoch": 31.42,
      "learning_rate": 0.00012317845362763168,
      "loss": 0.2569,
      "step": 31420
    },
    {
      "epoch": 31.43,
      "learning_rate": 0.00012315944303193497,
      "loss": 0.2352,
      "step": 31430
    },
    {
      "epoch": 31.44,
      "learning_rate": 0.000123140427169594,
      "loss": 0.3023,
      "step": 31440
    },
    {
      "epoch": 31.45,
      "learning_rate": 0.00012312140604268829,
      "loss": 0.2951,
      "step": 31450
    },
    {
      "epoch": 31.46,
      "learning_rate": 0.00012310237965329796,
      "loss": 0.2684,
      "step": 31460
    },
    {
      "epoch": 31.47,
      "learning_rate": 0.00012308334800350371,
      "loss": 0.2521,
      "step": 31470
    },
    {
      "epoch": 31.48,
      "learning_rate": 0.00012306431109538682,
      "loss": 0.2535,
      "step": 31480
    },
    {
      "epoch": 31.49,
      "learning_rate": 0.00012304526893102915,
      "loss": 0.3207,
      "step": 31490
    },
    {
      "epoch": 31.5,
      "learning_rate": 0.00012302622151251307,
      "loss": 0.2456,
      "step": 31500
    },
    {
      "epoch": 31.51,
      "learning_rate": 0.00012300716884192163,
      "loss": 0.2502,
      "step": 31510
    },
    {
      "epoch": 31.52,
      "learning_rate": 0.00012298811092133837,
      "loss": 0.2826,
      "step": 31520
    },
    {
      "epoch": 31.53,
      "learning_rate": 0.00012296904775284747,
      "loss": 0.2804,
      "step": 31530
    },
    {
      "epoch": 31.54,
      "learning_rate": 0.0001229499793385336,
      "loss": 0.3213,
      "step": 31540
    },
    {
      "epoch": 31.55,
      "learning_rate": 0.00012293090568048213,
      "loss": 0.3046,
      "step": 31550
    },
    {
      "epoch": 31.56,
      "learning_rate": 0.0001229118267807788,
      "loss": 0.2361,
      "step": 31560
    },
    {
      "epoch": 31.57,
      "learning_rate": 0.0001228927426415102,
      "loss": 0.2849,
      "step": 31570
    },
    {
      "epoch": 31.58,
      "learning_rate": 0.00012287365326476323,
      "loss": 0.349,
      "step": 31580
    },
    {
      "epoch": 31.59,
      "learning_rate": 0.00012285455865262553,
      "loss": 0.26,
      "step": 31590
    },
    {
      "epoch": 31.6,
      "learning_rate": 0.00012283545880718524,
      "loss": 0.2172,
      "step": 31600
    },
    {
      "epoch": 31.61,
      "learning_rate": 0.0001228163537305311,
      "loss": 0.2815,
      "step": 31610
    },
    {
      "epoch": 31.62,
      "learning_rate": 0.00012279915469058132,
      "loss": 1.7107,
      "step": 31620
    },
    {
      "epoch": 31.63,
      "learning_rate": 0.00012278003968037735,
      "loss": 2.0561,
      "step": 31630
    },
    {
      "epoch": 31.64,
      "learning_rate": 0.0001227609194450201,
      "loss": 0.3645,
      "step": 31640
    },
    {
      "epoch": 31.65,
      "learning_rate": 0.00012274179398660048,
      "loss": 0.317,
      "step": 31650
    },
    {
      "epoch": 31.66,
      "learning_rate": 0.00012272266330721004,
      "loss": 0.283,
      "step": 31660
    },
    {
      "epoch": 31.67,
      "learning_rate": 0.0001227035274089409,
      "loss": 0.2757,
      "step": 31670
    },
    {
      "epoch": 31.68,
      "learning_rate": 0.00012268438629388573,
      "loss": 0.2342,
      "step": 31680
    },
    {
      "epoch": 31.69,
      "learning_rate": 0.00012266523996413777,
      "loss": 0.2418,
      "step": 31690
    },
    {
      "epoch": 31.7,
      "learning_rate": 0.00012264608842179082,
      "loss": 0.3003,
      "step": 31700
    },
    {
      "epoch": 31.71,
      "learning_rate": 0.00012262693166893932,
      "loss": 0.3568,
      "step": 31710
    },
    {
      "epoch": 31.72,
      "learning_rate": 0.00012260776970767813,
      "loss": 0.4357,
      "step": 31720
    },
    {
      "epoch": 31.73,
      "learning_rate": 0.0001225886025401028,
      "loss": 0.3199,
      "step": 31730
    },
    {
      "epoch": 31.74,
      "learning_rate": 0.0001225694301683095,
      "loss": 0.2628,
      "step": 31740
    },
    {
      "epoch": 31.75,
      "learning_rate": 0.0001225502525943948,
      "loss": 0.2443,
      "step": 31750
    },
    {
      "epoch": 31.76,
      "learning_rate": 0.000122531069820456,
      "loss": 0.2858,
      "step": 31760
    },
    {
      "epoch": 31.77,
      "learning_rate": 0.00012251188184859085,
      "loss": 0.3152,
      "step": 31770
    },
    {
      "epoch": 31.78,
      "learning_rate": 0.00012249268868089772,
      "loss": 0.3049,
      "step": 31780
    },
    {
      "epoch": 31.79,
      "learning_rate": 0.00012247349031947556,
      "loss": 0.2618,
      "step": 31790
    },
    {
      "epoch": 31.8,
      "learning_rate": 0.0001224542867664239,
      "loss": 0.253,
      "step": 31800
    },
    {
      "epoch": 31.81,
      "learning_rate": 0.0001224350780238428,
      "loss": 0.3209,
      "step": 31810
    },
    {
      "epoch": 31.82,
      "learning_rate": 0.00012241586409383282,
      "loss": 0.3124,
      "step": 31820
    },
    {
      "epoch": 31.83,
      "learning_rate": 0.0001223966449784953,
      "loss": 0.2659,
      "step": 31830
    },
    {
      "epoch": 31.84,
      "learning_rate": 0.0001223774206799319,
      "loss": 0.3487,
      "step": 31840
    },
    {
      "epoch": 31.85,
      "learning_rate": 0.000122358191200245,
      "loss": 0.2526,
      "step": 31850
    },
    {
      "epoch": 31.86,
      "learning_rate": 0.00012233895654153754,
      "loss": 0.2219,
      "step": 31860
    },
    {
      "epoch": 31.87,
      "learning_rate": 0.00012231971670591295,
      "loss": 0.2402,
      "step": 31870
    },
    {
      "epoch": 31.88,
      "learning_rate": 0.0001223004716954753,
      "loss": 0.3074,
      "step": 31880
    },
    {
      "epoch": 31.89,
      "learning_rate": 0.00012228122151232917,
      "loss": 0.2849,
      "step": 31890
    },
    {
      "epoch": 31.9,
      "learning_rate": 0.00012226196615857974,
      "loss": 0.3005,
      "step": 31900
    },
    {
      "epoch": 31.91,
      "learning_rate": 0.00012224270563633273,
      "loss": 0.2492,
      "step": 31910
    },
    {
      "epoch": 31.92,
      "learning_rate": 0.00012222343994769448,
      "loss": 0.2847,
      "step": 31920
    },
    {
      "epoch": 31.93,
      "learning_rate": 0.00012220416909477187,
      "loss": 0.286,
      "step": 31930
    },
    {
      "epoch": 31.94,
      "learning_rate": 0.00012218489307967226,
      "loss": 0.2955,
      "step": 31940
    },
    {
      "epoch": 31.95,
      "learning_rate": 0.0001221656119045037,
      "loss": 0.2703,
      "step": 31950
    },
    {
      "epoch": 31.96,
      "learning_rate": 0.00012214632557137472,
      "loss": 0.2686,
      "step": 31960
    },
    {
      "epoch": 31.97,
      "learning_rate": 0.00012212703408239444,
      "loss": 0.3379,
      "step": 31970
    },
    {
      "epoch": 31.98,
      "learning_rate": 0.0001221077374396726,
      "loss": 0.3116,
      "step": 31980
    },
    {
      "epoch": 31.99,
      "learning_rate": 0.0001220884356453194,
      "loss": 0.3038,
      "step": 31990
    },
    {
      "epoch": 32.0,
      "learning_rate": 0.0001220691287014457,
      "loss": 0.2769,
      "step": 32000
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.27324944734573364,
      "eval_runtime": 15.3458,
      "eval_samples_per_second": 130.329,
      "eval_steps_per_second": 16.291,
      "step": 32000
    },
    {
      "epoch": 32.01,
      "learning_rate": 0.00012204981661016281,
      "loss": 0.2374,
      "step": 32010
    },
    {
      "epoch": 32.02,
      "learning_rate": 0.00012203049937358276,
      "loss": 0.2668,
      "step": 32020
    },
    {
      "epoch": 32.03,
      "learning_rate": 0.00012201117699381798,
      "loss": 0.2459,
      "step": 32030
    },
    {
      "epoch": 32.04,
      "learning_rate": 0.00012199184947298157,
      "loss": 0.205,
      "step": 32040
    },
    {
      "epoch": 32.05,
      "learning_rate": 0.00012197251681318717,
      "loss": 0.2514,
      "step": 32050
    },
    {
      "epoch": 32.06,
      "learning_rate": 0.00012195317901654896,
      "loss": 0.3419,
      "step": 32060
    },
    {
      "epoch": 32.07,
      "learning_rate": 0.00012193383608518164,
      "loss": 0.2976,
      "step": 32070
    },
    {
      "epoch": 32.08,
      "learning_rate": 0.0001219144880212006,
      "loss": 0.2772,
      "step": 32080
    },
    {
      "epoch": 32.09,
      "learning_rate": 0.00012189513482672167,
      "loss": 0.2451,
      "step": 32090
    },
    {
      "epoch": 32.1,
      "learning_rate": 0.00012187577650386131,
      "loss": 0.2166,
      "step": 32100
    },
    {
      "epoch": 32.11,
      "learning_rate": 0.00012185641305473651,
      "loss": 0.2602,
      "step": 32110
    },
    {
      "epoch": 32.12,
      "learning_rate": 0.00012183704448146484,
      "loss": 0.3124,
      "step": 32120
    },
    {
      "epoch": 32.13,
      "learning_rate": 0.0001218176707861644,
      "loss": 0.3558,
      "step": 32130
    },
    {
      "epoch": 32.14,
      "learning_rate": 0.00012179829197095383,
      "loss": 0.2872,
      "step": 32140
    },
    {
      "epoch": 32.15,
      "learning_rate": 0.00012177890803795245,
      "loss": 0.3131,
      "step": 32150
    },
    {
      "epoch": 32.16,
      "learning_rate": 0.00012175951898928002,
      "loss": 0.3296,
      "step": 32160
    },
    {
      "epoch": 32.17,
      "learning_rate": 0.00012174012482705686,
      "loss": 0.3209,
      "step": 32170
    },
    {
      "epoch": 32.18,
      "learning_rate": 0.00012172072555340396,
      "loss": 0.2938,
      "step": 32180
    },
    {
      "epoch": 32.19,
      "learning_rate": 0.00012170132117044276,
      "loss": 0.2308,
      "step": 32190
    },
    {
      "epoch": 32.2,
      "learning_rate": 0.00012168191168029525,
      "loss": 0.3078,
      "step": 32200
    },
    {
      "epoch": 32.21,
      "learning_rate": 0.00012166249708508409,
      "loss": 0.3171,
      "step": 32210
    },
    {
      "epoch": 32.22,
      "learning_rate": 0.00012164307738693241,
      "loss": 0.3088,
      "step": 32220
    },
    {
      "epoch": 32.23,
      "learning_rate": 0.0001216236525879639,
      "loss": 0.2991,
      "step": 32230
    },
    {
      "epoch": 32.24,
      "learning_rate": 0.00012160422269030284,
      "loss": 0.3113,
      "step": 32240
    },
    {
      "epoch": 32.25,
      "learning_rate": 0.00012158478769607408,
      "loss": 0.2255,
      "step": 32250
    },
    {
      "epoch": 32.26,
      "learning_rate": 0.00012156534760740295,
      "loss": 0.251,
      "step": 32260
    },
    {
      "epoch": 32.27,
      "learning_rate": 0.00012154590242641542,
      "loss": 0.2871,
      "step": 32270
    },
    {
      "epoch": 32.28,
      "learning_rate": 0.00012152645215523799,
      "loss": 0.1817,
      "step": 32280
    },
    {
      "epoch": 32.29,
      "learning_rate": 0.00012150699679599771,
      "loss": 0.3375,
      "step": 32290
    },
    {
      "epoch": 32.3,
      "learning_rate": 0.00012148753635082217,
      "loss": 0.3293,
      "step": 32300
    },
    {
      "epoch": 32.31,
      "learning_rate": 0.00012146807082183955,
      "loss": 0.2516,
      "step": 32310
    },
    {
      "epoch": 32.32,
      "learning_rate": 0.00012144860021117856,
      "loss": 0.303,
      "step": 32320
    },
    {
      "epoch": 32.33,
      "learning_rate": 0.00012142912452096851,
      "loss": 0.2954,
      "step": 32330
    },
    {
      "epoch": 32.34,
      "learning_rate": 0.00012140964375333917,
      "loss": 0.2263,
      "step": 32340
    },
    {
      "epoch": 32.35,
      "learning_rate": 0.000121390157910421,
      "loss": 0.3486,
      "step": 32350
    },
    {
      "epoch": 32.36,
      "learning_rate": 0.00012137066699434489,
      "loss": 0.2968,
      "step": 32360
    },
    {
      "epoch": 32.37,
      "learning_rate": 0.00012135117100724235,
      "loss": 0.2083,
      "step": 32370
    },
    {
      "epoch": 32.38,
      "learning_rate": 0.00012133166995124548,
      "loss": 0.2772,
      "step": 32380
    },
    {
      "epoch": 32.39,
      "learning_rate": 0.00012131216382848678,
      "loss": 0.2608,
      "step": 32390
    },
    {
      "epoch": 32.4,
      "learning_rate": 0.00012129265264109949,
      "loss": 0.3311,
      "step": 32400
    },
    {
      "epoch": 32.41,
      "learning_rate": 0.00012127313639121733,
      "loss": 0.3135,
      "step": 32410
    },
    {
      "epoch": 32.42,
      "learning_rate": 0.00012125361508097453,
      "loss": 0.2772,
      "step": 32420
    },
    {
      "epoch": 32.43,
      "learning_rate": 0.00012123408871250593,
      "loss": 0.2945,
      "step": 32430
    },
    {
      "epoch": 32.44,
      "learning_rate": 0.00012121455728794692,
      "loss": 0.2776,
      "step": 32440
    },
    {
      "epoch": 32.45,
      "learning_rate": 0.00012119502080943338,
      "loss": 0.267,
      "step": 32450
    },
    {
      "epoch": 32.46,
      "learning_rate": 0.0001211754792791018,
      "loss": 0.219,
      "step": 32460
    },
    {
      "epoch": 32.47,
      "learning_rate": 0.00012115593269908927,
      "loss": 0.2623,
      "step": 32470
    },
    {
      "epoch": 32.48,
      "learning_rate": 0.00012113638107153332,
      "loss": 0.2422,
      "step": 32480
    },
    {
      "epoch": 32.49,
      "learning_rate": 0.00012111682439857208,
      "loss": 0.2695,
      "step": 32490
    },
    {
      "epoch": 32.5,
      "learning_rate": 0.0001210972626823443,
      "loss": 0.2886,
      "step": 32500
    },
    {
      "epoch": 32.51,
      "learning_rate": 0.00012107769592498916,
      "loss": 0.2861,
      "step": 32510
    },
    {
      "epoch": 32.52,
      "learning_rate": 0.00012105812412864647,
      "loss": 0.3211,
      "step": 32520
    },
    {
      "epoch": 32.53,
      "learning_rate": 0.00012103854729545656,
      "loss": 0.2939,
      "step": 32530
    },
    {
      "epoch": 32.54,
      "learning_rate": 0.00012101896542756036,
      "loss": 0.3024,
      "step": 32540
    },
    {
      "epoch": 32.55,
      "learning_rate": 0.00012099937852709928,
      "loss": 0.2416,
      "step": 32550
    },
    {
      "epoch": 32.56,
      "learning_rate": 0.00012097978659621531,
      "loss": 0.2848,
      "step": 32560
    },
    {
      "epoch": 32.57,
      "learning_rate": 0.00012096018963705102,
      "loss": 0.2298,
      "step": 32570
    },
    {
      "epoch": 32.58,
      "learning_rate": 0.00012094058765174949,
      "loss": 0.2886,
      "step": 32580
    },
    {
      "epoch": 32.59,
      "learning_rate": 0.00012092098064245437,
      "loss": 0.2952,
      "step": 32590
    },
    {
      "epoch": 32.6,
      "learning_rate": 0.00012090136861130982,
      "loss": 0.2607,
      "step": 32600
    },
    {
      "epoch": 32.61,
      "learning_rate": 0.00012088175156046063,
      "loss": 0.2344,
      "step": 32610
    },
    {
      "epoch": 32.62,
      "learning_rate": 0.0001208621294920521,
      "loss": 0.2948,
      "step": 32620
    },
    {
      "epoch": 32.63,
      "learning_rate": 0.00012084250240823,
      "loss": 0.2601,
      "step": 32630
    },
    {
      "epoch": 32.64,
      "learning_rate": 0.00012082287031114077,
      "loss": 0.2256,
      "step": 32640
    },
    {
      "epoch": 32.65,
      "learning_rate": 0.00012080323320293135,
      "loss": 0.3208,
      "step": 32650
    },
    {
      "epoch": 32.66,
      "learning_rate": 0.0001207835910857492,
      "loss": 0.338,
      "step": 32660
    },
    {
      "epoch": 32.67,
      "learning_rate": 0.00012076394396174237,
      "loss": 0.3117,
      "step": 32670
    },
    {
      "epoch": 32.68,
      "learning_rate": 0.00012074429183305942,
      "loss": 0.3041,
      "step": 32680
    },
    {
      "epoch": 32.69,
      "learning_rate": 0.0001207246347018495,
      "loss": 0.2338,
      "step": 32690
    },
    {
      "epoch": 32.7,
      "learning_rate": 0.00012070497257026228,
      "loss": 0.3298,
      "step": 32700
    },
    {
      "epoch": 32.71,
      "learning_rate": 0.00012068530544044796,
      "loss": 0.1994,
      "step": 32710
    },
    {
      "epoch": 32.72,
      "learning_rate": 0.00012066563331455736,
      "loss": 0.2961,
      "step": 32720
    },
    {
      "epoch": 32.73,
      "learning_rate": 0.00012064595619474171,
      "loss": 0.2685,
      "step": 32730
    },
    {
      "epoch": 32.74,
      "learning_rate": 0.00012062627408315294,
      "loss": 0.2509,
      "step": 32740
    },
    {
      "epoch": 32.75,
      "learning_rate": 0.00012060658698194346,
      "loss": 0.2238,
      "step": 32750
    },
    {
      "epoch": 32.76,
      "learning_rate": 0.00012058689489326617,
      "loss": 0.2951,
      "step": 32760
    },
    {
      "epoch": 32.77,
      "learning_rate": 0.00012056719781927458,
      "loss": 0.2073,
      "step": 32770
    },
    {
      "epoch": 32.78,
      "learning_rate": 0.00012054749576212277,
      "loss": 0.2368,
      "step": 32780
    },
    {
      "epoch": 32.79,
      "learning_rate": 0.0001205277887239653,
      "loss": 0.2075,
      "step": 32790
    },
    {
      "epoch": 32.8,
      "learning_rate": 0.00012050807670695728,
      "loss": 0.2692,
      "step": 32800
    },
    {
      "epoch": 32.81,
      "learning_rate": 0.00012048835971325445,
      "loss": 0.3465,
      "step": 32810
    },
    {
      "epoch": 32.82,
      "learning_rate": 0.00012046863774501297,
      "loss": 0.3127,
      "step": 32820
    },
    {
      "epoch": 32.83,
      "learning_rate": 0.00012044891080438963,
      "loss": 0.2426,
      "step": 32830
    },
    {
      "epoch": 32.84,
      "learning_rate": 0.00012042917889354173,
      "loss": 0.2948,
      "step": 32840
    },
    {
      "epoch": 32.85,
      "learning_rate": 0.00012040944201462712,
      "loss": 0.2429,
      "step": 32850
    },
    {
      "epoch": 32.86,
      "learning_rate": 0.00012038970016980423,
      "loss": 0.2428,
      "step": 32860
    },
    {
      "epoch": 32.87,
      "learning_rate": 0.00012036995336123196,
      "loss": 0.296,
      "step": 32870
    },
    {
      "epoch": 32.88,
      "learning_rate": 0.00012035020159106979,
      "loss": 0.3541,
      "step": 32880
    },
    {
      "epoch": 32.89,
      "learning_rate": 0.00012033044486147778,
      "loss": 0.2258,
      "step": 32890
    },
    {
      "epoch": 32.9,
      "learning_rate": 0.00012031068317461645,
      "loss": 0.3122,
      "step": 32900
    },
    {
      "epoch": 32.91,
      "learning_rate": 0.00012029091653264695,
      "loss": 0.3229,
      "step": 32910
    },
    {
      "epoch": 32.92,
      "learning_rate": 0.00012027114493773093,
      "loss": 0.3213,
      "step": 32920
    },
    {
      "epoch": 32.93,
      "learning_rate": 0.00012025136839203053,
      "loss": 0.2861,
      "step": 32930
    },
    {
      "epoch": 32.94,
      "learning_rate": 0.00012023158689770851,
      "loss": 0.2859,
      "step": 32940
    },
    {
      "epoch": 32.95,
      "learning_rate": 0.00012021180045692819,
      "loss": 0.304,
      "step": 32950
    },
    {
      "epoch": 32.96,
      "learning_rate": 0.00012019200907185331,
      "loss": 0.2783,
      "step": 32960
    },
    {
      "epoch": 32.97,
      "learning_rate": 0.00012017221274464829,
      "loss": 0.2689,
      "step": 32970
    },
    {
      "epoch": 32.98,
      "learning_rate": 0.00012015241147747798,
      "loss": 0.2123,
      "step": 32980
    },
    {
      "epoch": 32.99,
      "learning_rate": 0.00012013260527250785,
      "loss": 0.3647,
      "step": 32990
    },
    {
      "epoch": 33.0,
      "learning_rate": 0.00012011279413190385,
      "loss": 0.2895,
      "step": 33000
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2739899158477783,
      "eval_runtime": 15.0452,
      "eval_samples_per_second": 132.932,
      "eval_steps_per_second": 16.617,
      "step": 33000
    },
    {
      "epoch": 33.01,
      "learning_rate": 0.00012009297805783252,
      "loss": 0.2477,
      "step": 33010
    },
    {
      "epoch": 33.02,
      "learning_rate": 0.00012007315705246091,
      "loss": 0.2669,
      "step": 33020
    },
    {
      "epoch": 33.03,
      "learning_rate": 0.00012005333111795659,
      "loss": 0.2985,
      "step": 33030
    },
    {
      "epoch": 33.04,
      "learning_rate": 0.00012003350025648774,
      "loss": 0.2766,
      "step": 33040
    },
    {
      "epoch": 33.05,
      "learning_rate": 0.00012001366447022299,
      "loss": 0.2207,
      "step": 33050
    },
    {
      "epoch": 33.06,
      "learning_rate": 0.0001199938237613316,
      "loss": 0.2461,
      "step": 33060
    },
    {
      "epoch": 33.07,
      "learning_rate": 0.00011997397813198326,
      "loss": 0.3055,
      "step": 33070
    },
    {
      "epoch": 33.08,
      "learning_rate": 0.00011995412758434832,
      "loss": 0.3553,
      "step": 33080
    },
    {
      "epoch": 33.09,
      "learning_rate": 0.00011993427212059752,
      "loss": 0.2707,
      "step": 33090
    },
    {
      "epoch": 33.1,
      "learning_rate": 0.00011991441174290234,
      "loss": 0.2253,
      "step": 33100
    },
    {
      "epoch": 33.11,
      "learning_rate": 0.00011989454645343459,
      "loss": 0.3201,
      "step": 33110
    },
    {
      "epoch": 33.12,
      "learning_rate": 0.00011987467625436673,
      "loss": 0.2635,
      "step": 33120
    },
    {
      "epoch": 33.13,
      "learning_rate": 0.00011985480114787175,
      "loss": 0.2859,
      "step": 33130
    },
    {
      "epoch": 33.14,
      "learning_rate": 0.00011983492113612317,
      "loss": 0.3451,
      "step": 33140
    },
    {
      "epoch": 33.15,
      "learning_rate": 0.000119815036221295,
      "loss": 0.2782,
      "step": 33150
    },
    {
      "epoch": 33.16,
      "learning_rate": 0.00011979514640556186,
      "loss": 0.2711,
      "step": 33160
    },
    {
      "epoch": 33.17,
      "learning_rate": 0.00011977525169109885,
      "loss": 0.3349,
      "step": 33170
    },
    {
      "epoch": 33.18,
      "learning_rate": 0.00011975535208008165,
      "loss": 0.2506,
      "step": 33180
    },
    {
      "epoch": 33.19,
      "learning_rate": 0.00011973544757468641,
      "loss": 0.2599,
      "step": 33190
    },
    {
      "epoch": 33.2,
      "learning_rate": 0.00011971553817708992,
      "loss": 0.2696,
      "step": 33200
    },
    {
      "epoch": 33.21,
      "learning_rate": 0.00011969562388946938,
      "loss": 0.2668,
      "step": 33210
    },
    {
      "epoch": 33.22,
      "learning_rate": 0.00011967570471400259,
      "loss": 0.2669,
      "step": 33220
    },
    {
      "epoch": 33.23,
      "learning_rate": 0.00011965578065286793,
      "loss": 0.2322,
      "step": 33230
    },
    {
      "epoch": 33.24,
      "learning_rate": 0.00011963585170824423,
      "loss": 0.2188,
      "step": 33240
    },
    {
      "epoch": 33.25,
      "learning_rate": 0.0001196159178823109,
      "loss": 0.3515,
      "step": 33250
    },
    {
      "epoch": 33.26,
      "learning_rate": 0.00011959597917724785,
      "loss": 0.271,
      "step": 33260
    },
    {
      "epoch": 33.27,
      "learning_rate": 0.00011957603559523559,
      "loss": 0.2706,
      "step": 33270
    },
    {
      "epoch": 33.28,
      "learning_rate": 0.00011955608713845508,
      "loss": 0.3176,
      "step": 33280
    },
    {
      "epoch": 33.29,
      "learning_rate": 0.0001195361338090879,
      "loss": 0.2464,
      "step": 33290
    },
    {
      "epoch": 33.3,
      "learning_rate": 0.00011951617560931604,
      "loss": 0.3063,
      "step": 33300
    },
    {
      "epoch": 33.31,
      "learning_rate": 0.00011949621254132217,
      "loss": 0.2961,
      "step": 33310
    },
    {
      "epoch": 33.32,
      "learning_rate": 0.00011947624460728939,
      "loss": 0.2594,
      "step": 33320
    },
    {
      "epoch": 33.33,
      "learning_rate": 0.00011945627180940138,
      "loss": 0.264,
      "step": 33330
    },
    {
      "epoch": 33.34,
      "learning_rate": 0.00011943629414984231,
      "loss": 0.261,
      "step": 33340
    },
    {
      "epoch": 33.35,
      "learning_rate": 0.00011941631163079693,
      "loss": 0.2397,
      "step": 33350
    },
    {
      "epoch": 33.36,
      "learning_rate": 0.0001193963242544505,
      "loss": 0.3162,
      "step": 33360
    },
    {
      "epoch": 33.37,
      "learning_rate": 0.00011937633202298878,
      "loss": 0.3216,
      "step": 33370
    },
    {
      "epoch": 33.38,
      "learning_rate": 0.0001193563349385981,
      "loss": 0.3037,
      "step": 33380
    },
    {
      "epoch": 33.39,
      "learning_rate": 0.00011933633300346534,
      "loss": 0.3206,
      "step": 33390
    },
    {
      "epoch": 33.4,
      "learning_rate": 0.00011931632621977784,
      "loss": 0.2857,
      "step": 33400
    },
    {
      "epoch": 33.41,
      "learning_rate": 0.00011929631458972355,
      "loss": 0.3038,
      "step": 33410
    },
    {
      "epoch": 33.42,
      "learning_rate": 0.00011927629811549087,
      "loss": 0.3294,
      "step": 33420
    },
    {
      "epoch": 33.43,
      "learning_rate": 0.00011925627679926885,
      "loss": 0.2619,
      "step": 33430
    },
    {
      "epoch": 33.44,
      "learning_rate": 0.00011923625064324687,
      "loss": 0.2938,
      "step": 33440
    },
    {
      "epoch": 33.45,
      "learning_rate": 0.00011921621964961508,
      "loss": 0.3039,
      "step": 33450
    },
    {
      "epoch": 33.46,
      "learning_rate": 0.00011919618382056398,
      "loss": 0.267,
      "step": 33460
    },
    {
      "epoch": 33.47,
      "learning_rate": 0.00011917614315828465,
      "loss": 0.2609,
      "step": 33470
    },
    {
      "epoch": 33.48,
      "learning_rate": 0.00011915609766496872,
      "loss": 0.2604,
      "step": 33480
    },
    {
      "epoch": 33.49,
      "learning_rate": 0.00011913604734280835,
      "loss": 0.313,
      "step": 33490
    },
    {
      "epoch": 33.5,
      "learning_rate": 0.00011911599219399621,
      "loss": 0.3124,
      "step": 33500
    },
    {
      "epoch": 33.51,
      "learning_rate": 0.00011909593222072547,
      "loss": 0.2334,
      "step": 33510
    },
    {
      "epoch": 33.52,
      "learning_rate": 0.00011907586742518987,
      "loss": 0.3205,
      "step": 33520
    },
    {
      "epoch": 33.53,
      "learning_rate": 0.0001190557978095837,
      "loss": 0.2665,
      "step": 33530
    },
    {
      "epoch": 33.54,
      "learning_rate": 0.00011903572337610172,
      "loss": 0.268,
      "step": 33540
    },
    {
      "epoch": 33.55,
      "learning_rate": 0.00011901564412693923,
      "loss": 0.2685,
      "step": 33550
    },
    {
      "epoch": 33.56,
      "learning_rate": 0.00011899556006429207,
      "loss": 0.2873,
      "step": 33560
    },
    {
      "epoch": 33.57,
      "learning_rate": 0.00011897547119035661,
      "loss": 0.2786,
      "step": 33570
    },
    {
      "epoch": 33.58,
      "learning_rate": 0.00011895537750732975,
      "loss": 0.2942,
      "step": 33580
    },
    {
      "epoch": 33.59,
      "learning_rate": 0.00011893527901740885,
      "loss": 0.2618,
      "step": 33590
    },
    {
      "epoch": 33.6,
      "learning_rate": 0.00011891517572279193,
      "loss": 0.31,
      "step": 33600
    },
    {
      "epoch": 33.61,
      "learning_rate": 0.0001188950676256774,
      "loss": 0.3495,
      "step": 33610
    },
    {
      "epoch": 33.62,
      "learning_rate": 0.00011887495472826429,
      "loss": 0.2249,
      "step": 33620
    },
    {
      "epoch": 33.63,
      "learning_rate": 0.0001188548370327521,
      "loss": 0.3212,
      "step": 33630
    },
    {
      "epoch": 33.64,
      "learning_rate": 0.00011883471454134084,
      "loss": 0.2166,
      "step": 33640
    },
    {
      "epoch": 33.65,
      "learning_rate": 0.00011881458725623112,
      "loss": 0.2514,
      "step": 33650
    },
    {
      "epoch": 33.66,
      "learning_rate": 0.000118794455179624,
      "loss": 0.3181,
      "step": 33660
    },
    {
      "epoch": 33.67,
      "learning_rate": 0.00011877431831372111,
      "loss": 0.2189,
      "step": 33670
    },
    {
      "epoch": 33.68,
      "learning_rate": 0.00011875417666072458,
      "loss": 0.2861,
      "step": 33680
    },
    {
      "epoch": 33.69,
      "learning_rate": 0.0001187340302228371,
      "loss": 0.2829,
      "step": 33690
    },
    {
      "epoch": 33.7,
      "learning_rate": 0.00011871387900226179,
      "loss": 0.2781,
      "step": 33700
    },
    {
      "epoch": 33.71,
      "learning_rate": 0.00011869372300120242,
      "loss": 0.2145,
      "step": 33710
    },
    {
      "epoch": 33.72,
      "learning_rate": 0.00011867356222186319,
      "loss": 0.2876,
      "step": 33720
    },
    {
      "epoch": 33.73,
      "learning_rate": 0.00011865339666644885,
      "loss": 0.2674,
      "step": 33730
    },
    {
      "epoch": 33.74,
      "learning_rate": 0.00011863322633716468,
      "loss": 0.2007,
      "step": 33740
    },
    {
      "epoch": 33.75,
      "learning_rate": 0.00011861305123621649,
      "loss": 0.2241,
      "step": 33750
    },
    {
      "epoch": 33.76,
      "learning_rate": 0.00011859287136581057,
      "loss": 0.3395,
      "step": 33760
    },
    {
      "epoch": 33.77,
      "learning_rate": 0.00011857268672815381,
      "loss": 0.2687,
      "step": 33770
    },
    {
      "epoch": 33.78,
      "learning_rate": 0.00011855249732545352,
      "loss": 0.2685,
      "step": 33780
    },
    {
      "epoch": 33.79,
      "learning_rate": 0.0001185323031599176,
      "loss": 0.3126,
      "step": 33790
    },
    {
      "epoch": 33.8,
      "learning_rate": 0.00011851210423375447,
      "loss": 0.3136,
      "step": 33800
    },
    {
      "epoch": 33.81,
      "learning_rate": 0.00011849190054917304,
      "loss": 0.1739,
      "step": 33810
    },
    {
      "epoch": 33.82,
      "learning_rate": 0.00011847169210838273,
      "loss": 0.3532,
      "step": 33820
    },
    {
      "epoch": 33.83,
      "learning_rate": 0.00011845147891359355,
      "loss": 0.3033,
      "step": 33830
    },
    {
      "epoch": 33.84,
      "learning_rate": 0.00011843126096701597,
      "loss": 0.2361,
      "step": 33840
    },
    {
      "epoch": 33.85,
      "learning_rate": 0.000118411038270861,
      "loss": 0.2694,
      "step": 33850
    },
    {
      "epoch": 33.86,
      "learning_rate": 0.00011839081082734011,
      "loss": 0.2588,
      "step": 33860
    },
    {
      "epoch": 33.87,
      "learning_rate": 0.0001183705786386654,
      "loss": 0.2338,
      "step": 33870
    },
    {
      "epoch": 33.88,
      "learning_rate": 0.00011835034170704943,
      "loss": 0.2313,
      "step": 33880
    },
    {
      "epoch": 33.89,
      "learning_rate": 0.00011833010003470526,
      "loss": 0.2942,
      "step": 33890
    },
    {
      "epoch": 33.9,
      "learning_rate": 0.00011830985362384649,
      "loss": 0.3173,
      "step": 33900
    },
    {
      "epoch": 33.91,
      "learning_rate": 0.00011828960247668725,
      "loss": 0.2695,
      "step": 33910
    },
    {
      "epoch": 33.92,
      "learning_rate": 0.00011826934659544215,
      "loss": 0.3567,
      "step": 33920
    },
    {
      "epoch": 33.93,
      "learning_rate": 0.00011824908598232641,
      "loss": 0.312,
      "step": 33930
    },
    {
      "epoch": 33.94,
      "learning_rate": 0.00011822882063955563,
      "loss": 0.294,
      "step": 33940
    },
    {
      "epoch": 33.95,
      "learning_rate": 0.00011820855056934599,
      "loss": 0.2409,
      "step": 33950
    },
    {
      "epoch": 33.96,
      "learning_rate": 0.00011818827577391426,
      "loss": 0.2646,
      "step": 33960
    },
    {
      "epoch": 33.97,
      "learning_rate": 0.00011816799625547759,
      "loss": 0.2395,
      "step": 33970
    },
    {
      "epoch": 33.98,
      "learning_rate": 0.00011814771201625377,
      "loss": 0.2615,
      "step": 33980
    },
    {
      "epoch": 33.99,
      "learning_rate": 0.00011812742305846103,
      "loss": 0.2806,
      "step": 33990
    },
    {
      "epoch": 34.0,
      "learning_rate": 0.00011810712938431815,
      "loss": 0.2945,
      "step": 34000
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27448028326034546,
      "eval_runtime": 14.4513,
      "eval_samples_per_second": 138.396,
      "eval_steps_per_second": 17.299,
      "step": 34000
    },
    {
      "epoch": 34.01,
      "learning_rate": 0.0001180868309960444,
      "loss": 0.3018,
      "step": 34010
    },
    {
      "epoch": 34.02,
      "learning_rate": 0.00011806652789585961,
      "loss": 0.302,
      "step": 34020
    },
    {
      "epoch": 34.03,
      "learning_rate": 0.00011804622008598407,
      "loss": 0.3,
      "step": 34030
    },
    {
      "epoch": 34.04,
      "learning_rate": 0.00011802590756863862,
      "loss": 0.2671,
      "step": 34040
    },
    {
      "epoch": 34.05,
      "learning_rate": 0.0001180055903460446,
      "loss": 0.3136,
      "step": 34050
    },
    {
      "epoch": 34.06,
      "learning_rate": 0.00011798526842042391,
      "loss": 0.3134,
      "step": 34060
    },
    {
      "epoch": 34.07,
      "learning_rate": 0.00011796494179399886,
      "loss": 0.2606,
      "step": 34070
    },
    {
      "epoch": 34.08,
      "learning_rate": 0.00011794461046899237,
      "loss": 0.2174,
      "step": 34080
    },
    {
      "epoch": 34.09,
      "learning_rate": 0.00011792427444762786,
      "loss": 0.2444,
      "step": 34090
    },
    {
      "epoch": 34.1,
      "learning_rate": 0.00011790393373212923,
      "loss": 0.2679,
      "step": 34100
    },
    {
      "epoch": 34.11,
      "learning_rate": 0.00011788358832472091,
      "loss": 0.3305,
      "step": 34110
    },
    {
      "epoch": 34.12,
      "learning_rate": 0.00011786323822762784,
      "loss": 0.327,
      "step": 34120
    },
    {
      "epoch": 34.13,
      "learning_rate": 0.00011784288344307549,
      "loss": 0.2775,
      "step": 34130
    },
    {
      "epoch": 34.14,
      "learning_rate": 0.0001178225239732898,
      "loss": 0.2926,
      "step": 34140
    },
    {
      "epoch": 34.15,
      "learning_rate": 0.00011780215982049729,
      "loss": 0.1985,
      "step": 34150
    },
    {
      "epoch": 34.16,
      "learning_rate": 0.00011778179098692494,
      "loss": 0.3498,
      "step": 34160
    },
    {
      "epoch": 34.17,
      "learning_rate": 0.00011776141747480024,
      "loss": 0.2424,
      "step": 34170
    },
    {
      "epoch": 34.18,
      "learning_rate": 0.00011774103928635123,
      "loss": 0.2318,
      "step": 34180
    },
    {
      "epoch": 34.19,
      "learning_rate": 0.00011772065642380642,
      "loss": 0.2987,
      "step": 34190
    },
    {
      "epoch": 34.2,
      "learning_rate": 0.00011770026888939483,
      "loss": 0.2184,
      "step": 34200
    },
    {
      "epoch": 34.21,
      "learning_rate": 0.00011767987668534603,
      "loss": 0.2693,
      "step": 34210
    },
    {
      "epoch": 34.22,
      "learning_rate": 0.00011765947981389012,
      "loss": 0.303,
      "step": 34220
    },
    {
      "epoch": 34.23,
      "learning_rate": 0.0001176390782772576,
      "loss": 0.2508,
      "step": 34230
    },
    {
      "epoch": 34.24,
      "learning_rate": 0.00011761867207767963,
      "loss": 0.2543,
      "step": 34240
    },
    {
      "epoch": 34.25,
      "learning_rate": 0.00011759826121738771,
      "loss": 0.2687,
      "step": 34250
    },
    {
      "epoch": 34.26,
      "learning_rate": 0.00011757784569861402,
      "loss": 0.2688,
      "step": 34260
    },
    {
      "epoch": 34.27,
      "learning_rate": 0.00011755742552359111,
      "loss": 0.2951,
      "step": 34270
    },
    {
      "epoch": 34.28,
      "learning_rate": 0.00011753700069455216,
      "loss": 0.2522,
      "step": 34280
    },
    {
      "epoch": 34.29,
      "learning_rate": 0.00011751657121373075,
      "loss": 0.2685,
      "step": 34290
    },
    {
      "epoch": 34.3,
      "learning_rate": 0.00011749613708336103,
      "loss": 0.2773,
      "step": 34300
    },
    {
      "epoch": 34.31,
      "learning_rate": 0.00011747569830567766,
      "loss": 0.2358,
      "step": 34310
    },
    {
      "epoch": 34.32,
      "learning_rate": 0.0001174552548829158,
      "loss": 0.2688,
      "step": 34320
    },
    {
      "epoch": 34.33,
      "learning_rate": 0.00011743480681731107,
      "loss": 0.2664,
      "step": 34330
    },
    {
      "epoch": 34.34,
      "learning_rate": 0.00011741435411109968,
      "loss": 0.2433,
      "step": 34340
    },
    {
      "epoch": 34.35,
      "learning_rate": 0.0001173938967665183,
      "loss": 0.2452,
      "step": 34350
    },
    {
      "epoch": 34.36,
      "learning_rate": 0.0001173734347858041,
      "loss": 0.2845,
      "step": 34360
    },
    {
      "epoch": 34.37,
      "learning_rate": 0.00011735296817119477,
      "loss": 0.3227,
      "step": 34370
    },
    {
      "epoch": 34.38,
      "learning_rate": 0.00011733249692492853,
      "loss": 0.357,
      "step": 34380
    },
    {
      "epoch": 34.39,
      "learning_rate": 0.00011731202104924407,
      "loss": 0.3264,
      "step": 34390
    },
    {
      "epoch": 34.4,
      "learning_rate": 0.00011729154054638059,
      "loss": 0.3067,
      "step": 34400
    },
    {
      "epoch": 34.41,
      "learning_rate": 0.00011727105541857783,
      "loss": 0.2673,
      "step": 34410
    },
    {
      "epoch": 34.42,
      "learning_rate": 0.00011725056566807601,
      "loss": 0.2347,
      "step": 34420
    },
    {
      "epoch": 34.43,
      "learning_rate": 0.00011723007129711585,
      "loss": 0.2448,
      "step": 34430
    },
    {
      "epoch": 34.44,
      "learning_rate": 0.00011720957230793857,
      "loss": 0.2081,
      "step": 34440
    },
    {
      "epoch": 34.45,
      "learning_rate": 0.00011718906870278594,
      "loss": 0.3308,
      "step": 34450
    },
    {
      "epoch": 34.46,
      "learning_rate": 0.00011716856048390019,
      "loss": 0.2773,
      "step": 34460
    },
    {
      "epoch": 34.47,
      "learning_rate": 0.00011714804765352405,
      "loss": 0.3042,
      "step": 34470
    },
    {
      "epoch": 34.48,
      "learning_rate": 0.00011712753021390077,
      "loss": 0.285,
      "step": 34480
    },
    {
      "epoch": 34.49,
      "learning_rate": 0.00011710700816727415,
      "loss": 0.3068,
      "step": 34490
    },
    {
      "epoch": 34.5,
      "learning_rate": 0.00011708648151588842,
      "loss": 0.2347,
      "step": 34500
    },
    {
      "epoch": 34.51,
      "learning_rate": 0.00011706595026198836,
      "loss": 0.2254,
      "step": 34510
    },
    {
      "epoch": 34.52,
      "learning_rate": 0.00011704541440781922,
      "loss": 0.2438,
      "step": 34520
    },
    {
      "epoch": 34.53,
      "learning_rate": 0.00011702487395562675,
      "loss": 0.27,
      "step": 34530
    },
    {
      "epoch": 34.54,
      "learning_rate": 0.00011700432890765727,
      "loss": 0.2445,
      "step": 34540
    },
    {
      "epoch": 34.55,
      "learning_rate": 0.00011698377926615756,
      "loss": 0.276,
      "step": 34550
    },
    {
      "epoch": 34.56,
      "learning_rate": 0.00011696322503337481,
      "loss": 0.2625,
      "step": 34560
    },
    {
      "epoch": 34.57,
      "learning_rate": 0.0001169426662115569,
      "loss": 0.2684,
      "step": 34570
    },
    {
      "epoch": 34.58,
      "learning_rate": 0.00011692210280295207,
      "loss": 0.2683,
      "step": 34580
    },
    {
      "epoch": 34.59,
      "learning_rate": 0.00011690153480980908,
      "loss": 0.3228,
      "step": 34590
    },
    {
      "epoch": 34.6,
      "learning_rate": 0.00011688096223437728,
      "loss": 0.3033,
      "step": 34600
    },
    {
      "epoch": 34.61,
      "learning_rate": 0.00011686038507890639,
      "loss": 0.2672,
      "step": 34610
    },
    {
      "epoch": 34.62,
      "learning_rate": 0.00011683980334564673,
      "loss": 0.289,
      "step": 34620
    },
    {
      "epoch": 34.63,
      "learning_rate": 0.00011681921703684909,
      "loss": 0.2886,
      "step": 34630
    },
    {
      "epoch": 34.64,
      "learning_rate": 0.00011679862615476475,
      "loss": 0.2836,
      "step": 34640
    },
    {
      "epoch": 34.65,
      "learning_rate": 0.00011677803070164546,
      "loss": 0.2984,
      "step": 34650
    },
    {
      "epoch": 34.66,
      "learning_rate": 0.00011675743067974358,
      "loss": 0.3378,
      "step": 34660
    },
    {
      "epoch": 34.67,
      "learning_rate": 0.00011673682609131187,
      "loss": 0.2685,
      "step": 34670
    },
    {
      "epoch": 34.68,
      "learning_rate": 0.00011671621693860358,
      "loss": 0.2862,
      "step": 34680
    },
    {
      "epoch": 34.69,
      "learning_rate": 0.00011669560322387255,
      "loss": 0.2692,
      "step": 34690
    },
    {
      "epoch": 34.7,
      "learning_rate": 0.00011667498494937304,
      "loss": 0.2429,
      "step": 34700
    },
    {
      "epoch": 34.71,
      "learning_rate": 0.00011665436211735982,
      "loss": 0.3307,
      "step": 34710
    },
    {
      "epoch": 34.72,
      "learning_rate": 0.00011663373473008819,
      "loss": 0.2775,
      "step": 34720
    },
    {
      "epoch": 34.73,
      "learning_rate": 0.00011661310278981392,
      "loss": 0.3459,
      "step": 34730
    },
    {
      "epoch": 34.74,
      "learning_rate": 0.00011659246629879329,
      "loss": 0.339,
      "step": 34740
    },
    {
      "epoch": 34.75,
      "learning_rate": 0.00011657182525928309,
      "loss": 0.3107,
      "step": 34750
    },
    {
      "epoch": 34.76,
      "learning_rate": 0.00011655117967354057,
      "loss": 0.3051,
      "step": 34760
    },
    {
      "epoch": 34.77,
      "learning_rate": 0.00011653052954382354,
      "loss": 0.3289,
      "step": 34770
    },
    {
      "epoch": 34.78,
      "learning_rate": 0.00011650987487239021,
      "loss": 0.3292,
      "step": 34780
    },
    {
      "epoch": 34.79,
      "learning_rate": 0.00011648921566149939,
      "loss": 0.26,
      "step": 34790
    },
    {
      "epoch": 34.8,
      "learning_rate": 0.00011646855191341032,
      "loss": 0.2779,
      "step": 34800
    },
    {
      "epoch": 34.81,
      "learning_rate": 0.00011644788363038275,
      "loss": 0.2512,
      "step": 34810
    },
    {
      "epoch": 34.82,
      "learning_rate": 0.00011642721081467696,
      "loss": 0.3378,
      "step": 34820
    },
    {
      "epoch": 34.83,
      "learning_rate": 0.00011640653346855367,
      "loss": 0.2339,
      "step": 34830
    },
    {
      "epoch": 34.84,
      "learning_rate": 0.00011638585159427412,
      "loss": 0.2062,
      "step": 34840
    },
    {
      "epoch": 34.85,
      "learning_rate": 0.00011636516519410006,
      "loss": 0.2066,
      "step": 34850
    },
    {
      "epoch": 34.86,
      "learning_rate": 0.00011634447427029377,
      "loss": 0.3017,
      "step": 34860
    },
    {
      "epoch": 34.87,
      "learning_rate": 0.00011632377882511789,
      "loss": 0.2352,
      "step": 34870
    },
    {
      "epoch": 34.88,
      "learning_rate": 0.00011630307886083568,
      "loss": 0.3544,
      "step": 34880
    },
    {
      "epoch": 34.89,
      "learning_rate": 0.00011628237437971092,
      "loss": 0.2429,
      "step": 34890
    },
    {
      "epoch": 34.9,
      "learning_rate": 0.00011626166538400773,
      "loss": 0.2947,
      "step": 34900
    },
    {
      "epoch": 34.91,
      "learning_rate": 0.00011624095187599084,
      "loss": 0.234,
      "step": 34910
    },
    {
      "epoch": 34.92,
      "learning_rate": 0.00011622023385792546,
      "loss": 0.3119,
      "step": 34920
    },
    {
      "epoch": 34.93,
      "learning_rate": 0.00011619951133207728,
      "loss": 0.2427,
      "step": 34930
    },
    {
      "epoch": 34.94,
      "learning_rate": 0.00011617878430071251,
      "loss": 0.3477,
      "step": 34940
    },
    {
      "epoch": 34.95,
      "learning_rate": 0.00011615805276609776,
      "loss": 0.2772,
      "step": 34950
    },
    {
      "epoch": 34.96,
      "learning_rate": 0.00011613731673050027,
      "loss": 0.2774,
      "step": 34960
    },
    {
      "epoch": 34.97,
      "learning_rate": 0.00011611657619618766,
      "loss": 0.2434,
      "step": 34970
    },
    {
      "epoch": 34.98,
      "learning_rate": 0.00011609583116542812,
      "loss": 0.3032,
      "step": 34980
    },
    {
      "epoch": 34.99,
      "learning_rate": 0.00011607508164049023,
      "loss": 0.3032,
      "step": 34990
    },
    {
      "epoch": 35.0,
      "learning_rate": 0.00011605432762364318,
      "loss": 0.2514,
      "step": 35000
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2730955183506012,
      "eval_runtime": 15.3215,
      "eval_samples_per_second": 130.535,
      "eval_steps_per_second": 16.317,
      "step": 35000
    },
    {
      "epoch": 35.01,
      "learning_rate": 0.00011603356911715659,
      "loss": 0.3032,
      "step": 35010
    },
    {
      "epoch": 35.02,
      "learning_rate": 0.00011601280612330057,
      "loss": 0.3102,
      "step": 35020
    },
    {
      "epoch": 35.03,
      "learning_rate": 0.00011599203864434574,
      "loss": 0.3485,
      "step": 35030
    },
    {
      "epoch": 35.04,
      "learning_rate": 0.00011597126668256319,
      "loss": 0.2157,
      "step": 35040
    },
    {
      "epoch": 35.05,
      "learning_rate": 0.00011595049024022453,
      "loss": 0.3396,
      "step": 35050
    },
    {
      "epoch": 35.06,
      "learning_rate": 0.00011592970931960183,
      "loss": 0.1984,
      "step": 35060
    },
    {
      "epoch": 35.07,
      "learning_rate": 0.00011590892392296762,
      "loss": 0.2459,
      "step": 35070
    },
    {
      "epoch": 35.08,
      "learning_rate": 0.00011588813405259503,
      "loss": 0.3324,
      "step": 35080
    },
    {
      "epoch": 35.09,
      "learning_rate": 0.00011586733971075755,
      "loss": 0.2773,
      "step": 35090
    },
    {
      "epoch": 35.1,
      "learning_rate": 0.00011584654089972924,
      "loss": 0.2856,
      "step": 35100
    },
    {
      "epoch": 35.11,
      "learning_rate": 0.00011582573762178464,
      "loss": 0.3064,
      "step": 35110
    },
    {
      "epoch": 35.12,
      "learning_rate": 0.00011580492987919877,
      "loss": 0.3199,
      "step": 35120
    },
    {
      "epoch": 35.13,
      "learning_rate": 0.00011578411767424708,
      "loss": 0.2781,
      "step": 35130
    },
    {
      "epoch": 35.14,
      "learning_rate": 0.00011576330100920565,
      "loss": 0.2771,
      "step": 35140
    },
    {
      "epoch": 35.15,
      "learning_rate": 0.00011574247988635088,
      "loss": 0.3909,
      "step": 35150
    },
    {
      "epoch": 35.16,
      "learning_rate": 0.00011572165430795975,
      "loss": 0.2836,
      "step": 35160
    },
    {
      "epoch": 35.17,
      "learning_rate": 0.00011570082427630974,
      "loss": 0.2801,
      "step": 35170
    },
    {
      "epoch": 35.18,
      "learning_rate": 0.00011567998979367878,
      "loss": 0.3396,
      "step": 35180
    },
    {
      "epoch": 35.19,
      "learning_rate": 0.0001156591508623453,
      "loss": 0.2432,
      "step": 35190
    },
    {
      "epoch": 35.2,
      "learning_rate": 0.00011563830748458823,
      "loss": 0.2688,
      "step": 35200
    },
    {
      "epoch": 35.21,
      "learning_rate": 0.00011561745966268693,
      "loss": 0.241,
      "step": 35210
    },
    {
      "epoch": 35.22,
      "learning_rate": 0.00011559660739892132,
      "loss": 0.2446,
      "step": 35220
    },
    {
      "epoch": 35.23,
      "learning_rate": 0.00011557575069557174,
      "loss": 0.2964,
      "step": 35230
    },
    {
      "epoch": 35.24,
      "learning_rate": 0.00011555488955491909,
      "loss": 0.3139,
      "step": 35240
    },
    {
      "epoch": 35.25,
      "learning_rate": 0.00011553402397924469,
      "loss": 0.3094,
      "step": 35250
    },
    {
      "epoch": 35.26,
      "learning_rate": 0.00011551315397083037,
      "loss": 0.276,
      "step": 35260
    },
    {
      "epoch": 35.27,
      "learning_rate": 0.00011549227953195842,
      "loss": 0.2572,
      "step": 35270
    },
    {
      "epoch": 35.28,
      "learning_rate": 0.00011547140066491168,
      "loss": 0.3177,
      "step": 35280
    },
    {
      "epoch": 35.29,
      "learning_rate": 0.00011545051737197339,
      "loss": 0.2191,
      "step": 35290
    },
    {
      "epoch": 35.3,
      "learning_rate": 0.00011542962965542738,
      "loss": 0.294,
      "step": 35300
    },
    {
      "epoch": 35.31,
      "learning_rate": 0.00011540873751755783,
      "loss": 0.2316,
      "step": 35310
    },
    {
      "epoch": 35.32,
      "learning_rate": 0.00011538784096064949,
      "loss": 0.3118,
      "step": 35320
    },
    {
      "epoch": 35.33,
      "learning_rate": 0.0001153669399869876,
      "loss": 0.2917,
      "step": 35330
    },
    {
      "epoch": 35.34,
      "learning_rate": 0.00011534603459885783,
      "loss": 0.2643,
      "step": 35340
    },
    {
      "epoch": 35.35,
      "learning_rate": 0.00011532512479854637,
      "loss": 0.2904,
      "step": 35350
    },
    {
      "epoch": 35.36,
      "learning_rate": 0.00011530421058833992,
      "loss": 0.2995,
      "step": 35360
    },
    {
      "epoch": 35.37,
      "learning_rate": 0.0001152832919705256,
      "loss": 0.2867,
      "step": 35370
    },
    {
      "epoch": 35.38,
      "learning_rate": 0.000115262368947391,
      "loss": 0.2321,
      "step": 35380
    },
    {
      "epoch": 35.39,
      "learning_rate": 0.00011524144152122428,
      "loss": 0.2974,
      "step": 35390
    },
    {
      "epoch": 35.4,
      "learning_rate": 0.00011522050969431402,
      "loss": 0.2742,
      "step": 35400
    },
    {
      "epoch": 35.41,
      "learning_rate": 0.0001151995734689493,
      "loss": 0.2769,
      "step": 35410
    },
    {
      "epoch": 35.42,
      "learning_rate": 0.00011517863284741965,
      "loss": 0.2464,
      "step": 35420
    },
    {
      "epoch": 35.43,
      "learning_rate": 0.00011515768783201512,
      "loss": 0.2322,
      "step": 35430
    },
    {
      "epoch": 35.44,
      "learning_rate": 0.00011513673842502623,
      "loss": 0.2518,
      "step": 35440
    },
    {
      "epoch": 35.45,
      "learning_rate": 0.00011511578462874396,
      "loss": 0.2698,
      "step": 35450
    },
    {
      "epoch": 35.46,
      "learning_rate": 0.0001150948264454598,
      "loss": 0.2425,
      "step": 35460
    },
    {
      "epoch": 35.47,
      "learning_rate": 0.00011507386387746572,
      "loss": 0.2998,
      "step": 35470
    },
    {
      "epoch": 35.48,
      "learning_rate": 0.00011505289692705412,
      "loss": 0.2435,
      "step": 35480
    },
    {
      "epoch": 35.49,
      "learning_rate": 0.00011503192559651793,
      "loss": 0.2467,
      "step": 35490
    },
    {
      "epoch": 35.5,
      "learning_rate": 0.00011501094988815054,
      "loss": 0.2856,
      "step": 35500
    },
    {
      "epoch": 35.51,
      "learning_rate": 0.00011498996980424584,
      "loss": 0.2685,
      "step": 35510
    },
    {
      "epoch": 35.52,
      "learning_rate": 0.00011496898534709815,
      "loss": 0.3086,
      "step": 35520
    },
    {
      "epoch": 35.53,
      "learning_rate": 0.00011494799651900232,
      "loss": 0.2654,
      "step": 35530
    },
    {
      "epoch": 35.54,
      "learning_rate": 0.00011492700332225364,
      "loss": 0.3302,
      "step": 35540
    },
    {
      "epoch": 35.55,
      "learning_rate": 0.00011490600575914793,
      "loss": 0.2787,
      "step": 35550
    },
    {
      "epoch": 35.56,
      "learning_rate": 0.00011488500383198143,
      "loss": 0.2242,
      "step": 35560
    },
    {
      "epoch": 35.57,
      "learning_rate": 0.00011486399754305086,
      "loss": 0.2934,
      "step": 35570
    },
    {
      "epoch": 35.58,
      "learning_rate": 0.00011484298689465348,
      "loss": 0.278,
      "step": 35580
    },
    {
      "epoch": 35.59,
      "learning_rate": 0.00011482197188908691,
      "loss": 0.3319,
      "step": 35590
    },
    {
      "epoch": 35.6,
      "learning_rate": 0.0001148009525286494,
      "loss": 0.2784,
      "step": 35600
    },
    {
      "epoch": 35.61,
      "learning_rate": 0.00011477992881563956,
      "loss": 0.2161,
      "step": 35610
    },
    {
      "epoch": 35.62,
      "learning_rate": 0.0001147589007523565,
      "loss": 0.3075,
      "step": 35620
    },
    {
      "epoch": 35.63,
      "learning_rate": 0.00011473786834109985,
      "loss": 0.2421,
      "step": 35630
    },
    {
      "epoch": 35.64,
      "learning_rate": 0.00011471683158416964,
      "loss": 0.2789,
      "step": 35640
    },
    {
      "epoch": 35.65,
      "learning_rate": 0.00011469789478928298,
      "loss": 0.3061,
      "step": 35650
    },
    {
      "epoch": 35.66,
      "learning_rate": 0.00011467684978191146,
      "loss": 0.2575,
      "step": 35660
    },
    {
      "epoch": 35.67,
      "learning_rate": 0.00011465580043553932,
      "loss": 0.2539,
      "step": 35670
    },
    {
      "epoch": 35.68,
      "learning_rate": 0.00011463474675246844,
      "loss": 0.2878,
      "step": 35680
    },
    {
      "epoch": 35.69,
      "learning_rate": 0.00011461368873500126,
      "loss": 0.2874,
      "step": 35690
    },
    {
      "epoch": 35.7,
      "learning_rate": 0.00011459262638544062,
      "loss": 0.2837,
      "step": 35700
    },
    {
      "epoch": 35.71,
      "learning_rate": 0.0001145715597060899,
      "loss": 0.2594,
      "step": 35710
    },
    {
      "epoch": 35.72,
      "learning_rate": 0.00011455048869925292,
      "loss": 0.3013,
      "step": 35720
    },
    {
      "epoch": 35.73,
      "learning_rate": 0.00011452941336723393,
      "loss": 0.2962,
      "step": 35730
    },
    {
      "epoch": 35.74,
      "learning_rate": 0.00011450833371233773,
      "loss": 0.3369,
      "step": 35740
    },
    {
      "epoch": 35.75,
      "learning_rate": 0.00011448724973686957,
      "loss": 0.2532,
      "step": 35750
    },
    {
      "epoch": 35.76,
      "learning_rate": 0.00011446616144313514,
      "loss": 0.268,
      "step": 35760
    },
    {
      "epoch": 35.77,
      "learning_rate": 0.00011444506883344062,
      "loss": 0.304,
      "step": 35770
    },
    {
      "epoch": 35.78,
      "learning_rate": 0.0001144239719100927,
      "loss": 0.2995,
      "step": 35780
    },
    {
      "epoch": 35.79,
      "learning_rate": 0.00011440287067539847,
      "loss": 0.2291,
      "step": 35790
    },
    {
      "epoch": 35.8,
      "learning_rate": 0.00011438176513166555,
      "loss": 0.3319,
      "step": 35800
    },
    {
      "epoch": 35.81,
      "learning_rate": 0.00011436065528120199,
      "loss": 0.3058,
      "step": 35810
    },
    {
      "epoch": 35.82,
      "learning_rate": 0.00011433954112631637,
      "loss": 0.2868,
      "step": 35820
    },
    {
      "epoch": 35.83,
      "learning_rate": 0.00011431842266931768,
      "loss": 0.2958,
      "step": 35830
    },
    {
      "epoch": 35.84,
      "learning_rate": 0.00011429729991251536,
      "loss": 0.2855,
      "step": 35840
    },
    {
      "epoch": 35.85,
      "learning_rate": 0.00011427617285821944,
      "loss": 0.2942,
      "step": 35850
    },
    {
      "epoch": 35.86,
      "learning_rate": 0.0001142550415087403,
      "loss": 0.2597,
      "step": 35860
    },
    {
      "epoch": 35.87,
      "learning_rate": 0.00011423390586638885,
      "loss": 0.3514,
      "step": 35870
    },
    {
      "epoch": 35.88,
      "learning_rate": 0.00011421276593347643,
      "loss": 0.3152,
      "step": 35880
    },
    {
      "epoch": 35.89,
      "learning_rate": 0.0001141916217123149,
      "loss": 0.2424,
      "step": 35890
    },
    {
      "epoch": 35.9,
      "learning_rate": 0.00011417047320521652,
      "loss": 0.3734,
      "step": 35900
    },
    {
      "epoch": 35.91,
      "learning_rate": 0.00011414932041449408,
      "loss": 0.2516,
      "step": 35910
    },
    {
      "epoch": 35.92,
      "learning_rate": 0.00011412816334246084,
      "loss": 0.2416,
      "step": 35920
    },
    {
      "epoch": 35.93,
      "learning_rate": 0.00011410700199143047,
      "loss": 0.2705,
      "step": 35930
    },
    {
      "epoch": 35.94,
      "learning_rate": 0.00011408583636371716,
      "loss": 0.2338,
      "step": 35940
    },
    {
      "epoch": 35.95,
      "learning_rate": 0.00011406466646163555,
      "loss": 0.269,
      "step": 35950
    },
    {
      "epoch": 35.96,
      "learning_rate": 0.00011404349228750075,
      "loss": 0.2593,
      "step": 35960
    },
    {
      "epoch": 35.97,
      "learning_rate": 0.00011402231384362836,
      "loss": 0.2729,
      "step": 35970
    },
    {
      "epoch": 35.98,
      "learning_rate": 0.00011400113113233436,
      "loss": 0.2271,
      "step": 35980
    },
    {
      "epoch": 35.99,
      "learning_rate": 0.0001139799441559353,
      "loss": 0.2608,
      "step": 35990
    },
    {
      "epoch": 36.0,
      "learning_rate": 0.00011395875291674816,
      "loss": 0.2484,
      "step": 36000
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.27368950843811035,
      "eval_runtime": 14.8453,
      "eval_samples_per_second": 134.723,
      "eval_steps_per_second": 16.84,
      "step": 36000
    },
    {
      "epoch": 36.01,
      "learning_rate": 0.00011393755741709038,
      "loss": 0.2283,
      "step": 36010
    },
    {
      "epoch": 36.02,
      "learning_rate": 0.00011391635765927986,
      "loss": 0.272,
      "step": 36020
    },
    {
      "epoch": 36.03,
      "learning_rate": 0.00011389515364563499,
      "loss": 0.3219,
      "step": 36030
    },
    {
      "epoch": 36.04,
      "learning_rate": 0.00011387394537847456,
      "loss": 0.3502,
      "step": 36040
    },
    {
      "epoch": 36.05,
      "learning_rate": 0.00011385273286011795,
      "loss": 0.2862,
      "step": 36050
    },
    {
      "epoch": 36.06,
      "learning_rate": 0.00011383151609288486,
      "loss": 0.2605,
      "step": 36060
    },
    {
      "epoch": 36.07,
      "learning_rate": 0.00011381029507909557,
      "loss": 0.2788,
      "step": 36070
    },
    {
      "epoch": 36.08,
      "learning_rate": 0.00011378906982107076,
      "loss": 0.2766,
      "step": 36080
    },
    {
      "epoch": 36.09,
      "learning_rate": 0.00011376784032113158,
      "loss": 0.2431,
      "step": 36090
    },
    {
      "epoch": 36.1,
      "learning_rate": 0.00011374660658159968,
      "loss": 0.3021,
      "step": 36100
    },
    {
      "epoch": 36.11,
      "learning_rate": 0.00011372536860479714,
      "loss": 0.2627,
      "step": 36110
    },
    {
      "epoch": 36.12,
      "learning_rate": 0.00011370412639304648,
      "loss": 0.2941,
      "step": 36120
    },
    {
      "epoch": 36.13,
      "learning_rate": 0.00011368287994867079,
      "loss": 0.2514,
      "step": 36130
    },
    {
      "epoch": 36.14,
      "learning_rate": 0.00011366162927399348,
      "loss": 0.3131,
      "step": 36140
    },
    {
      "epoch": 36.15,
      "learning_rate": 0.00011364037437133853,
      "loss": 0.3125,
      "step": 36150
    },
    {
      "epoch": 36.16,
      "learning_rate": 0.00011361911524303034,
      "loss": 0.2855,
      "step": 36160
    },
    {
      "epoch": 36.17,
      "learning_rate": 0.00011359785189139378,
      "loss": 0.2166,
      "step": 36170
    },
    {
      "epoch": 36.18,
      "learning_rate": 0.00011357658431875416,
      "loss": 0.2418,
      "step": 36180
    },
    {
      "epoch": 36.19,
      "learning_rate": 0.00011355531252743726,
      "loss": 0.2634,
      "step": 36190
    },
    {
      "epoch": 36.2,
      "learning_rate": 0.00011353403651976936,
      "loss": 0.3209,
      "step": 36200
    },
    {
      "epoch": 36.21,
      "learning_rate": 0.00011351275629807715,
      "loss": 0.2867,
      "step": 36210
    },
    {
      "epoch": 36.22,
      "learning_rate": 0.00011349147186468784,
      "loss": 0.252,
      "step": 36220
    },
    {
      "epoch": 36.23,
      "learning_rate": 0.00011347018322192901,
      "loss": 0.2261,
      "step": 36230
    },
    {
      "epoch": 36.24,
      "learning_rate": 0.0001134488903721288,
      "loss": 0.3293,
      "step": 36240
    },
    {
      "epoch": 36.25,
      "learning_rate": 0.00011342759331761574,
      "loss": 0.2779,
      "step": 36250
    },
    {
      "epoch": 36.26,
      "learning_rate": 0.00011340629206071884,
      "loss": 0.3215,
      "step": 36260
    },
    {
      "epoch": 36.27,
      "learning_rate": 0.0001133849866037676,
      "loss": 0.2826,
      "step": 36270
    },
    {
      "epoch": 36.28,
      "learning_rate": 0.00011336367694909193,
      "loss": 0.2805,
      "step": 36280
    },
    {
      "epoch": 36.29,
      "learning_rate": 0.00011334236309902223,
      "loss": 0.3256,
      "step": 36290
    },
    {
      "epoch": 36.3,
      "learning_rate": 0.00011332104505588935,
      "loss": 0.2941,
      "step": 36300
    },
    {
      "epoch": 36.31,
      "learning_rate": 0.00011329972282202459,
      "loss": 0.2955,
      "step": 36310
    },
    {
      "epoch": 36.32,
      "learning_rate": 0.00011327839639975975,
      "loss": 0.2782,
      "step": 36320
    },
    {
      "epoch": 36.33,
      "learning_rate": 0.000113257065791427,
      "loss": 0.3032,
      "step": 36330
    },
    {
      "epoch": 36.34,
      "learning_rate": 0.00011323573099935905,
      "loss": 0.2173,
      "step": 36340
    },
    {
      "epoch": 36.35,
      "learning_rate": 0.00011321439202588905,
      "loss": 0.2688,
      "step": 36350
    },
    {
      "epoch": 36.36,
      "learning_rate": 0.00011319304887335062,
      "loss": 0.2868,
      "step": 36360
    },
    {
      "epoch": 36.37,
      "learning_rate": 0.00011317170154407777,
      "loss": 0.1993,
      "step": 36370
    },
    {
      "epoch": 36.38,
      "learning_rate": 0.00011315035004040501,
      "loss": 0.2934,
      "step": 36380
    },
    {
      "epoch": 36.39,
      "learning_rate": 0.00011312899436466737,
      "loss": 0.3048,
      "step": 36390
    },
    {
      "epoch": 36.4,
      "learning_rate": 0.0001131076345192002,
      "loss": 0.2736,
      "step": 36400
    },
    {
      "epoch": 36.41,
      "learning_rate": 0.00011308627050633942,
      "loss": 0.2351,
      "step": 36410
    },
    {
      "epoch": 36.42,
      "learning_rate": 0.00011306490232842137,
      "loss": 0.2672,
      "step": 36420
    },
    {
      "epoch": 36.43,
      "learning_rate": 0.00011304352998778281,
      "loss": 0.3222,
      "step": 36430
    },
    {
      "epoch": 36.44,
      "learning_rate": 0.00011302215348676101,
      "loss": 0.2577,
      "step": 36440
    },
    {
      "epoch": 36.45,
      "learning_rate": 0.0001130007728276937,
      "loss": 0.2573,
      "step": 36450
    },
    {
      "epoch": 36.46,
      "learning_rate": 0.00011297938801291899,
      "loss": 0.2618,
      "step": 36460
    },
    {
      "epoch": 36.47,
      "learning_rate": 0.00011295799904477549,
      "loss": 0.3101,
      "step": 36470
    },
    {
      "epoch": 36.48,
      "learning_rate": 0.00011293660592560231,
      "loss": 0.2644,
      "step": 36480
    },
    {
      "epoch": 36.49,
      "learning_rate": 0.0001129152086577389,
      "loss": 0.2863,
      "step": 36490
    },
    {
      "epoch": 36.5,
      "learning_rate": 0.00011289380724352533,
      "loss": 0.294,
      "step": 36500
    },
    {
      "epoch": 36.51,
      "learning_rate": 0.00011287240168530194,
      "loss": 0.2611,
      "step": 36510
    },
    {
      "epoch": 36.52,
      "learning_rate": 0.00011285099198540963,
      "loss": 0.3289,
      "step": 36520
    },
    {
      "epoch": 36.53,
      "learning_rate": 0.00011282957814618979,
      "loss": 0.2378,
      "step": 36530
    },
    {
      "epoch": 36.54,
      "learning_rate": 0.00011280816016998412,
      "loss": 0.2579,
      "step": 36540
    },
    {
      "epoch": 36.55,
      "learning_rate": 0.00011278673805913493,
      "loss": 0.237,
      "step": 36550
    },
    {
      "epoch": 36.56,
      "learning_rate": 0.00011276531181598487,
      "loss": 0.2338,
      "step": 36560
    },
    {
      "epoch": 36.57,
      "learning_rate": 0.00011274388144287705,
      "loss": 0.2688,
      "step": 36570
    },
    {
      "epoch": 36.58,
      "learning_rate": 0.00011272244694215513,
      "loss": 0.2952,
      "step": 36580
    },
    {
      "epoch": 36.59,
      "learning_rate": 0.00011270100831616314,
      "loss": 0.3033,
      "step": 36590
    },
    {
      "epoch": 36.6,
      "learning_rate": 0.00011267956556724555,
      "loss": 0.242,
      "step": 36600
    },
    {
      "epoch": 36.61,
      "learning_rate": 0.00011265811869774733,
      "loss": 0.2955,
      "step": 36610
    },
    {
      "epoch": 36.62,
      "learning_rate": 0.00011263666771001386,
      "loss": 0.2711,
      "step": 36620
    },
    {
      "epoch": 36.63,
      "learning_rate": 0.00011261521260639098,
      "loss": 0.3115,
      "step": 36630
    },
    {
      "epoch": 36.64,
      "learning_rate": 0.00011259375338922503,
      "loss": 0.2665,
      "step": 36640
    },
    {
      "epoch": 36.65,
      "learning_rate": 0.00011257229006086272,
      "loss": 0.2627,
      "step": 36650
    },
    {
      "epoch": 36.66,
      "learning_rate": 0.00011255082262365124,
      "loss": 0.3128,
      "step": 36660
    },
    {
      "epoch": 36.67,
      "learning_rate": 0.00011252935107993828,
      "loss": 0.225,
      "step": 36670
    },
    {
      "epoch": 36.68,
      "learning_rate": 0.0001125078754320719,
      "loss": 0.2594,
      "step": 36680
    },
    {
      "epoch": 36.69,
      "learning_rate": 0.00011248639568240067,
      "loss": 0.2528,
      "step": 36690
    },
    {
      "epoch": 36.7,
      "learning_rate": 0.00011246491183327355,
      "loss": 0.2943,
      "step": 36700
    },
    {
      "epoch": 36.71,
      "learning_rate": 0.00011244342388704,
      "loss": 0.2646,
      "step": 36710
    },
    {
      "epoch": 36.72,
      "learning_rate": 0.00011242193184604991,
      "loss": 0.287,
      "step": 36720
    },
    {
      "epoch": 36.73,
      "learning_rate": 0.00011240043571265363,
      "loss": 0.3066,
      "step": 36730
    },
    {
      "epoch": 36.74,
      "learning_rate": 0.00011237893548920189,
      "loss": 0.2796,
      "step": 36740
    },
    {
      "epoch": 36.75,
      "learning_rate": 0.00011235743117804602,
      "loss": 0.329,
      "step": 36750
    },
    {
      "epoch": 36.76,
      "learning_rate": 0.00011233592278153758,
      "loss": 0.2094,
      "step": 36760
    },
    {
      "epoch": 36.77,
      "learning_rate": 0.00011231441030202883,
      "loss": 0.2947,
      "step": 36770
    },
    {
      "epoch": 36.78,
      "learning_rate": 0.00011229289374187223,
      "loss": 0.3216,
      "step": 36780
    },
    {
      "epoch": 36.79,
      "learning_rate": 0.00011227137310342084,
      "loss": 0.1903,
      "step": 36790
    },
    {
      "epoch": 36.8,
      "learning_rate": 0.00011224984838902813,
      "loss": 0.2864,
      "step": 36800
    },
    {
      "epoch": 36.81,
      "learning_rate": 0.000112228319601048,
      "loss": 0.33,
      "step": 36810
    },
    {
      "epoch": 36.82,
      "learning_rate": 0.00011220678674183481,
      "loss": 0.2595,
      "step": 36820
    },
    {
      "epoch": 36.83,
      "learning_rate": 0.00011218524981374337,
      "loss": 0.3333,
      "step": 36830
    },
    {
      "epoch": 36.84,
      "learning_rate": 0.00011216370881912892,
      "loss": 0.3313,
      "step": 36840
    },
    {
      "epoch": 36.85,
      "learning_rate": 0.00011214216376034715,
      "loss": 0.2513,
      "step": 36850
    },
    {
      "epoch": 36.86,
      "learning_rate": 0.00011212061463975418,
      "loss": 0.2889,
      "step": 36860
    },
    {
      "epoch": 36.87,
      "learning_rate": 0.0001120990614597066,
      "loss": 0.2961,
      "step": 36870
    },
    {
      "epoch": 36.88,
      "learning_rate": 0.00011207750422256145,
      "loss": 0.3168,
      "step": 36880
    },
    {
      "epoch": 36.89,
      "learning_rate": 0.00011205594293067618,
      "loss": 0.3154,
      "step": 36890
    },
    {
      "epoch": 36.9,
      "learning_rate": 0.0001120343775864087,
      "loss": 0.2542,
      "step": 36900
    },
    {
      "epoch": 36.91,
      "learning_rate": 0.00011201280819211737,
      "loss": 0.3116,
      "step": 36910
    },
    {
      "epoch": 36.92,
      "learning_rate": 0.00011199123475016098,
      "loss": 0.2948,
      "step": 36920
    },
    {
      "epoch": 36.93,
      "learning_rate": 0.00011196965726289878,
      "loss": 0.2858,
      "step": 36930
    },
    {
      "epoch": 36.94,
      "learning_rate": 0.00011194807573269044,
      "loss": 0.2862,
      "step": 36940
    },
    {
      "epoch": 36.95,
      "learning_rate": 0.00011192649016189608,
      "loss": 0.3032,
      "step": 36950
    },
    {
      "epoch": 36.96,
      "learning_rate": 0.00011190490055287628,
      "loss": 0.2517,
      "step": 36960
    },
    {
      "epoch": 36.97,
      "learning_rate": 0.00011188330690799205,
      "loss": 0.3201,
      "step": 36970
    },
    {
      "epoch": 36.98,
      "learning_rate": 0.00011186170922960483,
      "loss": 0.2695,
      "step": 36980
    },
    {
      "epoch": 36.99,
      "learning_rate": 0.00011184010752007649,
      "loss": 0.2169,
      "step": 36990
    },
    {
      "epoch": 37.0,
      "learning_rate": 0.00011181850178176941,
      "loss": 0.2601,
      "step": 37000
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27335718274116516,
      "eval_runtime": 15.12,
      "eval_samples_per_second": 132.275,
      "eval_steps_per_second": 16.534,
      "step": 37000
    },
    {
      "epoch": 37.01,
      "learning_rate": 0.0001117968920170463,
      "loss": 0.2691,
      "step": 37010
    },
    {
      "epoch": 37.02,
      "learning_rate": 0.00011177527822827043,
      "loss": 0.3393,
      "step": 37020
    },
    {
      "epoch": 37.03,
      "learning_rate": 0.0001117536604178054,
      "loss": 0.3297,
      "step": 37030
    },
    {
      "epoch": 37.04,
      "learning_rate": 0.00011173203858801533,
      "loss": 0.2947,
      "step": 37040
    },
    {
      "epoch": 37.05,
      "learning_rate": 0.00011171041274126476,
      "loss": 0.2952,
      "step": 37050
    },
    {
      "epoch": 37.06,
      "learning_rate": 0.00011168878287991864,
      "loss": 0.2952,
      "step": 37060
    },
    {
      "epoch": 37.07,
      "learning_rate": 0.0001116671490063424,
      "loss": 0.2425,
      "step": 37070
    },
    {
      "epoch": 37.08,
      "learning_rate": 0.00011164551112290183,
      "loss": 0.2974,
      "step": 37080
    },
    {
      "epoch": 37.09,
      "learning_rate": 0.0001116238692319633,
      "loss": 0.329,
      "step": 37090
    },
    {
      "epoch": 37.1,
      "learning_rate": 0.00011160222333589349,
      "loss": 0.2598,
      "step": 37100
    },
    {
      "epoch": 37.11,
      "learning_rate": 0.00011158057343705953,
      "loss": 0.293,
      "step": 37110
    },
    {
      "epoch": 37.12,
      "learning_rate": 0.00011155891953782909,
      "loss": 0.3518,
      "step": 37120
    },
    {
      "epoch": 37.13,
      "learning_rate": 0.00011153726164057017,
      "loss": 0.2707,
      "step": 37130
    },
    {
      "epoch": 37.14,
      "learning_rate": 0.00011151559974765125,
      "loss": 0.3038,
      "step": 37140
    },
    {
      "epoch": 37.15,
      "learning_rate": 0.00011149393386144123,
      "loss": 0.2863,
      "step": 37150
    },
    {
      "epoch": 37.16,
      "learning_rate": 0.0001114722639843095,
      "loss": 0.2864,
      "step": 37160
    },
    {
      "epoch": 37.17,
      "learning_rate": 0.00011145059011862577,
      "loss": 0.2803,
      "step": 37170
    },
    {
      "epoch": 37.18,
      "learning_rate": 0.00011142891226676035,
      "loss": 0.2777,
      "step": 37180
    },
    {
      "epoch": 37.19,
      "learning_rate": 0.00011140723043108384,
      "loss": 0.2946,
      "step": 37190
    },
    {
      "epoch": 37.2,
      "learning_rate": 0.00011138554461396733,
      "loss": 0.2684,
      "step": 37200
    },
    {
      "epoch": 37.21,
      "learning_rate": 0.00011136385481778239,
      "loss": 0.2774,
      "step": 37210
    },
    {
      "epoch": 37.22,
      "learning_rate": 0.00011134216104490094,
      "loss": 0.3033,
      "step": 37220
    },
    {
      "epoch": 37.23,
      "learning_rate": 0.00011132046329769541,
      "loss": 0.3108,
      "step": 37230
    },
    {
      "epoch": 37.24,
      "learning_rate": 0.00011129876157853861,
      "loss": 0.2065,
      "step": 37240
    },
    {
      "epoch": 37.25,
      "learning_rate": 0.00011127705588980382,
      "loss": 0.2864,
      "step": 37250
    },
    {
      "epoch": 37.26,
      "learning_rate": 0.00011125534623386477,
      "loss": 0.29,
      "step": 37260
    },
    {
      "epoch": 37.27,
      "learning_rate": 0.00011123363261309553,
      "loss": 0.3077,
      "step": 37270
    },
    {
      "epoch": 37.28,
      "learning_rate": 0.00011121191502987071,
      "loss": 0.3184,
      "step": 37280
    },
    {
      "epoch": 37.29,
      "learning_rate": 0.00011119019348656532,
      "loss": 0.2457,
      "step": 37290
    },
    {
      "epoch": 37.3,
      "learning_rate": 0.00011116846798555477,
      "loss": 0.3623,
      "step": 37300
    },
    {
      "epoch": 37.31,
      "learning_rate": 0.00011114673852921495,
      "loss": 0.3205,
      "step": 37310
    },
    {
      "epoch": 37.32,
      "learning_rate": 0.00011112500511992215,
      "loss": 0.3189,
      "step": 37320
    },
    {
      "epoch": 37.33,
      "learning_rate": 0.00011110326776005307,
      "loss": 0.2349,
      "step": 37330
    },
    {
      "epoch": 37.34,
      "learning_rate": 0.00011108152645198495,
      "loss": 0.234,
      "step": 37340
    },
    {
      "epoch": 37.35,
      "learning_rate": 0.00011105978119809534,
      "loss": 0.2722,
      "step": 37350
    },
    {
      "epoch": 37.36,
      "learning_rate": 0.00011103803200076225,
      "loss": 0.3052,
      "step": 37360
    },
    {
      "epoch": 37.37,
      "learning_rate": 0.00011101627886236417,
      "loss": 0.2439,
      "step": 37370
    },
    {
      "epoch": 37.38,
      "learning_rate": 0.00011099452178528,
      "loss": 0.2499,
      "step": 37380
    },
    {
      "epoch": 37.39,
      "learning_rate": 0.00011097276077188904,
      "loss": 0.3026,
      "step": 37390
    },
    {
      "epoch": 37.4,
      "learning_rate": 0.00011095099582457104,
      "loss": 0.2672,
      "step": 37400
    },
    {
      "epoch": 37.41,
      "learning_rate": 0.00011092922694570619,
      "loss": 0.1486,
      "step": 37410
    },
    {
      "epoch": 37.42,
      "learning_rate": 0.0001109074541376751,
      "loss": 0.2611,
      "step": 37420
    },
    {
      "epoch": 37.43,
      "learning_rate": 0.00011088567740285879,
      "loss": 0.2846,
      "step": 37430
    },
    {
      "epoch": 37.44,
      "learning_rate": 0.00011086389674363879,
      "loss": 0.2342,
      "step": 37440
    },
    {
      "epoch": 37.45,
      "learning_rate": 0.00011084211216239692,
      "loss": 0.3006,
      "step": 37450
    },
    {
      "epoch": 37.46,
      "learning_rate": 0.0001108203236615156,
      "loss": 0.2457,
      "step": 37460
    },
    {
      "epoch": 37.47,
      "learning_rate": 0.00011079853124337749,
      "loss": 0.2871,
      "step": 37470
    },
    {
      "epoch": 37.48,
      "learning_rate": 0.00011077673491036585,
      "loss": 0.2967,
      "step": 37480
    },
    {
      "epoch": 37.49,
      "learning_rate": 0.00011075493466486428,
      "loss": 0.269,
      "step": 37490
    },
    {
      "epoch": 37.5,
      "learning_rate": 0.0001107331305092568,
      "loss": 0.2845,
      "step": 37500
    },
    {
      "epoch": 37.51,
      "learning_rate": 0.0001107113224459279,
      "loss": 0.1898,
      "step": 37510
    },
    {
      "epoch": 37.52,
      "learning_rate": 0.00011068951047726244,
      "loss": 0.2298,
      "step": 37520
    },
    {
      "epoch": 37.53,
      "learning_rate": 0.0001106676946056458,
      "loss": 0.2542,
      "step": 37530
    },
    {
      "epoch": 37.54,
      "learning_rate": 0.00011064587483346371,
      "loss": 0.295,
      "step": 37540
    },
    {
      "epoch": 37.55,
      "learning_rate": 0.00011062405116310235,
      "loss": 0.2876,
      "step": 37550
    },
    {
      "epoch": 37.56,
      "learning_rate": 0.00011060222359694827,
      "loss": 0.3368,
      "step": 37560
    },
    {
      "epoch": 37.57,
      "learning_rate": 0.00011058039213738858,
      "loss": 0.2852,
      "step": 37570
    },
    {
      "epoch": 37.58,
      "learning_rate": 0.0001105585567868107,
      "loss": 0.2286,
      "step": 37580
    },
    {
      "epoch": 37.59,
      "learning_rate": 0.00011053671754760249,
      "loss": 0.3146,
      "step": 37590
    },
    {
      "epoch": 37.6,
      "learning_rate": 0.00011051487442215229,
      "loss": 0.2771,
      "step": 37600
    },
    {
      "epoch": 37.61,
      "learning_rate": 0.00011049302741284882,
      "loss": 0.2432,
      "step": 37610
    },
    {
      "epoch": 37.62,
      "learning_rate": 0.00011047117652208122,
      "loss": 0.2422,
      "step": 37620
    },
    {
      "epoch": 37.63,
      "learning_rate": 0.0001104493217522391,
      "loss": 0.3459,
      "step": 37630
    },
    {
      "epoch": 37.64,
      "learning_rate": 0.00011042746310571246,
      "loss": 0.2838,
      "step": 37640
    },
    {
      "epoch": 37.65,
      "learning_rate": 0.00011040778701124887,
      "loss": 0.2472,
      "step": 37650
    },
    {
      "epoch": 37.66,
      "learning_rate": 0.00011038592100560759,
      "loss": 0.2965,
      "step": 37660
    },
    {
      "epoch": 37.67,
      "learning_rate": 0.0001103640511302152,
      "loss": 0.2677,
      "step": 37670
    },
    {
      "epoch": 37.68,
      "learning_rate": 0.00011034217738746334,
      "loss": 0.2596,
      "step": 37680
    },
    {
      "epoch": 37.69,
      "learning_rate": 0.00011032029977974409,
      "loss": 0.3331,
      "step": 37690
    },
    {
      "epoch": 37.7,
      "learning_rate": 0.00011029841830944998,
      "loss": 0.2618,
      "step": 37700
    },
    {
      "epoch": 37.71,
      "learning_rate": 0.0001102765329789739,
      "loss": 0.2768,
      "step": 37710
    },
    {
      "epoch": 37.72,
      "learning_rate": 0.00011025464379070921,
      "loss": 0.314,
      "step": 37720
    },
    {
      "epoch": 37.73,
      "learning_rate": 0.00011023275074704968,
      "loss": 0.1715,
      "step": 37730
    },
    {
      "epoch": 37.74,
      "learning_rate": 0.0001102108538503895,
      "loss": 0.2404,
      "step": 37740
    },
    {
      "epoch": 37.75,
      "learning_rate": 0.00011018895310312328,
      "loss": 0.2523,
      "step": 37750
    },
    {
      "epoch": 37.76,
      "learning_rate": 0.00011016704850764606,
      "loss": 0.3221,
      "step": 37760
    },
    {
      "epoch": 37.77,
      "learning_rate": 0.0001101451400663533,
      "loss": 0.3375,
      "step": 37770
    },
    {
      "epoch": 37.78,
      "learning_rate": 0.00011012322778164086,
      "loss": 0.2849,
      "step": 37780
    },
    {
      "epoch": 37.79,
      "learning_rate": 0.00011010131165590502,
      "loss": 0.3053,
      "step": 37790
    },
    {
      "epoch": 37.8,
      "learning_rate": 0.0001100793916915425,
      "loss": 0.2722,
      "step": 37800
    },
    {
      "epoch": 37.81,
      "learning_rate": 0.00011005746789095048,
      "loss": 0.3359,
      "step": 37810
    },
    {
      "epoch": 37.82,
      "learning_rate": 0.00011003554025652645,
      "loss": 0.2511,
      "step": 37820
    },
    {
      "epoch": 37.83,
      "learning_rate": 0.00011001360879066842,
      "loss": 0.2823,
      "step": 37830
    },
    {
      "epoch": 37.84,
      "learning_rate": 0.00010999167349577479,
      "loss": 0.2792,
      "step": 37840
    },
    {
      "epoch": 37.85,
      "learning_rate": 0.00010996973437424435,
      "loss": 0.3641,
      "step": 37850
    },
    {
      "epoch": 37.86,
      "learning_rate": 0.00010994779142847633,
      "loss": 0.2345,
      "step": 37860
    },
    {
      "epoch": 37.87,
      "learning_rate": 0.00010992584466087038,
      "loss": 0.2849,
      "step": 37870
    },
    {
      "epoch": 37.88,
      "learning_rate": 0.00010990389407382657,
      "loss": 0.2452,
      "step": 37880
    },
    {
      "epoch": 37.89,
      "learning_rate": 0.00010988193966974539,
      "loss": 0.2747,
      "step": 37890
    },
    {
      "epoch": 37.9,
      "learning_rate": 0.00010985998145102773,
      "loss": 0.2773,
      "step": 37900
    },
    {
      "epoch": 37.91,
      "learning_rate": 0.00010983801942007488,
      "loss": 0.3133,
      "step": 37910
    },
    {
      "epoch": 37.92,
      "learning_rate": 0.00010981605357928864,
      "loss": 0.2596,
      "step": 37920
    },
    {
      "epoch": 37.93,
      "learning_rate": 0.00010979408393107113,
      "loss": 0.2629,
      "step": 37930
    },
    {
      "epoch": 37.94,
      "learning_rate": 0.00010977211047782488,
      "loss": 0.2698,
      "step": 37940
    },
    {
      "epoch": 37.95,
      "learning_rate": 0.00010975013322195293,
      "loss": 0.2215,
      "step": 37950
    },
    {
      "epoch": 37.96,
      "learning_rate": 0.00010972815216585865,
      "loss": 0.2851,
      "step": 37960
    },
    {
      "epoch": 37.97,
      "learning_rate": 0.00010970616731194587,
      "loss": 0.3064,
      "step": 37970
    },
    {
      "epoch": 37.98,
      "learning_rate": 0.0001096841786626188,
      "loss": 0.2088,
      "step": 37980
    },
    {
      "epoch": 37.99,
      "learning_rate": 0.0001096621862202821,
      "loss": 0.2955,
      "step": 37990
    },
    {
      "epoch": 38.0,
      "learning_rate": 0.00010964018998734083,
      "loss": 0.2692,
      "step": 38000
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2730991840362549,
      "eval_runtime": 14.7676,
      "eval_samples_per_second": 135.431,
      "eval_steps_per_second": 16.929,
      "step": 38000
    },
    {
      "epoch": 38.01,
      "learning_rate": 0.00010961818996620046,
      "loss": 0.2425,
      "step": 38010
    },
    {
      "epoch": 38.02,
      "learning_rate": 0.0001095961861592669,
      "loss": 0.2865,
      "step": 38020
    },
    {
      "epoch": 38.03,
      "learning_rate": 0.00010957417856894643,
      "loss": 0.2695,
      "step": 38030
    },
    {
      "epoch": 38.04,
      "learning_rate": 0.00010955216719764575,
      "loss": 0.2169,
      "step": 38040
    },
    {
      "epoch": 38.05,
      "learning_rate": 0.00010953015204777205,
      "loss": 0.2515,
      "step": 38050
    },
    {
      "epoch": 38.06,
      "learning_rate": 0.00010950813312173283,
      "loss": 0.2865,
      "step": 38060
    },
    {
      "epoch": 38.07,
      "learning_rate": 0.00010948611042193603,
      "loss": 0.2515,
      "step": 38070
    },
    {
      "epoch": 38.08,
      "learning_rate": 0.00010946408395079007,
      "loss": 0.2949,
      "step": 38080
    },
    {
      "epoch": 38.09,
      "learning_rate": 0.00010944205371070369,
      "loss": 0.3113,
      "step": 38090
    },
    {
      "epoch": 38.1,
      "learning_rate": 0.00010942001970408609,
      "loss": 0.2972,
      "step": 38100
    },
    {
      "epoch": 38.11,
      "learning_rate": 0.00010939798193334691,
      "loss": 0.2688,
      "step": 38110
    },
    {
      "epoch": 38.12,
      "learning_rate": 0.00010937594040089614,
      "loss": 0.2276,
      "step": 38120
    },
    {
      "epoch": 38.13,
      "learning_rate": 0.00010935389510914419,
      "loss": 0.3157,
      "step": 38130
    },
    {
      "epoch": 38.14,
      "learning_rate": 0.00010933184606050193,
      "loss": 0.2951,
      "step": 38140
    },
    {
      "epoch": 38.15,
      "learning_rate": 0.00010930979325738062,
      "loss": 0.2685,
      "step": 38150
    },
    {
      "epoch": 38.16,
      "learning_rate": 0.0001092877367021919,
      "loss": 0.2431,
      "step": 38160
    },
    {
      "epoch": 38.17,
      "learning_rate": 0.00010926567639734782,
      "loss": 0.3205,
      "step": 38170
    },
    {
      "epoch": 38.18,
      "learning_rate": 0.0001092436123452609,
      "loss": 0.251,
      "step": 38180
    },
    {
      "epoch": 38.19,
      "learning_rate": 0.00010922154454834402,
      "loss": 0.2696,
      "step": 38190
    },
    {
      "epoch": 38.2,
      "learning_rate": 0.00010919947300901047,
      "loss": 0.2517,
      "step": 38200
    },
    {
      "epoch": 38.21,
      "learning_rate": 0.00010917739772967397,
      "loss": 0.3113,
      "step": 38210
    },
    {
      "epoch": 38.22,
      "learning_rate": 0.00010915531871274865,
      "loss": 0.2303,
      "step": 38220
    },
    {
      "epoch": 38.23,
      "learning_rate": 0.00010913323596064902,
      "loss": 0.2272,
      "step": 38230
    },
    {
      "epoch": 38.24,
      "learning_rate": 0.00010911114947579001,
      "loss": 0.2458,
      "step": 38240
    },
    {
      "epoch": 38.25,
      "learning_rate": 0.00010908905926058701,
      "loss": 0.2458,
      "step": 38250
    },
    {
      "epoch": 38.26,
      "learning_rate": 0.00010906696531745573,
      "loss": 0.2676,
      "step": 38260
    },
    {
      "epoch": 38.27,
      "learning_rate": 0.00010904486764881234,
      "loss": 0.1992,
      "step": 38270
    },
    {
      "epoch": 38.28,
      "learning_rate": 0.00010902276625707342,
      "loss": 0.2351,
      "step": 38280
    },
    {
      "epoch": 38.29,
      "learning_rate": 0.00010900066114465593,
      "loss": 0.2687,
      "step": 38290
    },
    {
      "epoch": 38.3,
      "learning_rate": 0.00010897855231397724,
      "loss": 0.2863,
      "step": 38300
    },
    {
      "epoch": 38.31,
      "learning_rate": 0.00010895643976745518,
      "loss": 0.2602,
      "step": 38310
    },
    {
      "epoch": 38.32,
      "learning_rate": 0.00010893432350750789,
      "loss": 0.2776,
      "step": 38320
    },
    {
      "epoch": 38.33,
      "learning_rate": 0.00010891220353655402,
      "loss": 0.2591,
      "step": 38330
    },
    {
      "epoch": 38.34,
      "learning_rate": 0.00010889007985701256,
      "loss": 0.2015,
      "step": 38340
    },
    {
      "epoch": 38.35,
      "learning_rate": 0.0001088679524713029,
      "loss": 0.2662,
      "step": 38350
    },
    {
      "epoch": 38.36,
      "learning_rate": 0.0001088458213818449,
      "loss": 0.2524,
      "step": 38360
    },
    {
      "epoch": 38.37,
      "learning_rate": 0.00010882368659105876,
      "loss": 0.2685,
      "step": 38370
    },
    {
      "epoch": 38.38,
      "learning_rate": 0.00010880154810136509,
      "loss": 0.2664,
      "step": 38380
    },
    {
      "epoch": 38.39,
      "learning_rate": 0.00010877940591518494,
      "loss": 0.2248,
      "step": 38390
    },
    {
      "epoch": 38.4,
      "learning_rate": 0.00010875726003493976,
      "loss": 0.2874,
      "step": 38400
    },
    {
      "epoch": 38.41,
      "learning_rate": 0.00010873511046305138,
      "loss": 0.2443,
      "step": 38410
    },
    {
      "epoch": 38.42,
      "learning_rate": 0.00010871295720194202,
      "loss": 0.2521,
      "step": 38420
    },
    {
      "epoch": 38.43,
      "learning_rate": 0.00010869080025403435,
      "loss": 0.2853,
      "step": 38430
    },
    {
      "epoch": 38.44,
      "learning_rate": 0.00010866863962175141,
      "loss": 0.2936,
      "step": 38440
    },
    {
      "epoch": 38.45,
      "learning_rate": 0.00010864647530751668,
      "loss": 0.3142,
      "step": 38450
    },
    {
      "epoch": 38.46,
      "learning_rate": 0.00010862430731375399,
      "loss": 0.2967,
      "step": 38460
    },
    {
      "epoch": 38.47,
      "learning_rate": 0.0001086021356428876,
      "loss": 0.2769,
      "step": 38470
    },
    {
      "epoch": 38.48,
      "learning_rate": 0.00010857996029734219,
      "loss": 0.2605,
      "step": 38480
    },
    {
      "epoch": 38.49,
      "learning_rate": 0.0001085577812795428,
      "loss": 0.2595,
      "step": 38490
    },
    {
      "epoch": 38.5,
      "learning_rate": 0.00010853559859191492,
      "loss": 0.378,
      "step": 38500
    },
    {
      "epoch": 38.51,
      "learning_rate": 0.00010851341223688438,
      "loss": 0.2517,
      "step": 38510
    },
    {
      "epoch": 38.52,
      "learning_rate": 0.00010849122221687746,
      "loss": 0.3442,
      "step": 38520
    },
    {
      "epoch": 38.53,
      "learning_rate": 0.00010846902853432083,
      "loss": 0.2556,
      "step": 38530
    },
    {
      "epoch": 38.54,
      "learning_rate": 0.0001084468311916416,
      "loss": 0.2383,
      "step": 38540
    },
    {
      "epoch": 38.55,
      "learning_rate": 0.00010842463019126713,
      "loss": 0.2695,
      "step": 38550
    },
    {
      "epoch": 38.56,
      "learning_rate": 0.00010840242553562541,
      "loss": 0.3288,
      "step": 38560
    },
    {
      "epoch": 38.57,
      "learning_rate": 0.00010838021722714463,
      "loss": 0.2707,
      "step": 38570
    },
    {
      "epoch": 38.58,
      "learning_rate": 0.00010835800526825348,
      "loss": 0.2512,
      "step": 38580
    },
    {
      "epoch": 38.59,
      "learning_rate": 0.00010833578966138103,
      "loss": 0.3678,
      "step": 38590
    },
    {
      "epoch": 38.6,
      "learning_rate": 0.00010831357040895675,
      "loss": 0.2907,
      "step": 38600
    },
    {
      "epoch": 38.61,
      "learning_rate": 0.00010829134751341049,
      "loss": 0.2567,
      "step": 38610
    },
    {
      "epoch": 38.62,
      "learning_rate": 0.00010826912097717252,
      "loss": 0.3246,
      "step": 38620
    },
    {
      "epoch": 38.63,
      "learning_rate": 0.00010824689080267351,
      "loss": 0.2888,
      "step": 38630
    },
    {
      "epoch": 38.64,
      "learning_rate": 0.0001082246569923445,
      "loss": 0.3381,
      "step": 38640
    },
    {
      "epoch": 38.65,
      "learning_rate": 0.00010820241954861694,
      "loss": 0.3019,
      "step": 38650
    },
    {
      "epoch": 38.66,
      "learning_rate": 0.0001081801784739227,
      "loss": 0.2939,
      "step": 38660
    },
    {
      "epoch": 38.67,
      "learning_rate": 0.00010815793377069403,
      "loss": 0.2288,
      "step": 38670
    },
    {
      "epoch": 38.68,
      "learning_rate": 0.00010813568544136359,
      "loss": 0.2792,
      "step": 38680
    },
    {
      "epoch": 38.69,
      "learning_rate": 0.0001081134334883644,
      "loss": 0.3493,
      "step": 38690
    },
    {
      "epoch": 38.7,
      "learning_rate": 0.00010809117791412991,
      "loss": 0.2444,
      "step": 38700
    },
    {
      "epoch": 38.71,
      "learning_rate": 0.00010806891872109393,
      "loss": 0.2678,
      "step": 38710
    },
    {
      "epoch": 38.72,
      "learning_rate": 0.00010804665591169075,
      "loss": 0.3238,
      "step": 38720
    },
    {
      "epoch": 38.73,
      "learning_rate": 0.00010802438948835496,
      "loss": 0.2872,
      "step": 38730
    },
    {
      "epoch": 38.74,
      "learning_rate": 0.00010800211945352158,
      "loss": 0.3211,
      "step": 38740
    },
    {
      "epoch": 38.75,
      "learning_rate": 0.00010797984580962604,
      "loss": 0.1907,
      "step": 38750
    },
    {
      "epoch": 38.76,
      "learning_rate": 0.00010795756855910416,
      "loss": 0.2868,
      "step": 38760
    },
    {
      "epoch": 38.77,
      "learning_rate": 0.0001079352877043921,
      "loss": 0.3138,
      "step": 38770
    },
    {
      "epoch": 38.78,
      "learning_rate": 0.00010791300324792651,
      "loss": 0.2591,
      "step": 38780
    },
    {
      "epoch": 38.79,
      "learning_rate": 0.00010789071519214437,
      "loss": 0.3132,
      "step": 38790
    },
    {
      "epoch": 38.8,
      "learning_rate": 0.00010786842353948306,
      "loss": 0.3117,
      "step": 38800
    },
    {
      "epoch": 38.81,
      "learning_rate": 0.00010784612829238038,
      "loss": 0.3833,
      "step": 38810
    },
    {
      "epoch": 38.82,
      "learning_rate": 0.00010782382945327448,
      "loss": 0.2957,
      "step": 38820
    },
    {
      "epoch": 38.83,
      "learning_rate": 0.00010780152702460398,
      "loss": 0.3292,
      "step": 38830
    },
    {
      "epoch": 38.84,
      "learning_rate": 0.00010777922100880774,
      "loss": 0.2777,
      "step": 38840
    },
    {
      "epoch": 38.85,
      "learning_rate": 0.00010775691140832521,
      "loss": 0.3468,
      "step": 38850
    },
    {
      "epoch": 38.86,
      "learning_rate": 0.0001077345982255961,
      "loss": 0.3299,
      "step": 38860
    },
    {
      "epoch": 38.87,
      "learning_rate": 0.00010771228146306053,
      "loss": 0.2253,
      "step": 38870
    },
    {
      "epoch": 38.88,
      "learning_rate": 0.00010768996112315904,
      "loss": 0.2596,
      "step": 38880
    },
    {
      "epoch": 38.89,
      "learning_rate": 0.00010766763720833256,
      "loss": 0.3175,
      "step": 38890
    },
    {
      "epoch": 38.9,
      "learning_rate": 0.00010764530972102239,
      "loss": 0.3041,
      "step": 38900
    },
    {
      "epoch": 38.91,
      "learning_rate": 0.00010762297866367023,
      "loss": 0.2929,
      "step": 38910
    },
    {
      "epoch": 38.92,
      "learning_rate": 0.00010760064403871815,
      "loss": 0.2846,
      "step": 38920
    },
    {
      "epoch": 38.93,
      "learning_rate": 0.00010757830584860869,
      "loss": 0.2525,
      "step": 38930
    },
    {
      "epoch": 38.94,
      "learning_rate": 0.00010755596409578465,
      "loss": 0.3568,
      "step": 38940
    },
    {
      "epoch": 38.95,
      "learning_rate": 0.00010753361878268934,
      "loss": 0.2513,
      "step": 38950
    },
    {
      "epoch": 38.96,
      "learning_rate": 0.00010751126991176638,
      "loss": 0.2917,
      "step": 38960
    },
    {
      "epoch": 38.97,
      "learning_rate": 0.00010748891748545984,
      "loss": 0.2358,
      "step": 38970
    },
    {
      "epoch": 38.98,
      "learning_rate": 0.00010746656150621413,
      "loss": 0.3316,
      "step": 38980
    },
    {
      "epoch": 38.99,
      "learning_rate": 0.00010744420197647405,
      "loss": 0.2036,
      "step": 38990
    },
    {
      "epoch": 39.0,
      "learning_rate": 0.00010742183889868483,
      "loss": 0.2888,
      "step": 39000
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2744711935520172,
      "eval_runtime": 14.5371,
      "eval_samples_per_second": 137.579,
      "eval_steps_per_second": 17.197,
      "step": 39000
    },
    {
      "epoch": 39.01,
      "learning_rate": 0.00010739947227529205,
      "loss": 0.242,
      "step": 39010
    },
    {
      "epoch": 39.02,
      "learning_rate": 0.00010737710210874171,
      "loss": 0.2643,
      "step": 39020
    },
    {
      "epoch": 39.03,
      "learning_rate": 0.00010735472840148015,
      "loss": 0.245,
      "step": 39030
    },
    {
      "epoch": 39.04,
      "learning_rate": 0.00010733235115595414,
      "loss": 0.2981,
      "step": 39040
    },
    {
      "epoch": 39.05,
      "learning_rate": 0.00010730997037461082,
      "loss": 0.294,
      "step": 39050
    },
    {
      "epoch": 39.06,
      "learning_rate": 0.00010728758605989769,
      "loss": 0.2626,
      "step": 39060
    },
    {
      "epoch": 39.07,
      "learning_rate": 0.00010726519821426272,
      "loss": 0.2962,
      "step": 39070
    },
    {
      "epoch": 39.08,
      "learning_rate": 0.00010724280684015419,
      "loss": 0.3167,
      "step": 39080
    },
    {
      "epoch": 39.09,
      "learning_rate": 0.00010722041194002076,
      "loss": 0.3023,
      "step": 39090
    },
    {
      "epoch": 39.1,
      "learning_rate": 0.00010719801351631154,
      "loss": 0.2173,
      "step": 39100
    },
    {
      "epoch": 39.11,
      "learning_rate": 0.00010717561157147596,
      "loss": 0.2597,
      "step": 39110
    },
    {
      "epoch": 39.12,
      "learning_rate": 0.00010715320610796386,
      "loss": 0.3207,
      "step": 39120
    },
    {
      "epoch": 39.13,
      "learning_rate": 0.00010713079712822551,
      "loss": 0.2601,
      "step": 39130
    },
    {
      "epoch": 39.14,
      "learning_rate": 0.00010710838463471148,
      "loss": 0.3045,
      "step": 39140
    },
    {
      "epoch": 39.15,
      "learning_rate": 0.00010708596862987277,
      "loss": 0.2961,
      "step": 39150
    },
    {
      "epoch": 39.16,
      "learning_rate": 0.00010706354911616079,
      "loss": 0.2783,
      "step": 39160
    },
    {
      "epoch": 39.17,
      "learning_rate": 0.00010704112609602726,
      "loss": 0.2774,
      "step": 39170
    },
    {
      "epoch": 39.18,
      "learning_rate": 0.0001070186995719244,
      "loss": 0.2597,
      "step": 39180
    },
    {
      "epoch": 39.19,
      "learning_rate": 0.00010699626954630465,
      "loss": 0.2416,
      "step": 39190
    },
    {
      "epoch": 39.2,
      "learning_rate": 0.00010697383602162098,
      "loss": 0.3133,
      "step": 39200
    },
    {
      "epoch": 39.21,
      "learning_rate": 0.00010695139900032669,
      "loss": 0.2715,
      "step": 39210
    },
    {
      "epoch": 39.22,
      "learning_rate": 0.00010692895848487542,
      "loss": 0.2606,
      "step": 39220
    },
    {
      "epoch": 39.23,
      "learning_rate": 0.00010690651447772127,
      "loss": 0.2424,
      "step": 39230
    },
    {
      "epoch": 39.24,
      "learning_rate": 0.00010688406698131866,
      "loss": 0.2689,
      "step": 39240
    },
    {
      "epoch": 39.25,
      "learning_rate": 0.00010686161599812243,
      "loss": 0.2957,
      "step": 39250
    },
    {
      "epoch": 39.26,
      "learning_rate": 0.00010683916153058779,
      "loss": 0.3563,
      "step": 39260
    },
    {
      "epoch": 39.27,
      "learning_rate": 0.00010681670358117028,
      "loss": 0.261,
      "step": 39270
    },
    {
      "epoch": 39.28,
      "learning_rate": 0.00010679424215232591,
      "loss": 0.2873,
      "step": 39280
    },
    {
      "epoch": 39.29,
      "learning_rate": 0.00010677177724651105,
      "loss": 0.286,
      "step": 39290
    },
    {
      "epoch": 39.3,
      "learning_rate": 0.00010674930886618238,
      "loss": 0.2779,
      "step": 39300
    },
    {
      "epoch": 39.31,
      "learning_rate": 0.00010672683701379701,
      "loss": 0.2967,
      "step": 39310
    },
    {
      "epoch": 39.32,
      "learning_rate": 0.00010670436169181246,
      "loss": 0.2519,
      "step": 39320
    },
    {
      "epoch": 39.33,
      "learning_rate": 0.00010668188290268659,
      "loss": 0.2608,
      "step": 39330
    },
    {
      "epoch": 39.34,
      "learning_rate": 0.00010665940064887764,
      "loss": 0.2425,
      "step": 39340
    },
    {
      "epoch": 39.35,
      "learning_rate": 0.00010663691493284421,
      "loss": 0.2801,
      "step": 39350
    },
    {
      "epoch": 39.36,
      "learning_rate": 0.00010661442575704535,
      "loss": 0.2945,
      "step": 39360
    },
    {
      "epoch": 39.37,
      "learning_rate": 0.00010659193312394043,
      "loss": 0.269,
      "step": 39370
    },
    {
      "epoch": 39.38,
      "learning_rate": 0.00010656943703598917,
      "loss": 0.3304,
      "step": 39380
    },
    {
      "epoch": 39.39,
      "learning_rate": 0.00010654693749565177,
      "loss": 0.2855,
      "step": 39390
    },
    {
      "epoch": 39.4,
      "learning_rate": 0.00010652443450538867,
      "loss": 0.2922,
      "step": 39400
    },
    {
      "epoch": 39.41,
      "learning_rate": 0.00010650192806766085,
      "loss": 0.306,
      "step": 39410
    },
    {
      "epoch": 39.42,
      "learning_rate": 0.00010647941818492954,
      "loss": 0.2467,
      "step": 39420
    },
    {
      "epoch": 39.43,
      "learning_rate": 0.00010645690485965637,
      "loss": 0.2292,
      "step": 39430
    },
    {
      "epoch": 39.44,
      "learning_rate": 0.00010643438809430336,
      "loss": 0.2851,
      "step": 39440
    },
    {
      "epoch": 39.45,
      "learning_rate": 0.00010641186789133297,
      "loss": 0.3134,
      "step": 39450
    },
    {
      "epoch": 39.46,
      "learning_rate": 0.00010638934425320792,
      "loss": 0.3079,
      "step": 39460
    },
    {
      "epoch": 39.47,
      "learning_rate": 0.00010636681718239137,
      "loss": 0.2288,
      "step": 39470
    },
    {
      "epoch": 39.48,
      "learning_rate": 0.00010634428668134686,
      "loss": 0.2592,
      "step": 39480
    },
    {
      "epoch": 39.49,
      "learning_rate": 0.00010632175275253828,
      "loss": 0.3177,
      "step": 39490
    },
    {
      "epoch": 39.5,
      "learning_rate": 0.00010629921539842991,
      "loss": 0.2831,
      "step": 39500
    },
    {
      "epoch": 39.51,
      "learning_rate": 0.0001062766746214864,
      "loss": 0.285,
      "step": 39510
    },
    {
      "epoch": 39.52,
      "learning_rate": 0.00010625413042417277,
      "loss": 0.2952,
      "step": 39520
    },
    {
      "epoch": 39.53,
      "learning_rate": 0.00010623158280895445,
      "loss": 0.2927,
      "step": 39530
    },
    {
      "epoch": 39.54,
      "learning_rate": 0.00010620903177829717,
      "loss": 0.3665,
      "step": 39540
    },
    {
      "epoch": 39.55,
      "learning_rate": 0.0001061864773346671,
      "loss": 0.1837,
      "step": 39550
    },
    {
      "epoch": 39.56,
      "learning_rate": 0.00010616391948053076,
      "loss": 0.2058,
      "step": 39560
    },
    {
      "epoch": 39.57,
      "learning_rate": 0.00010614135821835503,
      "loss": 0.2653,
      "step": 39570
    },
    {
      "epoch": 39.58,
      "learning_rate": 0.0001061187935506072,
      "loss": 0.2473,
      "step": 39580
    },
    {
      "epoch": 39.59,
      "learning_rate": 0.0001060962254797549,
      "loss": 0.3483,
      "step": 39590
    },
    {
      "epoch": 39.6,
      "learning_rate": 0.00010607365400826611,
      "loss": 0.2732,
      "step": 39600
    },
    {
      "epoch": 39.61,
      "learning_rate": 0.00010605107913860926,
      "loss": 0.262,
      "step": 39610
    },
    {
      "epoch": 39.62,
      "learning_rate": 0.00010602850087325307,
      "loss": 0.2316,
      "step": 39620
    },
    {
      "epoch": 39.63,
      "learning_rate": 0.00010600591921466666,
      "loss": 0.302,
      "step": 39630
    },
    {
      "epoch": 39.64,
      "learning_rate": 0.00010598333416531957,
      "loss": 0.2575,
      "step": 39640
    },
    {
      "epoch": 39.65,
      "learning_rate": 0.0001059607457276816,
      "loss": 0.2558,
      "step": 39650
    },
    {
      "epoch": 39.66,
      "learning_rate": 0.00010593815390422304,
      "loss": 0.2327,
      "step": 39660
    },
    {
      "epoch": 39.67,
      "learning_rate": 0.00010591781837027569,
      "loss": 0.3362,
      "step": 39670
    },
    {
      "epoch": 39.68,
      "learning_rate": 0.00010589522012056482,
      "loss": 0.3194,
      "step": 39680
    },
    {
      "epoch": 39.69,
      "learning_rate": 0.00010587261849219913,
      "loss": 0.2789,
      "step": 39690
    },
    {
      "epoch": 39.7,
      "learning_rate": 0.00010585001348765028,
      "loss": 0.2883,
      "step": 39700
    },
    {
      "epoch": 39.71,
      "learning_rate": 0.00010582740510939037,
      "loss": 0.2599,
      "step": 39710
    },
    {
      "epoch": 39.72,
      "learning_rate": 0.00010580479335989177,
      "loss": 0.2169,
      "step": 39720
    },
    {
      "epoch": 39.73,
      "learning_rate": 0.00010578217824162731,
      "loss": 0.26,
      "step": 39730
    },
    {
      "epoch": 39.74,
      "learning_rate": 0.00010575955975707007,
      "loss": 0.3374,
      "step": 39740
    },
    {
      "epoch": 39.75,
      "learning_rate": 0.00010573693790869365,
      "loss": 0.3379,
      "step": 39750
    },
    {
      "epoch": 39.76,
      "learning_rate": 0.00010571431269897191,
      "loss": 0.2012,
      "step": 39760
    },
    {
      "epoch": 39.77,
      "learning_rate": 0.0001056916841303791,
      "loss": 0.2343,
      "step": 39770
    },
    {
      "epoch": 39.78,
      "learning_rate": 0.00010566905220538987,
      "loss": 0.2862,
      "step": 39780
    },
    {
      "epoch": 39.79,
      "learning_rate": 0.00010564641692647919,
      "loss": 0.2428,
      "step": 39790
    },
    {
      "epoch": 39.8,
      "learning_rate": 0.00010562377829612242,
      "loss": 0.3381,
      "step": 39800
    },
    {
      "epoch": 39.81,
      "learning_rate": 0.00010560113631679533,
      "loss": 0.287,
      "step": 39810
    },
    {
      "epoch": 39.82,
      "learning_rate": 0.00010557849099097396,
      "loss": 0.3313,
      "step": 39820
    },
    {
      "epoch": 39.83,
      "learning_rate": 0.0001055558423211348,
      "loss": 0.3038,
      "step": 39830
    },
    {
      "epoch": 39.84,
      "learning_rate": 0.00010553319030975466,
      "loss": 0.295,
      "step": 39840
    },
    {
      "epoch": 39.85,
      "learning_rate": 0.00010551053495931073,
      "loss": 0.2512,
      "step": 39850
    },
    {
      "epoch": 39.86,
      "learning_rate": 0.00010548787627228057,
      "loss": 0.2941,
      "step": 39860
    },
    {
      "epoch": 39.87,
      "learning_rate": 0.00010546521425114209,
      "loss": 0.2867,
      "step": 39870
    },
    {
      "epoch": 39.88,
      "learning_rate": 0.0001054425488983736,
      "loss": 0.2669,
      "step": 39880
    },
    {
      "epoch": 39.89,
      "learning_rate": 0.00010541988021645372,
      "loss": 0.2943,
      "step": 39890
    },
    {
      "epoch": 39.9,
      "learning_rate": 0.00010539720820786147,
      "loss": 0.298,
      "step": 39900
    },
    {
      "epoch": 39.91,
      "learning_rate": 0.00010537453287507623,
      "loss": 0.291,
      "step": 39910
    },
    {
      "epoch": 39.92,
      "learning_rate": 0.00010535185422057778,
      "loss": 0.2559,
      "step": 39920
    },
    {
      "epoch": 39.93,
      "learning_rate": 0.00010532917224684615,
      "loss": 0.307,
      "step": 39930
    },
    {
      "epoch": 39.94,
      "learning_rate": 0.00010530648695636186,
      "loss": 0.3018,
      "step": 39940
    },
    {
      "epoch": 39.95,
      "learning_rate": 0.00010528379835160572,
      "loss": 0.2422,
      "step": 39950
    },
    {
      "epoch": 39.96,
      "learning_rate": 0.0001052611064350589,
      "loss": 0.2606,
      "step": 39960
    },
    {
      "epoch": 39.97,
      "learning_rate": 0.000105238411209203,
      "loss": 0.2964,
      "step": 39970
    },
    {
      "epoch": 39.98,
      "learning_rate": 0.0001052157126765199,
      "loss": 0.2706,
      "step": 39980
    },
    {
      "epoch": 39.99,
      "learning_rate": 0.00010519301083949188,
      "loss": 0.3126,
      "step": 39990
    },
    {
      "epoch": 40.0,
      "learning_rate": 0.00010517030570060163,
      "loss": 0.2855,
      "step": 40000
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.273139089345932,
      "eval_runtime": 14.8781,
      "eval_samples_per_second": 134.426,
      "eval_steps_per_second": 16.803,
      "step": 40000
    },
    {
      "epoch": 40.01,
      "learning_rate": 0.0001051475972623321,
      "loss": 0.2079,
      "step": 40010
    },
    {
      "epoch": 40.02,
      "learning_rate": 0.00010512488552716663,
      "loss": 0.2012,
      "step": 40020
    },
    {
      "epoch": 40.03,
      "learning_rate": 0.00010510217049758899,
      "loss": 0.2665,
      "step": 40030
    },
    {
      "epoch": 40.04,
      "learning_rate": 0.00010507945217608323,
      "loss": 0.2125,
      "step": 40040
    },
    {
      "epoch": 40.05,
      "learning_rate": 0.00010505673056513381,
      "loss": 0.3803,
      "step": 40050
    },
    {
      "epoch": 40.06,
      "learning_rate": 0.00010503400566722553,
      "loss": 0.2684,
      "step": 40060
    },
    {
      "epoch": 40.07,
      "learning_rate": 0.00010501127748484355,
      "loss": 0.3364,
      "step": 40070
    },
    {
      "epoch": 40.08,
      "learning_rate": 0.00010498854602047337,
      "loss": 0.2206,
      "step": 40080
    },
    {
      "epoch": 40.09,
      "learning_rate": 0.00010496581127660088,
      "loss": 0.2777,
      "step": 40090
    },
    {
      "epoch": 40.1,
      "learning_rate": 0.00010494307325571234,
      "loss": 0.2947,
      "step": 40100
    },
    {
      "epoch": 40.11,
      "learning_rate": 0.00010492033196029434,
      "loss": 0.3036,
      "step": 40110
    },
    {
      "epoch": 40.12,
      "learning_rate": 0.00010489758739283378,
      "loss": 0.2516,
      "step": 40120
    },
    {
      "epoch": 40.13,
      "learning_rate": 0.00010487483955581805,
      "loss": 0.2863,
      "step": 40130
    },
    {
      "epoch": 40.14,
      "learning_rate": 0.00010485208845173475,
      "loss": 0.2681,
      "step": 40140
    },
    {
      "epoch": 40.15,
      "learning_rate": 0.00010482933408307197,
      "loss": 0.2877,
      "step": 40150
    },
    {
      "epoch": 40.16,
      "learning_rate": 0.00010480657645231805,
      "loss": 0.2167,
      "step": 40160
    },
    {
      "epoch": 40.17,
      "learning_rate": 0.00010478381556196174,
      "loss": 0.2861,
      "step": 40170
    },
    {
      "epoch": 40.18,
      "learning_rate": 0.00010476105141449213,
      "loss": 0.3019,
      "step": 40180
    },
    {
      "epoch": 40.19,
      "learning_rate": 0.0001047382840123987,
      "loss": 0.3658,
      "step": 40190
    },
    {
      "epoch": 40.2,
      "learning_rate": 0.00010471551335817124,
      "loss": 0.2518,
      "step": 40200
    },
    {
      "epoch": 40.21,
      "learning_rate": 0.0001046927394542999,
      "loss": 0.2707,
      "step": 40210
    },
    {
      "epoch": 40.22,
      "learning_rate": 0.00010466996230327523,
      "loss": 0.3206,
      "step": 40220
    },
    {
      "epoch": 40.23,
      "learning_rate": 0.00010464718190758809,
      "loss": 0.2514,
      "step": 40230
    },
    {
      "epoch": 40.24,
      "learning_rate": 0.0001046243982697297,
      "loss": 0.3296,
      "step": 40240
    },
    {
      "epoch": 40.25,
      "learning_rate": 0.00010460161139219167,
      "loss": 0.2585,
      "step": 40250
    },
    {
      "epoch": 40.26,
      "learning_rate": 0.00010457882127746592,
      "loss": 0.286,
      "step": 40260
    },
    {
      "epoch": 40.27,
      "learning_rate": 0.00010455602792804474,
      "loss": 0.284,
      "step": 40270
    },
    {
      "epoch": 40.28,
      "learning_rate": 0.00010453323134642078,
      "loss": 0.297,
      "step": 40280
    },
    {
      "epoch": 40.29,
      "learning_rate": 0.00010451043153508706,
      "loss": 0.2858,
      "step": 40290
    },
    {
      "epoch": 40.3,
      "learning_rate": 0.0001044876284965369,
      "loss": 0.2884,
      "step": 40300
    },
    {
      "epoch": 40.31,
      "learning_rate": 0.00010446482223326401,
      "loss": 0.2695,
      "step": 40310
    },
    {
      "epoch": 40.32,
      "learning_rate": 0.00010444201274776248,
      "loss": 0.3163,
      "step": 40320
    },
    {
      "epoch": 40.33,
      "learning_rate": 0.00010441920004252672,
      "loss": 0.2874,
      "step": 40330
    },
    {
      "epoch": 40.34,
      "learning_rate": 0.00010439638412005142,
      "loss": 0.278,
      "step": 40340
    },
    {
      "epoch": 40.35,
      "learning_rate": 0.0001043735649828318,
      "loss": 0.2526,
      "step": 40350
    },
    {
      "epoch": 40.36,
      "learning_rate": 0.00010435074263336325,
      "loss": 0.2874,
      "step": 40360
    },
    {
      "epoch": 40.37,
      "learning_rate": 0.00010432791707414162,
      "loss": 0.2301,
      "step": 40370
    },
    {
      "epoch": 40.38,
      "learning_rate": 0.00010430508830766307,
      "loss": 0.3004,
      "step": 40380
    },
    {
      "epoch": 40.39,
      "learning_rate": 0.00010428225633642414,
      "loss": 0.1954,
      "step": 40390
    },
    {
      "epoch": 40.4,
      "learning_rate": 0.00010425942116292167,
      "loss": 0.2771,
      "step": 40400
    },
    {
      "epoch": 40.41,
      "learning_rate": 0.00010423658278965286,
      "loss": 0.2619,
      "step": 40410
    },
    {
      "epoch": 40.42,
      "learning_rate": 0.00010421374121911534,
      "loss": 0.2678,
      "step": 40420
    },
    {
      "epoch": 40.43,
      "learning_rate": 0.00010419089645380702,
      "loss": 0.3058,
      "step": 40430
    },
    {
      "epoch": 40.44,
      "learning_rate": 0.00010416804849622613,
      "loss": 0.303,
      "step": 40440
    },
    {
      "epoch": 40.45,
      "learning_rate": 0.00010414519734887132,
      "loss": 0.286,
      "step": 40450
    },
    {
      "epoch": 40.46,
      "learning_rate": 0.00010412234301424154,
      "loss": 0.2706,
      "step": 40460
    },
    {
      "epoch": 40.47,
      "learning_rate": 0.00010409948549483611,
      "loss": 0.2941,
      "step": 40470
    },
    {
      "epoch": 40.48,
      "learning_rate": 0.00010407662479315471,
      "loss": 0.2235,
      "step": 40480
    },
    {
      "epoch": 40.49,
      "learning_rate": 0.00010405376091169734,
      "loss": 0.2246,
      "step": 40490
    },
    {
      "epoch": 40.5,
      "learning_rate": 0.00010403089385296433,
      "loss": 0.3508,
      "step": 40500
    },
    {
      "epoch": 40.51,
      "learning_rate": 0.00010400802361945646,
      "loss": 0.2696,
      "step": 40510
    },
    {
      "epoch": 40.52,
      "learning_rate": 0.00010398515021367471,
      "loss": 0.2303,
      "step": 40520
    },
    {
      "epoch": 40.53,
      "learning_rate": 0.00010396227363812051,
      "loss": 0.3007,
      "step": 40530
    },
    {
      "epoch": 40.54,
      "learning_rate": 0.00010393939389529561,
      "loss": 0.2698,
      "step": 40540
    },
    {
      "epoch": 40.55,
      "learning_rate": 0.00010391651098770213,
      "loss": 0.2832,
      "step": 40550
    },
    {
      "epoch": 40.56,
      "learning_rate": 0.00010389362491784245,
      "loss": 0.3022,
      "step": 40560
    },
    {
      "epoch": 40.57,
      "learning_rate": 0.0001038707356882194,
      "loss": 0.3139,
      "step": 40570
    },
    {
      "epoch": 40.58,
      "learning_rate": 0.00010384784330133612,
      "loss": 0.2163,
      "step": 40580
    },
    {
      "epoch": 40.59,
      "learning_rate": 0.00010382494775969603,
      "loss": 0.3131,
      "step": 40590
    },
    {
      "epoch": 40.6,
      "learning_rate": 0.00010380204906580302,
      "loss": 0.2856,
      "step": 40600
    },
    {
      "epoch": 40.61,
      "learning_rate": 0.00010377914722216123,
      "loss": 0.2741,
      "step": 40610
    },
    {
      "epoch": 40.62,
      "learning_rate": 0.00010375624223127515,
      "loss": 0.2974,
      "step": 40620
    },
    {
      "epoch": 40.63,
      "learning_rate": 0.00010373333409564967,
      "loss": 0.3215,
      "step": 40630
    },
    {
      "epoch": 40.64,
      "learning_rate": 0.00010371042281778996,
      "loss": 0.2948,
      "step": 40640
    },
    {
      "epoch": 40.65,
      "learning_rate": 0.00010368750840020157,
      "loss": 0.2333,
      "step": 40650
    },
    {
      "epoch": 40.66,
      "learning_rate": 0.00010366459084539041,
      "loss": 0.3113,
      "step": 40660
    },
    {
      "epoch": 40.67,
      "learning_rate": 0.0001036416701558627,
      "loss": 0.2237,
      "step": 40670
    },
    {
      "epoch": 40.68,
      "learning_rate": 0.00010361874633412499,
      "loss": 0.2868,
      "step": 40680
    },
    {
      "epoch": 40.69,
      "learning_rate": 0.0001035958193826842,
      "loss": 0.3243,
      "step": 40690
    },
    {
      "epoch": 40.7,
      "learning_rate": 0.0001035728893040476,
      "loss": 0.2954,
      "step": 40700
    },
    {
      "epoch": 40.71,
      "learning_rate": 0.0001035499561007228,
      "loss": 0.3091,
      "step": 40710
    },
    {
      "epoch": 40.72,
      "learning_rate": 0.0001035270197752177,
      "loss": 0.2694,
      "step": 40720
    },
    {
      "epoch": 40.73,
      "learning_rate": 0.00010350408033004062,
      "loss": 0.2727,
      "step": 40730
    },
    {
      "epoch": 40.74,
      "learning_rate": 0.0001034811377677002,
      "loss": 0.2587,
      "step": 40740
    },
    {
      "epoch": 40.75,
      "learning_rate": 0.00010345819209070532,
      "loss": 0.2484,
      "step": 40750
    },
    {
      "epoch": 40.76,
      "learning_rate": 0.00010343524330156537,
      "loss": 0.2944,
      "step": 40760
    },
    {
      "epoch": 40.77,
      "learning_rate": 0.00010341229140278996,
      "loss": 0.2811,
      "step": 40770
    },
    {
      "epoch": 40.78,
      "learning_rate": 0.0001033893363968891,
      "loss": 0.3575,
      "step": 40780
    },
    {
      "epoch": 40.79,
      "learning_rate": 0.00010336637828637306,
      "loss": 0.3224,
      "step": 40790
    },
    {
      "epoch": 40.8,
      "learning_rate": 0.00010334341707375256,
      "loss": 0.2943,
      "step": 40800
    },
    {
      "epoch": 40.81,
      "learning_rate": 0.00010332045276153858,
      "loss": 0.2773,
      "step": 40810
    },
    {
      "epoch": 40.82,
      "learning_rate": 0.00010329748535224244,
      "loss": 0.2424,
      "step": 40820
    },
    {
      "epoch": 40.83,
      "learning_rate": 0.00010327451484837586,
      "loss": 0.2525,
      "step": 40830
    },
    {
      "epoch": 40.84,
      "learning_rate": 0.00010325154125245088,
      "loss": 0.252,
      "step": 40840
    },
    {
      "epoch": 40.85,
      "learning_rate": 0.00010322856456697978,
      "loss": 0.2598,
      "step": 40850
    },
    {
      "epoch": 40.86,
      "learning_rate": 0.00010320558479447532,
      "loss": 0.3036,
      "step": 40860
    },
    {
      "epoch": 40.87,
      "learning_rate": 0.0001031826019374505,
      "loss": 0.3123,
      "step": 40870
    },
    {
      "epoch": 40.88,
      "learning_rate": 0.0001031596159984187,
      "loss": 0.2949,
      "step": 40880
    },
    {
      "epoch": 40.89,
      "learning_rate": 0.00010313662697989367,
      "loss": 0.2774,
      "step": 40890
    },
    {
      "epoch": 40.9,
      "learning_rate": 0.00010311363488438939,
      "loss": 0.3033,
      "step": 40900
    },
    {
      "epoch": 40.91,
      "learning_rate": 0.00010309063971442026,
      "loss": 0.2692,
      "step": 40910
    },
    {
      "epoch": 40.92,
      "learning_rate": 0.000103067641472501,
      "loss": 0.259,
      "step": 40920
    },
    {
      "epoch": 40.93,
      "learning_rate": 0.0001030446401611467,
      "loss": 0.2175,
      "step": 40930
    },
    {
      "epoch": 40.94,
      "learning_rate": 0.00010302163578287271,
      "loss": 0.2168,
      "step": 40940
    },
    {
      "epoch": 40.95,
      "learning_rate": 0.00010299862834019473,
      "loss": 0.2513,
      "step": 40950
    },
    {
      "epoch": 40.96,
      "learning_rate": 0.00010297561783562889,
      "loss": 0.2601,
      "step": 40960
    },
    {
      "epoch": 40.97,
      "learning_rate": 0.00010295260427169151,
      "loss": 0.303,
      "step": 40970
    },
    {
      "epoch": 40.98,
      "learning_rate": 0.00010292958765089937,
      "loss": 0.3627,
      "step": 40980
    },
    {
      "epoch": 40.99,
      "learning_rate": 0.0001029065679757695,
      "loss": 0.2849,
      "step": 40990
    },
    {
      "epoch": 41.0,
      "learning_rate": 0.00010288354524881933,
      "loss": 0.3111,
      "step": 41000
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2735119163990021,
      "eval_runtime": 14.6059,
      "eval_samples_per_second": 136.931,
      "eval_steps_per_second": 17.116,
      "step": 41000
    },
    {
      "epoch": 41.01,
      "learning_rate": 0.00010286051947256657,
      "loss": 0.2607,
      "step": 41010
    },
    {
      "epoch": 41.02,
      "learning_rate": 0.0001028374906495293,
      "loss": 0.2405,
      "step": 41020
    },
    {
      "epoch": 41.03,
      "learning_rate": 0.0001028144587822259,
      "loss": 0.3276,
      "step": 41030
    },
    {
      "epoch": 41.04,
      "learning_rate": 0.00010279142387317508,
      "loss": 0.2501,
      "step": 41040
    },
    {
      "epoch": 41.05,
      "learning_rate": 0.00010276838592489595,
      "loss": 0.2258,
      "step": 41050
    },
    {
      "epoch": 41.06,
      "learning_rate": 0.00010274534493990789,
      "loss": 0.2594,
      "step": 41060
    },
    {
      "epoch": 41.07,
      "learning_rate": 0.0001027223009207306,
      "loss": 0.2832,
      "step": 41070
    },
    {
      "epoch": 41.08,
      "learning_rate": 0.00010269925386988418,
      "loss": 0.2747,
      "step": 41080
    },
    {
      "epoch": 41.09,
      "learning_rate": 0.000102676203789889,
      "loss": 0.2519,
      "step": 41090
    },
    {
      "epoch": 41.1,
      "learning_rate": 0.00010265315068326577,
      "loss": 0.2831,
      "step": 41100
    },
    {
      "epoch": 41.11,
      "learning_rate": 0.00010263009455253556,
      "loss": 0.2761,
      "step": 41110
    },
    {
      "epoch": 41.12,
      "learning_rate": 0.00010260703540021977,
      "loss": 0.2583,
      "step": 41120
    },
    {
      "epoch": 41.13,
      "learning_rate": 0.00010258397322884009,
      "loss": 0.2842,
      "step": 41130
    },
    {
      "epoch": 41.14,
      "learning_rate": 0.00010256090804091856,
      "loss": 0.2254,
      "step": 41140
    },
    {
      "epoch": 41.15,
      "learning_rate": 0.00010253783983897756,
      "loss": 0.2775,
      "step": 41150
    },
    {
      "epoch": 41.16,
      "learning_rate": 0.00010251476862553982,
      "loss": 0.2665,
      "step": 41160
    },
    {
      "epoch": 41.17,
      "learning_rate": 0.00010249169440312833,
      "loss": 0.3915,
      "step": 41170
    },
    {
      "epoch": 41.18,
      "learning_rate": 0.00010246861717426648,
      "loss": 0.2866,
      "step": 41180
    },
    {
      "epoch": 41.19,
      "learning_rate": 0.00010244553694147796,
      "loss": 0.3125,
      "step": 41190
    },
    {
      "epoch": 41.2,
      "learning_rate": 0.00010242245370728678,
      "loss": 0.2924,
      "step": 41200
    },
    {
      "epoch": 41.21,
      "learning_rate": 0.00010239936747421728,
      "loss": 0.2828,
      "step": 41210
    },
    {
      "epoch": 41.22,
      "learning_rate": 0.00010237627824479417,
      "loss": 0.2328,
      "step": 41220
    },
    {
      "epoch": 41.23,
      "learning_rate": 0.0001023531860215424,
      "loss": 0.2123,
      "step": 41230
    },
    {
      "epoch": 41.24,
      "learning_rate": 0.00010233009080698735,
      "loss": 0.2427,
      "step": 41240
    },
    {
      "epoch": 41.25,
      "learning_rate": 0.00010230699260365467,
      "loss": 0.2696,
      "step": 41250
    },
    {
      "epoch": 41.26,
      "learning_rate": 0.00010228389141407031,
      "loss": 0.3272,
      "step": 41260
    },
    {
      "epoch": 41.27,
      "learning_rate": 0.00010226078724076063,
      "loss": 0.2743,
      "step": 41270
    },
    {
      "epoch": 41.28,
      "learning_rate": 0.00010223768008625224,
      "loss": 0.2958,
      "step": 41280
    },
    {
      "epoch": 41.29,
      "learning_rate": 0.0001022145699530721,
      "loss": 0.349,
      "step": 41290
    },
    {
      "epoch": 41.3,
      "learning_rate": 0.0001021914568437475,
      "loss": 0.2695,
      "step": 41300
    },
    {
      "epoch": 41.31,
      "learning_rate": 0.00010216834076080608,
      "loss": 0.3427,
      "step": 41310
    },
    {
      "epoch": 41.32,
      "learning_rate": 0.00010214522170677573,
      "loss": 0.3218,
      "step": 41320
    },
    {
      "epoch": 41.33,
      "learning_rate": 0.00010212209968418477,
      "loss": 0.3224,
      "step": 41330
    },
    {
      "epoch": 41.34,
      "learning_rate": 0.00010209897469556175,
      "loss": 0.2592,
      "step": 41340
    },
    {
      "epoch": 41.35,
      "learning_rate": 0.00010207584674343561,
      "loss": 0.2806,
      "step": 41350
    },
    {
      "epoch": 41.36,
      "learning_rate": 0.00010205271583033558,
      "loss": 0.2091,
      "step": 41360
    },
    {
      "epoch": 41.37,
      "learning_rate": 0.00010202958195879122,
      "loss": 0.2835,
      "step": 41370
    },
    {
      "epoch": 41.38,
      "learning_rate": 0.00010200644513133241,
      "loss": 0.2341,
      "step": 41380
    },
    {
      "epoch": 41.39,
      "learning_rate": 0.00010198330535048936,
      "loss": 0.2459,
      "step": 41390
    },
    {
      "epoch": 41.4,
      "learning_rate": 0.00010196016261879262,
      "loss": 0.2438,
      "step": 41400
    },
    {
      "epoch": 41.41,
      "learning_rate": 0.00010193701693877304,
      "loss": 0.2994,
      "step": 41410
    },
    {
      "epoch": 41.42,
      "learning_rate": 0.00010191386831296176,
      "loss": 0.3095,
      "step": 41420
    },
    {
      "epoch": 41.43,
      "learning_rate": 0.00010189071674389032,
      "loss": 0.3033,
      "step": 41430
    },
    {
      "epoch": 41.44,
      "learning_rate": 0.00010186756223409052,
      "loss": 0.3301,
      "step": 41440
    },
    {
      "epoch": 41.45,
      "learning_rate": 0.0001018444047860945,
      "loss": 0.2899,
      "step": 41450
    },
    {
      "epoch": 41.46,
      "learning_rate": 0.00010182124440243476,
      "loss": 0.3324,
      "step": 41460
    },
    {
      "epoch": 41.47,
      "learning_rate": 0.00010179808108564403,
      "loss": 0.2608,
      "step": 41470
    },
    {
      "epoch": 41.48,
      "learning_rate": 0.00010177491483825549,
      "loss": 0.2502,
      "step": 41480
    },
    {
      "epoch": 41.49,
      "learning_rate": 0.00010175174566280245,
      "loss": 0.2844,
      "step": 41490
    },
    {
      "epoch": 41.5,
      "learning_rate": 0.00010172857356181877,
      "loss": 0.2929,
      "step": 41500
    },
    {
      "epoch": 41.51,
      "learning_rate": 0.00010170539853783846,
      "loss": 0.2803,
      "step": 41510
    },
    {
      "epoch": 41.52,
      "learning_rate": 0.00010168222059339592,
      "loss": 0.2997,
      "step": 41520
    },
    {
      "epoch": 41.53,
      "learning_rate": 0.00010165903973102585,
      "loss": 0.2261,
      "step": 41530
    },
    {
      "epoch": 41.54,
      "learning_rate": 0.00010163585595326328,
      "loss": 0.339,
      "step": 41540
    },
    {
      "epoch": 41.55,
      "learning_rate": 0.00010161266926264353,
      "loss": 0.3298,
      "step": 41550
    },
    {
      "epoch": 41.56,
      "learning_rate": 0.00010158947966170229,
      "loss": 0.2635,
      "step": 41560
    },
    {
      "epoch": 41.57,
      "learning_rate": 0.00010156628715297553,
      "loss": 0.2901,
      "step": 41570
    },
    {
      "epoch": 41.58,
      "learning_rate": 0.00010154309173899956,
      "loss": 0.2252,
      "step": 41580
    },
    {
      "epoch": 41.59,
      "learning_rate": 0.00010151989342231096,
      "loss": 0.2594,
      "step": 41590
    },
    {
      "epoch": 41.6,
      "learning_rate": 0.00010149669220544672,
      "loss": 0.2859,
      "step": 41600
    },
    {
      "epoch": 41.61,
      "learning_rate": 0.00010147348809094404,
      "loss": 0.1917,
      "step": 41610
    },
    {
      "epoch": 41.62,
      "learning_rate": 0.00010145028108134051,
      "loss": 0.2422,
      "step": 41620
    },
    {
      "epoch": 41.63,
      "learning_rate": 0.00010142707117917401,
      "loss": 0.2248,
      "step": 41630
    },
    {
      "epoch": 41.64,
      "learning_rate": 0.00010140385838698274,
      "loss": 0.3294,
      "step": 41640
    },
    {
      "epoch": 41.65,
      "learning_rate": 0.00010138064270730519,
      "loss": 0.2866,
      "step": 41650
    },
    {
      "epoch": 41.66,
      "learning_rate": 0.00010135742414268025,
      "loss": 0.3212,
      "step": 41660
    },
    {
      "epoch": 41.67,
      "learning_rate": 0.00010133420269564703,
      "loss": 0.1992,
      "step": 41670
    },
    {
      "epoch": 41.68,
      "learning_rate": 0.00010131097836874498,
      "loss": 0.3204,
      "step": 41680
    },
    {
      "epoch": 41.69,
      "learning_rate": 0.0001012877511645139,
      "loss": 0.3293,
      "step": 41690
    },
    {
      "epoch": 41.7,
      "learning_rate": 0.00010126452108549387,
      "loss": 0.3031,
      "step": 41700
    },
    {
      "epoch": 41.71,
      "learning_rate": 0.0001012412881342253,
      "loss": 0.2543,
      "step": 41710
    },
    {
      "epoch": 41.72,
      "learning_rate": 0.00010122037602441099,
      "loss": 0.3259,
      "step": 41720
    },
    {
      "epoch": 41.73,
      "learning_rate": 0.00010119713762287015,
      "loss": 0.2752,
      "step": 41730
    },
    {
      "epoch": 41.74,
      "learning_rate": 0.00010117389635644975,
      "loss": 0.2586,
      "step": 41740
    },
    {
      "epoch": 41.75,
      "learning_rate": 0.00010115065222769135,
      "loss": 0.3023,
      "step": 41750
    },
    {
      "epoch": 41.76,
      "learning_rate": 0.00010112740523913697,
      "loss": 0.2744,
      "step": 41760
    },
    {
      "epoch": 41.77,
      "learning_rate": 0.00010110415539332883,
      "loss": 0.2874,
      "step": 41770
    },
    {
      "epoch": 41.78,
      "learning_rate": 0.00010108090269280949,
      "loss": 0.3141,
      "step": 41780
    },
    {
      "epoch": 41.79,
      "learning_rate": 0.00010105764714012185,
      "loss": 0.3169,
      "step": 41790
    },
    {
      "epoch": 41.8,
      "learning_rate": 0.00010103438873780912,
      "loss": 0.2316,
      "step": 41800
    },
    {
      "epoch": 41.81,
      "learning_rate": 0.00010101112748841474,
      "loss": 0.2362,
      "step": 41810
    },
    {
      "epoch": 41.82,
      "learning_rate": 0.0001009878633944826,
      "loss": 0.3172,
      "step": 41820
    },
    {
      "epoch": 41.83,
      "learning_rate": 0.00010096459645855677,
      "loss": 0.3386,
      "step": 41830
    },
    {
      "epoch": 41.84,
      "learning_rate": 0.00010094132668318171,
      "loss": 0.2266,
      "step": 41840
    },
    {
      "epoch": 41.85,
      "learning_rate": 0.00010091805407090217,
      "loss": 0.251,
      "step": 41850
    },
    {
      "epoch": 41.86,
      "learning_rate": 0.0001008947786242632,
      "loss": 0.3037,
      "step": 41860
    },
    {
      "epoch": 41.87,
      "learning_rate": 0.00010087150034581018,
      "loss": 0.2331,
      "step": 41870
    },
    {
      "epoch": 41.88,
      "learning_rate": 0.00010084821923808876,
      "loss": 0.3038,
      "step": 41880
    },
    {
      "epoch": 41.89,
      "learning_rate": 0.00010082493530364497,
      "loss": 0.3694,
      "step": 41890
    },
    {
      "epoch": 41.9,
      "learning_rate": 0.00010080164854502508,
      "loss": 0.2862,
      "step": 41900
    },
    {
      "epoch": 41.91,
      "learning_rate": 0.00010077835896477567,
      "loss": 0.3428,
      "step": 41910
    },
    {
      "epoch": 41.92,
      "learning_rate": 0.00010075506656544373,
      "loss": 0.279,
      "step": 41920
    },
    {
      "epoch": 41.93,
      "learning_rate": 0.00010073177134957641,
      "loss": 0.2799,
      "step": 41930
    },
    {
      "epoch": 41.94,
      "learning_rate": 0.00010070847331972122,
      "loss": 0.1912,
      "step": 41940
    },
    {
      "epoch": 41.95,
      "learning_rate": 0.0001006851724784261,
      "loss": 0.2149,
      "step": 41950
    },
    {
      "epoch": 41.96,
      "learning_rate": 0.00010066186882823912,
      "loss": 0.288,
      "step": 41960
    },
    {
      "epoch": 41.97,
      "learning_rate": 0.00010063856237170872,
      "loss": 0.3045,
      "step": 41970
    },
    {
      "epoch": 41.98,
      "learning_rate": 0.00010061525311138372,
      "loss": 0.2734,
      "step": 41980
    },
    {
      "epoch": 41.99,
      "learning_rate": 0.00010059194104981313,
      "loss": 0.3214,
      "step": 41990
    },
    {
      "epoch": 42.0,
      "learning_rate": 0.00010056862618954635,
      "loss": 0.2684,
      "step": 42000
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2732619047164917,
      "eval_runtime": 14.5566,
      "eval_samples_per_second": 137.395,
      "eval_steps_per_second": 17.174,
      "step": 42000
    },
    {
      "epoch": 42.01,
      "learning_rate": 0.00010054530853313305,
      "loss": 0.2602,
      "step": 42010
    },
    {
      "epoch": 42.02,
      "learning_rate": 0.00010052198808312322,
      "loss": 0.3637,
      "step": 42020
    },
    {
      "epoch": 42.03,
      "learning_rate": 0.00010049866484206713,
      "loss": 0.285,
      "step": 42030
    },
    {
      "epoch": 42.04,
      "learning_rate": 0.00010047533881251543,
      "loss": 0.2303,
      "step": 42040
    },
    {
      "epoch": 42.05,
      "learning_rate": 0.00010045200999701894,
      "loss": 0.2753,
      "step": 42050
    },
    {
      "epoch": 42.06,
      "learning_rate": 0.00010042867839812893,
      "loss": 0.3366,
      "step": 42060
    },
    {
      "epoch": 42.07,
      "learning_rate": 0.00010040534401839686,
      "loss": 0.2382,
      "step": 42070
    },
    {
      "epoch": 42.08,
      "learning_rate": 0.00010038200686037458,
      "loss": 0.2805,
      "step": 42080
    },
    {
      "epoch": 42.09,
      "learning_rate": 0.00010035866692661414,
      "loss": 0.3192,
      "step": 42090
    },
    {
      "epoch": 42.1,
      "learning_rate": 0.00010033532421966806,
      "loss": 0.2547,
      "step": 42100
    },
    {
      "epoch": 42.11,
      "learning_rate": 0.00010031197874208901,
      "loss": 0.3067,
      "step": 42110
    },
    {
      "epoch": 42.12,
      "learning_rate": 0.00010028863049643002,
      "loss": 0.3528,
      "step": 42120
    },
    {
      "epoch": 42.13,
      "learning_rate": 0.00010026527948524443,
      "loss": 0.3335,
      "step": 42130
    },
    {
      "epoch": 42.14,
      "learning_rate": 0.00010024192571108583,
      "loss": 0.2647,
      "step": 42140
    },
    {
      "epoch": 42.15,
      "learning_rate": 0.00010021856917650822,
      "loss": 0.3268,
      "step": 42150
    },
    {
      "epoch": 42.16,
      "learning_rate": 0.00010019520988406577,
      "loss": 0.3167,
      "step": 42160
    },
    {
      "epoch": 42.17,
      "learning_rate": 0.00010017184783631308,
      "loss": 0.277,
      "step": 42170
    },
    {
      "epoch": 42.18,
      "learning_rate": 0.00010014848303580492,
      "loss": 0.2521,
      "step": 42180
    },
    {
      "epoch": 42.19,
      "learning_rate": 0.0001001251154850965,
      "loss": 0.2094,
      "step": 42190
    },
    {
      "epoch": 42.2,
      "learning_rate": 0.00010010174518674321,
      "loss": 0.2798,
      "step": 42200
    },
    {
      "epoch": 42.21,
      "learning_rate": 0.00010007837214330081,
      "loss": 0.3447,
      "step": 42210
    },
    {
      "epoch": 42.22,
      "learning_rate": 0.00010005499635732534,
      "loss": 0.2958,
      "step": 42220
    },
    {
      "epoch": 42.23,
      "learning_rate": 0.00010003161783137312,
      "loss": 0.2722,
      "step": 42230
    },
    {
      "epoch": 42.24,
      "learning_rate": 0.00010000823656800081,
      "loss": 0.2889,
      "step": 42240
    },
    {
      "epoch": 42.25,
      "learning_rate": 9.998485256976537e-05,
      "loss": 0.2429,
      "step": 42250
    },
    {
      "epoch": 42.26,
      "learning_rate": 9.9961465839224e-05,
      "loss": 0.3117,
      "step": 42260
    },
    {
      "epoch": 42.27,
      "learning_rate": 9.993807637893426e-05,
      "loss": 0.3303,
      "step": 42270
    },
    {
      "epoch": 42.28,
      "learning_rate": 9.991468419145399e-05,
      "loss": 0.2952,
      "step": 42280
    },
    {
      "epoch": 42.29,
      "learning_rate": 9.989128927934128e-05,
      "loss": 0.3552,
      "step": 42290
    },
    {
      "epoch": 42.3,
      "learning_rate": 9.986789164515464e-05,
      "loss": 0.2885,
      "step": 42300
    },
    {
      "epoch": 42.31,
      "learning_rate": 9.984449129145274e-05,
      "loss": 0.3117,
      "step": 42310
    },
    {
      "epoch": 42.32,
      "learning_rate": 9.982108822079462e-05,
      "loss": 0.3288,
      "step": 42320
    },
    {
      "epoch": 42.33,
      "learning_rate": 9.979768243573961e-05,
      "loss": 0.2257,
      "step": 42330
    },
    {
      "epoch": 42.34,
      "learning_rate": 9.977427393884734e-05,
      "loss": 0.2338,
      "step": 42340
    },
    {
      "epoch": 42.35,
      "learning_rate": 9.975086273267771e-05,
      "loss": 0.2986,
      "step": 42350
    },
    {
      "epoch": 42.36,
      "learning_rate": 9.972744881979096e-05,
      "loss": 0.2989,
      "step": 42360
    },
    {
      "epoch": 42.37,
      "learning_rate": 9.970403220274758e-05,
      "loss": 0.3804,
      "step": 42370
    },
    {
      "epoch": 42.38,
      "learning_rate": 9.968061288410838e-05,
      "loss": 0.2658,
      "step": 42380
    },
    {
      "epoch": 42.39,
      "learning_rate": 9.965719086643444e-05,
      "loss": 0.2749,
      "step": 42390
    },
    {
      "epoch": 42.4,
      "learning_rate": 9.963376615228722e-05,
      "loss": 0.2433,
      "step": 42400
    },
    {
      "epoch": 42.41,
      "learning_rate": 9.961033874422835e-05,
      "loss": 0.3206,
      "step": 42410
    },
    {
      "epoch": 42.42,
      "learning_rate": 9.95869086448198e-05,
      "loss": 0.2669,
      "step": 42420
    },
    {
      "epoch": 42.43,
      "learning_rate": 9.956347585662394e-05,
      "loss": 0.2666,
      "step": 42430
    },
    {
      "epoch": 42.44,
      "learning_rate": 9.954004038220326e-05,
      "loss": 0.2533,
      "step": 42440
    },
    {
      "epoch": 42.45,
      "learning_rate": 9.951660222412067e-05,
      "loss": 0.1884,
      "step": 42450
    },
    {
      "epoch": 42.46,
      "learning_rate": 9.949316138493933e-05,
      "loss": 0.2504,
      "step": 42460
    },
    {
      "epoch": 42.47,
      "learning_rate": 9.946971786722269e-05,
      "loss": 0.302,
      "step": 42470
    },
    {
      "epoch": 42.48,
      "learning_rate": 9.944627167353447e-05,
      "loss": 0.2686,
      "step": 42480
    },
    {
      "epoch": 42.49,
      "learning_rate": 9.942282280643874e-05,
      "loss": 0.235,
      "step": 42490
    },
    {
      "epoch": 42.5,
      "learning_rate": 9.939937126849985e-05,
      "loss": 0.2578,
      "step": 42500
    },
    {
      "epoch": 42.51,
      "learning_rate": 9.937591706228237e-05,
      "loss": 0.2747,
      "step": 42510
    },
    {
      "epoch": 42.52,
      "learning_rate": 9.935246019035126e-05,
      "loss": 0.2406,
      "step": 42520
    },
    {
      "epoch": 42.53,
      "learning_rate": 9.932900065527172e-05,
      "loss": 0.2212,
      "step": 42530
    },
    {
      "epoch": 42.54,
      "learning_rate": 9.930553845960924e-05,
      "loss": 0.2766,
      "step": 42540
    },
    {
      "epoch": 42.55,
      "learning_rate": 9.928207360592964e-05,
      "loss": 0.2813,
      "step": 42550
    },
    {
      "epoch": 42.56,
      "learning_rate": 9.925860609679893e-05,
      "loss": 0.2678,
      "step": 42560
    },
    {
      "epoch": 42.57,
      "learning_rate": 9.923513593478357e-05,
      "loss": 0.2253,
      "step": 42570
    },
    {
      "epoch": 42.58,
      "learning_rate": 9.921166312245016e-05,
      "loss": 0.3381,
      "step": 42580
    },
    {
      "epoch": 42.59,
      "learning_rate": 9.91881876623657e-05,
      "loss": 0.1906,
      "step": 42590
    },
    {
      "epoch": 42.6,
      "learning_rate": 9.916470955709738e-05,
      "loss": 0.2251,
      "step": 42600
    },
    {
      "epoch": 42.61,
      "learning_rate": 9.914122880921275e-05,
      "loss": 0.3472,
      "step": 42610
    },
    {
      "epoch": 42.62,
      "learning_rate": 9.911774542127965e-05,
      "loss": 0.2863,
      "step": 42620
    },
    {
      "epoch": 42.63,
      "learning_rate": 9.909425939586618e-05,
      "loss": 0.357,
      "step": 42630
    },
    {
      "epoch": 42.64,
      "learning_rate": 9.90707707355407e-05,
      "loss": 0.2684,
      "step": 42640
    },
    {
      "epoch": 42.65,
      "learning_rate": 9.904727944287193e-05,
      "loss": 0.3037,
      "step": 42650
    },
    {
      "epoch": 42.66,
      "learning_rate": 9.902378552042884e-05,
      "loss": 0.2949,
      "step": 42660
    },
    {
      "epoch": 42.67,
      "learning_rate": 9.900028897078069e-05,
      "loss": 0.2922,
      "step": 42670
    },
    {
      "epoch": 42.68,
      "learning_rate": 9.897678979649702e-05,
      "loss": 0.2548,
      "step": 42680
    },
    {
      "epoch": 42.69,
      "learning_rate": 9.895328800014767e-05,
      "loss": 0.3225,
      "step": 42690
    },
    {
      "epoch": 42.7,
      "learning_rate": 9.892978358430274e-05,
      "loss": 0.226,
      "step": 42700
    },
    {
      "epoch": 42.71,
      "learning_rate": 9.890627655153267e-05,
      "loss": 0.2682,
      "step": 42710
    },
    {
      "epoch": 42.72,
      "learning_rate": 9.888276690440815e-05,
      "loss": 0.2427,
      "step": 42720
    },
    {
      "epoch": 42.73,
      "learning_rate": 9.885925464550014e-05,
      "loss": 0.2858,
      "step": 42730
    },
    {
      "epoch": 42.74,
      "learning_rate": 9.883573977737988e-05,
      "loss": 0.3034,
      "step": 42740
    },
    {
      "epoch": 42.75,
      "learning_rate": 9.8812222302619e-05,
      "loss": 0.2947,
      "step": 42750
    },
    {
      "epoch": 42.76,
      "learning_rate": 9.878870222378928e-05,
      "loss": 0.2774,
      "step": 42760
    },
    {
      "epoch": 42.77,
      "learning_rate": 9.876517954346281e-05,
      "loss": 0.2423,
      "step": 42770
    },
    {
      "epoch": 42.78,
      "learning_rate": 9.874165426421208e-05,
      "loss": 0.2874,
      "step": 42780
    },
    {
      "epoch": 42.79,
      "learning_rate": 9.871812638860973e-05,
      "loss": 0.2513,
      "step": 42790
    },
    {
      "epoch": 42.8,
      "learning_rate": 9.869459591922873e-05,
      "loss": 0.3033,
      "step": 42800
    },
    {
      "epoch": 42.81,
      "learning_rate": 9.867106285864233e-05,
      "loss": 0.286,
      "step": 42810
    },
    {
      "epoch": 42.82,
      "learning_rate": 9.864752720942411e-05,
      "loss": 0.2321,
      "step": 42820
    },
    {
      "epoch": 42.83,
      "learning_rate": 9.862398897414785e-05,
      "loss": 0.269,
      "step": 42830
    },
    {
      "epoch": 42.84,
      "learning_rate": 9.860044815538768e-05,
      "loss": 0.3137,
      "step": 42840
    },
    {
      "epoch": 42.85,
      "learning_rate": 9.857690475571799e-05,
      "loss": 0.2769,
      "step": 42850
    },
    {
      "epoch": 42.86,
      "learning_rate": 9.855335877771342e-05,
      "loss": 0.3273,
      "step": 42860
    },
    {
      "epoch": 42.87,
      "learning_rate": 9.852981022394897e-05,
      "loss": 0.3125,
      "step": 42870
    },
    {
      "epoch": 42.88,
      "learning_rate": 9.850625909699986e-05,
      "loss": 0.3079,
      "step": 42880
    },
    {
      "epoch": 42.89,
      "learning_rate": 9.848270539944156e-05,
      "loss": 0.2619,
      "step": 42890
    },
    {
      "epoch": 42.9,
      "learning_rate": 9.845914913384994e-05,
      "loss": 0.251,
      "step": 42900
    },
    {
      "epoch": 42.91,
      "learning_rate": 9.843559030280101e-05,
      "loss": 0.259,
      "step": 42910
    },
    {
      "epoch": 42.92,
      "learning_rate": 9.841202890887119e-05,
      "loss": 0.2883,
      "step": 42920
    },
    {
      "epoch": 42.93,
      "learning_rate": 9.838846495463705e-05,
      "loss": 0.1725,
      "step": 42930
    },
    {
      "epoch": 42.94,
      "learning_rate": 9.836489844267558e-05,
      "loss": 0.2234,
      "step": 42940
    },
    {
      "epoch": 42.95,
      "learning_rate": 9.834132937556395e-05,
      "loss": 0.2142,
      "step": 42950
    },
    {
      "epoch": 42.96,
      "learning_rate": 9.83177577558796e-05,
      "loss": 0.2361,
      "step": 42960
    },
    {
      "epoch": 42.97,
      "learning_rate": 9.829418358620034e-05,
      "loss": 0.3038,
      "step": 42970
    },
    {
      "epoch": 42.98,
      "learning_rate": 9.82706068691042e-05,
      "loss": 0.2512,
      "step": 42980
    },
    {
      "epoch": 42.99,
      "learning_rate": 9.824702760716942e-05,
      "loss": 0.3643,
      "step": 42990
    },
    {
      "epoch": 43.0,
      "learning_rate": 9.822344580297472e-05,
      "loss": 0.2257,
      "step": 43000
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.273169606924057,
      "eval_runtime": 14.5614,
      "eval_samples_per_second": 137.349,
      "eval_steps_per_second": 17.169,
      "step": 43000
    },
    {
      "epoch": 43.01,
      "learning_rate": 9.819986145909888e-05,
      "loss": 0.3014,
      "step": 43010
    },
    {
      "epoch": 43.02,
      "learning_rate": 9.817627457812105e-05,
      "loss": 0.2435,
      "step": 43020
    },
    {
      "epoch": 43.03,
      "learning_rate": 9.81526851626207e-05,
      "loss": 0.2694,
      "step": 43030
    },
    {
      "epoch": 43.04,
      "learning_rate": 9.81290932151775e-05,
      "loss": 0.2936,
      "step": 43040
    },
    {
      "epoch": 43.05,
      "learning_rate": 9.810549873837144e-05,
      "loss": 0.2957,
      "step": 43050
    },
    {
      "epoch": 43.06,
      "learning_rate": 9.808190173478278e-05,
      "loss": 0.251,
      "step": 43060
    },
    {
      "epoch": 43.07,
      "learning_rate": 9.805830220699204e-05,
      "loss": 0.2243,
      "step": 43070
    },
    {
      "epoch": 43.08,
      "learning_rate": 9.803470015758006e-05,
      "loss": 0.1974,
      "step": 43080
    },
    {
      "epoch": 43.09,
      "learning_rate": 9.801109558912787e-05,
      "loss": 0.252,
      "step": 43090
    },
    {
      "epoch": 43.1,
      "learning_rate": 9.79874885042169e-05,
      "loss": 0.2959,
      "step": 43100
    },
    {
      "epoch": 43.11,
      "learning_rate": 9.796387890542875e-05,
      "loss": 0.3198,
      "step": 43110
    },
    {
      "epoch": 43.12,
      "learning_rate": 9.79402667953453e-05,
      "loss": 0.2872,
      "step": 43120
    },
    {
      "epoch": 43.13,
      "learning_rate": 9.791665217654877e-05,
      "loss": 0.2186,
      "step": 43130
    },
    {
      "epoch": 43.14,
      "learning_rate": 9.789303505162163e-05,
      "loss": 0.2771,
      "step": 43140
    },
    {
      "epoch": 43.15,
      "learning_rate": 9.786941542314657e-05,
      "loss": 0.3381,
      "step": 43150
    },
    {
      "epoch": 43.16,
      "learning_rate": 9.784579329370663e-05,
      "loss": 0.3218,
      "step": 43160
    },
    {
      "epoch": 43.17,
      "learning_rate": 9.782216866588512e-05,
      "loss": 0.336,
      "step": 43170
    },
    {
      "epoch": 43.18,
      "learning_rate": 9.77985415422655e-05,
      "loss": 0.2339,
      "step": 43180
    },
    {
      "epoch": 43.19,
      "learning_rate": 9.77749119254317e-05,
      "loss": 0.2943,
      "step": 43190
    },
    {
      "epoch": 43.2,
      "learning_rate": 9.775127981796775e-05,
      "loss": 0.268,
      "step": 43200
    },
    {
      "epoch": 43.21,
      "learning_rate": 9.772764522245804e-05,
      "loss": 0.2587,
      "step": 43210
    },
    {
      "epoch": 43.22,
      "learning_rate": 9.770400814148724e-05,
      "loss": 0.2602,
      "step": 43220
    },
    {
      "epoch": 43.23,
      "learning_rate": 9.768036857764024e-05,
      "loss": 0.3145,
      "step": 43230
    },
    {
      "epoch": 43.24,
      "learning_rate": 9.765672653350221e-05,
      "loss": 0.2776,
      "step": 43240
    },
    {
      "epoch": 43.25,
      "learning_rate": 9.763308201165865e-05,
      "loss": 0.2946,
      "step": 43250
    },
    {
      "epoch": 43.26,
      "learning_rate": 9.760943501469525e-05,
      "loss": 0.3034,
      "step": 43260
    },
    {
      "epoch": 43.27,
      "learning_rate": 9.758578554519806e-05,
      "loss": 0.3292,
      "step": 43270
    },
    {
      "epoch": 43.28,
      "learning_rate": 9.756213360575329e-05,
      "loss": 0.2691,
      "step": 43280
    },
    {
      "epoch": 43.29,
      "learning_rate": 9.753847919894752e-05,
      "loss": 0.3544,
      "step": 43290
    },
    {
      "epoch": 43.3,
      "learning_rate": 9.751482232736757e-05,
      "loss": 0.2768,
      "step": 43300
    },
    {
      "epoch": 43.31,
      "learning_rate": 9.749116299360047e-05,
      "loss": 0.2219,
      "step": 43310
    },
    {
      "epoch": 43.32,
      "learning_rate": 9.746750120023363e-05,
      "loss": 0.2406,
      "step": 43320
    },
    {
      "epoch": 43.33,
      "learning_rate": 9.744383694985463e-05,
      "loss": 0.1943,
      "step": 43330
    },
    {
      "epoch": 43.34,
      "learning_rate": 9.742017024505135e-05,
      "loss": 0.2701,
      "step": 43340
    },
    {
      "epoch": 43.35,
      "learning_rate": 9.739650108841196e-05,
      "loss": 0.2782,
      "step": 43350
    },
    {
      "epoch": 43.36,
      "learning_rate": 9.73728294825249e-05,
      "loss": 0.2497,
      "step": 43360
    },
    {
      "epoch": 43.37,
      "learning_rate": 9.734915542997884e-05,
      "loss": 0.1875,
      "step": 43370
    },
    {
      "epoch": 43.38,
      "learning_rate": 9.732547893336274e-05,
      "loss": 0.2627,
      "step": 43380
    },
    {
      "epoch": 43.39,
      "learning_rate": 9.730179999526584e-05,
      "loss": 0.2644,
      "step": 43390
    },
    {
      "epoch": 43.4,
      "learning_rate": 9.727811861827761e-05,
      "loss": 0.2966,
      "step": 43400
    },
    {
      "epoch": 43.41,
      "learning_rate": 9.725443480498783e-05,
      "loss": 0.2883,
      "step": 43410
    },
    {
      "epoch": 43.42,
      "learning_rate": 9.723074855798653e-05,
      "loss": 0.3146,
      "step": 43420
    },
    {
      "epoch": 43.43,
      "learning_rate": 9.720705987986397e-05,
      "loss": 0.2599,
      "step": 43430
    },
    {
      "epoch": 43.44,
      "learning_rate": 9.718336877321073e-05,
      "loss": 0.2257,
      "step": 43440
    },
    {
      "epoch": 43.45,
      "learning_rate": 9.715967524061765e-05,
      "loss": 0.2774,
      "step": 43450
    },
    {
      "epoch": 43.46,
      "learning_rate": 9.713597928467578e-05,
      "loss": 0.293,
      "step": 43460
    },
    {
      "epoch": 43.47,
      "learning_rate": 9.711228090797651e-05,
      "loss": 0.2447,
      "step": 43470
    },
    {
      "epoch": 43.48,
      "learning_rate": 9.708858011311144e-05,
      "loss": 0.2712,
      "step": 43480
    },
    {
      "epoch": 43.49,
      "learning_rate": 9.706487690267248e-05,
      "loss": 0.2842,
      "step": 43490
    },
    {
      "epoch": 43.5,
      "learning_rate": 9.704117127925172e-05,
      "loss": 0.2776,
      "step": 43500
    },
    {
      "epoch": 43.51,
      "learning_rate": 9.701746324544164e-05,
      "loss": 0.2911,
      "step": 43510
    },
    {
      "epoch": 43.52,
      "learning_rate": 9.699375280383485e-05,
      "loss": 0.3388,
      "step": 43520
    },
    {
      "epoch": 43.53,
      "learning_rate": 9.697003995702434e-05,
      "loss": 0.3294,
      "step": 43530
    },
    {
      "epoch": 43.54,
      "learning_rate": 9.694632470760328e-05,
      "loss": 0.2871,
      "step": 43540
    },
    {
      "epoch": 43.55,
      "learning_rate": 9.692260705816516e-05,
      "loss": 0.26,
      "step": 43550
    },
    {
      "epoch": 43.56,
      "learning_rate": 9.689888701130367e-05,
      "loss": 0.2772,
      "step": 43560
    },
    {
      "epoch": 43.57,
      "learning_rate": 9.687516456961286e-05,
      "loss": 0.3295,
      "step": 43570
    },
    {
      "epoch": 43.58,
      "learning_rate": 9.685143973568692e-05,
      "loss": 0.2256,
      "step": 43580
    },
    {
      "epoch": 43.59,
      "learning_rate": 9.682771251212038e-05,
      "loss": 0.2599,
      "step": 43590
    },
    {
      "epoch": 43.6,
      "learning_rate": 9.680398290150803e-05,
      "loss": 0.2689,
      "step": 43600
    },
    {
      "epoch": 43.61,
      "learning_rate": 9.678025090644488e-05,
      "loss": 0.2001,
      "step": 43610
    },
    {
      "epoch": 43.62,
      "learning_rate": 9.675651652952626e-05,
      "loss": 0.364,
      "step": 43620
    },
    {
      "epoch": 43.63,
      "learning_rate": 9.673277977334765e-05,
      "loss": 0.208,
      "step": 43630
    },
    {
      "epoch": 43.64,
      "learning_rate": 9.670904064050496e-05,
      "loss": 0.3553,
      "step": 43640
    },
    {
      "epoch": 43.65,
      "learning_rate": 9.668529913359422e-05,
      "loss": 0.3637,
      "step": 43650
    },
    {
      "epoch": 43.66,
      "learning_rate": 9.666155525521175e-05,
      "loss": 0.3211,
      "step": 43660
    },
    {
      "epoch": 43.67,
      "learning_rate": 9.663780900795419e-05,
      "loss": 0.2866,
      "step": 43670
    },
    {
      "epoch": 43.68,
      "learning_rate": 9.661406039441837e-05,
      "loss": 0.2778,
      "step": 43680
    },
    {
      "epoch": 43.69,
      "learning_rate": 9.659030941720137e-05,
      "loss": 0.3208,
      "step": 43690
    },
    {
      "epoch": 43.7,
      "learning_rate": 9.656655607890063e-05,
      "loss": 0.2437,
      "step": 43700
    },
    {
      "epoch": 43.71,
      "learning_rate": 9.654280038211373e-05,
      "loss": 0.2772,
      "step": 43710
    },
    {
      "epoch": 43.72,
      "learning_rate": 9.652141824064701e-05,
      "loss": 0.26,
      "step": 43720
    },
    {
      "epoch": 43.73,
      "learning_rate": 9.649765806989382e-05,
      "loss": 0.2589,
      "step": 43730
    },
    {
      "epoch": 43.74,
      "learning_rate": 9.647389554818906e-05,
      "loss": 0.2182,
      "step": 43740
    },
    {
      "epoch": 43.75,
      "learning_rate": 9.645013067813137e-05,
      "loss": 0.3138,
      "step": 43750
    },
    {
      "epoch": 43.76,
      "learning_rate": 9.642636346231962e-05,
      "loss": 0.3014,
      "step": 43760
    },
    {
      "epoch": 43.77,
      "learning_rate": 9.640259390335301e-05,
      "loss": 0.3115,
      "step": 43770
    },
    {
      "epoch": 43.78,
      "learning_rate": 9.637882200383088e-05,
      "loss": 0.2864,
      "step": 43780
    },
    {
      "epoch": 43.79,
      "learning_rate": 9.635504776635295e-05,
      "loss": 0.2757,
      "step": 43790
    },
    {
      "epoch": 43.8,
      "learning_rate": 9.633127119351905e-05,
      "loss": 0.3164,
      "step": 43800
    },
    {
      "epoch": 43.81,
      "learning_rate": 9.630749228792947e-05,
      "loss": 0.334,
      "step": 43810
    },
    {
      "epoch": 43.82,
      "learning_rate": 9.628371105218453e-05,
      "loss": 0.3152,
      "step": 43820
    },
    {
      "epoch": 43.83,
      "learning_rate": 9.625992748888493e-05,
      "loss": 0.2254,
      "step": 43830
    },
    {
      "epoch": 43.84,
      "learning_rate": 9.623614160063168e-05,
      "loss": 0.2866,
      "step": 43840
    },
    {
      "epoch": 43.85,
      "learning_rate": 9.621235339002588e-05,
      "loss": 0.2858,
      "step": 43850
    },
    {
      "epoch": 43.86,
      "learning_rate": 9.6188562859669e-05,
      "loss": 0.2246,
      "step": 43860
    },
    {
      "epoch": 43.87,
      "learning_rate": 9.616477001216275e-05,
      "loss": 0.2613,
      "step": 43870
    },
    {
      "epoch": 43.88,
      "learning_rate": 9.614097485010908e-05,
      "loss": 0.2431,
      "step": 43880
    },
    {
      "epoch": 43.89,
      "learning_rate": 9.611717737611018e-05,
      "loss": 0.3396,
      "step": 43890
    },
    {
      "epoch": 43.9,
      "learning_rate": 9.609337759276851e-05,
      "loss": 0.2964,
      "step": 43900
    },
    {
      "epoch": 43.91,
      "learning_rate": 9.606957550268677e-05,
      "loss": 0.2501,
      "step": 43910
    },
    {
      "epoch": 43.92,
      "learning_rate": 9.604577110846794e-05,
      "loss": 0.2609,
      "step": 43920
    },
    {
      "epoch": 43.93,
      "learning_rate": 9.602196441271522e-05,
      "loss": 0.3292,
      "step": 43930
    },
    {
      "epoch": 43.94,
      "learning_rate": 9.59981554180321e-05,
      "loss": 0.3121,
      "step": 43940
    },
    {
      "epoch": 43.95,
      "learning_rate": 9.597434412702223e-05,
      "loss": 0.3206,
      "step": 43950
    },
    {
      "epoch": 43.96,
      "learning_rate": 9.595053054228965e-05,
      "loss": 0.2433,
      "step": 43960
    },
    {
      "epoch": 43.97,
      "learning_rate": 9.592671466643855e-05,
      "loss": 0.2943,
      "step": 43970
    },
    {
      "epoch": 43.98,
      "learning_rate": 9.590289650207337e-05,
      "loss": 0.2416,
      "step": 43980
    },
    {
      "epoch": 43.99,
      "learning_rate": 9.587907605179891e-05,
      "loss": 0.2518,
      "step": 43990
    },
    {
      "epoch": 44.0,
      "learning_rate": 9.585525331822005e-05,
      "loss": 0.2716,
      "step": 44000
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.27352991700172424,
      "eval_runtime": 14.5454,
      "eval_samples_per_second": 137.5,
      "eval_steps_per_second": 17.188,
      "step": 44000
    },
    {
      "epoch": 44.01,
      "learning_rate": 9.583142830394203e-05,
      "loss": 0.218,
      "step": 44010
    },
    {
      "epoch": 44.02,
      "learning_rate": 9.580760101157036e-05,
      "loss": 0.2167,
      "step": 44020
    },
    {
      "epoch": 44.03,
      "learning_rate": 9.578377144371068e-05,
      "loss": 0.2728,
      "step": 44030
    },
    {
      "epoch": 44.04,
      "learning_rate": 9.575993960296904e-05,
      "loss": 0.2394,
      "step": 44040
    },
    {
      "epoch": 44.05,
      "learning_rate": 9.57361054919516e-05,
      "loss": 0.3344,
      "step": 44050
    },
    {
      "epoch": 44.06,
      "learning_rate": 9.571226911326486e-05,
      "loss": 0.3079,
      "step": 44060
    },
    {
      "epoch": 44.07,
      "learning_rate": 9.568843046951551e-05,
      "loss": 0.3022,
      "step": 44070
    },
    {
      "epoch": 44.08,
      "learning_rate": 9.566458956331048e-05,
      "loss": 0.3083,
      "step": 44080
    },
    {
      "epoch": 44.09,
      "learning_rate": 9.564074639725703e-05,
      "loss": 0.3401,
      "step": 44090
    },
    {
      "epoch": 44.1,
      "learning_rate": 9.561690097396259e-05,
      "loss": 0.2947,
      "step": 44100
    },
    {
      "epoch": 44.11,
      "learning_rate": 9.559305329603483e-05,
      "loss": 0.3045,
      "step": 44110
    },
    {
      "epoch": 44.12,
      "learning_rate": 9.556920336608175e-05,
      "loss": 0.2505,
      "step": 44120
    },
    {
      "epoch": 44.13,
      "learning_rate": 9.55453511867115e-05,
      "loss": 0.2948,
      "step": 44130
    },
    {
      "epoch": 44.14,
      "learning_rate": 9.552149676053254e-05,
      "loss": 0.2685,
      "step": 44140
    },
    {
      "epoch": 44.15,
      "learning_rate": 9.549764009015355e-05,
      "loss": 0.297,
      "step": 44150
    },
    {
      "epoch": 44.16,
      "learning_rate": 9.547378117818346e-05,
      "loss": 0.3129,
      "step": 44160
    },
    {
      "epoch": 44.17,
      "learning_rate": 9.544992002723144e-05,
      "loss": 0.2769,
      "step": 44170
    },
    {
      "epoch": 44.18,
      "learning_rate": 9.54260566399069e-05,
      "loss": 0.2521,
      "step": 44180
    },
    {
      "epoch": 44.19,
      "learning_rate": 9.540219101881952e-05,
      "loss": 0.2421,
      "step": 44190
    },
    {
      "epoch": 44.2,
      "learning_rate": 9.537832316657922e-05,
      "loss": 0.2349,
      "step": 44200
    },
    {
      "epoch": 44.21,
      "learning_rate": 9.535445308579612e-05,
      "loss": 0.2682,
      "step": 44210
    },
    {
      "epoch": 44.22,
      "learning_rate": 9.533058077908064e-05,
      "loss": 0.2767,
      "step": 44220
    },
    {
      "epoch": 44.23,
      "learning_rate": 9.53067062490434e-05,
      "loss": 0.3118,
      "step": 44230
    },
    {
      "epoch": 44.24,
      "learning_rate": 9.528282949829531e-05,
      "loss": 0.2526,
      "step": 44240
    },
    {
      "epoch": 44.25,
      "learning_rate": 9.525895052944749e-05,
      "loss": 0.2578,
      "step": 44250
    },
    {
      "epoch": 44.26,
      "learning_rate": 9.523506934511127e-05,
      "loss": 0.3107,
      "step": 44260
    },
    {
      "epoch": 44.27,
      "learning_rate": 9.521118594789832e-05,
      "loss": 0.1899,
      "step": 44270
    },
    {
      "epoch": 44.28,
      "learning_rate": 9.518730034042043e-05,
      "loss": 0.2977,
      "step": 44280
    },
    {
      "epoch": 44.29,
      "learning_rate": 9.516341252528975e-05,
      "loss": 0.2596,
      "step": 44290
    },
    {
      "epoch": 44.3,
      "learning_rate": 9.513952250511857e-05,
      "loss": 0.2681,
      "step": 44300
    },
    {
      "epoch": 44.31,
      "learning_rate": 9.51156302825195e-05,
      "loss": 0.219,
      "step": 44310
    },
    {
      "epoch": 44.32,
      "learning_rate": 9.509173586010537e-05,
      "loss": 0.2868,
      "step": 44320
    },
    {
      "epoch": 44.33,
      "learning_rate": 9.506783924048916e-05,
      "loss": 0.2859,
      "step": 44330
    },
    {
      "epoch": 44.34,
      "learning_rate": 9.504394042628427e-05,
      "loss": 0.2861,
      "step": 44340
    },
    {
      "epoch": 44.35,
      "learning_rate": 9.502003942010418e-05,
      "loss": 0.3204,
      "step": 44350
    },
    {
      "epoch": 44.36,
      "learning_rate": 9.499613622456267e-05,
      "loss": 0.3027,
      "step": 44360
    },
    {
      "epoch": 44.37,
      "learning_rate": 9.497223084227376e-05,
      "loss": 0.3721,
      "step": 44370
    },
    {
      "epoch": 44.38,
      "learning_rate": 9.494832327585174e-05,
      "loss": 0.251,
      "step": 44380
    },
    {
      "epoch": 44.39,
      "learning_rate": 9.492441352791107e-05,
      "loss": 0.2867,
      "step": 44390
    },
    {
      "epoch": 44.4,
      "learning_rate": 9.490050160106646e-05,
      "loss": 0.1764,
      "step": 44400
    },
    {
      "epoch": 44.41,
      "learning_rate": 9.487658749793294e-05,
      "loss": 0.2679,
      "step": 44410
    },
    {
      "epoch": 44.42,
      "learning_rate": 9.48526712211257e-05,
      "loss": 0.3095,
      "step": 44420
    },
    {
      "epoch": 44.43,
      "learning_rate": 9.482875277326017e-05,
      "loss": 0.29,
      "step": 44430
    },
    {
      "epoch": 44.44,
      "learning_rate": 9.480483215695207e-05,
      "loss": 0.3154,
      "step": 44440
    },
    {
      "epoch": 44.45,
      "learning_rate": 9.47809093748173e-05,
      "loss": 0.2167,
      "step": 44450
    },
    {
      "epoch": 44.46,
      "learning_rate": 9.4756984429472e-05,
      "loss": 0.2169,
      "step": 44460
    },
    {
      "epoch": 44.47,
      "learning_rate": 9.473305732353259e-05,
      "loss": 0.2339,
      "step": 44470
    },
    {
      "epoch": 44.48,
      "learning_rate": 9.47091280596157e-05,
      "loss": 0.2742,
      "step": 44480
    },
    {
      "epoch": 44.49,
      "learning_rate": 9.46851966403382e-05,
      "loss": 0.2886,
      "step": 44490
    },
    {
      "epoch": 44.5,
      "learning_rate": 9.466126306831719e-05,
      "loss": 0.2967,
      "step": 44500
    },
    {
      "epoch": 44.51,
      "learning_rate": 9.463732734617001e-05,
      "loss": 0.2966,
      "step": 44510
    },
    {
      "epoch": 44.52,
      "learning_rate": 9.461338947651424e-05,
      "loss": 0.3147,
      "step": 44520
    },
    {
      "epoch": 44.53,
      "learning_rate": 9.458944946196767e-05,
      "loss": 0.2823,
      "step": 44530
    },
    {
      "epoch": 44.54,
      "learning_rate": 9.45655073051484e-05,
      "loss": 0.2328,
      "step": 44540
    },
    {
      "epoch": 44.55,
      "learning_rate": 9.454156300867464e-05,
      "loss": 0.2707,
      "step": 44550
    },
    {
      "epoch": 44.56,
      "learning_rate": 9.451761657516491e-05,
      "loss": 0.3287,
      "step": 44560
    },
    {
      "epoch": 44.57,
      "learning_rate": 9.449366800723802e-05,
      "loss": 0.3003,
      "step": 44570
    },
    {
      "epoch": 44.58,
      "learning_rate": 9.446971730751287e-05,
      "loss": 0.295,
      "step": 44580
    },
    {
      "epoch": 44.59,
      "learning_rate": 9.444576447860872e-05,
      "loss": 0.3287,
      "step": 44590
    },
    {
      "epoch": 44.6,
      "learning_rate": 9.4421809523145e-05,
      "loss": 0.261,
      "step": 44600
    },
    {
      "epoch": 44.61,
      "learning_rate": 9.43978524437414e-05,
      "loss": 0.2786,
      "step": 44610
    },
    {
      "epoch": 44.62,
      "learning_rate": 9.437389324301781e-05,
      "loss": 0.2412,
      "step": 44620
    },
    {
      "epoch": 44.63,
      "learning_rate": 9.434993192359439e-05,
      "loss": 0.2756,
      "step": 44630
    },
    {
      "epoch": 44.64,
      "learning_rate": 9.432596848809152e-05,
      "loss": 0.327,
      "step": 44640
    },
    {
      "epoch": 44.65,
      "learning_rate": 9.430200293912975e-05,
      "loss": 0.3066,
      "step": 44650
    },
    {
      "epoch": 44.66,
      "learning_rate": 9.427803527933002e-05,
      "loss": 0.3309,
      "step": 44660
    },
    {
      "epoch": 44.67,
      "learning_rate": 9.425406551131329e-05,
      "loss": 0.2248,
      "step": 44670
    },
    {
      "epoch": 44.68,
      "learning_rate": 9.42300936377009e-05,
      "loss": 0.3284,
      "step": 44680
    },
    {
      "epoch": 44.69,
      "learning_rate": 9.42061196611144e-05,
      "loss": 0.2435,
      "step": 44690
    },
    {
      "epoch": 44.7,
      "learning_rate": 9.418214358417554e-05,
      "loss": 0.286,
      "step": 44700
    },
    {
      "epoch": 44.71,
      "learning_rate": 9.41581654095063e-05,
      "loss": 0.2687,
      "step": 44710
    },
    {
      "epoch": 44.72,
      "learning_rate": 9.413418513972886e-05,
      "loss": 0.2836,
      "step": 44720
    },
    {
      "epoch": 44.73,
      "learning_rate": 9.411020277746572e-05,
      "loss": 0.2712,
      "step": 44730
    },
    {
      "epoch": 44.74,
      "learning_rate": 9.408621832533953e-05,
      "loss": 0.2542,
      "step": 44740
    },
    {
      "epoch": 44.75,
      "learning_rate": 9.406223178597322e-05,
      "loss": 0.2941,
      "step": 44750
    },
    {
      "epoch": 44.76,
      "learning_rate": 9.403824316198988e-05,
      "loss": 0.3037,
      "step": 44760
    },
    {
      "epoch": 44.77,
      "learning_rate": 9.401425245601288e-05,
      "loss": 0.3456,
      "step": 44770
    },
    {
      "epoch": 44.78,
      "learning_rate": 9.399025967066583e-05,
      "loss": 0.3296,
      "step": 44780
    },
    {
      "epoch": 44.79,
      "learning_rate": 9.396626480857256e-05,
      "loss": 0.2001,
      "step": 44790
    },
    {
      "epoch": 44.8,
      "learning_rate": 9.394226787235708e-05,
      "loss": 0.2336,
      "step": 44800
    },
    {
      "epoch": 44.81,
      "learning_rate": 9.391826886464362e-05,
      "loss": 0.2175,
      "step": 44810
    },
    {
      "epoch": 44.82,
      "learning_rate": 9.389426778805676e-05,
      "loss": 0.3121,
      "step": 44820
    },
    {
      "epoch": 44.83,
      "learning_rate": 9.387026464522118e-05,
      "loss": 0.319,
      "step": 44830
    },
    {
      "epoch": 44.84,
      "learning_rate": 9.384625943876182e-05,
      "loss": 0.2093,
      "step": 44840
    },
    {
      "epoch": 44.85,
      "learning_rate": 9.382225217130387e-05,
      "loss": 0.2965,
      "step": 44850
    },
    {
      "epoch": 44.86,
      "learning_rate": 9.379824284547273e-05,
      "loss": 0.2912,
      "step": 44860
    },
    {
      "epoch": 44.87,
      "learning_rate": 9.3774231463894e-05,
      "loss": 0.2264,
      "step": 44870
    },
    {
      "epoch": 44.88,
      "learning_rate": 9.375021802919354e-05,
      "loss": 0.2849,
      "step": 44880
    },
    {
      "epoch": 44.89,
      "learning_rate": 9.372620254399745e-05,
      "loss": 0.2597,
      "step": 44890
    },
    {
      "epoch": 44.9,
      "learning_rate": 9.370218501093198e-05,
      "loss": 0.2888,
      "step": 44900
    },
    {
      "epoch": 44.91,
      "learning_rate": 9.367816543262367e-05,
      "loss": 0.283,
      "step": 44910
    },
    {
      "epoch": 44.92,
      "learning_rate": 9.365414381169929e-05,
      "loss": 0.2519,
      "step": 44920
    },
    {
      "epoch": 44.93,
      "learning_rate": 9.363012015078579e-05,
      "loss": 0.2565,
      "step": 44930
    },
    {
      "epoch": 44.94,
      "learning_rate": 9.360609445251035e-05,
      "loss": 0.2686,
      "step": 44940
    },
    {
      "epoch": 44.95,
      "learning_rate": 9.35820667195004e-05,
      "loss": 0.3115,
      "step": 44950
    },
    {
      "epoch": 44.96,
      "learning_rate": 9.355803695438356e-05,
      "loss": 0.375,
      "step": 44960
    },
    {
      "epoch": 44.97,
      "learning_rate": 9.35340051597877e-05,
      "loss": 0.2835,
      "step": 44970
    },
    {
      "epoch": 44.98,
      "learning_rate": 9.350997133834093e-05,
      "loss": 0.2873,
      "step": 44980
    },
    {
      "epoch": 44.99,
      "learning_rate": 9.348593549267148e-05,
      "loss": 0.3065,
      "step": 44990
    },
    {
      "epoch": 45.0,
      "learning_rate": 9.346189762540797e-05,
      "loss": 0.2689,
      "step": 45000
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.808,
      "eval_loss": 0.2730914354324341,
      "eval_runtime": 15.7709,
      "eval_samples_per_second": 126.816,
      "eval_steps_per_second": 15.852,
      "step": 45000
    },
    {
      "epoch": 45.01,
      "learning_rate": 9.343785773917903e-05,
      "loss": 0.3119,
      "step": 45010
    },
    {
      "epoch": 45.02,
      "learning_rate": 9.341381583661374e-05,
      "loss": 0.2689,
      "step": 45020
    },
    {
      "epoch": 45.03,
      "learning_rate": 9.33897719203412e-05,
      "loss": 0.2771,
      "step": 45030
    },
    {
      "epoch": 45.04,
      "learning_rate": 9.336572599299087e-05,
      "loss": 0.2927,
      "step": 45040
    },
    {
      "epoch": 45.05,
      "learning_rate": 9.334167805719237e-05,
      "loss": 0.2544,
      "step": 45050
    },
    {
      "epoch": 45.06,
      "learning_rate": 9.331762811557554e-05,
      "loss": 0.3772,
      "step": 45060
    },
    {
      "epoch": 45.07,
      "learning_rate": 9.329357617077041e-05,
      "loss": 0.3113,
      "step": 45070
    },
    {
      "epoch": 45.08,
      "learning_rate": 9.32695222254073e-05,
      "loss": 0.314,
      "step": 45080
    },
    {
      "epoch": 45.09,
      "learning_rate": 9.324546628211671e-05,
      "loss": 0.2846,
      "step": 45090
    },
    {
      "epoch": 45.1,
      "learning_rate": 9.322140834352937e-05,
      "loss": 0.2672,
      "step": 45100
    },
    {
      "epoch": 45.11,
      "learning_rate": 9.31973484122762e-05,
      "loss": 0.27,
      "step": 45110
    },
    {
      "epoch": 45.12,
      "learning_rate": 9.317328649098836e-05,
      "loss": 0.2417,
      "step": 45120
    },
    {
      "epoch": 45.13,
      "learning_rate": 9.314922258229722e-05,
      "loss": 0.2774,
      "step": 45130
    },
    {
      "epoch": 45.14,
      "learning_rate": 9.312515668883442e-05,
      "loss": 0.2763,
      "step": 45140
    },
    {
      "epoch": 45.15,
      "learning_rate": 9.310108881323173e-05,
      "loss": 0.2504,
      "step": 45150
    },
    {
      "epoch": 45.16,
      "learning_rate": 9.307701895812115e-05,
      "loss": 0.2806,
      "step": 45160
    },
    {
      "epoch": 45.17,
      "learning_rate": 9.305294712613498e-05,
      "loss": 0.2891,
      "step": 45170
    },
    {
      "epoch": 45.18,
      "learning_rate": 9.302887331990567e-05,
      "loss": 0.2471,
      "step": 45180
    },
    {
      "epoch": 45.19,
      "learning_rate": 9.300479754206586e-05,
      "loss": 0.2844,
      "step": 45190
    },
    {
      "epoch": 45.2,
      "learning_rate": 9.298071979524845e-05,
      "loss": 0.3263,
      "step": 45200
    },
    {
      "epoch": 45.21,
      "learning_rate": 9.295664008208659e-05,
      "loss": 0.2593,
      "step": 45210
    },
    {
      "epoch": 45.22,
      "learning_rate": 9.293255840521353e-05,
      "loss": 0.3048,
      "step": 45220
    },
    {
      "epoch": 45.23,
      "learning_rate": 9.290847476726286e-05,
      "loss": 0.2668,
      "step": 45230
    },
    {
      "epoch": 45.24,
      "learning_rate": 9.288438917086832e-05,
      "loss": 0.2702,
      "step": 45240
    },
    {
      "epoch": 45.25,
      "learning_rate": 9.286030161866386e-05,
      "loss": 0.2676,
      "step": 45250
    },
    {
      "epoch": 45.26,
      "learning_rate": 9.283621211328365e-05,
      "loss": 0.3023,
      "step": 45260
    },
    {
      "epoch": 45.27,
      "learning_rate": 9.281212065736213e-05,
      "loss": 0.2197,
      "step": 45270
    },
    {
      "epoch": 45.28,
      "learning_rate": 9.27928460900056e-05,
      "loss": 0.3421,
      "step": 45280
    },
    {
      "epoch": 45.29,
      "learning_rate": 9.2768751129749e-05,
      "loss": 0.3527,
      "step": 45290
    },
    {
      "epoch": 45.3,
      "learning_rate": 9.274465422632851e-05,
      "loss": 0.3386,
      "step": 45300
    },
    {
      "epoch": 45.31,
      "learning_rate": 9.27205553823793e-05,
      "loss": 0.2203,
      "step": 45310
    },
    {
      "epoch": 45.32,
      "learning_rate": 9.26964546005368e-05,
      "loss": 0.29,
      "step": 45320
    },
    {
      "epoch": 45.33,
      "learning_rate": 9.267235188343661e-05,
      "loss": 0.214,
      "step": 45330
    },
    {
      "epoch": 45.34,
      "learning_rate": 9.26482472337146e-05,
      "loss": 0.2531,
      "step": 45340
    },
    {
      "epoch": 45.35,
      "learning_rate": 9.262414065400682e-05,
      "loss": 0.2696,
      "step": 45350
    },
    {
      "epoch": 45.36,
      "learning_rate": 9.260003214694952e-05,
      "loss": 0.2508,
      "step": 45360
    },
    {
      "epoch": 45.37,
      "learning_rate": 9.257592171517913e-05,
      "loss": 0.2336,
      "step": 45370
    },
    {
      "epoch": 45.38,
      "learning_rate": 9.25518093613324e-05,
      "loss": 0.2784,
      "step": 45380
    },
    {
      "epoch": 45.39,
      "learning_rate": 9.252769508804619e-05,
      "loss": 0.2249,
      "step": 45390
    },
    {
      "epoch": 45.4,
      "learning_rate": 9.250357889795757e-05,
      "loss": 0.2876,
      "step": 45400
    },
    {
      "epoch": 45.41,
      "learning_rate": 9.24794607937039e-05,
      "loss": 0.3375,
      "step": 45410
    },
    {
      "epoch": 45.42,
      "learning_rate": 9.245534077792268e-05,
      "loss": 0.2343,
      "step": 45420
    },
    {
      "epoch": 45.43,
      "learning_rate": 9.243121885325161e-05,
      "loss": 0.2079,
      "step": 45430
    },
    {
      "epoch": 45.44,
      "learning_rate": 9.240709502232868e-05,
      "loss": 0.1824,
      "step": 45440
    },
    {
      "epoch": 45.45,
      "learning_rate": 9.238296928779201e-05,
      "loss": 0.2898,
      "step": 45450
    },
    {
      "epoch": 45.46,
      "learning_rate": 9.235884165227992e-05,
      "loss": 0.2592,
      "step": 45460
    },
    {
      "epoch": 45.47,
      "learning_rate": 9.233471211843104e-05,
      "loss": 0.2666,
      "step": 45470
    },
    {
      "epoch": 45.48,
      "learning_rate": 9.231058068888409e-05,
      "loss": 0.3502,
      "step": 45480
    },
    {
      "epoch": 45.49,
      "learning_rate": 9.228644736627809e-05,
      "loss": 0.3227,
      "step": 45490
    },
    {
      "epoch": 45.5,
      "learning_rate": 9.226231215325215e-05,
      "loss": 0.3271,
      "step": 45500
    },
    {
      "epoch": 45.51,
      "learning_rate": 9.223817505244573e-05,
      "loss": 0.2586,
      "step": 45510
    },
    {
      "epoch": 45.52,
      "learning_rate": 9.221403606649839e-05,
      "loss": 0.3396,
      "step": 45520
    },
    {
      "epoch": 45.53,
      "learning_rate": 9.218989519804996e-05,
      "loss": 0.2799,
      "step": 45530
    },
    {
      "epoch": 45.54,
      "learning_rate": 9.216575244974044e-05,
      "loss": 0.295,
      "step": 45540
    },
    {
      "epoch": 45.55,
      "learning_rate": 9.214160782421003e-05,
      "loss": 0.2852,
      "step": 45550
    },
    {
      "epoch": 45.56,
      "learning_rate": 9.211746132409916e-05,
      "loss": 0.2778,
      "step": 45560
    },
    {
      "epoch": 45.57,
      "learning_rate": 9.209331295204846e-05,
      "loss": 0.2834,
      "step": 45570
    },
    {
      "epoch": 45.58,
      "learning_rate": 9.206916271069876e-05,
      "loss": 0.2332,
      "step": 45580
    },
    {
      "epoch": 45.59,
      "learning_rate": 9.204501060269107e-05,
      "loss": 0.3368,
      "step": 45590
    },
    {
      "epoch": 45.6,
      "learning_rate": 9.202085663066667e-05,
      "loss": 0.2645,
      "step": 45600
    },
    {
      "epoch": 45.61,
      "learning_rate": 9.199670079726697e-05,
      "loss": 0.2691,
      "step": 45610
    },
    {
      "epoch": 45.62,
      "learning_rate": 9.197254310513361e-05,
      "loss": 0.3206,
      "step": 45620
    },
    {
      "epoch": 45.63,
      "learning_rate": 9.194838355690848e-05,
      "loss": 0.3299,
      "step": 45630
    },
    {
      "epoch": 45.64,
      "learning_rate": 9.192422215523362e-05,
      "loss": 0.2774,
      "step": 45640
    },
    {
      "epoch": 45.65,
      "learning_rate": 9.190005890275122e-05,
      "loss": 0.2753,
      "step": 45650
    },
    {
      "epoch": 45.66,
      "learning_rate": 9.187589380210383e-05,
      "loss": 0.2593,
      "step": 45660
    },
    {
      "epoch": 45.67,
      "learning_rate": 9.185172685593406e-05,
      "loss": 0.1809,
      "step": 45670
    },
    {
      "epoch": 45.68,
      "learning_rate": 9.182755806688475e-05,
      "loss": 0.3305,
      "step": 45680
    },
    {
      "epoch": 45.69,
      "learning_rate": 9.1803387437599e-05,
      "loss": 0.2511,
      "step": 45690
    },
    {
      "epoch": 45.7,
      "learning_rate": 9.177921497072007e-05,
      "loss": 0.318,
      "step": 45700
    },
    {
      "epoch": 45.71,
      "learning_rate": 9.175504066889144e-05,
      "loss": 0.2949,
      "step": 45710
    },
    {
      "epoch": 45.72,
      "learning_rate": 9.173086453475671e-05,
      "loss": 0.2869,
      "step": 45720
    },
    {
      "epoch": 45.73,
      "learning_rate": 9.170668657095981e-05,
      "loss": 0.2861,
      "step": 45730
    },
    {
      "epoch": 45.74,
      "learning_rate": 9.16825067801448e-05,
      "loss": 0.2342,
      "step": 45740
    },
    {
      "epoch": 45.75,
      "learning_rate": 9.165832516495591e-05,
      "loss": 0.3035,
      "step": 45750
    },
    {
      "epoch": 45.76,
      "learning_rate": 9.16341417280376e-05,
      "loss": 0.2684,
      "step": 45760
    },
    {
      "epoch": 45.77,
      "learning_rate": 9.16099564720346e-05,
      "loss": 0.305,
      "step": 45770
    },
    {
      "epoch": 45.78,
      "learning_rate": 9.158576939959172e-05,
      "loss": 0.2595,
      "step": 45780
    },
    {
      "epoch": 45.79,
      "learning_rate": 9.156158051335402e-05,
      "loss": 0.3115,
      "step": 45790
    },
    {
      "epoch": 45.8,
      "learning_rate": 9.153738981596682e-05,
      "loss": 0.2684,
      "step": 45800
    },
    {
      "epoch": 45.81,
      "learning_rate": 9.151319731007548e-05,
      "loss": 0.252,
      "step": 45810
    },
    {
      "epoch": 45.82,
      "learning_rate": 9.148900299832575e-05,
      "loss": 0.2083,
      "step": 45820
    },
    {
      "epoch": 45.83,
      "learning_rate": 9.146480688336343e-05,
      "loss": 0.2252,
      "step": 45830
    },
    {
      "epoch": 45.84,
      "learning_rate": 9.144060896783459e-05,
      "loss": 0.26,
      "step": 45840
    },
    {
      "epoch": 45.85,
      "learning_rate": 9.141640925438545e-05,
      "loss": 0.278,
      "step": 45850
    },
    {
      "epoch": 45.86,
      "learning_rate": 9.13922077456625e-05,
      "loss": 0.3291,
      "step": 45860
    },
    {
      "epoch": 45.87,
      "learning_rate": 9.136800444431235e-05,
      "loss": 0.3539,
      "step": 45870
    },
    {
      "epoch": 45.88,
      "learning_rate": 9.134379935298182e-05,
      "loss": 0.2459,
      "step": 45880
    },
    {
      "epoch": 45.89,
      "learning_rate": 9.131959247431799e-05,
      "loss": 0.3544,
      "step": 45890
    },
    {
      "epoch": 45.9,
      "learning_rate": 9.129538381096807e-05,
      "loss": 0.3391,
      "step": 45900
    },
    {
      "epoch": 45.91,
      "learning_rate": 9.127117336557945e-05,
      "loss": 0.3031,
      "step": 45910
    },
    {
      "epoch": 45.92,
      "learning_rate": 9.124696114079979e-05,
      "loss": 0.2518,
      "step": 45920
    },
    {
      "epoch": 45.93,
      "learning_rate": 9.122274713927688e-05,
      "loss": 0.2882,
      "step": 45930
    },
    {
      "epoch": 45.94,
      "learning_rate": 9.119853136365874e-05,
      "loss": 0.3095,
      "step": 45940
    },
    {
      "epoch": 45.95,
      "learning_rate": 9.117431381659357e-05,
      "loss": 0.3237,
      "step": 45950
    },
    {
      "epoch": 45.96,
      "learning_rate": 9.115009450072973e-05,
      "loss": 0.3016,
      "step": 45960
    },
    {
      "epoch": 45.97,
      "learning_rate": 9.112587341871587e-05,
      "loss": 0.2802,
      "step": 45970
    },
    {
      "epoch": 45.98,
      "learning_rate": 9.110165057320072e-05,
      "loss": 0.3119,
      "step": 45980
    },
    {
      "epoch": 45.99,
      "learning_rate": 9.107742596683325e-05,
      "loss": 0.2423,
      "step": 45990
    },
    {
      "epoch": 46.0,
      "learning_rate": 9.10531996022627e-05,
      "loss": 0.2694,
      "step": 46000
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27318835258483887,
      "eval_runtime": 15.2388,
      "eval_samples_per_second": 131.244,
      "eval_steps_per_second": 16.406,
      "step": 46000
    },
    {
      "epoch": 46.01,
      "learning_rate": 9.102897148213833e-05,
      "loss": 0.199,
      "step": 46010
    },
    {
      "epoch": 46.02,
      "learning_rate": 9.100474160910976e-05,
      "loss": 0.2622,
      "step": 46020
    },
    {
      "epoch": 46.03,
      "learning_rate": 9.098050998582672e-05,
      "loss": 0.2773,
      "step": 46030
    },
    {
      "epoch": 46.04,
      "learning_rate": 9.095627661493911e-05,
      "loss": 0.2437,
      "step": 46040
    },
    {
      "epoch": 46.05,
      "learning_rate": 9.09320414990971e-05,
      "loss": 0.2857,
      "step": 46050
    },
    {
      "epoch": 46.06,
      "learning_rate": 9.090780464095098e-05,
      "loss": 0.2393,
      "step": 46060
    },
    {
      "epoch": 46.07,
      "learning_rate": 9.088356604315127e-05,
      "loss": 0.2358,
      "step": 46070
    },
    {
      "epoch": 46.08,
      "learning_rate": 9.085932570834864e-05,
      "loss": 0.3498,
      "step": 46080
    },
    {
      "epoch": 46.09,
      "learning_rate": 9.083508363919402e-05,
      "loss": 0.3153,
      "step": 46090
    },
    {
      "epoch": 46.1,
      "learning_rate": 9.081083983833842e-05,
      "loss": 0.2764,
      "step": 46100
    },
    {
      "epoch": 46.11,
      "learning_rate": 9.078659430843318e-05,
      "loss": 0.3306,
      "step": 46110
    },
    {
      "epoch": 46.12,
      "learning_rate": 9.076234705212972e-05,
      "loss": 0.2937,
      "step": 46120
    },
    {
      "epoch": 46.13,
      "learning_rate": 9.073809807207966e-05,
      "loss": 0.2498,
      "step": 46130
    },
    {
      "epoch": 46.14,
      "learning_rate": 9.071384737093486e-05,
      "loss": 0.3216,
      "step": 46140
    },
    {
      "epoch": 46.15,
      "learning_rate": 9.068959495134738e-05,
      "loss": 0.2329,
      "step": 46150
    },
    {
      "epoch": 46.16,
      "learning_rate": 9.066534081596933e-05,
      "loss": 0.2682,
      "step": 46160
    },
    {
      "epoch": 46.17,
      "learning_rate": 9.06410849674532e-05,
      "loss": 0.2683,
      "step": 46170
    },
    {
      "epoch": 46.18,
      "learning_rate": 9.061682740845151e-05,
      "loss": 0.2896,
      "step": 46180
    },
    {
      "epoch": 46.19,
      "learning_rate": 9.059256814161707e-05,
      "loss": 0.2497,
      "step": 46190
    },
    {
      "epoch": 46.2,
      "learning_rate": 9.056830716960281e-05,
      "loss": 0.298,
      "step": 46200
    },
    {
      "epoch": 46.21,
      "learning_rate": 9.054404449506191e-05,
      "loss": 0.2904,
      "step": 46210
    },
    {
      "epoch": 46.22,
      "learning_rate": 9.051978012064762e-05,
      "loss": 0.2491,
      "step": 46220
    },
    {
      "epoch": 46.23,
      "learning_rate": 9.049551404901355e-05,
      "loss": 0.2838,
      "step": 46230
    },
    {
      "epoch": 46.24,
      "learning_rate": 9.047124628281335e-05,
      "loss": 0.2147,
      "step": 46240
    },
    {
      "epoch": 46.25,
      "learning_rate": 9.044697682470093e-05,
      "loss": 0.292,
      "step": 46250
    },
    {
      "epoch": 46.26,
      "learning_rate": 9.042270567733033e-05,
      "loss": 0.2581,
      "step": 46260
    },
    {
      "epoch": 46.27,
      "learning_rate": 9.039843284335584e-05,
      "loss": 0.2323,
      "step": 46270
    },
    {
      "epoch": 46.28,
      "learning_rate": 9.037415832543189e-05,
      "loss": 0.29,
      "step": 46280
    },
    {
      "epoch": 46.29,
      "learning_rate": 9.034988212621307e-05,
      "loss": 0.2881,
      "step": 46290
    },
    {
      "epoch": 46.3,
      "learning_rate": 9.032560424835426e-05,
      "loss": 0.2431,
      "step": 46300
    },
    {
      "epoch": 46.31,
      "learning_rate": 9.030132469451039e-05,
      "loss": 0.3423,
      "step": 46310
    },
    {
      "epoch": 46.32,
      "learning_rate": 9.027704346733664e-05,
      "loss": 0.263,
      "step": 46320
    },
    {
      "epoch": 46.33,
      "learning_rate": 9.025276056948841e-05,
      "loss": 0.2206,
      "step": 46330
    },
    {
      "epoch": 46.34,
      "learning_rate": 9.022847600362121e-05,
      "loss": 0.3138,
      "step": 46340
    },
    {
      "epoch": 46.35,
      "learning_rate": 9.020418977239076e-05,
      "loss": 0.3555,
      "step": 46350
    },
    {
      "epoch": 46.36,
      "learning_rate": 9.017990187845299e-05,
      "loss": 0.2973,
      "step": 46360
    },
    {
      "epoch": 46.37,
      "learning_rate": 9.015561232446397e-05,
      "loss": 0.2566,
      "step": 46370
    },
    {
      "epoch": 46.38,
      "learning_rate": 9.013132111307997e-05,
      "loss": 0.3039,
      "step": 46380
    },
    {
      "epoch": 46.39,
      "learning_rate": 9.010702824695744e-05,
      "loss": 0.2965,
      "step": 46390
    },
    {
      "epoch": 46.4,
      "learning_rate": 9.008273372875302e-05,
      "loss": 0.2954,
      "step": 46400
    },
    {
      "epoch": 46.41,
      "learning_rate": 9.005843756112352e-05,
      "loss": 0.3206,
      "step": 46410
    },
    {
      "epoch": 46.42,
      "learning_rate": 9.003413974672591e-05,
      "loss": 0.2785,
      "step": 46420
    },
    {
      "epoch": 46.43,
      "learning_rate": 9.000984028821738e-05,
      "loss": 0.3184,
      "step": 46430
    },
    {
      "epoch": 46.44,
      "learning_rate": 8.998553918825532e-05,
      "loss": 0.2788,
      "step": 46440
    },
    {
      "epoch": 46.45,
      "learning_rate": 8.996123644949718e-05,
      "loss": 0.2165,
      "step": 46450
    },
    {
      "epoch": 46.46,
      "learning_rate": 8.993693207460074e-05,
      "loss": 0.3153,
      "step": 46460
    },
    {
      "epoch": 46.47,
      "learning_rate": 8.991262606622384e-05,
      "loss": 0.3736,
      "step": 46470
    },
    {
      "epoch": 46.48,
      "learning_rate": 8.988831842702461e-05,
      "loss": 0.315,
      "step": 46480
    },
    {
      "epoch": 46.49,
      "learning_rate": 8.986400915966122e-05,
      "loss": 0.2001,
      "step": 46490
    },
    {
      "epoch": 46.5,
      "learning_rate": 8.983969826679217e-05,
      "loss": 0.3129,
      "step": 46500
    },
    {
      "epoch": 46.51,
      "learning_rate": 8.981538575107603e-05,
      "loss": 0.2758,
      "step": 46510
    },
    {
      "epoch": 46.52,
      "learning_rate": 8.979107161517156e-05,
      "loss": 0.3032,
      "step": 46520
    },
    {
      "epoch": 46.53,
      "learning_rate": 8.976675586173775e-05,
      "loss": 0.2956,
      "step": 46530
    },
    {
      "epoch": 46.54,
      "learning_rate": 8.974243849343372e-05,
      "loss": 0.259,
      "step": 46540
    },
    {
      "epoch": 46.55,
      "learning_rate": 8.971811951291876e-05,
      "loss": 0.3566,
      "step": 46550
    },
    {
      "epoch": 46.56,
      "learning_rate": 8.969379892285242e-05,
      "loss": 0.2927,
      "step": 46560
    },
    {
      "epoch": 46.57,
      "learning_rate": 8.96694767258943e-05,
      "loss": 0.2102,
      "step": 46570
    },
    {
      "epoch": 46.58,
      "learning_rate": 8.964515292470424e-05,
      "loss": 0.2414,
      "step": 46580
    },
    {
      "epoch": 46.59,
      "learning_rate": 8.96208275219423e-05,
      "loss": 0.2847,
      "step": 46590
    },
    {
      "epoch": 46.6,
      "learning_rate": 8.959650052026864e-05,
      "loss": 0.3651,
      "step": 46600
    },
    {
      "epoch": 46.61,
      "learning_rate": 8.95721719223436e-05,
      "loss": 0.2961,
      "step": 46610
    },
    {
      "epoch": 46.62,
      "learning_rate": 8.95478417308278e-05,
      "loss": 0.2744,
      "step": 46620
    },
    {
      "epoch": 46.63,
      "learning_rate": 8.952350994838186e-05,
      "loss": 0.263,
      "step": 46630
    },
    {
      "epoch": 46.64,
      "learning_rate": 8.949917657766673e-05,
      "loss": 0.2255,
      "step": 46640
    },
    {
      "epoch": 46.65,
      "learning_rate": 8.947484162134344e-05,
      "loss": 0.239,
      "step": 46650
    },
    {
      "epoch": 46.66,
      "learning_rate": 8.945050508207323e-05,
      "loss": 0.2283,
      "step": 46660
    },
    {
      "epoch": 46.67,
      "learning_rate": 8.942616696251751e-05,
      "loss": 0.2938,
      "step": 46670
    },
    {
      "epoch": 46.68,
      "learning_rate": 8.940182726533786e-05,
      "loss": 0.3135,
      "step": 46680
    },
    {
      "epoch": 46.69,
      "learning_rate": 8.937748599319604e-05,
      "loss": 0.3225,
      "step": 46690
    },
    {
      "epoch": 46.7,
      "learning_rate": 8.935314314875397e-05,
      "loss": 0.2898,
      "step": 46700
    },
    {
      "epoch": 46.71,
      "learning_rate": 8.932879873467373e-05,
      "loss": 0.2851,
      "step": 46710
    },
    {
      "epoch": 46.72,
      "learning_rate": 8.930445275361761e-05,
      "loss": 0.3118,
      "step": 46720
    },
    {
      "epoch": 46.73,
      "learning_rate": 8.928010520824805e-05,
      "loss": 0.2653,
      "step": 46730
    },
    {
      "epoch": 46.74,
      "learning_rate": 8.925575610122765e-05,
      "loss": 0.3209,
      "step": 46740
    },
    {
      "epoch": 46.75,
      "learning_rate": 8.92314054352192e-05,
      "loss": 0.2165,
      "step": 46750
    },
    {
      "epoch": 46.76,
      "learning_rate": 8.920705321288564e-05,
      "loss": 0.2775,
      "step": 46760
    },
    {
      "epoch": 46.77,
      "learning_rate": 8.91826994368901e-05,
      "loss": 0.2324,
      "step": 46770
    },
    {
      "epoch": 46.78,
      "learning_rate": 8.915834410989588e-05,
      "loss": 0.2352,
      "step": 46780
    },
    {
      "epoch": 46.79,
      "learning_rate": 8.913398723456644e-05,
      "loss": 0.1878,
      "step": 46790
    },
    {
      "epoch": 46.8,
      "learning_rate": 8.910962881356538e-05,
      "loss": 0.3223,
      "step": 46800
    },
    {
      "epoch": 46.81,
      "learning_rate": 8.908526884955655e-05,
      "loss": 0.3112,
      "step": 46810
    },
    {
      "epoch": 46.82,
      "learning_rate": 8.906090734520391e-05,
      "loss": 0.2445,
      "step": 46820
    },
    {
      "epoch": 46.83,
      "learning_rate": 8.903654430317155e-05,
      "loss": 0.3298,
      "step": 46830
    },
    {
      "epoch": 46.84,
      "learning_rate": 8.901217972612383e-05,
      "loss": 0.2448,
      "step": 46840
    },
    {
      "epoch": 46.85,
      "learning_rate": 8.898781361672519e-05,
      "loss": 0.2767,
      "step": 46850
    },
    {
      "epoch": 46.86,
      "learning_rate": 8.89634459776403e-05,
      "loss": 0.3166,
      "step": 46860
    },
    {
      "epoch": 46.87,
      "learning_rate": 8.893907681153394e-05,
      "loss": 0.2049,
      "step": 46870
    },
    {
      "epoch": 46.88,
      "learning_rate": 8.89147061210711e-05,
      "loss": 0.2604,
      "step": 46880
    },
    {
      "epoch": 46.89,
      "learning_rate": 8.889033390891691e-05,
      "loss": 0.3426,
      "step": 46890
    },
    {
      "epoch": 46.9,
      "learning_rate": 8.886596017773669e-05,
      "loss": 0.2884,
      "step": 46900
    },
    {
      "epoch": 46.91,
      "learning_rate": 8.884158493019593e-05,
      "loss": 0.2539,
      "step": 46910
    },
    {
      "epoch": 46.92,
      "learning_rate": 8.881720816896023e-05,
      "loss": 0.3348,
      "step": 46920
    },
    {
      "epoch": 46.93,
      "learning_rate": 8.879282989669542e-05,
      "loss": 0.3119,
      "step": 46930
    },
    {
      "epoch": 46.94,
      "learning_rate": 8.876845011606748e-05,
      "loss": 0.2772,
      "step": 46940
    },
    {
      "epoch": 46.95,
      "learning_rate": 8.874406882974253e-05,
      "loss": 0.2944,
      "step": 46950
    },
    {
      "epoch": 46.96,
      "learning_rate": 8.871968604038687e-05,
      "loss": 0.2523,
      "step": 46960
    },
    {
      "epoch": 46.97,
      "learning_rate": 8.869530175066696e-05,
      "loss": 0.2863,
      "step": 46970
    },
    {
      "epoch": 46.98,
      "learning_rate": 8.867091596324948e-05,
      "loss": 0.2611,
      "step": 46980
    },
    {
      "epoch": 46.99,
      "learning_rate": 8.864652868080117e-05,
      "loss": 0.234,
      "step": 46990
    },
    {
      "epoch": 47.0,
      "learning_rate": 8.862213990598898e-05,
      "loss": 0.2946,
      "step": 47000
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.8105,
      "eval_loss": 0.2730400264263153,
      "eval_runtime": 15.0268,
      "eval_samples_per_second": 133.095,
      "eval_steps_per_second": 16.637,
      "step": 47000
    },
    {
      "epoch": 47.01,
      "learning_rate": 8.859774964148008e-05,
      "loss": 0.2422,
      "step": 47010
    },
    {
      "epoch": 47.02,
      "learning_rate": 8.85733578899417e-05,
      "loss": 0.3119,
      "step": 47020
    },
    {
      "epoch": 47.03,
      "learning_rate": 8.854896465404133e-05,
      "loss": 0.2959,
      "step": 47030
    },
    {
      "epoch": 47.04,
      "learning_rate": 8.852456993644654e-05,
      "loss": 0.289,
      "step": 47040
    },
    {
      "epoch": 47.05,
      "learning_rate": 8.850017373982514e-05,
      "loss": 0.2327,
      "step": 47050
    },
    {
      "epoch": 47.06,
      "learning_rate": 8.847577606684499e-05,
      "loss": 0.2937,
      "step": 47060
    },
    {
      "epoch": 47.07,
      "learning_rate": 8.845137692017427e-05,
      "loss": 0.2613,
      "step": 47070
    },
    {
      "epoch": 47.08,
      "learning_rate": 8.842697630248118e-05,
      "loss": 0.2251,
      "step": 47080
    },
    {
      "epoch": 47.09,
      "learning_rate": 8.840257421643415e-05,
      "loss": 0.2489,
      "step": 47090
    },
    {
      "epoch": 47.1,
      "learning_rate": 8.837817066470176e-05,
      "loss": 0.3031,
      "step": 47100
    },
    {
      "epoch": 47.11,
      "learning_rate": 8.835376564995273e-05,
      "loss": 0.2783,
      "step": 47110
    },
    {
      "epoch": 47.12,
      "learning_rate": 8.832935917485596e-05,
      "loss": 0.3182,
      "step": 47120
    },
    {
      "epoch": 47.13,
      "learning_rate": 8.830495124208052e-05,
      "loss": 0.337,
      "step": 47130
    },
    {
      "epoch": 47.14,
      "learning_rate": 8.828054185429563e-05,
      "loss": 0.2577,
      "step": 47140
    },
    {
      "epoch": 47.15,
      "learning_rate": 8.825613101417061e-05,
      "loss": 0.3122,
      "step": 47150
    },
    {
      "epoch": 47.16,
      "learning_rate": 8.823171872437508e-05,
      "loss": 0.2904,
      "step": 47160
    },
    {
      "epoch": 47.17,
      "learning_rate": 8.820730498757868e-05,
      "loss": 0.3051,
      "step": 47170
    },
    {
      "epoch": 47.18,
      "learning_rate": 8.818288980645122e-05,
      "loss": 0.2693,
      "step": 47180
    },
    {
      "epoch": 47.19,
      "learning_rate": 8.815847318366278e-05,
      "loss": 0.2996,
      "step": 47190
    },
    {
      "epoch": 47.2,
      "learning_rate": 8.813405512188349e-05,
      "loss": 0.2778,
      "step": 47200
    },
    {
      "epoch": 47.21,
      "learning_rate": 8.810963562378368e-05,
      "loss": 0.2864,
      "step": 47210
    },
    {
      "epoch": 47.22,
      "learning_rate": 8.808521469203381e-05,
      "loss": 0.2344,
      "step": 47220
    },
    {
      "epoch": 47.23,
      "learning_rate": 8.806079232930456e-05,
      "loss": 0.2513,
      "step": 47230
    },
    {
      "epoch": 47.24,
      "learning_rate": 8.803636853826671e-05,
      "loss": 0.2827,
      "step": 47240
    },
    {
      "epoch": 47.25,
      "learning_rate": 8.801194332159118e-05,
      "loss": 0.2263,
      "step": 47250
    },
    {
      "epoch": 47.26,
      "learning_rate": 8.798751668194908e-05,
      "loss": 0.2954,
      "step": 47260
    },
    {
      "epoch": 47.27,
      "learning_rate": 8.796308862201169e-05,
      "loss": 0.3302,
      "step": 47270
    },
    {
      "epoch": 47.28,
      "learning_rate": 8.793865914445043e-05,
      "loss": 0.3809,
      "step": 47280
    },
    {
      "epoch": 47.29,
      "learning_rate": 8.791422825193684e-05,
      "loss": 0.3034,
      "step": 47290
    },
    {
      "epoch": 47.3,
      "learning_rate": 8.78897959471427e-05,
      "loss": 0.2343,
      "step": 47300
    },
    {
      "epoch": 47.31,
      "learning_rate": 8.786536223273982e-05,
      "loss": 0.2684,
      "step": 47310
    },
    {
      "epoch": 47.32,
      "learning_rate": 8.784092711140026e-05,
      "loss": 0.2696,
      "step": 47320
    },
    {
      "epoch": 47.33,
      "learning_rate": 8.781649058579624e-05,
      "loss": 0.2734,
      "step": 47330
    },
    {
      "epoch": 47.34,
      "learning_rate": 8.779205265860007e-05,
      "loss": 0.2864,
      "step": 47340
    },
    {
      "epoch": 47.35,
      "learning_rate": 8.776761333248426e-05,
      "loss": 0.2597,
      "step": 47350
    },
    {
      "epoch": 47.36,
      "learning_rate": 8.774317261012146e-05,
      "loss": 0.3141,
      "step": 47360
    },
    {
      "epoch": 47.37,
      "learning_rate": 8.771873049418443e-05,
      "loss": 0.2518,
      "step": 47370
    },
    {
      "epoch": 47.38,
      "learning_rate": 8.769428698734619e-05,
      "loss": 0.3014,
      "step": 47380
    },
    {
      "epoch": 47.39,
      "learning_rate": 8.76698420922798e-05,
      "loss": 0.3209,
      "step": 47390
    },
    {
      "epoch": 47.4,
      "learning_rate": 8.764539581165853e-05,
      "loss": 0.298,
      "step": 47400
    },
    {
      "epoch": 47.41,
      "learning_rate": 8.762094814815578e-05,
      "loss": 0.2619,
      "step": 47410
    },
    {
      "epoch": 47.42,
      "learning_rate": 8.759649910444512e-05,
      "loss": 0.2546,
      "step": 47420
    },
    {
      "epoch": 47.43,
      "learning_rate": 8.757204868320025e-05,
      "loss": 0.2219,
      "step": 47430
    },
    {
      "epoch": 47.44,
      "learning_rate": 8.754759688709504e-05,
      "loss": 0.3235,
      "step": 47440
    },
    {
      "epoch": 47.45,
      "learning_rate": 8.75231437188035e-05,
      "loss": 0.2178,
      "step": 47450
    },
    {
      "epoch": 47.46,
      "learning_rate": 8.74986891809998e-05,
      "loss": 0.2167,
      "step": 47460
    },
    {
      "epoch": 47.47,
      "learning_rate": 8.74742332763582e-05,
      "loss": 0.3209,
      "step": 47470
    },
    {
      "epoch": 47.48,
      "learning_rate": 8.744977600755324e-05,
      "loss": 0.2518,
      "step": 47480
    },
    {
      "epoch": 47.49,
      "learning_rate": 8.742531737725951e-05,
      "loss": 0.2518,
      "step": 47490
    },
    {
      "epoch": 47.5,
      "learning_rate": 8.740085738815172e-05,
      "loss": 0.1809,
      "step": 47500
    },
    {
      "epoch": 47.51,
      "learning_rate": 8.737639604290484e-05,
      "loss": 0.2779,
      "step": 47510
    },
    {
      "epoch": 47.52,
      "learning_rate": 8.735193334419388e-05,
      "loss": 0.2344,
      "step": 47520
    },
    {
      "epoch": 47.53,
      "learning_rate": 8.732746929469405e-05,
      "loss": 0.2774,
      "step": 47530
    },
    {
      "epoch": 47.54,
      "learning_rate": 8.730300389708072e-05,
      "loss": 0.2847,
      "step": 47540
    },
    {
      "epoch": 47.55,
      "learning_rate": 8.72785371540294e-05,
      "loss": 0.3121,
      "step": 47550
    },
    {
      "epoch": 47.56,
      "learning_rate": 8.72540690682157e-05,
      "loss": 0.3047,
      "step": 47560
    },
    {
      "epoch": 47.57,
      "learning_rate": 8.722959964231544e-05,
      "loss": 0.2881,
      "step": 47570
    },
    {
      "epoch": 47.58,
      "learning_rate": 8.720512887900454e-05,
      "loss": 0.2862,
      "step": 47580
    },
    {
      "epoch": 47.59,
      "learning_rate": 8.71806567809591e-05,
      "loss": 0.2945,
      "step": 47590
    },
    {
      "epoch": 47.6,
      "learning_rate": 8.715618335085534e-05,
      "loss": 0.373,
      "step": 47600
    },
    {
      "epoch": 47.61,
      "learning_rate": 8.713170859136967e-05,
      "loss": 0.2764,
      "step": 47610
    },
    {
      "epoch": 47.62,
      "learning_rate": 8.710723250517857e-05,
      "loss": 0.2856,
      "step": 47620
    },
    {
      "epoch": 47.63,
      "learning_rate": 8.708275509495872e-05,
      "loss": 0.2334,
      "step": 47630
    },
    {
      "epoch": 47.64,
      "learning_rate": 8.705827636338695e-05,
      "loss": 0.2366,
      "step": 47640
    },
    {
      "epoch": 47.65,
      "learning_rate": 8.70337963131402e-05,
      "loss": 0.2515,
      "step": 47650
    },
    {
      "epoch": 47.66,
      "learning_rate": 8.700931494689556e-05,
      "loss": 0.2763,
      "step": 47660
    },
    {
      "epoch": 47.67,
      "learning_rate": 8.698483226733032e-05,
      "loss": 0.3735,
      "step": 47670
    },
    {
      "epoch": 47.68,
      "learning_rate": 8.696034827712183e-05,
      "loss": 0.346,
      "step": 47680
    },
    {
      "epoch": 47.69,
      "learning_rate": 8.693586297894764e-05,
      "loss": 0.2953,
      "step": 47690
    },
    {
      "epoch": 47.7,
      "learning_rate": 8.691137637548542e-05,
      "loss": 0.2325,
      "step": 47700
    },
    {
      "epoch": 47.71,
      "learning_rate": 8.688688846941298e-05,
      "loss": 0.3479,
      "step": 47710
    },
    {
      "epoch": 47.72,
      "learning_rate": 8.686239926340829e-05,
      "loss": 0.1993,
      "step": 47720
    },
    {
      "epoch": 47.73,
      "learning_rate": 8.683790876014947e-05,
      "loss": 0.3813,
      "step": 47730
    },
    {
      "epoch": 47.74,
      "learning_rate": 8.681341696231473e-05,
      "loss": 0.3026,
      "step": 47740
    },
    {
      "epoch": 47.75,
      "learning_rate": 8.678892387258248e-05,
      "loss": 0.2692,
      "step": 47750
    },
    {
      "epoch": 47.76,
      "learning_rate": 8.676442949363124e-05,
      "loss": 0.2852,
      "step": 47760
    },
    {
      "epoch": 47.77,
      "learning_rate": 8.673993382813968e-05,
      "loss": 0.3123,
      "step": 47770
    },
    {
      "epoch": 47.78,
      "learning_rate": 8.67154368787866e-05,
      "loss": 0.2667,
      "step": 47780
    },
    {
      "epoch": 47.79,
      "learning_rate": 8.669093864825095e-05,
      "loss": 0.2594,
      "step": 47790
    },
    {
      "epoch": 47.8,
      "learning_rate": 8.666643913921182e-05,
      "loss": 0.2897,
      "step": 47800
    },
    {
      "epoch": 47.81,
      "learning_rate": 8.664193835434847e-05,
      "loss": 0.2547,
      "step": 47810
    },
    {
      "epoch": 47.82,
      "learning_rate": 8.661743629634023e-05,
      "loss": 0.2569,
      "step": 47820
    },
    {
      "epoch": 47.83,
      "learning_rate": 8.659293296786662e-05,
      "loss": 0.3115,
      "step": 47830
    },
    {
      "epoch": 47.84,
      "learning_rate": 8.656842837160733e-05,
      "loss": 0.2171,
      "step": 47840
    },
    {
      "epoch": 47.85,
      "learning_rate": 8.654392251024205e-05,
      "loss": 0.3382,
      "step": 47850
    },
    {
      "epoch": 47.86,
      "learning_rate": 8.651941538645078e-05,
      "loss": 0.2976,
      "step": 47860
    },
    {
      "epoch": 47.87,
      "learning_rate": 8.649490700291357e-05,
      "loss": 0.285,
      "step": 47870
    },
    {
      "epoch": 47.88,
      "learning_rate": 8.647039736231062e-05,
      "loss": 0.3018,
      "step": 47880
    },
    {
      "epoch": 47.89,
      "learning_rate": 8.644588646732224e-05,
      "loss": 0.2678,
      "step": 47890
    },
    {
      "epoch": 47.9,
      "learning_rate": 8.642137432062895e-05,
      "loss": 0.3174,
      "step": 47900
    },
    {
      "epoch": 47.91,
      "learning_rate": 8.639686092491131e-05,
      "loss": 0.2831,
      "step": 47910
    },
    {
      "epoch": 47.92,
      "learning_rate": 8.637234628285011e-05,
      "loss": 0.3415,
      "step": 47920
    },
    {
      "epoch": 47.93,
      "learning_rate": 8.63478303971262e-05,
      "loss": 0.232,
      "step": 47930
    },
    {
      "epoch": 47.94,
      "learning_rate": 8.632331327042064e-05,
      "loss": 0.2091,
      "step": 47940
    },
    {
      "epoch": 47.95,
      "learning_rate": 8.629879490541454e-05,
      "loss": 0.2237,
      "step": 47950
    },
    {
      "epoch": 47.96,
      "learning_rate": 8.627427530478924e-05,
      "loss": 0.2569,
      "step": 47960
    },
    {
      "epoch": 47.97,
      "learning_rate": 8.624975447122614e-05,
      "loss": 0.288,
      "step": 47970
    },
    {
      "epoch": 47.98,
      "learning_rate": 8.622523240740679e-05,
      "loss": 0.1932,
      "step": 47980
    },
    {
      "epoch": 47.99,
      "learning_rate": 8.620070911601293e-05,
      "loss": 0.2355,
      "step": 47990
    },
    {
      "epoch": 48.0,
      "learning_rate": 8.617618459972634e-05,
      "loss": 0.2642,
      "step": 48000
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2742145359516144,
      "eval_runtime": 15.0622,
      "eval_samples_per_second": 132.783,
      "eval_steps_per_second": 16.598,
      "step": 48000
    },
    {
      "epoch": 48.01,
      "learning_rate": 8.615165886122901e-05,
      "loss": 0.2554,
      "step": 48010
    },
    {
      "epoch": 48.02,
      "learning_rate": 8.612713190320304e-05,
      "loss": 0.3187,
      "step": 48020
    },
    {
      "epoch": 48.03,
      "learning_rate": 8.610260372833064e-05,
      "loss": 0.2964,
      "step": 48030
    },
    {
      "epoch": 48.04,
      "learning_rate": 8.607807433929417e-05,
      "loss": 0.297,
      "step": 48040
    },
    {
      "epoch": 48.05,
      "learning_rate": 8.60535437387762e-05,
      "loss": 0.27,
      "step": 48050
    },
    {
      "epoch": 48.06,
      "learning_rate": 8.602901192945928e-05,
      "loss": 0.2577,
      "step": 48060
    },
    {
      "epoch": 48.07,
      "learning_rate": 8.600447891402618e-05,
      "loss": 0.3662,
      "step": 48070
    },
    {
      "epoch": 48.08,
      "learning_rate": 8.597994469515982e-05,
      "loss": 0.3568,
      "step": 48080
    },
    {
      "epoch": 48.09,
      "learning_rate": 8.595540927554324e-05,
      "loss": 0.293,
      "step": 48090
    },
    {
      "epoch": 48.1,
      "learning_rate": 8.593087265785956e-05,
      "loss": 0.3078,
      "step": 48100
    },
    {
      "epoch": 48.11,
      "learning_rate": 8.590633484479206e-05,
      "loss": 0.3157,
      "step": 48110
    },
    {
      "epoch": 48.12,
      "learning_rate": 8.58817958390242e-05,
      "loss": 0.2726,
      "step": 48120
    },
    {
      "epoch": 48.13,
      "learning_rate": 8.58572556432395e-05,
      "loss": 0.2963,
      "step": 48130
    },
    {
      "epoch": 48.14,
      "learning_rate": 8.583271426012164e-05,
      "loss": 0.2605,
      "step": 48140
    },
    {
      "epoch": 48.15,
      "learning_rate": 8.580817169235446e-05,
      "loss": 0.2166,
      "step": 48150
    },
    {
      "epoch": 48.16,
      "learning_rate": 8.578362794262184e-05,
      "loss": 0.2445,
      "step": 48160
    },
    {
      "epoch": 48.17,
      "learning_rate": 8.57590830136079e-05,
      "loss": 0.3348,
      "step": 48170
    },
    {
      "epoch": 48.18,
      "learning_rate": 8.57345369079968e-05,
      "loss": 0.3584,
      "step": 48180
    },
    {
      "epoch": 48.19,
      "learning_rate": 8.570998962847291e-05,
      "loss": 0.3048,
      "step": 48190
    },
    {
      "epoch": 48.2,
      "learning_rate": 8.568544117772063e-05,
      "loss": 0.2605,
      "step": 48200
    },
    {
      "epoch": 48.21,
      "learning_rate": 8.566089155842458e-05,
      "loss": 0.2923,
      "step": 48210
    },
    {
      "epoch": 48.22,
      "learning_rate": 8.563634077326948e-05,
      "loss": 0.314,
      "step": 48220
    },
    {
      "epoch": 48.23,
      "learning_rate": 8.561178882494012e-05,
      "loss": 0.2879,
      "step": 48230
    },
    {
      "epoch": 48.24,
      "learning_rate": 8.55872357161215e-05,
      "loss": 0.3075,
      "step": 48240
    },
    {
      "epoch": 48.25,
      "learning_rate": 8.556268144949868e-05,
      "loss": 0.3919,
      "step": 48250
    },
    {
      "epoch": 48.26,
      "learning_rate": 8.553812602775694e-05,
      "loss": 0.2967,
      "step": 48260
    },
    {
      "epoch": 48.27,
      "learning_rate": 8.551356945358153e-05,
      "loss": 0.3126,
      "step": 48270
    },
    {
      "epoch": 48.28,
      "learning_rate": 8.5489011729658e-05,
      "loss": 0.2689,
      "step": 48280
    },
    {
      "epoch": 48.29,
      "learning_rate": 8.546445285867192e-05,
      "loss": 0.2686,
      "step": 48290
    },
    {
      "epoch": 48.3,
      "learning_rate": 8.543989284330899e-05,
      "loss": 0.2344,
      "step": 48300
    },
    {
      "epoch": 48.31,
      "learning_rate": 8.541533168625508e-05,
      "loss": 0.3301,
      "step": 48310
    },
    {
      "epoch": 48.32,
      "learning_rate": 8.539076939019617e-05,
      "loss": 0.2511,
      "step": 48320
    },
    {
      "epoch": 48.33,
      "learning_rate": 8.536620595781833e-05,
      "loss": 0.2516,
      "step": 48330
    },
    {
      "epoch": 48.34,
      "learning_rate": 8.53416413918078e-05,
      "loss": 0.2422,
      "step": 48340
    },
    {
      "epoch": 48.35,
      "learning_rate": 8.531707569485091e-05,
      "loss": 0.2952,
      "step": 48350
    },
    {
      "epoch": 48.36,
      "learning_rate": 8.529250886963412e-05,
      "loss": 0.208,
      "step": 48360
    },
    {
      "epoch": 48.37,
      "learning_rate": 8.526794091884404e-05,
      "loss": 0.2448,
      "step": 48370
    },
    {
      "epoch": 48.38,
      "learning_rate": 8.52433718451674e-05,
      "loss": 0.2753,
      "step": 48380
    },
    {
      "epoch": 48.39,
      "learning_rate": 8.521880165129099e-05,
      "loss": 0.31,
      "step": 48390
    },
    {
      "epoch": 48.4,
      "learning_rate": 8.519423033990181e-05,
      "loss": 0.3107,
      "step": 48400
    },
    {
      "epoch": 48.41,
      "learning_rate": 8.51696579136869e-05,
      "loss": 0.211,
      "step": 48410
    },
    {
      "epoch": 48.42,
      "learning_rate": 8.514508437533354e-05,
      "loss": 0.3116,
      "step": 48420
    },
    {
      "epoch": 48.43,
      "learning_rate": 8.512050972752897e-05,
      "loss": 0.2884,
      "step": 48430
    },
    {
      "epoch": 48.44,
      "learning_rate": 8.509593397296068e-05,
      "loss": 0.2648,
      "step": 48440
    },
    {
      "epoch": 48.45,
      "learning_rate": 8.507135711431624e-05,
      "loss": 0.2777,
      "step": 48450
    },
    {
      "epoch": 48.46,
      "learning_rate": 8.504677915428331e-05,
      "loss": 0.2427,
      "step": 48460
    },
    {
      "epoch": 48.47,
      "learning_rate": 8.502220009554974e-05,
      "loss": 0.2426,
      "step": 48470
    },
    {
      "epoch": 48.48,
      "learning_rate": 8.499761994080343e-05,
      "loss": 0.3382,
      "step": 48480
    },
    {
      "epoch": 48.49,
      "learning_rate": 8.497303869273241e-05,
      "loss": 0.2248,
      "step": 48490
    },
    {
      "epoch": 48.5,
      "learning_rate": 8.494845635402488e-05,
      "loss": 0.3188,
      "step": 48500
    },
    {
      "epoch": 48.51,
      "learning_rate": 8.492387292736914e-05,
      "loss": 0.2765,
      "step": 48510
    },
    {
      "epoch": 48.52,
      "learning_rate": 8.489928841545356e-05,
      "loss": 0.2644,
      "step": 48520
    },
    {
      "epoch": 48.53,
      "learning_rate": 8.487470282096671e-05,
      "loss": 0.253,
      "step": 48530
    },
    {
      "epoch": 48.54,
      "learning_rate": 8.485011614659718e-05,
      "loss": 0.2623,
      "step": 48540
    },
    {
      "epoch": 48.55,
      "learning_rate": 8.482552839503376e-05,
      "loss": 0.2625,
      "step": 48550
    },
    {
      "epoch": 48.56,
      "learning_rate": 8.480093956896533e-05,
      "loss": 0.2593,
      "step": 48560
    },
    {
      "epoch": 48.57,
      "learning_rate": 8.47763496710809e-05,
      "loss": 0.251,
      "step": 48570
    },
    {
      "epoch": 48.58,
      "learning_rate": 8.475175870406953e-05,
      "loss": 0.2563,
      "step": 48580
    },
    {
      "epoch": 48.59,
      "learning_rate": 8.472716667062052e-05,
      "loss": 0.2679,
      "step": 48590
    },
    {
      "epoch": 48.6,
      "learning_rate": 8.470257357342319e-05,
      "loss": 0.2866,
      "step": 48600
    },
    {
      "epoch": 48.61,
      "learning_rate": 8.467797941516699e-05,
      "loss": 0.2599,
      "step": 48610
    },
    {
      "epoch": 48.62,
      "learning_rate": 8.46533841985415e-05,
      "loss": 0.3215,
      "step": 48620
    },
    {
      "epoch": 48.63,
      "learning_rate": 8.462878792623645e-05,
      "loss": 0.275,
      "step": 48630
    },
    {
      "epoch": 48.64,
      "learning_rate": 8.460419060094161e-05,
      "loss": 0.3045,
      "step": 48640
    },
    {
      "epoch": 48.65,
      "learning_rate": 8.457959222534692e-05,
      "loss": 0.2622,
      "step": 48650
    },
    {
      "epoch": 48.66,
      "learning_rate": 8.455499280214245e-05,
      "loss": 0.2993,
      "step": 48660
    },
    {
      "epoch": 48.67,
      "learning_rate": 8.453039233401833e-05,
      "loss": 0.2576,
      "step": 48670
    },
    {
      "epoch": 48.68,
      "learning_rate": 8.450579082366482e-05,
      "loss": 0.3631,
      "step": 48680
    },
    {
      "epoch": 48.69,
      "learning_rate": 8.448118827377232e-05,
      "loss": 0.3132,
      "step": 48690
    },
    {
      "epoch": 48.7,
      "learning_rate": 8.445658468703135e-05,
      "loss": 0.3158,
      "step": 48700
    },
    {
      "epoch": 48.71,
      "learning_rate": 8.443198006613246e-05,
      "loss": 0.248,
      "step": 48710
    },
    {
      "epoch": 48.72,
      "learning_rate": 8.440737441376644e-05,
      "loss": 0.2808,
      "step": 48720
    },
    {
      "epoch": 48.73,
      "learning_rate": 8.438276773262409e-05,
      "loss": 0.2942,
      "step": 48730
    },
    {
      "epoch": 48.74,
      "learning_rate": 8.435816002539634e-05,
      "loss": 0.2335,
      "step": 48740
    },
    {
      "epoch": 48.75,
      "learning_rate": 8.433355129477431e-05,
      "loss": 0.2123,
      "step": 48750
    },
    {
      "epoch": 48.76,
      "learning_rate": 8.430894154344916e-05,
      "loss": 0.2552,
      "step": 48760
    },
    {
      "epoch": 48.77,
      "learning_rate": 8.428433077411212e-05,
      "loss": 0.2987,
      "step": 48770
    },
    {
      "epoch": 48.78,
      "learning_rate": 8.425971898945464e-05,
      "loss": 0.2947,
      "step": 48780
    },
    {
      "epoch": 48.79,
      "learning_rate": 8.423510619216821e-05,
      "loss": 0.2457,
      "step": 48790
    },
    {
      "epoch": 48.8,
      "learning_rate": 8.421049238494447e-05,
      "loss": 0.3155,
      "step": 48800
    },
    {
      "epoch": 48.81,
      "learning_rate": 8.41858775704751e-05,
      "loss": 0.1986,
      "step": 48810
    },
    {
      "epoch": 48.82,
      "learning_rate": 8.4161261751452e-05,
      "loss": 0.2935,
      "step": 48820
    },
    {
      "epoch": 48.83,
      "learning_rate": 8.413664493056708e-05,
      "loss": 0.2575,
      "step": 48830
    },
    {
      "epoch": 48.84,
      "learning_rate": 8.411202711051239e-05,
      "loss": 0.2513,
      "step": 48840
    },
    {
      "epoch": 48.85,
      "learning_rate": 8.408740829398012e-05,
      "loss": 0.3161,
      "step": 48850
    },
    {
      "epoch": 48.86,
      "learning_rate": 8.406278848366255e-05,
      "loss": 0.2845,
      "step": 48860
    },
    {
      "epoch": 48.87,
      "learning_rate": 8.403816768225205e-05,
      "loss": 0.313,
      "step": 48870
    },
    {
      "epoch": 48.88,
      "learning_rate": 8.401354589244112e-05,
      "loss": 0.2141,
      "step": 48880
    },
    {
      "epoch": 48.89,
      "learning_rate": 8.398892311692238e-05,
      "loss": 0.2487,
      "step": 48890
    },
    {
      "epoch": 48.9,
      "learning_rate": 8.39642993583885e-05,
      "loss": 0.2614,
      "step": 48900
    },
    {
      "epoch": 48.91,
      "learning_rate": 8.393967461953234e-05,
      "loss": 0.2443,
      "step": 48910
    },
    {
      "epoch": 48.92,
      "learning_rate": 8.391504890304679e-05,
      "loss": 0.2238,
      "step": 48920
    },
    {
      "epoch": 48.93,
      "learning_rate": 8.389042221162489e-05,
      "loss": 0.277,
      "step": 48930
    },
    {
      "epoch": 48.94,
      "learning_rate": 8.386579454795981e-05,
      "loss": 0.2847,
      "step": 48940
    },
    {
      "epoch": 48.95,
      "learning_rate": 8.384116591474475e-05,
      "loss": 0.2643,
      "step": 48950
    },
    {
      "epoch": 48.96,
      "learning_rate": 8.381653631467308e-05,
      "loss": 0.2692,
      "step": 48960
    },
    {
      "epoch": 48.97,
      "learning_rate": 8.379190575043825e-05,
      "loss": 0.2682,
      "step": 48970
    },
    {
      "epoch": 48.98,
      "learning_rate": 8.376727422473382e-05,
      "loss": 0.3033,
      "step": 48980
    },
    {
      "epoch": 48.99,
      "learning_rate": 8.374264174025348e-05,
      "loss": 0.2695,
      "step": 48990
    },
    {
      "epoch": 49.0,
      "learning_rate": 8.371800829969097e-05,
      "loss": 0.2773,
      "step": 49000
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.814,
      "eval_loss": 0.2729106545448303,
      "eval_runtime": 15.1994,
      "eval_samples_per_second": 131.584,
      "eval_steps_per_second": 16.448,
      "step": 49000
    },
    {
      "epoch": 49.01,
      "learning_rate": 8.369337390574019e-05,
      "loss": 0.3111,
      "step": 49010
    },
    {
      "epoch": 49.02,
      "learning_rate": 8.366873856109511e-05,
      "loss": 0.3376,
      "step": 49020
    },
    {
      "epoch": 49.03,
      "learning_rate": 8.364410226844981e-05,
      "loss": 0.3288,
      "step": 49030
    },
    {
      "epoch": 49.04,
      "learning_rate": 8.361946503049848e-05,
      "loss": 0.2772,
      "step": 49040
    },
    {
      "epoch": 49.05,
      "learning_rate": 8.359482684993543e-05,
      "loss": 0.3225,
      "step": 49050
    },
    {
      "epoch": 49.06,
      "learning_rate": 8.3570187729455e-05,
      "loss": 0.309,
      "step": 49060
    },
    {
      "epoch": 49.07,
      "learning_rate": 8.354554767175175e-05,
      "loss": 0.2744,
      "step": 49070
    },
    {
      "epoch": 49.08,
      "learning_rate": 8.352090667952027e-05,
      "loss": 0.2876,
      "step": 49080
    },
    {
      "epoch": 49.09,
      "learning_rate": 8.34962647554552e-05,
      "loss": 0.2535,
      "step": 49090
    },
    {
      "epoch": 49.1,
      "learning_rate": 8.347162190225143e-05,
      "loss": 0.2712,
      "step": 49100
    },
    {
      "epoch": 49.11,
      "learning_rate": 8.344697812260381e-05,
      "loss": 0.3152,
      "step": 49110
    },
    {
      "epoch": 49.12,
      "learning_rate": 8.342233341920737e-05,
      "loss": 0.3046,
      "step": 49120
    },
    {
      "epoch": 49.13,
      "learning_rate": 8.33976877947572e-05,
      "loss": 0.2669,
      "step": 49130
    },
    {
      "epoch": 49.14,
      "learning_rate": 8.337304125194853e-05,
      "loss": 0.2465,
      "step": 49140
    },
    {
      "epoch": 49.15,
      "learning_rate": 8.334839379347666e-05,
      "loss": 0.2738,
      "step": 49150
    },
    {
      "epoch": 49.16,
      "learning_rate": 8.332374542203698e-05,
      "loss": 0.2672,
      "step": 49160
    },
    {
      "epoch": 49.17,
      "learning_rate": 8.329909614032502e-05,
      "loss": 0.202,
      "step": 49170
    },
    {
      "epoch": 49.18,
      "learning_rate": 8.32744459510364e-05,
      "loss": 0.2956,
      "step": 49180
    },
    {
      "epoch": 49.19,
      "learning_rate": 8.324979485686678e-05,
      "loss": 0.1901,
      "step": 49190
    },
    {
      "epoch": 49.2,
      "learning_rate": 8.322514286051203e-05,
      "loss": 0.3275,
      "step": 49200
    },
    {
      "epoch": 49.21,
      "learning_rate": 8.320048996466802e-05,
      "loss": 0.2657,
      "step": 49210
    },
    {
      "epoch": 49.22,
      "learning_rate": 8.317583617203072e-05,
      "loss": 0.3105,
      "step": 49220
    },
    {
      "epoch": 49.23,
      "learning_rate": 8.31511814852963e-05,
      "loss": 0.3527,
      "step": 49230
    },
    {
      "epoch": 49.24,
      "learning_rate": 8.312652590716094e-05,
      "loss": 0.227,
      "step": 49240
    },
    {
      "epoch": 49.25,
      "learning_rate": 8.310433512691977e-05,
      "loss": 0.3647,
      "step": 49250
    },
    {
      "epoch": 49.26,
      "learning_rate": 8.307967786255096e-05,
      "loss": 0.2673,
      "step": 49260
    },
    {
      "epoch": 49.27,
      "learning_rate": 8.305501971460072e-05,
      "loss": 0.2694,
      "step": 49270
    },
    {
      "epoch": 49.28,
      "learning_rate": 8.303036068576566e-05,
      "loss": 0.2423,
      "step": 49280
    },
    {
      "epoch": 49.29,
      "learning_rate": 8.300570077874239e-05,
      "loss": 0.5392,
      "step": 49290
    },
    {
      "epoch": 49.3,
      "learning_rate": 8.298103999622775e-05,
      "loss": 0.322,
      "step": 49300
    },
    {
      "epoch": 49.31,
      "learning_rate": 8.295637834091858e-05,
      "loss": 0.2047,
      "step": 49310
    },
    {
      "epoch": 49.32,
      "learning_rate": 8.29317158155118e-05,
      "loss": 0.3037,
      "step": 49320
    },
    {
      "epoch": 49.33,
      "learning_rate": 8.290705242270455e-05,
      "loss": 0.2512,
      "step": 49330
    },
    {
      "epoch": 49.34,
      "learning_rate": 8.288238816519391e-05,
      "loss": 0.2395,
      "step": 49340
    },
    {
      "epoch": 49.35,
      "learning_rate": 8.285772304567716e-05,
      "loss": 0.3141,
      "step": 49350
    },
    {
      "epoch": 49.36,
      "learning_rate": 8.283305706685162e-05,
      "loss": 0.2866,
      "step": 49360
    },
    {
      "epoch": 49.37,
      "learning_rate": 8.280839023141475e-05,
      "loss": 0.3484,
      "step": 49370
    },
    {
      "epoch": 49.38,
      "learning_rate": 8.278372254206403e-05,
      "loss": 0.2995,
      "step": 49380
    },
    {
      "epoch": 49.39,
      "learning_rate": 8.275905400149716e-05,
      "loss": 0.2869,
      "step": 49390
    },
    {
      "epoch": 49.4,
      "learning_rate": 8.273438461241178e-05,
      "loss": 0.2645,
      "step": 49400
    },
    {
      "epoch": 49.41,
      "learning_rate": 8.270971437750574e-05,
      "loss": 0.3124,
      "step": 49410
    },
    {
      "epoch": 49.42,
      "learning_rate": 8.268504329947692e-05,
      "loss": 0.3136,
      "step": 49420
    },
    {
      "epoch": 49.43,
      "learning_rate": 8.266037138102333e-05,
      "loss": 0.2427,
      "step": 49430
    },
    {
      "epoch": 49.44,
      "learning_rate": 8.263569862484305e-05,
      "loss": 0.2773,
      "step": 49440
    },
    {
      "epoch": 49.45,
      "learning_rate": 8.261102503363421e-05,
      "loss": 0.2568,
      "step": 49450
    },
    {
      "epoch": 49.46,
      "learning_rate": 8.258635061009515e-05,
      "loss": 0.2306,
      "step": 49460
    },
    {
      "epoch": 49.47,
      "learning_rate": 8.256167535692418e-05,
      "loss": 0.2757,
      "step": 49470
    },
    {
      "epoch": 49.48,
      "learning_rate": 8.253699927681976e-05,
      "loss": 0.2557,
      "step": 49480
    },
    {
      "epoch": 49.49,
      "learning_rate": 8.251232237248046e-05,
      "loss": 0.2891,
      "step": 49490
    },
    {
      "epoch": 49.5,
      "learning_rate": 8.248764464660484e-05,
      "loss": 0.2704,
      "step": 49500
    },
    {
      "epoch": 49.51,
      "learning_rate": 8.246296610189167e-05,
      "loss": 0.2511,
      "step": 49510
    },
    {
      "epoch": 49.52,
      "learning_rate": 8.243828674103977e-05,
      "loss": 0.2432,
      "step": 49520
    },
    {
      "epoch": 49.53,
      "learning_rate": 8.241360656674799e-05,
      "loss": 0.3106,
      "step": 49530
    },
    {
      "epoch": 49.54,
      "learning_rate": 8.238892558171537e-05,
      "loss": 0.2578,
      "step": 49540
    },
    {
      "epoch": 49.55,
      "learning_rate": 8.236424378864091e-05,
      "loss": 0.2446,
      "step": 49550
    },
    {
      "epoch": 49.56,
      "learning_rate": 8.233956119022387e-05,
      "loss": 0.3287,
      "step": 49560
    },
    {
      "epoch": 49.57,
      "learning_rate": 8.231487778916343e-05,
      "loss": 0.3241,
      "step": 49570
    },
    {
      "epoch": 49.58,
      "learning_rate": 8.229019358815896e-05,
      "loss": 0.2892,
      "step": 49580
    },
    {
      "epoch": 49.59,
      "learning_rate": 8.226550858990988e-05,
      "loss": 0.2691,
      "step": 49590
    },
    {
      "epoch": 49.6,
      "learning_rate": 8.22408227971157e-05,
      "loss": 0.2842,
      "step": 49600
    },
    {
      "epoch": 49.61,
      "learning_rate": 8.2216136212476e-05,
      "loss": 0.3006,
      "step": 49610
    },
    {
      "epoch": 49.62,
      "learning_rate": 8.219144883869054e-05,
      "loss": 0.2878,
      "step": 49620
    },
    {
      "epoch": 49.63,
      "learning_rate": 8.216676067845901e-05,
      "loss": 0.2274,
      "step": 49630
    },
    {
      "epoch": 49.64,
      "learning_rate": 8.214207173448132e-05,
      "loss": 0.2928,
      "step": 49640
    },
    {
      "epoch": 49.65,
      "learning_rate": 8.21173820094574e-05,
      "loss": 0.3101,
      "step": 49650
    },
    {
      "epoch": 49.66,
      "learning_rate": 8.20926915060873e-05,
      "loss": 0.3165,
      "step": 49660
    },
    {
      "epoch": 49.67,
      "learning_rate": 8.206800022707109e-05,
      "loss": 0.2711,
      "step": 49670
    },
    {
      "epoch": 49.68,
      "learning_rate": 8.204330817510904e-05,
      "loss": 0.2799,
      "step": 49680
    },
    {
      "epoch": 49.69,
      "learning_rate": 8.201861535290138e-05,
      "loss": 0.2873,
      "step": 49690
    },
    {
      "epoch": 49.7,
      "learning_rate": 8.19939217631485e-05,
      "loss": 0.2346,
      "step": 49700
    },
    {
      "epoch": 49.71,
      "learning_rate": 8.196922740855084e-05,
      "loss": 0.2862,
      "step": 49710
    },
    {
      "epoch": 49.72,
      "learning_rate": 8.194453229180895e-05,
      "loss": 0.2774,
      "step": 49720
    },
    {
      "epoch": 49.73,
      "learning_rate": 8.191983641562347e-05,
      "loss": 0.2682,
      "step": 49730
    },
    {
      "epoch": 49.74,
      "learning_rate": 8.189513978269505e-05,
      "loss": 0.2512,
      "step": 49740
    },
    {
      "epoch": 49.75,
      "learning_rate": 8.187044239572453e-05,
      "loss": 0.2952,
      "step": 49750
    },
    {
      "epoch": 49.76,
      "learning_rate": 8.184574425741277e-05,
      "loss": 0.2598,
      "step": 49760
    },
    {
      "epoch": 49.77,
      "learning_rate": 8.18210453704607e-05,
      "loss": 0.2883,
      "step": 49770
    },
    {
      "epoch": 49.78,
      "learning_rate": 8.179634573756935e-05,
      "loss": 0.2416,
      "step": 49780
    },
    {
      "epoch": 49.79,
      "learning_rate": 8.177164536143988e-05,
      "loss": 0.3042,
      "step": 49790
    },
    {
      "epoch": 49.8,
      "learning_rate": 8.174694424477342e-05,
      "loss": 0.3027,
      "step": 49800
    },
    {
      "epoch": 49.81,
      "learning_rate": 8.172224239027131e-05,
      "loss": 0.2946,
      "step": 49810
    },
    {
      "epoch": 49.82,
      "learning_rate": 8.169753980063487e-05,
      "loss": 0.33,
      "step": 49820
    },
    {
      "epoch": 49.83,
      "learning_rate": 8.167283647856553e-05,
      "loss": 0.2522,
      "step": 49830
    },
    {
      "epoch": 49.84,
      "learning_rate": 8.164813242676483e-05,
      "loss": 0.312,
      "step": 49840
    },
    {
      "epoch": 49.85,
      "learning_rate": 8.162342764793439e-05,
      "loss": 0.2427,
      "step": 49850
    },
    {
      "epoch": 49.86,
      "learning_rate": 8.159872214477584e-05,
      "loss": 0.2866,
      "step": 49860
    },
    {
      "epoch": 49.87,
      "learning_rate": 8.157401591999094e-05,
      "loss": 0.2337,
      "step": 49870
    },
    {
      "epoch": 49.88,
      "learning_rate": 8.154930897628156e-05,
      "loss": 0.3015,
      "step": 49880
    },
    {
      "epoch": 49.89,
      "learning_rate": 8.152460131634962e-05,
      "loss": 0.3218,
      "step": 49890
    },
    {
      "epoch": 49.9,
      "learning_rate": 8.149989294289705e-05,
      "loss": 0.2787,
      "step": 49900
    },
    {
      "epoch": 49.91,
      "learning_rate": 8.147518385862598e-05,
      "loss": 0.303,
      "step": 49910
    },
    {
      "epoch": 49.92,
      "learning_rate": 8.145047406623855e-05,
      "loss": 0.2436,
      "step": 49920
    },
    {
      "epoch": 49.93,
      "learning_rate": 8.142576356843694e-05,
      "loss": 0.3387,
      "step": 49930
    },
    {
      "epoch": 49.94,
      "learning_rate": 8.140105236792353e-05,
      "loss": 0.2268,
      "step": 49940
    },
    {
      "epoch": 49.95,
      "learning_rate": 8.137634046740064e-05,
      "loss": 0.2488,
      "step": 49950
    },
    {
      "epoch": 49.96,
      "learning_rate": 8.135162786957072e-05,
      "loss": 0.2501,
      "step": 49960
    },
    {
      "epoch": 49.97,
      "learning_rate": 8.132691457713634e-05,
      "loss": 0.3137,
      "step": 49970
    },
    {
      "epoch": 49.98,
      "learning_rate": 8.130220059280012e-05,
      "loss": 0.3224,
      "step": 49980
    },
    {
      "epoch": 49.99,
      "learning_rate": 8.127748591926468e-05,
      "loss": 0.2421,
      "step": 49990
    },
    {
      "epoch": 50.0,
      "learning_rate": 8.125277055923284e-05,
      "loss": 0.2764,
      "step": 50000
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.27317729592323303,
      "eval_runtime": 15.283,
      "eval_samples_per_second": 130.864,
      "eval_steps_per_second": 16.358,
      "step": 50000
    },
    {
      "epoch": 50.01,
      "learning_rate": 8.122805451540741e-05,
      "loss": 0.3045,
      "step": 50010
    },
    {
      "epoch": 50.02,
      "learning_rate": 8.120333779049129e-05,
      "loss": 0.2866,
      "step": 50020
    },
    {
      "epoch": 50.03,
      "learning_rate": 8.117862038718749e-05,
      "loss": 0.2951,
      "step": 50030
    },
    {
      "epoch": 50.04,
      "learning_rate": 8.115390230819904e-05,
      "loss": 0.2741,
      "step": 50040
    },
    {
      "epoch": 50.05,
      "learning_rate": 8.112918355622911e-05,
      "loss": 0.337,
      "step": 50050
    },
    {
      "epoch": 50.06,
      "learning_rate": 8.110446413398086e-05,
      "loss": 0.2326,
      "step": 50060
    },
    {
      "epoch": 50.07,
      "learning_rate": 8.10797440441576e-05,
      "loss": 0.3045,
      "step": 50070
    },
    {
      "epoch": 50.08,
      "learning_rate": 8.105502328946265e-05,
      "loss": 0.2378,
      "step": 50080
    },
    {
      "epoch": 50.09,
      "learning_rate": 8.103030187259948e-05,
      "loss": 0.2419,
      "step": 50090
    },
    {
      "epoch": 50.1,
      "learning_rate": 8.100557979627156e-05,
      "loss": 0.3043,
      "step": 50100
    },
    {
      "epoch": 50.11,
      "learning_rate": 8.098085706318246e-05,
      "loss": 0.2035,
      "step": 50110
    },
    {
      "epoch": 50.12,
      "learning_rate": 8.095613367603582e-05,
      "loss": 0.2766,
      "step": 50120
    },
    {
      "epoch": 50.13,
      "learning_rate": 8.093140963753536e-05,
      "loss": 0.2739,
      "step": 50130
    },
    {
      "epoch": 50.14,
      "learning_rate": 8.090668495038486e-05,
      "loss": 0.3105,
      "step": 50140
    },
    {
      "epoch": 50.15,
      "learning_rate": 8.088195961728817e-05,
      "loss": 0.3323,
      "step": 50150
    },
    {
      "epoch": 50.16,
      "learning_rate": 8.085723364094923e-05,
      "loss": 0.2772,
      "step": 50160
    },
    {
      "epoch": 50.17,
      "learning_rate": 8.083250702407202e-05,
      "loss": 0.277,
      "step": 50170
    },
    {
      "epoch": 50.18,
      "learning_rate": 8.080777976936061e-05,
      "loss": 0.243,
      "step": 50180
    },
    {
      "epoch": 50.19,
      "learning_rate": 8.078305187951914e-05,
      "loss": 0.3117,
      "step": 50190
    },
    {
      "epoch": 50.2,
      "learning_rate": 8.075832335725182e-05,
      "loss": 0.269,
      "step": 50200
    },
    {
      "epoch": 50.21,
      "learning_rate": 8.073359420526289e-05,
      "loss": 0.295,
      "step": 50210
    },
    {
      "epoch": 50.22,
      "learning_rate": 8.070886442625674e-05,
      "loss": 0.2083,
      "step": 50220
    },
    {
      "epoch": 50.23,
      "learning_rate": 8.068413402293776e-05,
      "loss": 0.2775,
      "step": 50230
    },
    {
      "epoch": 50.24,
      "learning_rate": 8.065940299801043e-05,
      "loss": 0.2092,
      "step": 50240
    },
    {
      "epoch": 50.25,
      "learning_rate": 8.063467135417927e-05,
      "loss": 0.2413,
      "step": 50250
    },
    {
      "epoch": 50.26,
      "learning_rate": 8.060993909414895e-05,
      "loss": 0.2516,
      "step": 50260
    },
    {
      "epoch": 50.27,
      "learning_rate": 8.05852062206241e-05,
      "loss": 0.3266,
      "step": 50270
    },
    {
      "epoch": 50.28,
      "learning_rate": 8.056047273630952e-05,
      "loss": 0.2746,
      "step": 50280
    },
    {
      "epoch": 50.29,
      "learning_rate": 8.053573864390998e-05,
      "loss": 0.2514,
      "step": 50290
    },
    {
      "epoch": 50.3,
      "learning_rate": 8.051100394613041e-05,
      "loss": 0.2894,
      "step": 50300
    },
    {
      "epoch": 50.31,
      "learning_rate": 8.04862686456757e-05,
      "loss": 0.3002,
      "step": 50310
    },
    {
      "epoch": 50.32,
      "learning_rate": 8.046153274525092e-05,
      "loss": 0.2546,
      "step": 50320
    },
    {
      "epoch": 50.33,
      "learning_rate": 8.043679624756113e-05,
      "loss": 0.2606,
      "step": 50330
    },
    {
      "epoch": 50.34,
      "learning_rate": 8.041205915531147e-05,
      "loss": 0.2253,
      "step": 50340
    },
    {
      "epoch": 50.35,
      "learning_rate": 8.038732147120717e-05,
      "loss": 0.329,
      "step": 50350
    },
    {
      "epoch": 50.36,
      "learning_rate": 8.03625831979535e-05,
      "loss": 0.3038,
      "step": 50360
    },
    {
      "epoch": 50.37,
      "learning_rate": 8.033784433825577e-05,
      "loss": 0.2867,
      "step": 50370
    },
    {
      "epoch": 50.38,
      "learning_rate": 8.031310489481941e-05,
      "loss": 0.2868,
      "step": 50380
    },
    {
      "epoch": 50.39,
      "learning_rate": 8.028836487034992e-05,
      "loss": 0.2599,
      "step": 50390
    },
    {
      "epoch": 50.4,
      "learning_rate": 8.026362426755277e-05,
      "loss": 0.3039,
      "step": 50400
    },
    {
      "epoch": 50.41,
      "learning_rate": 8.023888308913357e-05,
      "loss": 0.3649,
      "step": 50410
    },
    {
      "epoch": 50.42,
      "learning_rate": 8.021414133779802e-05,
      "loss": 0.2686,
      "step": 50420
    },
    {
      "epoch": 50.43,
      "learning_rate": 8.018939901625182e-05,
      "loss": 0.2687,
      "step": 50430
    },
    {
      "epoch": 50.44,
      "learning_rate": 8.016465612720072e-05,
      "loss": 0.2943,
      "step": 50440
    },
    {
      "epoch": 50.45,
      "learning_rate": 8.01399126733506e-05,
      "loss": 0.2617,
      "step": 50450
    },
    {
      "epoch": 50.46,
      "learning_rate": 8.011516865740736e-05,
      "loss": 0.2416,
      "step": 50460
    },
    {
      "epoch": 50.47,
      "learning_rate": 8.009042408207695e-05,
      "loss": 0.2773,
      "step": 50470
    },
    {
      "epoch": 50.48,
      "learning_rate": 8.006567895006544e-05,
      "loss": 0.2679,
      "step": 50480
    },
    {
      "epoch": 50.49,
      "learning_rate": 8.004093326407889e-05,
      "loss": 0.3288,
      "step": 50490
    },
    {
      "epoch": 50.5,
      "learning_rate": 8.001618702682345e-05,
      "loss": 0.2752,
      "step": 50500
    },
    {
      "epoch": 50.51,
      "learning_rate": 7.999144024100535e-05,
      "loss": 0.3707,
      "step": 50510
    },
    {
      "epoch": 50.52,
      "learning_rate": 7.996669290933085e-05,
      "loss": 0.2245,
      "step": 50520
    },
    {
      "epoch": 50.53,
      "learning_rate": 7.994194503450626e-05,
      "loss": 0.2165,
      "step": 50530
    },
    {
      "epoch": 50.54,
      "learning_rate": 7.991719661923801e-05,
      "loss": 0.2415,
      "step": 50540
    },
    {
      "epoch": 50.55,
      "learning_rate": 7.989244766623252e-05,
      "loss": 0.3465,
      "step": 50550
    },
    {
      "epoch": 50.56,
      "learning_rate": 7.986769817819631e-05,
      "loss": 0.2316,
      "step": 50560
    },
    {
      "epoch": 50.57,
      "learning_rate": 7.984294815783595e-05,
      "loss": 0.2721,
      "step": 50570
    },
    {
      "epoch": 50.58,
      "learning_rate": 7.981819760785806e-05,
      "loss": 0.2971,
      "step": 50580
    },
    {
      "epoch": 50.59,
      "learning_rate": 7.979344653096932e-05,
      "loss": 0.3471,
      "step": 50590
    },
    {
      "epoch": 50.6,
      "learning_rate": 7.976869492987646e-05,
      "loss": 0.3028,
      "step": 50600
    },
    {
      "epoch": 50.61,
      "learning_rate": 7.974394280728631e-05,
      "loss": 0.3027,
      "step": 50610
    },
    {
      "epoch": 50.62,
      "learning_rate": 7.971919016590573e-05,
      "loss": 0.2333,
      "step": 50620
    },
    {
      "epoch": 50.63,
      "learning_rate": 7.969443700844157e-05,
      "loss": 0.2647,
      "step": 50630
    },
    {
      "epoch": 50.64,
      "learning_rate": 7.966968333760086e-05,
      "loss": 0.2347,
      "step": 50640
    },
    {
      "epoch": 50.65,
      "learning_rate": 7.96449291560906e-05,
      "loss": 0.2708,
      "step": 50650
    },
    {
      "epoch": 50.66,
      "learning_rate": 7.962017446661786e-05,
      "loss": 0.3178,
      "step": 50660
    },
    {
      "epoch": 50.67,
      "learning_rate": 7.959541927188978e-05,
      "loss": 0.3058,
      "step": 50670
    },
    {
      "epoch": 50.68,
      "learning_rate": 7.957066357461358e-05,
      "loss": 0.2797,
      "step": 50680
    },
    {
      "epoch": 50.69,
      "learning_rate": 7.954590737749646e-05,
      "loss": 0.3185,
      "step": 50690
    },
    {
      "epoch": 50.7,
      "learning_rate": 7.952115068324576e-05,
      "loss": 0.2422,
      "step": 50700
    },
    {
      "epoch": 50.71,
      "learning_rate": 7.949639349456881e-05,
      "loss": 0.2723,
      "step": 50710
    },
    {
      "epoch": 50.72,
      "learning_rate": 7.947163581417304e-05,
      "loss": 0.2349,
      "step": 50720
    },
    {
      "epoch": 50.73,
      "learning_rate": 7.944687764476589e-05,
      "loss": 0.2781,
      "step": 50730
    },
    {
      "epoch": 50.74,
      "learning_rate": 7.94221189890549e-05,
      "loss": 0.2429,
      "step": 50740
    },
    {
      "epoch": 50.75,
      "learning_rate": 7.939735984974763e-05,
      "loss": 0.2504,
      "step": 50750
    },
    {
      "epoch": 50.76,
      "learning_rate": 7.937260022955165e-05,
      "loss": 0.2615,
      "step": 50760
    },
    {
      "epoch": 50.77,
      "learning_rate": 7.934784013117472e-05,
      "loss": 0.3208,
      "step": 50770
    },
    {
      "epoch": 50.78,
      "learning_rate": 7.932307955732453e-05,
      "loss": 0.2601,
      "step": 50780
    },
    {
      "epoch": 50.79,
      "learning_rate": 7.929831851070884e-05,
      "loss": 0.3106,
      "step": 50790
    },
    {
      "epoch": 50.8,
      "learning_rate": 7.927355699403554e-05,
      "loss": 0.2773,
      "step": 50800
    },
    {
      "epoch": 50.81,
      "learning_rate": 7.924879501001244e-05,
      "loss": 0.2766,
      "step": 50810
    },
    {
      "epoch": 50.82,
      "learning_rate": 7.922403256134751e-05,
      "loss": 0.2654,
      "step": 50820
    },
    {
      "epoch": 50.83,
      "learning_rate": 7.919926965074872e-05,
      "loss": 0.3159,
      "step": 50830
    },
    {
      "epoch": 50.84,
      "learning_rate": 7.917450628092414e-05,
      "loss": 0.3887,
      "step": 50840
    },
    {
      "epoch": 50.85,
      "learning_rate": 7.91497424545818e-05,
      "loss": 0.233,
      "step": 50850
    },
    {
      "epoch": 50.86,
      "learning_rate": 7.91249781744299e-05,
      "loss": 0.2574,
      "step": 50860
    },
    {
      "epoch": 50.87,
      "learning_rate": 7.910021344317656e-05,
      "loss": 0.251,
      "step": 50870
    },
    {
      "epoch": 50.88,
      "learning_rate": 7.907544826353004e-05,
      "loss": 0.2943,
      "step": 50880
    },
    {
      "epoch": 50.89,
      "learning_rate": 7.905068263819865e-05,
      "loss": 0.2711,
      "step": 50890
    },
    {
      "epoch": 50.9,
      "learning_rate": 7.902591656989069e-05,
      "loss": 0.2768,
      "step": 50900
    },
    {
      "epoch": 50.91,
      "learning_rate": 7.900115006131453e-05,
      "loss": 0.338,
      "step": 50910
    },
    {
      "epoch": 50.92,
      "learning_rate": 7.897638311517863e-05,
      "loss": 0.2596,
      "step": 50920
    },
    {
      "epoch": 50.93,
      "learning_rate": 7.895161573419145e-05,
      "loss": 0.2168,
      "step": 50930
    },
    {
      "epoch": 50.94,
      "learning_rate": 7.892684792106151e-05,
      "loss": 0.3205,
      "step": 50940
    },
    {
      "epoch": 50.95,
      "learning_rate": 7.89020796784974e-05,
      "loss": 0.2693,
      "step": 50950
    },
    {
      "epoch": 50.96,
      "learning_rate": 7.88773110092077e-05,
      "loss": 0.2862,
      "step": 50960
    },
    {
      "epoch": 50.97,
      "learning_rate": 7.885254191590112e-05,
      "loss": 0.2689,
      "step": 50970
    },
    {
      "epoch": 50.98,
      "learning_rate": 7.882777240128632e-05,
      "loss": 0.2343,
      "step": 50980
    },
    {
      "epoch": 50.99,
      "learning_rate": 7.88030024680721e-05,
      "loss": 0.3282,
      "step": 50990
    },
    {
      "epoch": 51.0,
      "learning_rate": 7.877823211896726e-05,
      "loss": 0.3128,
      "step": 51000
    },
    {
      "epoch": 51.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27322056889533997,
      "eval_runtime": 15.3098,
      "eval_samples_per_second": 130.635,
      "eval_steps_per_second": 16.329,
      "step": 51000
    },
    {
      "epoch": 51.01,
      "learning_rate": 7.875346135668061e-05,
      "loss": 0.2951,
      "step": 51010
    },
    {
      "epoch": 51.02,
      "learning_rate": 7.87286901839211e-05,
      "loss": 0.2079,
      "step": 51020
    },
    {
      "epoch": 51.03,
      "learning_rate": 7.870391860339762e-05,
      "loss": 0.3193,
      "step": 51030
    },
    {
      "epoch": 51.04,
      "learning_rate": 7.867914661781916e-05,
      "loss": 0.2679,
      "step": 51040
    },
    {
      "epoch": 51.05,
      "learning_rate": 7.865437422989478e-05,
      "loss": 0.3067,
      "step": 51050
    },
    {
      "epoch": 51.06,
      "learning_rate": 7.86296014423335e-05,
      "loss": 0.313,
      "step": 51060
    },
    {
      "epoch": 51.07,
      "learning_rate": 7.860482825784448e-05,
      "loss": 0.2513,
      "step": 51070
    },
    {
      "epoch": 51.08,
      "learning_rate": 7.858005467913687e-05,
      "loss": 0.3375,
      "step": 51080
    },
    {
      "epoch": 51.09,
      "learning_rate": 7.855528070891986e-05,
      "loss": 0.3024,
      "step": 51090
    },
    {
      "epoch": 51.1,
      "learning_rate": 7.853050634990269e-05,
      "loss": 0.3206,
      "step": 51100
    },
    {
      "epoch": 51.11,
      "learning_rate": 7.850573160479466e-05,
      "loss": 0.2797,
      "step": 51110
    },
    {
      "epoch": 51.12,
      "learning_rate": 7.848095647630508e-05,
      "loss": 0.2924,
      "step": 51120
    },
    {
      "epoch": 51.13,
      "learning_rate": 7.845618096714334e-05,
      "loss": 0.2891,
      "step": 51130
    },
    {
      "epoch": 51.14,
      "learning_rate": 7.843140508001885e-05,
      "loss": 0.2677,
      "step": 51140
    },
    {
      "epoch": 51.15,
      "learning_rate": 7.840662881764105e-05,
      "loss": 0.2791,
      "step": 51150
    },
    {
      "epoch": 51.16,
      "learning_rate": 7.838185218271947e-05,
      "loss": 0.2943,
      "step": 51160
    },
    {
      "epoch": 51.17,
      "learning_rate": 7.835707517796357e-05,
      "loss": 0.3031,
      "step": 51170
    },
    {
      "epoch": 51.18,
      "learning_rate": 7.833229780608301e-05,
      "loss": 0.2514,
      "step": 51180
    },
    {
      "epoch": 51.19,
      "learning_rate": 7.83075200697874e-05,
      "loss": 0.321,
      "step": 51190
    },
    {
      "epoch": 51.2,
      "learning_rate": 7.82827419717863e-05,
      "loss": 0.2765,
      "step": 51200
    },
    {
      "epoch": 51.21,
      "learning_rate": 7.825796351478954e-05,
      "loss": 0.3205,
      "step": 51210
    },
    {
      "epoch": 51.22,
      "learning_rate": 7.823318470150674e-05,
      "loss": 0.3123,
      "step": 51220
    },
    {
      "epoch": 51.23,
      "learning_rate": 7.820840553464774e-05,
      "loss": 0.2159,
      "step": 51230
    },
    {
      "epoch": 51.24,
      "learning_rate": 7.818362601692235e-05,
      "loss": 0.3294,
      "step": 51240
    },
    {
      "epoch": 51.25,
      "learning_rate": 7.815884615104038e-05,
      "loss": 0.2861,
      "step": 51250
    },
    {
      "epoch": 51.26,
      "learning_rate": 7.813406593971176e-05,
      "loss": 0.3034,
      "step": 51260
    },
    {
      "epoch": 51.27,
      "learning_rate": 7.81092853856464e-05,
      "loss": 0.3561,
      "step": 51270
    },
    {
      "epoch": 51.28,
      "learning_rate": 7.808450449155426e-05,
      "loss": 0.2598,
      "step": 51280
    },
    {
      "epoch": 51.29,
      "learning_rate": 7.805972326014534e-05,
      "loss": 0.1907,
      "step": 51290
    },
    {
      "epoch": 51.3,
      "learning_rate": 7.803494169412969e-05,
      "loss": 0.2687,
      "step": 51300
    },
    {
      "epoch": 51.31,
      "learning_rate": 7.801015979621738e-05,
      "loss": 0.2339,
      "step": 51310
    },
    {
      "epoch": 51.32,
      "learning_rate": 7.798537756911851e-05,
      "loss": 0.2714,
      "step": 51320
    },
    {
      "epoch": 51.33,
      "learning_rate": 7.796059501554323e-05,
      "loss": 0.2681,
      "step": 51330
    },
    {
      "epoch": 51.34,
      "learning_rate": 7.793581213820177e-05,
      "loss": 0.3463,
      "step": 51340
    },
    {
      "epoch": 51.35,
      "learning_rate": 7.79110289398043e-05,
      "loss": 0.2431,
      "step": 51350
    },
    {
      "epoch": 51.36,
      "learning_rate": 7.788624542306106e-05,
      "loss": 0.3022,
      "step": 51360
    },
    {
      "epoch": 51.37,
      "learning_rate": 7.786146159068236e-05,
      "loss": 0.3211,
      "step": 51370
    },
    {
      "epoch": 51.38,
      "learning_rate": 7.783667744537855e-05,
      "loss": 0.3212,
      "step": 51380
    },
    {
      "epoch": 51.39,
      "learning_rate": 7.781189298985992e-05,
      "loss": 0.2256,
      "step": 51390
    },
    {
      "epoch": 51.4,
      "learning_rate": 7.778710822683692e-05,
      "loss": 0.2814,
      "step": 51400
    },
    {
      "epoch": 51.41,
      "learning_rate": 7.776232315901996e-05,
      "loss": 0.2616,
      "step": 51410
    },
    {
      "epoch": 51.42,
      "learning_rate": 7.773753778911949e-05,
      "loss": 0.3011,
      "step": 51420
    },
    {
      "epoch": 51.43,
      "learning_rate": 7.771275211984601e-05,
      "loss": 0.298,
      "step": 51430
    },
    {
      "epoch": 51.44,
      "learning_rate": 7.768796615391003e-05,
      "loss": 0.2716,
      "step": 51440
    },
    {
      "epoch": 51.45,
      "learning_rate": 7.766317989402211e-05,
      "loss": 0.2879,
      "step": 51450
    },
    {
      "epoch": 51.46,
      "learning_rate": 7.763839334289283e-05,
      "loss": 0.2774,
      "step": 51460
    },
    {
      "epoch": 51.47,
      "learning_rate": 7.761360650323284e-05,
      "loss": 0.2601,
      "step": 51470
    },
    {
      "epoch": 51.48,
      "learning_rate": 7.758881937775277e-05,
      "loss": 0.3123,
      "step": 51480
    },
    {
      "epoch": 51.49,
      "learning_rate": 7.756403196916328e-05,
      "loss": 0.2427,
      "step": 51490
    },
    {
      "epoch": 51.5,
      "learning_rate": 7.753924428017514e-05,
      "loss": 0.2864,
      "step": 51500
    },
    {
      "epoch": 51.51,
      "learning_rate": 7.751445631349906e-05,
      "loss": 0.2946,
      "step": 51510
    },
    {
      "epoch": 51.52,
      "learning_rate": 7.748966807184581e-05,
      "loss": 0.2601,
      "step": 51520
    },
    {
      "epoch": 51.53,
      "learning_rate": 7.746487955792621e-05,
      "loss": 0.3467,
      "step": 51530
    },
    {
      "epoch": 51.54,
      "learning_rate": 7.744009077445107e-05,
      "loss": 0.2604,
      "step": 51540
    },
    {
      "epoch": 51.55,
      "learning_rate": 7.741530172413128e-05,
      "loss": 0.2607,
      "step": 51550
    },
    {
      "epoch": 51.56,
      "learning_rate": 7.739051240967772e-05,
      "loss": 0.2688,
      "step": 51560
    },
    {
      "epoch": 51.57,
      "learning_rate": 7.736572283380131e-05,
      "loss": 0.2429,
      "step": 51570
    },
    {
      "epoch": 51.58,
      "learning_rate": 7.734093299921302e-05,
      "loss": 0.2343,
      "step": 51580
    },
    {
      "epoch": 51.59,
      "learning_rate": 7.731614290862383e-05,
      "loss": 0.278,
      "step": 51590
    },
    {
      "epoch": 51.6,
      "learning_rate": 7.729135256474471e-05,
      "loss": 0.1807,
      "step": 51600
    },
    {
      "epoch": 51.61,
      "learning_rate": 7.726656197028674e-05,
      "loss": 0.2935,
      "step": 51610
    },
    {
      "epoch": 51.62,
      "learning_rate": 7.724177112796094e-05,
      "loss": 0.2468,
      "step": 51620
    },
    {
      "epoch": 51.63,
      "learning_rate": 7.721698004047845e-05,
      "loss": 0.2992,
      "step": 51630
    },
    {
      "epoch": 51.64,
      "learning_rate": 7.719218871055034e-05,
      "loss": 0.3544,
      "step": 51640
    },
    {
      "epoch": 51.65,
      "learning_rate": 7.716739714088775e-05,
      "loss": 0.2645,
      "step": 51650
    },
    {
      "epoch": 51.66,
      "learning_rate": 7.714260533420189e-05,
      "loss": 0.181,
      "step": 51660
    },
    {
      "epoch": 51.67,
      "learning_rate": 7.711781329320393e-05,
      "loss": 0.2669,
      "step": 51670
    },
    {
      "epoch": 51.68,
      "learning_rate": 7.709302102060507e-05,
      "loss": 0.234,
      "step": 51680
    },
    {
      "epoch": 51.69,
      "learning_rate": 7.70682285191166e-05,
      "loss": 0.2246,
      "step": 51690
    },
    {
      "epoch": 51.7,
      "learning_rate": 7.704343579144976e-05,
      "loss": 0.3422,
      "step": 51700
    },
    {
      "epoch": 51.71,
      "learning_rate": 7.701864284031585e-05,
      "loss": 0.2651,
      "step": 51710
    },
    {
      "epoch": 51.72,
      "learning_rate": 7.69938496684262e-05,
      "loss": 0.2084,
      "step": 51720
    },
    {
      "epoch": 51.73,
      "learning_rate": 7.696905627849218e-05,
      "loss": 0.2515,
      "step": 51730
    },
    {
      "epoch": 51.74,
      "learning_rate": 7.694426267322508e-05,
      "loss": 0.2696,
      "step": 51740
    },
    {
      "epoch": 51.75,
      "learning_rate": 7.691946885533635e-05,
      "loss": 0.2826,
      "step": 51750
    },
    {
      "epoch": 51.76,
      "learning_rate": 7.689467482753741e-05,
      "loss": 0.2929,
      "step": 51760
    },
    {
      "epoch": 51.77,
      "learning_rate": 7.686988059253965e-05,
      "loss": 0.2941,
      "step": 51770
    },
    {
      "epoch": 51.78,
      "learning_rate": 7.684508615305458e-05,
      "loss": 0.2874,
      "step": 51780
    },
    {
      "epoch": 51.79,
      "learning_rate": 7.682029151179365e-05,
      "loss": 0.2499,
      "step": 51790
    },
    {
      "epoch": 51.8,
      "learning_rate": 7.679549667146838e-05,
      "loss": 0.2366,
      "step": 51800
    },
    {
      "epoch": 51.81,
      "learning_rate": 7.677070163479028e-05,
      "loss": 0.2442,
      "step": 51810
    },
    {
      "epoch": 51.82,
      "learning_rate": 7.674590640447093e-05,
      "loss": 0.3313,
      "step": 51820
    },
    {
      "epoch": 51.83,
      "learning_rate": 7.67211109832219e-05,
      "loss": 0.3919,
      "step": 51830
    },
    {
      "epoch": 51.84,
      "learning_rate": 7.669631537375473e-05,
      "loss": 0.2768,
      "step": 51840
    },
    {
      "epoch": 51.85,
      "learning_rate": 7.667151957878107e-05,
      "loss": 0.1961,
      "step": 51850
    },
    {
      "epoch": 51.86,
      "learning_rate": 7.664672360101255e-05,
      "loss": 0.2961,
      "step": 51860
    },
    {
      "epoch": 51.87,
      "learning_rate": 7.662192744316079e-05,
      "loss": 0.3217,
      "step": 51870
    },
    {
      "epoch": 51.88,
      "learning_rate": 7.659713110793751e-05,
      "loss": 0.2879,
      "step": 51880
    },
    {
      "epoch": 51.89,
      "learning_rate": 7.657233459805437e-05,
      "loss": 0.2642,
      "step": 51890
    },
    {
      "epoch": 51.9,
      "learning_rate": 7.654753791622305e-05,
      "loss": 0.2274,
      "step": 51900
    },
    {
      "epoch": 51.91,
      "learning_rate": 7.652274106515535e-05,
      "loss": 0.2816,
      "step": 51910
    },
    {
      "epoch": 51.92,
      "learning_rate": 7.649794404756297e-05,
      "loss": 0.2739,
      "step": 51920
    },
    {
      "epoch": 51.93,
      "learning_rate": 7.647314686615765e-05,
      "loss": 0.3032,
      "step": 51930
    },
    {
      "epoch": 51.94,
      "learning_rate": 7.644834952365123e-05,
      "loss": 0.26,
      "step": 51940
    },
    {
      "epoch": 51.95,
      "learning_rate": 7.642355202275548e-05,
      "loss": 0.2514,
      "step": 51950
    },
    {
      "epoch": 51.96,
      "learning_rate": 7.639875436618223e-05,
      "loss": 0.2696,
      "step": 51960
    },
    {
      "epoch": 51.97,
      "learning_rate": 7.637395655664328e-05,
      "loss": 0.252,
      "step": 51970
    },
    {
      "epoch": 51.98,
      "learning_rate": 7.634915859685052e-05,
      "loss": 0.3043,
      "step": 51980
    },
    {
      "epoch": 51.99,
      "learning_rate": 7.632436048951583e-05,
      "loss": 0.2859,
      "step": 51990
    },
    {
      "epoch": 52.0,
      "learning_rate": 7.629956223735102e-05,
      "loss": 0.3384,
      "step": 52000
    },
    {
      "epoch": 52.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2731320559978485,
      "eval_runtime": 14.7742,
      "eval_samples_per_second": 135.371,
      "eval_steps_per_second": 16.921,
      "step": 52000
    },
    {
      "epoch": 52.01,
      "learning_rate": 7.627476384306807e-05,
      "loss": 0.2946,
      "step": 52010
    },
    {
      "epoch": 52.02,
      "learning_rate": 7.624996530937885e-05,
      "loss": 0.2167,
      "step": 52020
    },
    {
      "epoch": 52.03,
      "learning_rate": 7.622516663899531e-05,
      "loss": 0.2942,
      "step": 52030
    },
    {
      "epoch": 52.04,
      "learning_rate": 7.620036783462938e-05,
      "loss": 0.269,
      "step": 52040
    },
    {
      "epoch": 52.05,
      "learning_rate": 7.617556889899303e-05,
      "loss": 0.2156,
      "step": 52050
    },
    {
      "epoch": 52.06,
      "learning_rate": 7.615076983479823e-05,
      "loss": 0.275,
      "step": 52060
    },
    {
      "epoch": 52.07,
      "learning_rate": 7.612597064475699e-05,
      "loss": 0.283,
      "step": 52070
    },
    {
      "epoch": 52.08,
      "learning_rate": 7.610117133158128e-05,
      "loss": 0.3068,
      "step": 52080
    },
    {
      "epoch": 52.09,
      "learning_rate": 7.607637189798312e-05,
      "loss": 0.3287,
      "step": 52090
    },
    {
      "epoch": 52.1,
      "learning_rate": 7.605157234667458e-05,
      "loss": 0.2942,
      "step": 52100
    },
    {
      "epoch": 52.11,
      "learning_rate": 7.602677268036764e-05,
      "loss": 0.2937,
      "step": 52110
    },
    {
      "epoch": 52.12,
      "learning_rate": 7.600197290177438e-05,
      "loss": 0.2879,
      "step": 52120
    },
    {
      "epoch": 52.13,
      "learning_rate": 7.597717301360687e-05,
      "loss": 0.2833,
      "step": 52130
    },
    {
      "epoch": 52.14,
      "learning_rate": 7.595237301857722e-05,
      "loss": 0.2306,
      "step": 52140
    },
    {
      "epoch": 52.15,
      "learning_rate": 7.592757291939746e-05,
      "loss": 0.2943,
      "step": 52150
    },
    {
      "epoch": 52.16,
      "learning_rate": 7.590277271877972e-05,
      "loss": 0.2814,
      "step": 52160
    },
    {
      "epoch": 52.17,
      "learning_rate": 7.587797241943613e-05,
      "loss": 0.2657,
      "step": 52170
    },
    {
      "epoch": 52.18,
      "learning_rate": 7.585317202407879e-05,
      "loss": 0.2772,
      "step": 52180
    },
    {
      "epoch": 52.19,
      "learning_rate": 7.582837153541981e-05,
      "loss": 0.277,
      "step": 52190
    },
    {
      "epoch": 52.2,
      "learning_rate": 7.580357095617141e-05,
      "loss": 0.3011,
      "step": 52200
    },
    {
      "epoch": 52.21,
      "learning_rate": 7.577877028904569e-05,
      "loss": 0.2884,
      "step": 52210
    },
    {
      "epoch": 52.22,
      "learning_rate": 7.57539695367548e-05,
      "loss": 0.3063,
      "step": 52220
    },
    {
      "epoch": 52.23,
      "learning_rate": 7.572916870201094e-05,
      "loss": 0.3328,
      "step": 52230
    },
    {
      "epoch": 52.24,
      "learning_rate": 7.570436778752631e-05,
      "loss": 0.2674,
      "step": 52240
    },
    {
      "epoch": 52.25,
      "learning_rate": 7.567956679601306e-05,
      "loss": 0.2368,
      "step": 52250
    },
    {
      "epoch": 52.26,
      "learning_rate": 7.56547657301834e-05,
      "loss": 0.2951,
      "step": 52260
    },
    {
      "epoch": 52.27,
      "learning_rate": 7.562996459274954e-05,
      "loss": 0.2635,
      "step": 52270
    },
    {
      "epoch": 52.28,
      "learning_rate": 7.560516338642371e-05,
      "loss": 0.2337,
      "step": 52280
    },
    {
      "epoch": 52.29,
      "learning_rate": 7.558036211391812e-05,
      "loss": 0.2781,
      "step": 52290
    },
    {
      "epoch": 52.3,
      "learning_rate": 7.555556077794501e-05,
      "loss": 0.2953,
      "step": 52300
    },
    {
      "epoch": 52.31,
      "learning_rate": 7.55307593812166e-05,
      "loss": 0.2946,
      "step": 52310
    },
    {
      "epoch": 52.32,
      "learning_rate": 7.550595792644513e-05,
      "loss": 0.3131,
      "step": 52320
    },
    {
      "epoch": 52.33,
      "learning_rate": 7.54811564163429e-05,
      "loss": 0.2598,
      "step": 52330
    },
    {
      "epoch": 52.34,
      "learning_rate": 7.54563548536221e-05,
      "loss": 0.2583,
      "step": 52340
    },
    {
      "epoch": 52.35,
      "learning_rate": 7.543155324099503e-05,
      "loss": 0.2522,
      "step": 52350
    },
    {
      "epoch": 52.36,
      "learning_rate": 7.540675158117394e-05,
      "loss": 0.2699,
      "step": 52360
    },
    {
      "epoch": 52.37,
      "learning_rate": 7.538194987687112e-05,
      "loss": 0.3104,
      "step": 52370
    },
    {
      "epoch": 52.38,
      "learning_rate": 7.535714813079881e-05,
      "loss": 0.2883,
      "step": 52380
    },
    {
      "epoch": 52.39,
      "learning_rate": 7.533234634566934e-05,
      "loss": 0.2781,
      "step": 52390
    },
    {
      "epoch": 52.4,
      "learning_rate": 7.530754452419497e-05,
      "loss": 0.2355,
      "step": 52400
    },
    {
      "epoch": 52.41,
      "learning_rate": 7.528274266908797e-05,
      "loss": 0.3013,
      "step": 52410
    },
    {
      "epoch": 52.42,
      "learning_rate": 7.525794078306068e-05,
      "loss": 0.2422,
      "step": 52420
    },
    {
      "epoch": 52.43,
      "learning_rate": 7.523313886882538e-05,
      "loss": 0.3474,
      "step": 52430
    },
    {
      "epoch": 52.44,
      "learning_rate": 7.520833692909435e-05,
      "loss": 0.2964,
      "step": 52440
    },
    {
      "epoch": 52.45,
      "learning_rate": 7.518353496657991e-05,
      "loss": 0.3279,
      "step": 52450
    },
    {
      "epoch": 52.46,
      "learning_rate": 7.515873298399436e-05,
      "loss": 0.2903,
      "step": 52460
    },
    {
      "epoch": 52.47,
      "learning_rate": 7.513393098405e-05,
      "loss": 0.2753,
      "step": 52470
    },
    {
      "epoch": 52.48,
      "learning_rate": 7.510912896945916e-05,
      "loss": 0.2846,
      "step": 52480
    },
    {
      "epoch": 52.49,
      "learning_rate": 7.508432694293415e-05,
      "loss": 0.2823,
      "step": 52490
    },
    {
      "epoch": 52.5,
      "learning_rate": 7.505952490718726e-05,
      "loss": 0.2442,
      "step": 52500
    },
    {
      "epoch": 52.51,
      "learning_rate": 7.503472286493082e-05,
      "loss": 0.3712,
      "step": 52510
    },
    {
      "epoch": 52.52,
      "learning_rate": 7.500992081887713e-05,
      "loss": 0.3023,
      "step": 52520
    },
    {
      "epoch": 52.53,
      "learning_rate": 7.498511877173853e-05,
      "loss": 0.3235,
      "step": 52530
    },
    {
      "epoch": 52.54,
      "learning_rate": 7.49603167262273e-05,
      "loss": 0.2316,
      "step": 52540
    },
    {
      "epoch": 52.55,
      "learning_rate": 7.493551468505579e-05,
      "loss": 0.2715,
      "step": 52550
    },
    {
      "epoch": 52.56,
      "learning_rate": 7.49107126509363e-05,
      "loss": 0.2892,
      "step": 52560
    },
    {
      "epoch": 52.57,
      "learning_rate": 7.488591062658114e-05,
      "loss": 0.2628,
      "step": 52570
    },
    {
      "epoch": 52.58,
      "learning_rate": 7.486110861470261e-05,
      "loss": 0.2495,
      "step": 52580
    },
    {
      "epoch": 52.59,
      "learning_rate": 7.483630661801302e-05,
      "loss": 0.3039,
      "step": 52590
    },
    {
      "epoch": 52.6,
      "learning_rate": 7.481150463922471e-05,
      "loss": 0.3086,
      "step": 52600
    },
    {
      "epoch": 52.61,
      "learning_rate": 7.478670268104997e-05,
      "loss": 0.3454,
      "step": 52610
    },
    {
      "epoch": 52.62,
      "learning_rate": 7.476190074620111e-05,
      "loss": 0.2886,
      "step": 52620
    },
    {
      "epoch": 52.63,
      "learning_rate": 7.473709883739042e-05,
      "loss": 0.2837,
      "step": 52630
    },
    {
      "epoch": 52.64,
      "learning_rate": 7.471229695733021e-05,
      "loss": 0.2231,
      "step": 52640
    },
    {
      "epoch": 52.65,
      "learning_rate": 7.468749510873275e-05,
      "loss": 0.2569,
      "step": 52650
    },
    {
      "epoch": 52.66,
      "learning_rate": 7.466269329431037e-05,
      "loss": 0.2722,
      "step": 52660
    },
    {
      "epoch": 52.67,
      "learning_rate": 7.463789151677536e-05,
      "loss": 0.2137,
      "step": 52670
    },
    {
      "epoch": 52.68,
      "learning_rate": 7.461308977883997e-05,
      "loss": 0.2613,
      "step": 52680
    },
    {
      "epoch": 52.69,
      "learning_rate": 7.458828808321651e-05,
      "loss": 0.2679,
      "step": 52690
    },
    {
      "epoch": 52.7,
      "learning_rate": 7.456348643261726e-05,
      "loss": 0.3218,
      "step": 52700
    },
    {
      "epoch": 52.71,
      "learning_rate": 7.453868482975443e-05,
      "loss": 0.2946,
      "step": 52710
    },
    {
      "epoch": 52.72,
      "learning_rate": 7.451388327734037e-05,
      "loss": 0.3118,
      "step": 52720
    },
    {
      "epoch": 52.73,
      "learning_rate": 7.44890817780873e-05,
      "loss": 0.3124,
      "step": 52730
    },
    {
      "epoch": 52.74,
      "learning_rate": 7.446428033470747e-05,
      "loss": 0.1994,
      "step": 52740
    },
    {
      "epoch": 52.75,
      "learning_rate": 7.443947894991315e-05,
      "loss": 0.2686,
      "step": 52750
    },
    {
      "epoch": 52.76,
      "learning_rate": 7.441467762641656e-05,
      "loss": 0.3126,
      "step": 52760
    },
    {
      "epoch": 52.77,
      "learning_rate": 7.438987636692995e-05,
      "loss": 0.243,
      "step": 52770
    },
    {
      "epoch": 52.78,
      "learning_rate": 7.436507517416551e-05,
      "loss": 0.2945,
      "step": 52780
    },
    {
      "epoch": 52.79,
      "learning_rate": 7.434027405083553e-05,
      "loss": 0.2257,
      "step": 52790
    },
    {
      "epoch": 52.8,
      "learning_rate": 7.431547299965219e-05,
      "loss": 0.2596,
      "step": 52800
    },
    {
      "epoch": 52.81,
      "learning_rate": 7.429067202332769e-05,
      "loss": 0.261,
      "step": 52810
    },
    {
      "epoch": 52.82,
      "learning_rate": 7.426587112457423e-05,
      "loss": 0.2864,
      "step": 52820
    },
    {
      "epoch": 52.83,
      "learning_rate": 7.4241070306104e-05,
      "loss": 0.2946,
      "step": 52830
    },
    {
      "epoch": 52.84,
      "learning_rate": 7.421626957062916e-05,
      "loss": 0.2856,
      "step": 52840
    },
    {
      "epoch": 52.85,
      "learning_rate": 7.419146892086192e-05,
      "loss": 0.3214,
      "step": 52850
    },
    {
      "epoch": 52.86,
      "learning_rate": 7.416666835951443e-05,
      "loss": 0.2342,
      "step": 52860
    },
    {
      "epoch": 52.87,
      "learning_rate": 7.414186788929883e-05,
      "loss": 0.2865,
      "step": 52870
    },
    {
      "epoch": 52.88,
      "learning_rate": 7.411706751292726e-05,
      "loss": 0.2247,
      "step": 52880
    },
    {
      "epoch": 52.89,
      "learning_rate": 7.409226723311188e-05,
      "loss": 0.2597,
      "step": 52890
    },
    {
      "epoch": 52.9,
      "learning_rate": 7.406746705256475e-05,
      "loss": 0.2604,
      "step": 52900
    },
    {
      "epoch": 52.91,
      "learning_rate": 7.404266697399804e-05,
      "loss": 0.2853,
      "step": 52910
    },
    {
      "epoch": 52.92,
      "learning_rate": 7.401786700012385e-05,
      "loss": 0.3103,
      "step": 52920
    },
    {
      "epoch": 52.93,
      "learning_rate": 7.399306713365423e-05,
      "loss": 0.2859,
      "step": 52930
    },
    {
      "epoch": 52.94,
      "learning_rate": 7.39682673773013e-05,
      "loss": 0.1818,
      "step": 52940
    },
    {
      "epoch": 52.95,
      "learning_rate": 7.394346773377705e-05,
      "loss": 0.2655,
      "step": 52950
    },
    {
      "epoch": 52.96,
      "learning_rate": 7.391866820579363e-05,
      "loss": 0.2634,
      "step": 52960
    },
    {
      "epoch": 52.97,
      "learning_rate": 7.389386879606298e-05,
      "loss": 0.287,
      "step": 52970
    },
    {
      "epoch": 52.98,
      "learning_rate": 7.386906950729721e-05,
      "loss": 0.3099,
      "step": 52980
    },
    {
      "epoch": 52.99,
      "learning_rate": 7.384427034220829e-05,
      "loss": 0.3179,
      "step": 52990
    },
    {
      "epoch": 53.0,
      "learning_rate": 7.381947130350823e-05,
      "loss": 0.2618,
      "step": 53000
    },
    {
      "epoch": 53.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27375537157058716,
      "eval_runtime": 15.2153,
      "eval_samples_per_second": 131.446,
      "eval_steps_per_second": 16.431,
      "step": 53000
    },
    {
      "epoch": 53.01,
      "learning_rate": 7.379467239390902e-05,
      "loss": 0.2579,
      "step": 53010
    },
    {
      "epoch": 53.02,
      "learning_rate": 7.376987361612262e-05,
      "loss": 0.2673,
      "step": 53020
    },
    {
      "epoch": 53.03,
      "learning_rate": 7.374507497286096e-05,
      "loss": 0.2246,
      "step": 53030
    },
    {
      "epoch": 53.04,
      "learning_rate": 7.372027646683604e-05,
      "loss": 0.2085,
      "step": 53040
    },
    {
      "epoch": 53.05,
      "learning_rate": 7.369547810075977e-05,
      "loss": 0.2699,
      "step": 53050
    },
    {
      "epoch": 53.06,
      "learning_rate": 7.367067987734406e-05,
      "loss": 0.2951,
      "step": 53060
    },
    {
      "epoch": 53.07,
      "learning_rate": 7.364588179930079e-05,
      "loss": 0.2853,
      "step": 53070
    },
    {
      "epoch": 53.08,
      "learning_rate": 7.362108386934184e-05,
      "loss": 0.2868,
      "step": 53080
    },
    {
      "epoch": 53.09,
      "learning_rate": 7.359628609017911e-05,
      "loss": 0.355,
      "step": 53090
    },
    {
      "epoch": 53.1,
      "learning_rate": 7.357148846452438e-05,
      "loss": 0.2771,
      "step": 53100
    },
    {
      "epoch": 53.11,
      "learning_rate": 7.354669099508955e-05,
      "loss": 0.2628,
      "step": 53110
    },
    {
      "epoch": 53.12,
      "learning_rate": 7.352189368458642e-05,
      "loss": 0.2254,
      "step": 53120
    },
    {
      "epoch": 53.13,
      "learning_rate": 7.349709653572676e-05,
      "loss": 0.3122,
      "step": 53130
    },
    {
      "epoch": 53.14,
      "learning_rate": 7.347229955122237e-05,
      "loss": 0.2516,
      "step": 53140
    },
    {
      "epoch": 53.15,
      "learning_rate": 7.344750273378501e-05,
      "loss": 0.2258,
      "step": 53150
    },
    {
      "epoch": 53.16,
      "learning_rate": 7.342270608612638e-05,
      "loss": 0.2775,
      "step": 53160
    },
    {
      "epoch": 53.17,
      "learning_rate": 7.339790961095827e-05,
      "loss": 0.2861,
      "step": 53170
    },
    {
      "epoch": 53.18,
      "learning_rate": 7.337311331099236e-05,
      "loss": 0.329,
      "step": 53180
    },
    {
      "epoch": 53.19,
      "learning_rate": 7.334831718894033e-05,
      "loss": 0.226,
      "step": 53190
    },
    {
      "epoch": 53.2,
      "learning_rate": 7.332352124751384e-05,
      "loss": 0.33,
      "step": 53200
    },
    {
      "epoch": 53.21,
      "learning_rate": 7.329872548942455e-05,
      "loss": 0.3638,
      "step": 53210
    },
    {
      "epoch": 53.22,
      "learning_rate": 7.327392991738406e-05,
      "loss": 0.267,
      "step": 53220
    },
    {
      "epoch": 53.23,
      "learning_rate": 7.324913453410403e-05,
      "loss": 0.29,
      "step": 53230
    },
    {
      "epoch": 53.24,
      "learning_rate": 7.3224339342296e-05,
      "loss": 0.2932,
      "step": 53240
    },
    {
      "epoch": 53.25,
      "learning_rate": 7.319954434467157e-05,
      "loss": 0.2156,
      "step": 53250
    },
    {
      "epoch": 53.26,
      "learning_rate": 7.317474954394225e-05,
      "loss": 0.2467,
      "step": 53260
    },
    {
      "epoch": 53.27,
      "learning_rate": 7.314995494281958e-05,
      "loss": 0.2791,
      "step": 53270
    },
    {
      "epoch": 53.28,
      "learning_rate": 7.312516054401506e-05,
      "loss": 0.2592,
      "step": 53280
    },
    {
      "epoch": 53.29,
      "learning_rate": 7.310036635024012e-05,
      "loss": 0.283,
      "step": 53290
    },
    {
      "epoch": 53.3,
      "learning_rate": 7.307557236420631e-05,
      "loss": 0.2772,
      "step": 53300
    },
    {
      "epoch": 53.31,
      "learning_rate": 7.3050778588625e-05,
      "loss": 0.207,
      "step": 53310
    },
    {
      "epoch": 53.32,
      "learning_rate": 7.302598502620761e-05,
      "loss": 0.2687,
      "step": 53320
    },
    {
      "epoch": 53.33,
      "learning_rate": 7.300119167966555e-05,
      "loss": 0.2311,
      "step": 53330
    },
    {
      "epoch": 53.34,
      "learning_rate": 7.297639855171014e-05,
      "loss": 0.2876,
      "step": 53340
    },
    {
      "epoch": 53.35,
      "learning_rate": 7.295160564505273e-05,
      "loss": 0.3076,
      "step": 53350
    },
    {
      "epoch": 53.36,
      "learning_rate": 7.292681296240467e-05,
      "loss": 0.3126,
      "step": 53360
    },
    {
      "epoch": 53.37,
      "learning_rate": 7.290202050647723e-05,
      "loss": 0.2313,
      "step": 53370
    },
    {
      "epoch": 53.38,
      "learning_rate": 7.287722827998166e-05,
      "loss": 0.2674,
      "step": 53380
    },
    {
      "epoch": 53.39,
      "learning_rate": 7.285243628562922e-05,
      "loss": 0.2875,
      "step": 53390
    },
    {
      "epoch": 53.4,
      "learning_rate": 7.282764452613111e-05,
      "loss": 0.2871,
      "step": 53400
    },
    {
      "epoch": 53.41,
      "learning_rate": 7.280285300419851e-05,
      "loss": 0.2915,
      "step": 53410
    },
    {
      "epoch": 53.42,
      "learning_rate": 7.277806172254265e-05,
      "loss": 0.2976,
      "step": 53420
    },
    {
      "epoch": 53.43,
      "learning_rate": 7.275327068387459e-05,
      "loss": 0.3017,
      "step": 53430
    },
    {
      "epoch": 53.44,
      "learning_rate": 7.272847989090548e-05,
      "loss": 0.253,
      "step": 53440
    },
    {
      "epoch": 53.45,
      "learning_rate": 7.270368934634639e-05,
      "loss": 0.2655,
      "step": 53450
    },
    {
      "epoch": 53.46,
      "learning_rate": 7.267889905290839e-05,
      "loss": 0.2574,
      "step": 53460
    },
    {
      "epoch": 53.47,
      "learning_rate": 7.26541090133025e-05,
      "loss": 0.309,
      "step": 53470
    },
    {
      "epoch": 53.48,
      "learning_rate": 7.26293192302397e-05,
      "loss": 0.2958,
      "step": 53480
    },
    {
      "epoch": 53.49,
      "learning_rate": 7.260452970643098e-05,
      "loss": 0.3445,
      "step": 53490
    },
    {
      "epoch": 53.5,
      "learning_rate": 7.25797404445873e-05,
      "loss": 0.3081,
      "step": 53500
    },
    {
      "epoch": 53.51,
      "learning_rate": 7.255495144741959e-05,
      "loss": 0.2845,
      "step": 53510
    },
    {
      "epoch": 53.52,
      "learning_rate": 7.253016271763869e-05,
      "loss": 0.2846,
      "step": 53520
    },
    {
      "epoch": 53.53,
      "learning_rate": 7.25053742579555e-05,
      "loss": 0.2592,
      "step": 53530
    },
    {
      "epoch": 53.54,
      "learning_rate": 7.24805860710808e-05,
      "loss": 0.2003,
      "step": 53540
    },
    {
      "epoch": 53.55,
      "learning_rate": 7.245579815972544e-05,
      "loss": 0.3163,
      "step": 53550
    },
    {
      "epoch": 53.56,
      "learning_rate": 7.243101052660017e-05,
      "loss": 0.2557,
      "step": 53560
    },
    {
      "epoch": 53.57,
      "learning_rate": 7.240622317441573e-05,
      "loss": 0.2868,
      "step": 53570
    },
    {
      "epoch": 53.58,
      "learning_rate": 7.238143610588282e-05,
      "loss": 0.2619,
      "step": 53580
    },
    {
      "epoch": 53.59,
      "learning_rate": 7.235664932371212e-05,
      "loss": 0.2248,
      "step": 53590
    },
    {
      "epoch": 53.6,
      "learning_rate": 7.233186283061427e-05,
      "loss": 0.2942,
      "step": 53600
    },
    {
      "epoch": 53.61,
      "learning_rate": 7.230707662929988e-05,
      "loss": 0.2702,
      "step": 53610
    },
    {
      "epoch": 53.62,
      "learning_rate": 7.228229072247956e-05,
      "loss": 0.2695,
      "step": 53620
    },
    {
      "epoch": 53.63,
      "learning_rate": 7.225750511286383e-05,
      "loss": 0.2769,
      "step": 53630
    },
    {
      "epoch": 53.64,
      "learning_rate": 7.223271980316322e-05,
      "loss": 0.3043,
      "step": 53640
    },
    {
      "epoch": 53.65,
      "learning_rate": 7.220793479608823e-05,
      "loss": 0.2597,
      "step": 53650
    },
    {
      "epoch": 53.66,
      "learning_rate": 7.218315009434926e-05,
      "loss": 0.2765,
      "step": 53660
    },
    {
      "epoch": 53.67,
      "learning_rate": 7.215836570065676e-05,
      "loss": 0.3189,
      "step": 53670
    },
    {
      "epoch": 53.68,
      "learning_rate": 7.213358161772114e-05,
      "loss": 0.2429,
      "step": 53680
    },
    {
      "epoch": 53.69,
      "learning_rate": 7.210879784825274e-05,
      "loss": 0.3405,
      "step": 53690
    },
    {
      "epoch": 53.7,
      "learning_rate": 7.208401439496181e-05,
      "loss": 0.1817,
      "step": 53700
    },
    {
      "epoch": 53.71,
      "learning_rate": 7.205923126055871e-05,
      "loss": 0.2684,
      "step": 53710
    },
    {
      "epoch": 53.72,
      "learning_rate": 7.203444844775367e-05,
      "loss": 0.2428,
      "step": 53720
    },
    {
      "epoch": 53.73,
      "learning_rate": 7.200966595925686e-05,
      "loss": 0.2511,
      "step": 53730
    },
    {
      "epoch": 53.74,
      "learning_rate": 7.198488379777849e-05,
      "loss": 0.2722,
      "step": 53740
    },
    {
      "epoch": 53.75,
      "learning_rate": 7.196010196602871e-05,
      "loss": 0.3542,
      "step": 53750
    },
    {
      "epoch": 53.76,
      "learning_rate": 7.193532046671761e-05,
      "loss": 0.2988,
      "step": 53760
    },
    {
      "epoch": 53.77,
      "learning_rate": 7.191053930255526e-05,
      "loss": 0.3996,
      "step": 53770
    },
    {
      "epoch": 53.78,
      "learning_rate": 7.188575847625167e-05,
      "loss": 0.2953,
      "step": 53780
    },
    {
      "epoch": 53.79,
      "learning_rate": 7.186097799051686e-05,
      "loss": 0.3557,
      "step": 53790
    },
    {
      "epoch": 53.8,
      "learning_rate": 7.183619784806076e-05,
      "loss": 0.2763,
      "step": 53800
    },
    {
      "epoch": 53.81,
      "learning_rate": 7.181141805159332e-05,
      "loss": 0.2423,
      "step": 53810
    },
    {
      "epoch": 53.82,
      "learning_rate": 7.178663860382442e-05,
      "loss": 0.226,
      "step": 53820
    },
    {
      "epoch": 53.83,
      "learning_rate": 7.176185950746388e-05,
      "loss": 0.299,
      "step": 53830
    },
    {
      "epoch": 53.84,
      "learning_rate": 7.173708076522153e-05,
      "loss": 0.2767,
      "step": 53840
    },
    {
      "epoch": 53.85,
      "learning_rate": 7.171230237980711e-05,
      "loss": 0.2765,
      "step": 53850
    },
    {
      "epoch": 53.86,
      "learning_rate": 7.168752435393033e-05,
      "loss": 0.3056,
      "step": 53860
    },
    {
      "epoch": 53.87,
      "learning_rate": 7.166274669030095e-05,
      "loss": 0.2503,
      "step": 53870
    },
    {
      "epoch": 53.88,
      "learning_rate": 7.163796939162855e-05,
      "loss": 0.3294,
      "step": 53880
    },
    {
      "epoch": 53.89,
      "learning_rate": 7.161319246062278e-05,
      "loss": 0.2076,
      "step": 53890
    },
    {
      "epoch": 53.9,
      "learning_rate": 7.158841589999319e-05,
      "loss": 0.3211,
      "step": 53900
    },
    {
      "epoch": 53.91,
      "learning_rate": 7.156363971244928e-05,
      "loss": 0.2888,
      "step": 53910
    },
    {
      "epoch": 53.92,
      "learning_rate": 7.153886390070057e-05,
      "loss": 0.3286,
      "step": 53920
    },
    {
      "epoch": 53.93,
      "learning_rate": 7.151408846745653e-05,
      "loss": 0.2083,
      "step": 53930
    },
    {
      "epoch": 53.94,
      "learning_rate": 7.148931341542653e-05,
      "loss": 0.2937,
      "step": 53940
    },
    {
      "epoch": 53.95,
      "learning_rate": 7.14645387473199e-05,
      "loss": 0.2795,
      "step": 53950
    },
    {
      "epoch": 53.96,
      "learning_rate": 7.143976446584603e-05,
      "loss": 0.2775,
      "step": 53960
    },
    {
      "epoch": 53.97,
      "learning_rate": 7.141499057371416e-05,
      "loss": 0.3467,
      "step": 53970
    },
    {
      "epoch": 53.98,
      "learning_rate": 7.139021707363353e-05,
      "loss": 0.3377,
      "step": 53980
    },
    {
      "epoch": 53.99,
      "learning_rate": 7.13654439683133e-05,
      "loss": 0.2956,
      "step": 53990
    },
    {
      "epoch": 54.0,
      "learning_rate": 7.134067126046269e-05,
      "loss": 0.208,
      "step": 54000
    },
    {
      "epoch": 54.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.2731175124645233,
      "eval_runtime": 14.9764,
      "eval_samples_per_second": 133.544,
      "eval_steps_per_second": 16.693,
      "step": 54000
    },
    {
      "epoch": 54.01,
      "learning_rate": 7.131589895279078e-05,
      "loss": 0.269,
      "step": 54010
    },
    {
      "epoch": 54.02,
      "learning_rate": 7.12911270480066e-05,
      "loss": 0.2596,
      "step": 54020
    },
    {
      "epoch": 54.03,
      "learning_rate": 7.12663555488192e-05,
      "loss": 0.295,
      "step": 54030
    },
    {
      "epoch": 54.04,
      "learning_rate": 7.124158445793755e-05,
      "loss": 0.3283,
      "step": 54040
    },
    {
      "epoch": 54.05,
      "learning_rate": 7.121681377807053e-05,
      "loss": 0.2561,
      "step": 54050
    },
    {
      "epoch": 54.06,
      "learning_rate": 7.11920435119271e-05,
      "loss": 0.2943,
      "step": 54060
    },
    {
      "epoch": 54.07,
      "learning_rate": 7.116727366221608e-05,
      "loss": 0.232,
      "step": 54070
    },
    {
      "epoch": 54.08,
      "learning_rate": 7.114250423164624e-05,
      "loss": 0.2909,
      "step": 54080
    },
    {
      "epoch": 54.09,
      "learning_rate": 7.111773522292634e-05,
      "loss": 0.3305,
      "step": 54090
    },
    {
      "epoch": 54.1,
      "learning_rate": 7.109296663876507e-05,
      "loss": 0.3438,
      "step": 54100
    },
    {
      "epoch": 54.11,
      "learning_rate": 7.106819848187107e-05,
      "loss": 0.3554,
      "step": 54110
    },
    {
      "epoch": 54.12,
      "learning_rate": 7.1043430754953e-05,
      "loss": 0.2713,
      "step": 54120
    },
    {
      "epoch": 54.13,
      "learning_rate": 7.10186634607194e-05,
      "loss": 0.2773,
      "step": 54130
    },
    {
      "epoch": 54.14,
      "learning_rate": 7.099389660187878e-05,
      "loss": 0.2937,
      "step": 54140
    },
    {
      "epoch": 54.15,
      "learning_rate": 7.09691301811396e-05,
      "loss": 0.3113,
      "step": 54150
    },
    {
      "epoch": 54.16,
      "learning_rate": 7.094436420121026e-05,
      "loss": 0.2941,
      "step": 54160
    },
    {
      "epoch": 54.17,
      "learning_rate": 7.091959866479919e-05,
      "loss": 0.2341,
      "step": 54170
    },
    {
      "epoch": 54.18,
      "learning_rate": 7.089483357461464e-05,
      "loss": 0.2012,
      "step": 54180
    },
    {
      "epoch": 54.19,
      "learning_rate": 7.087006893336493e-05,
      "loss": 0.3052,
      "step": 54190
    },
    {
      "epoch": 54.2,
      "learning_rate": 7.084530474375828e-05,
      "loss": 0.3869,
      "step": 54200
    },
    {
      "epoch": 54.21,
      "learning_rate": 7.082054100850287e-05,
      "loss": 0.2682,
      "step": 54210
    },
    {
      "epoch": 54.22,
      "learning_rate": 7.07957777303068e-05,
      "loss": 0.2172,
      "step": 54220
    },
    {
      "epoch": 54.23,
      "learning_rate": 7.077101491187815e-05,
      "loss": 0.2981,
      "step": 54230
    },
    {
      "epoch": 54.24,
      "learning_rate": 7.074625255592492e-05,
      "loss": 0.2218,
      "step": 54240
    },
    {
      "epoch": 54.25,
      "learning_rate": 7.072149066515516e-05,
      "loss": 0.2116,
      "step": 54250
    },
    {
      "epoch": 54.26,
      "learning_rate": 7.069672924227674e-05,
      "loss": 0.2871,
      "step": 54260
    },
    {
      "epoch": 54.27,
      "learning_rate": 7.067196828999754e-05,
      "loss": 0.3777,
      "step": 54270
    },
    {
      "epoch": 54.28,
      "learning_rate": 7.064720781102539e-05,
      "loss": 0.3262,
      "step": 54280
    },
    {
      "epoch": 54.29,
      "learning_rate": 7.062244780806803e-05,
      "loss": 0.2841,
      "step": 54290
    },
    {
      "epoch": 54.3,
      "learning_rate": 7.059768828383322e-05,
      "loss": 0.2742,
      "step": 54300
    },
    {
      "epoch": 54.31,
      "learning_rate": 7.057292924102855e-05,
      "loss": 0.2299,
      "step": 54310
    },
    {
      "epoch": 54.32,
      "learning_rate": 7.054817068236172e-05,
      "loss": 0.2527,
      "step": 54320
    },
    {
      "epoch": 54.33,
      "learning_rate": 7.052341261054026e-05,
      "loss": 0.2794,
      "step": 54330
    },
    {
      "epoch": 54.34,
      "learning_rate": 7.049865502827166e-05,
      "loss": 0.1925,
      "step": 54340
    },
    {
      "epoch": 54.35,
      "learning_rate": 7.047389793826338e-05,
      "loss": 0.2905,
      "step": 54350
    },
    {
      "epoch": 54.36,
      "learning_rate": 7.04491413432228e-05,
      "loss": 0.3348,
      "step": 54360
    },
    {
      "epoch": 54.37,
      "learning_rate": 7.042438524585727e-05,
      "loss": 0.3449,
      "step": 54370
    },
    {
      "epoch": 54.38,
      "learning_rate": 7.039962964887411e-05,
      "loss": 0.3294,
      "step": 54380
    },
    {
      "epoch": 54.39,
      "learning_rate": 7.037487455498055e-05,
      "loss": 0.2689,
      "step": 54390
    },
    {
      "epoch": 54.4,
      "learning_rate": 7.035011996688373e-05,
      "loss": 0.3201,
      "step": 54400
    },
    {
      "epoch": 54.41,
      "learning_rate": 7.03253658872908e-05,
      "loss": 0.3115,
      "step": 54410
    },
    {
      "epoch": 54.42,
      "learning_rate": 7.030061231890885e-05,
      "loss": 0.2602,
      "step": 54420
    },
    {
      "epoch": 54.43,
      "learning_rate": 7.027585926444485e-05,
      "loss": 0.3104,
      "step": 54430
    },
    {
      "epoch": 54.44,
      "learning_rate": 7.025110672660579e-05,
      "loss": 0.294,
      "step": 54440
    },
    {
      "epoch": 54.45,
      "learning_rate": 7.022635470809853e-05,
      "loss": 0.2081,
      "step": 54450
    },
    {
      "epoch": 54.46,
      "learning_rate": 7.020160321162998e-05,
      "loss": 0.2338,
      "step": 54460
    },
    {
      "epoch": 54.47,
      "learning_rate": 7.017685223990687e-05,
      "loss": 0.3115,
      "step": 54470
    },
    {
      "epoch": 54.48,
      "learning_rate": 7.015210179563597e-05,
      "loss": 0.269,
      "step": 54480
    },
    {
      "epoch": 54.49,
      "learning_rate": 7.01273518815239e-05,
      "loss": 0.2243,
      "step": 54490
    },
    {
      "epoch": 54.5,
      "learning_rate": 7.01026025002773e-05,
      "loss": 0.293,
      "step": 54500
    },
    {
      "epoch": 54.51,
      "learning_rate": 7.007785365460275e-05,
      "loss": 0.2607,
      "step": 54510
    },
    {
      "epoch": 54.52,
      "learning_rate": 7.005310534720672e-05,
      "loss": 0.2618,
      "step": 54520
    },
    {
      "epoch": 54.53,
      "learning_rate": 7.002835758079565e-05,
      "loss": 0.2686,
      "step": 54530
    },
    {
      "epoch": 54.54,
      "learning_rate": 7.000361035807593e-05,
      "loss": 0.3034,
      "step": 54540
    },
    {
      "epoch": 54.55,
      "learning_rate": 6.997886368175386e-05,
      "loss": 0.2763,
      "step": 54550
    },
    {
      "epoch": 54.56,
      "learning_rate": 6.995411755453567e-05,
      "loss": 0.2277,
      "step": 54560
    },
    {
      "epoch": 54.57,
      "learning_rate": 6.992937197912765e-05,
      "loss": 0.3391,
      "step": 54570
    },
    {
      "epoch": 54.58,
      "learning_rate": 6.990462695823587e-05,
      "loss": 0.2884,
      "step": 54580
    },
    {
      "epoch": 54.59,
      "learning_rate": 6.987988249456644e-05,
      "loss": 0.3289,
      "step": 54590
    },
    {
      "epoch": 54.6,
      "learning_rate": 6.985513859082534e-05,
      "loss": 0.2697,
      "step": 54600
    },
    {
      "epoch": 54.61,
      "learning_rate": 6.983039524971856e-05,
      "loss": 0.2844,
      "step": 54610
    },
    {
      "epoch": 54.62,
      "learning_rate": 6.980565247395196e-05,
      "loss": 0.2511,
      "step": 54620
    },
    {
      "epoch": 54.63,
      "learning_rate": 6.978091026623142e-05,
      "loss": 0.3126,
      "step": 54630
    },
    {
      "epoch": 54.64,
      "learning_rate": 6.975616862926268e-05,
      "loss": 0.2339,
      "step": 54640
    },
    {
      "epoch": 54.65,
      "learning_rate": 6.973142756575147e-05,
      "loss": 0.2202,
      "step": 54650
    },
    {
      "epoch": 54.66,
      "learning_rate": 6.97066870784034e-05,
      "loss": 0.3114,
      "step": 54660
    },
    {
      "epoch": 54.67,
      "learning_rate": 6.968194716992408e-05,
      "loss": 0.2705,
      "step": 54670
    },
    {
      "epoch": 54.68,
      "learning_rate": 6.965720784301903e-05,
      "loss": 0.2561,
      "step": 54680
    },
    {
      "epoch": 54.69,
      "learning_rate": 6.963246910039368e-05,
      "loss": 0.2472,
      "step": 54690
    },
    {
      "epoch": 54.7,
      "learning_rate": 6.960773094475343e-05,
      "loss": 0.2536,
      "step": 54700
    },
    {
      "epoch": 54.71,
      "learning_rate": 6.958299337880364e-05,
      "loss": 0.3498,
      "step": 54710
    },
    {
      "epoch": 54.72,
      "learning_rate": 6.955825640524954e-05,
      "loss": 0.3258,
      "step": 54720
    },
    {
      "epoch": 54.73,
      "learning_rate": 6.953352002679636e-05,
      "loss": 0.2935,
      "step": 54730
    },
    {
      "epoch": 54.74,
      "learning_rate": 6.95087842461492e-05,
      "loss": 0.2428,
      "step": 54740
    },
    {
      "epoch": 54.75,
      "learning_rate": 6.94840490660131e-05,
      "loss": 0.2636,
      "step": 54750
    },
    {
      "epoch": 54.76,
      "learning_rate": 6.945931448909315e-05,
      "loss": 0.3139,
      "step": 54760
    },
    {
      "epoch": 54.77,
      "learning_rate": 6.943458051809421e-05,
      "loss": 0.2691,
      "step": 54770
    },
    {
      "epoch": 54.78,
      "learning_rate": 6.94098471557212e-05,
      "loss": 0.3021,
      "step": 54780
    },
    {
      "epoch": 54.79,
      "learning_rate": 6.938511440467889e-05,
      "loss": 0.2696,
      "step": 54790
    },
    {
      "epoch": 54.8,
      "learning_rate": 6.936038226767204e-05,
      "loss": 0.2508,
      "step": 54800
    },
    {
      "epoch": 54.81,
      "learning_rate": 6.933565074740526e-05,
      "loss": 0.2349,
      "step": 54810
    },
    {
      "epoch": 54.82,
      "learning_rate": 6.931091984658322e-05,
      "loss": 0.1995,
      "step": 54820
    },
    {
      "epoch": 54.83,
      "learning_rate": 6.928618956791046e-05,
      "loss": 0.2247,
      "step": 54830
    },
    {
      "epoch": 54.84,
      "learning_rate": 6.92614599140914e-05,
      "loss": 0.2752,
      "step": 54840
    },
    {
      "epoch": 54.85,
      "learning_rate": 6.923673088783045e-05,
      "loss": 0.2819,
      "step": 54850
    },
    {
      "epoch": 54.86,
      "learning_rate": 6.921200249183196e-05,
      "loss": 0.2519,
      "step": 54860
    },
    {
      "epoch": 54.87,
      "learning_rate": 6.918727472880016e-05,
      "loss": 0.2009,
      "step": 54870
    },
    {
      "epoch": 54.88,
      "learning_rate": 6.916254760143925e-05,
      "loss": 0.3455,
      "step": 54880
    },
    {
      "epoch": 54.89,
      "learning_rate": 6.913782111245338e-05,
      "loss": 0.3117,
      "step": 54890
    },
    {
      "epoch": 54.9,
      "learning_rate": 6.911309526454658e-05,
      "loss": 0.2771,
      "step": 54900
    },
    {
      "epoch": 54.91,
      "learning_rate": 6.90883700604228e-05,
      "loss": 0.2846,
      "step": 54910
    },
    {
      "epoch": 54.92,
      "learning_rate": 6.9063645502786e-05,
      "loss": 0.2351,
      "step": 54920
    },
    {
      "epoch": 54.93,
      "learning_rate": 6.903892159434003e-05,
      "loss": 0.2861,
      "step": 54930
    },
    {
      "epoch": 54.94,
      "learning_rate": 6.901419833778859e-05,
      "loss": 0.3107,
      "step": 54940
    },
    {
      "epoch": 54.95,
      "learning_rate": 6.898947573583542e-05,
      "loss": 0.2836,
      "step": 54950
    },
    {
      "epoch": 54.96,
      "learning_rate": 6.896475379118417e-05,
      "loss": 0.2583,
      "step": 54960
    },
    {
      "epoch": 54.97,
      "learning_rate": 6.894003250653838e-05,
      "loss": 0.218,
      "step": 54970
    },
    {
      "epoch": 54.98,
      "learning_rate": 6.891531188460152e-05,
      "loss": 0.2737,
      "step": 54980
    },
    {
      "epoch": 54.99,
      "learning_rate": 6.8890591928077e-05,
      "loss": 0.3475,
      "step": 54990
    },
    {
      "epoch": 55.0,
      "learning_rate": 6.886587263966815e-05,
      "loss": 0.2579,
      "step": 55000
    },
    {
      "epoch": 55.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2741016149520874,
      "eval_runtime": 14.9142,
      "eval_samples_per_second": 134.1,
      "eval_steps_per_second": 16.763,
      "step": 55000
    },
    {
      "epoch": 55.01,
      "learning_rate": 6.884115402207823e-05,
      "loss": 0.2886,
      "step": 55010
    },
    {
      "epoch": 55.02,
      "learning_rate": 6.881643607801048e-05,
      "loss": 0.3074,
      "step": 55020
    },
    {
      "epoch": 55.03,
      "learning_rate": 6.879171881016798e-05,
      "loss": 0.2666,
      "step": 55030
    },
    {
      "epoch": 55.04,
      "learning_rate": 6.876700222125377e-05,
      "loss": 0.3276,
      "step": 55040
    },
    {
      "epoch": 55.05,
      "learning_rate": 6.874228631397082e-05,
      "loss": 0.2595,
      "step": 55050
    },
    {
      "epoch": 55.06,
      "learning_rate": 6.871757109102205e-05,
      "loss": 0.2642,
      "step": 55060
    },
    {
      "epoch": 55.07,
      "learning_rate": 6.86928565551102e-05,
      "loss": 0.2461,
      "step": 55070
    },
    {
      "epoch": 55.08,
      "learning_rate": 6.866814270893813e-05,
      "loss": 0.2446,
      "step": 55080
    },
    {
      "epoch": 55.09,
      "learning_rate": 6.864342955520845e-05,
      "loss": 0.2432,
      "step": 55090
    },
    {
      "epoch": 55.1,
      "learning_rate": 6.861871709662377e-05,
      "loss": 0.2872,
      "step": 55100
    },
    {
      "epoch": 55.11,
      "learning_rate": 6.859400533588657e-05,
      "loss": 0.3025,
      "step": 55110
    },
    {
      "epoch": 55.12,
      "learning_rate": 6.856929427569931e-05,
      "loss": 0.2683,
      "step": 55120
    },
    {
      "epoch": 55.13,
      "learning_rate": 6.854458391876436e-05,
      "loss": 0.2792,
      "step": 55130
    },
    {
      "epoch": 55.14,
      "learning_rate": 6.851987426778402e-05,
      "loss": 0.2849,
      "step": 55140
    },
    {
      "epoch": 55.15,
      "learning_rate": 6.849516532546049e-05,
      "loss": 0.3035,
      "step": 55150
    },
    {
      "epoch": 55.16,
      "learning_rate": 6.847045709449588e-05,
      "loss": 0.3273,
      "step": 55160
    },
    {
      "epoch": 55.17,
      "learning_rate": 6.844574957759228e-05,
      "loss": 0.3393,
      "step": 55170
    },
    {
      "epoch": 55.18,
      "learning_rate": 6.842104277745165e-05,
      "loss": 0.2907,
      "step": 55180
    },
    {
      "epoch": 55.19,
      "learning_rate": 6.83963366967759e-05,
      "loss": 0.2836,
      "step": 55190
    },
    {
      "epoch": 55.2,
      "learning_rate": 6.837163133826681e-05,
      "loss": 0.2629,
      "step": 55200
    },
    {
      "epoch": 55.21,
      "learning_rate": 6.834692670462618e-05,
      "loss": 0.2781,
      "step": 55210
    },
    {
      "epoch": 55.22,
      "learning_rate": 6.832222279855563e-05,
      "loss": 0.2847,
      "step": 55220
    },
    {
      "epoch": 55.23,
      "learning_rate": 6.829751962275677e-05,
      "loss": 0.2697,
      "step": 55230
    },
    {
      "epoch": 55.24,
      "learning_rate": 6.827281717993109e-05,
      "loss": 0.2674,
      "step": 55240
    },
    {
      "epoch": 55.25,
      "learning_rate": 6.825058561031276e-05,
      "loss": 0.3078,
      "step": 55250
    },
    {
      "epoch": 55.26,
      "learning_rate": 6.822588456757846e-05,
      "loss": 0.3082,
      "step": 55260
    },
    {
      "epoch": 55.27,
      "learning_rate": 6.82011842656512e-05,
      "loss": 0.3418,
      "step": 55270
    },
    {
      "epoch": 55.28,
      "learning_rate": 6.817648470723224e-05,
      "loss": 0.2801,
      "step": 55280
    },
    {
      "epoch": 55.29,
      "learning_rate": 6.815178589502266e-05,
      "loss": 0.3286,
      "step": 55290
    },
    {
      "epoch": 55.3,
      "learning_rate": 6.812708783172348e-05,
      "loss": 0.2712,
      "step": 55300
    },
    {
      "epoch": 55.31,
      "learning_rate": 6.810239052003564e-05,
      "loss": 0.2502,
      "step": 55310
    },
    {
      "epoch": 55.32,
      "learning_rate": 6.807769396266e-05,
      "loss": 0.3311,
      "step": 55320
    },
    {
      "epoch": 55.33,
      "learning_rate": 6.805299816229731e-05,
      "loss": 0.2718,
      "step": 55330
    },
    {
      "epoch": 55.34,
      "learning_rate": 6.802830312164833e-05,
      "loss": 0.19,
      "step": 55340
    },
    {
      "epoch": 55.35,
      "learning_rate": 6.800360884341364e-05,
      "loss": 0.237,
      "step": 55350
    },
    {
      "epoch": 55.36,
      "learning_rate": 6.797891533029377e-05,
      "loss": 0.2447,
      "step": 55360
    },
    {
      "epoch": 55.37,
      "learning_rate": 6.795422258498916e-05,
      "loss": 0.2338,
      "step": 55370
    },
    {
      "epoch": 55.38,
      "learning_rate": 6.792953061020015e-05,
      "loss": 0.26,
      "step": 55380
    },
    {
      "epoch": 55.39,
      "learning_rate": 6.790483940862707e-05,
      "loss": 0.2518,
      "step": 55390
    },
    {
      "epoch": 55.4,
      "learning_rate": 6.788014898297007e-05,
      "loss": 0.2855,
      "step": 55400
    },
    {
      "epoch": 55.41,
      "learning_rate": 6.785545933592927e-05,
      "loss": 0.2714,
      "step": 55410
    },
    {
      "epoch": 55.42,
      "learning_rate": 6.783077047020469e-05,
      "loss": 0.2453,
      "step": 55420
    },
    {
      "epoch": 55.43,
      "learning_rate": 6.78060823884963e-05,
      "loss": 0.3033,
      "step": 55430
    },
    {
      "epoch": 55.44,
      "learning_rate": 6.778139509350391e-05,
      "loss": 0.2857,
      "step": 55440
    },
    {
      "epoch": 55.45,
      "learning_rate": 6.775670858792731e-05,
      "loss": 0.3458,
      "step": 55450
    },
    {
      "epoch": 55.46,
      "learning_rate": 6.773202287446612e-05,
      "loss": 0.2612,
      "step": 55460
    },
    {
      "epoch": 55.47,
      "learning_rate": 6.770733795582003e-05,
      "loss": 0.2596,
      "step": 55470
    },
    {
      "epoch": 55.48,
      "learning_rate": 6.768265383468849e-05,
      "loss": 0.2693,
      "step": 55480
    },
    {
      "epoch": 55.49,
      "learning_rate": 6.765797051377093e-05,
      "loss": 0.2865,
      "step": 55490
    },
    {
      "epoch": 55.5,
      "learning_rate": 6.763328799576667e-05,
      "loss": 0.3209,
      "step": 55500
    },
    {
      "epoch": 55.51,
      "learning_rate": 6.760860628337498e-05,
      "loss": 0.2847,
      "step": 55510
    },
    {
      "epoch": 55.52,
      "learning_rate": 6.758392537929493e-05,
      "loss": 0.2249,
      "step": 55520
    },
    {
      "epoch": 55.53,
      "learning_rate": 6.75592452862257e-05,
      "loss": 0.2453,
      "step": 55530
    },
    {
      "epoch": 55.54,
      "learning_rate": 6.753456600686622e-05,
      "loss": 0.3365,
      "step": 55540
    },
    {
      "epoch": 55.55,
      "learning_rate": 6.750988754391536e-05,
      "loss": 0.2511,
      "step": 55550
    },
    {
      "epoch": 55.56,
      "learning_rate": 6.748520990007197e-05,
      "loss": 0.301,
      "step": 55560
    },
    {
      "epoch": 55.57,
      "learning_rate": 6.74605330780347e-05,
      "loss": 0.2121,
      "step": 55570
    },
    {
      "epoch": 55.58,
      "learning_rate": 6.74358570805022e-05,
      "loss": 0.2498,
      "step": 55580
    },
    {
      "epoch": 55.59,
      "learning_rate": 6.741118191017297e-05,
      "loss": 0.237,
      "step": 55590
    },
    {
      "epoch": 55.6,
      "learning_rate": 6.73865075697455e-05,
      "loss": 0.272,
      "step": 55600
    },
    {
      "epoch": 55.61,
      "learning_rate": 6.736183406191812e-05,
      "loss": 0.3217,
      "step": 55610
    },
    {
      "epoch": 55.62,
      "learning_rate": 6.73371613893891e-05,
      "loss": 0.2673,
      "step": 55620
    },
    {
      "epoch": 55.63,
      "learning_rate": 6.731248955485655e-05,
      "loss": 0.2262,
      "step": 55630
    },
    {
      "epoch": 55.64,
      "learning_rate": 6.728781856101862e-05,
      "loss": 0.2651,
      "step": 55640
    },
    {
      "epoch": 55.65,
      "learning_rate": 6.726314841057323e-05,
      "loss": 0.2628,
      "step": 55650
    },
    {
      "epoch": 55.66,
      "learning_rate": 6.72384791062183e-05,
      "loss": 0.3062,
      "step": 55660
    },
    {
      "epoch": 55.67,
      "learning_rate": 6.721381065065164e-05,
      "loss": 0.276,
      "step": 55670
    },
    {
      "epoch": 55.68,
      "learning_rate": 6.718914304657094e-05,
      "loss": 0.2435,
      "step": 55680
    },
    {
      "epoch": 55.69,
      "learning_rate": 6.716447629667381e-05,
      "loss": 0.2184,
      "step": 55690
    },
    {
      "epoch": 55.7,
      "learning_rate": 6.713981040365778e-05,
      "loss": 0.2615,
      "step": 55700
    },
    {
      "epoch": 55.71,
      "learning_rate": 6.711514537022023e-05,
      "loss": 0.1995,
      "step": 55710
    },
    {
      "epoch": 55.72,
      "learning_rate": 6.709048119905856e-05,
      "loss": 0.3119,
      "step": 55720
    },
    {
      "epoch": 55.73,
      "learning_rate": 6.706581789286996e-05,
      "loss": 0.2526,
      "step": 55730
    },
    {
      "epoch": 55.74,
      "learning_rate": 6.70411554543516e-05,
      "loss": 0.3454,
      "step": 55740
    },
    {
      "epoch": 55.75,
      "learning_rate": 6.701649388620053e-05,
      "loss": 0.3183,
      "step": 55750
    },
    {
      "epoch": 55.76,
      "learning_rate": 6.699183319111367e-05,
      "loss": 0.3077,
      "step": 55760
    },
    {
      "epoch": 55.77,
      "learning_rate": 6.696717337178788e-05,
      "loss": 0.2667,
      "step": 55770
    },
    {
      "epoch": 55.78,
      "learning_rate": 6.694251443091992e-05,
      "loss": 0.2476,
      "step": 55780
    },
    {
      "epoch": 55.79,
      "learning_rate": 6.69178563712065e-05,
      "loss": 0.3182,
      "step": 55790
    },
    {
      "epoch": 55.8,
      "learning_rate": 6.689319919534415e-05,
      "loss": 0.3423,
      "step": 55800
    },
    {
      "epoch": 55.81,
      "learning_rate": 6.686854290602933e-05,
      "loss": 0.3318,
      "step": 55810
    },
    {
      "epoch": 55.82,
      "learning_rate": 6.684388750595845e-05,
      "loss": 0.2461,
      "step": 55820
    },
    {
      "epoch": 55.83,
      "learning_rate": 6.681923299782778e-05,
      "loss": 0.3254,
      "step": 55830
    },
    {
      "epoch": 55.84,
      "learning_rate": 6.679457938433345e-05,
      "loss": 0.3034,
      "step": 55840
    },
    {
      "epoch": 55.85,
      "learning_rate": 6.67699266681716e-05,
      "loss": 0.3261,
      "step": 55850
    },
    {
      "epoch": 55.86,
      "learning_rate": 6.674527485203821e-05,
      "loss": 0.2699,
      "step": 55860
    },
    {
      "epoch": 55.87,
      "learning_rate": 6.672062393862914e-05,
      "loss": 0.2514,
      "step": 55870
    },
    {
      "epoch": 55.88,
      "learning_rate": 6.669597393064018e-05,
      "loss": 0.3128,
      "step": 55880
    },
    {
      "epoch": 55.89,
      "learning_rate": 6.667132483076705e-05,
      "loss": 0.2611,
      "step": 55890
    },
    {
      "epoch": 55.9,
      "learning_rate": 6.664667664170528e-05,
      "loss": 0.3039,
      "step": 55900
    },
    {
      "epoch": 55.91,
      "learning_rate": 6.662202936615042e-05,
      "loss": 0.2394,
      "step": 55910
    },
    {
      "epoch": 55.92,
      "learning_rate": 6.659738300679781e-05,
      "loss": 0.302,
      "step": 55920
    },
    {
      "epoch": 55.93,
      "learning_rate": 6.657766658079263e-05,
      "loss": 0.8205,
      "step": 55930
    },
    {
      "epoch": 55.94,
      "learning_rate": 6.655302187739619e-05,
      "loss": 0.2877,
      "step": 55940
    },
    {
      "epoch": 55.95,
      "learning_rate": 6.652837809774857e-05,
      "loss": 0.291,
      "step": 55950
    },
    {
      "epoch": 55.96,
      "learning_rate": 6.65037352445448e-05,
      "loss": 0.3488,
      "step": 55960
    },
    {
      "epoch": 55.97,
      "learning_rate": 6.647909332047976e-05,
      "loss": 0.3055,
      "step": 55970
    },
    {
      "epoch": 55.98,
      "learning_rate": 6.645445232824825e-05,
      "loss": 0.3016,
      "step": 55980
    },
    {
      "epoch": 55.99,
      "learning_rate": 6.642981227054498e-05,
      "loss": 0.2566,
      "step": 55990
    },
    {
      "epoch": 56.0,
      "learning_rate": 6.640517315006458e-05,
      "loss": 0.235,
      "step": 56000
    },
    {
      "epoch": 56.0,
      "eval_accuracy": 0.8045,
      "eval_loss": 0.2750225365161896,
      "eval_runtime": 14.3825,
      "eval_samples_per_second": 139.057,
      "eval_steps_per_second": 17.382,
      "step": 56000
    },
    {
      "epoch": 56.01,
      "learning_rate": 6.638053496950152e-05,
      "loss": 0.2387,
      "step": 56010
    },
    {
      "epoch": 56.02,
      "learning_rate": 6.63558977315502e-05,
      "loss": 0.2348,
      "step": 56020
    },
    {
      "epoch": 56.03,
      "learning_rate": 6.63312614389049e-05,
      "loss": 0.2428,
      "step": 56030
    },
    {
      "epoch": 56.04,
      "learning_rate": 6.630662609425982e-05,
      "loss": 0.2415,
      "step": 56040
    },
    {
      "epoch": 56.05,
      "learning_rate": 6.628199170030901e-05,
      "loss": 0.255,
      "step": 56050
    },
    {
      "epoch": 56.06,
      "learning_rate": 6.625735825974651e-05,
      "loss": 0.2553,
      "step": 56060
    },
    {
      "epoch": 56.07,
      "learning_rate": 6.623272577526617e-05,
      "loss": 0.2699,
      "step": 56070
    },
    {
      "epoch": 56.08,
      "learning_rate": 6.620809424956176e-05,
      "loss": 0.3126,
      "step": 56080
    },
    {
      "epoch": 56.09,
      "learning_rate": 6.618346368532692e-05,
      "loss": 0.2643,
      "step": 56090
    },
    {
      "epoch": 56.1,
      "learning_rate": 6.615883408525526e-05,
      "loss": 0.2873,
      "step": 56100
    },
    {
      "epoch": 56.11,
      "learning_rate": 6.613420545204017e-05,
      "loss": 0.2599,
      "step": 56110
    },
    {
      "epoch": 56.12,
      "learning_rate": 6.610957778837509e-05,
      "loss": 0.3113,
      "step": 56120
    },
    {
      "epoch": 56.13,
      "learning_rate": 6.60849510969532e-05,
      "loss": 0.34,
      "step": 56130
    },
    {
      "epoch": 56.14,
      "learning_rate": 6.606032538046766e-05,
      "loss": 0.2842,
      "step": 56140
    },
    {
      "epoch": 56.15,
      "learning_rate": 6.60357006416115e-05,
      "loss": 0.2699,
      "step": 56150
    },
    {
      "epoch": 56.16,
      "learning_rate": 6.601107688307762e-05,
      "loss": 0.3104,
      "step": 56160
    },
    {
      "epoch": 56.17,
      "learning_rate": 6.598645410755886e-05,
      "loss": 0.3362,
      "step": 56170
    },
    {
      "epoch": 56.18,
      "learning_rate": 6.596183231774794e-05,
      "loss": 0.3143,
      "step": 56180
    },
    {
      "epoch": 56.19,
      "learning_rate": 6.593721151633745e-05,
      "loss": 0.2593,
      "step": 56190
    },
    {
      "epoch": 56.2,
      "learning_rate": 6.591259170601986e-05,
      "loss": 0.2176,
      "step": 56200
    },
    {
      "epoch": 56.21,
      "learning_rate": 6.588797288948761e-05,
      "loss": 0.2701,
      "step": 56210
    },
    {
      "epoch": 56.22,
      "learning_rate": 6.586335506943294e-05,
      "loss": 0.2084,
      "step": 56220
    },
    {
      "epoch": 56.23,
      "learning_rate": 6.583873824854802e-05,
      "loss": 0.217,
      "step": 56230
    },
    {
      "epoch": 56.24,
      "learning_rate": 6.581412242952487e-05,
      "loss": 0.2586,
      "step": 56240
    },
    {
      "epoch": 56.25,
      "learning_rate": 6.578950761505553e-05,
      "loss": 0.3175,
      "step": 56250
    },
    {
      "epoch": 56.26,
      "learning_rate": 6.576489380783177e-05,
      "loss": 0.2552,
      "step": 56260
    },
    {
      "epoch": 56.27,
      "learning_rate": 6.574028101054535e-05,
      "loss": 0.2886,
      "step": 56270
    },
    {
      "epoch": 56.28,
      "learning_rate": 6.571566922588787e-05,
      "loss": 0.2736,
      "step": 56280
    },
    {
      "epoch": 56.29,
      "learning_rate": 6.569105845655086e-05,
      "loss": 0.2941,
      "step": 56290
    },
    {
      "epoch": 56.3,
      "learning_rate": 6.566644870522565e-05,
      "loss": 0.2594,
      "step": 56300
    },
    {
      "epoch": 56.31,
      "learning_rate": 6.564183997460362e-05,
      "loss": 0.357,
      "step": 56310
    },
    {
      "epoch": 56.32,
      "learning_rate": 6.561723226737591e-05,
      "loss": 0.268,
      "step": 56320
    },
    {
      "epoch": 56.33,
      "learning_rate": 6.559262558623356e-05,
      "loss": 0.3378,
      "step": 56330
    },
    {
      "epoch": 56.34,
      "learning_rate": 6.556801993386752e-05,
      "loss": 0.2951,
      "step": 56340
    },
    {
      "epoch": 56.35,
      "learning_rate": 6.554341531296866e-05,
      "loss": 0.2761,
      "step": 56350
    },
    {
      "epoch": 56.36,
      "learning_rate": 6.551881172622768e-05,
      "loss": 0.2765,
      "step": 56360
    },
    {
      "epoch": 56.37,
      "learning_rate": 6.549420917633515e-05,
      "loss": 0.2655,
      "step": 56370
    },
    {
      "epoch": 56.38,
      "learning_rate": 6.546960766598167e-05,
      "loss": 0.3329,
      "step": 56380
    },
    {
      "epoch": 56.39,
      "learning_rate": 6.544500719785754e-05,
      "loss": 0.3275,
      "step": 56390
    },
    {
      "epoch": 56.4,
      "learning_rate": 6.542040777465307e-05,
      "loss": 0.3593,
      "step": 56400
    },
    {
      "epoch": 56.41,
      "learning_rate": 6.539580939905839e-05,
      "loss": 0.3326,
      "step": 56410
    },
    {
      "epoch": 56.42,
      "learning_rate": 6.537121207376356e-05,
      "loss": 0.2774,
      "step": 56420
    },
    {
      "epoch": 56.43,
      "learning_rate": 6.534661580145849e-05,
      "loss": 0.2453,
      "step": 56430
    },
    {
      "epoch": 56.44,
      "learning_rate": 6.5322020584833e-05,
      "loss": 0.2076,
      "step": 56440
    },
    {
      "epoch": 56.45,
      "learning_rate": 6.529742642657681e-05,
      "loss": 0.2355,
      "step": 56450
    },
    {
      "epoch": 56.46,
      "learning_rate": 6.527283332937948e-05,
      "loss": 0.261,
      "step": 56460
    },
    {
      "epoch": 56.47,
      "learning_rate": 6.524824129593047e-05,
      "loss": 0.2521,
      "step": 56470
    },
    {
      "epoch": 56.48,
      "learning_rate": 6.522365032891913e-05,
      "loss": 0.2518,
      "step": 56480
    },
    {
      "epoch": 56.49,
      "learning_rate": 6.519906043103466e-05,
      "loss": 0.3269,
      "step": 56490
    },
    {
      "epoch": 56.5,
      "learning_rate": 6.517447160496623e-05,
      "loss": 0.2976,
      "step": 56500
    },
    {
      "epoch": 56.51,
      "learning_rate": 6.514988385340282e-05,
      "loss": 0.3105,
      "step": 56510
    },
    {
      "epoch": 56.52,
      "learning_rate": 6.512529717903329e-05,
      "loss": 0.2994,
      "step": 56520
    },
    {
      "epoch": 56.53,
      "learning_rate": 6.510071158454642e-05,
      "loss": 0.2858,
      "step": 56530
    },
    {
      "epoch": 56.54,
      "learning_rate": 6.507612707263086e-05,
      "loss": 0.1976,
      "step": 56540
    },
    {
      "epoch": 56.55,
      "learning_rate": 6.505154364597512e-05,
      "loss": 0.2329,
      "step": 56550
    },
    {
      "epoch": 56.56,
      "learning_rate": 6.502696130726758e-05,
      "loss": 0.2691,
      "step": 56560
    },
    {
      "epoch": 56.57,
      "learning_rate": 6.500238005919657e-05,
      "loss": 0.2666,
      "step": 56570
    },
    {
      "epoch": 56.58,
      "learning_rate": 6.497779990445027e-05,
      "loss": 0.2605,
      "step": 56580
    },
    {
      "epoch": 56.59,
      "learning_rate": 6.495322084571669e-05,
      "loss": 0.2499,
      "step": 56590
    },
    {
      "epoch": 56.6,
      "learning_rate": 6.492864288568377e-05,
      "loss": 0.3198,
      "step": 56600
    },
    {
      "epoch": 56.61,
      "learning_rate": 6.49040660270393e-05,
      "loss": 0.2434,
      "step": 56610
    },
    {
      "epoch": 56.62,
      "learning_rate": 6.4879490272471e-05,
      "loss": 0.2882,
      "step": 56620
    },
    {
      "epoch": 56.63,
      "learning_rate": 6.485491562466646e-05,
      "loss": 0.2988,
      "step": 56630
    },
    {
      "epoch": 56.64,
      "learning_rate": 6.483034208631308e-05,
      "loss": 0.2673,
      "step": 56640
    },
    {
      "epoch": 56.65,
      "learning_rate": 6.480576966009819e-05,
      "loss": 0.3034,
      "step": 56650
    },
    {
      "epoch": 56.66,
      "learning_rate": 6.4781198348709e-05,
      "loss": 0.2852,
      "step": 56660
    },
    {
      "epoch": 56.67,
      "learning_rate": 6.475662815483261e-05,
      "loss": 0.3403,
      "step": 56670
    },
    {
      "epoch": 56.68,
      "learning_rate": 6.473205908115595e-05,
      "loss": 0.3114,
      "step": 56680
    },
    {
      "epoch": 56.69,
      "learning_rate": 6.470749113036587e-05,
      "loss": 0.2835,
      "step": 56690
    },
    {
      "epoch": 56.7,
      "learning_rate": 6.46829243051491e-05,
      "loss": 0.2899,
      "step": 56700
    },
    {
      "epoch": 56.71,
      "learning_rate": 6.465835860819222e-05,
      "loss": 0.2772,
      "step": 56710
    },
    {
      "epoch": 56.72,
      "learning_rate": 6.463379404218169e-05,
      "loss": 0.2672,
      "step": 56720
    },
    {
      "epoch": 56.73,
      "learning_rate": 6.460923060980384e-05,
      "loss": 0.3618,
      "step": 56730
    },
    {
      "epoch": 56.74,
      "learning_rate": 6.458466831374492e-05,
      "loss": 0.2825,
      "step": 56740
    },
    {
      "epoch": 56.75,
      "learning_rate": 6.4560107156691e-05,
      "loss": 0.2637,
      "step": 56750
    },
    {
      "epoch": 56.76,
      "learning_rate": 6.453554714132809e-05,
      "loss": 0.2939,
      "step": 56760
    },
    {
      "epoch": 56.77,
      "learning_rate": 6.451098827034199e-05,
      "loss": 0.2534,
      "step": 56770
    },
    {
      "epoch": 56.78,
      "learning_rate": 6.448643054641847e-05,
      "loss": 0.2571,
      "step": 56780
    },
    {
      "epoch": 56.79,
      "learning_rate": 6.446187397224309e-05,
      "loss": 0.2747,
      "step": 56790
    },
    {
      "epoch": 56.8,
      "learning_rate": 6.443731855050132e-05,
      "loss": 0.191,
      "step": 56800
    },
    {
      "epoch": 56.81,
      "learning_rate": 6.441276428387849e-05,
      "loss": 0.3421,
      "step": 56810
    },
    {
      "epoch": 56.82,
      "learning_rate": 6.438821117505987e-05,
      "loss": 0.2748,
      "step": 56820
    },
    {
      "epoch": 56.83,
      "learning_rate": 6.436365922673052e-05,
      "loss": 0.3094,
      "step": 56830
    },
    {
      "epoch": 56.84,
      "learning_rate": 6.43391084415754e-05,
      "loss": 0.2278,
      "step": 56840
    },
    {
      "epoch": 56.85,
      "learning_rate": 6.431455882227937e-05,
      "loss": 0.3512,
      "step": 56850
    },
    {
      "epoch": 56.86,
      "learning_rate": 6.429001037152709e-05,
      "loss": 0.2618,
      "step": 56860
    },
    {
      "epoch": 56.87,
      "learning_rate": 6.426546309200318e-05,
      "loss": 0.2587,
      "step": 56870
    },
    {
      "epoch": 56.88,
      "learning_rate": 6.424091698639209e-05,
      "loss": 0.2484,
      "step": 56880
    },
    {
      "epoch": 56.89,
      "learning_rate": 6.421637205737815e-05,
      "loss": 0.2669,
      "step": 56890
    },
    {
      "epoch": 56.9,
      "learning_rate": 6.419182830764555e-05,
      "loss": 0.2288,
      "step": 56900
    },
    {
      "epoch": 56.91,
      "learning_rate": 6.416728573987836e-05,
      "loss": 0.2977,
      "step": 56910
    },
    {
      "epoch": 56.92,
      "learning_rate": 6.41427443567605e-05,
      "loss": 0.2858,
      "step": 56920
    },
    {
      "epoch": 56.93,
      "learning_rate": 6.411820416097582e-05,
      "loss": 0.2782,
      "step": 56930
    },
    {
      "epoch": 56.94,
      "learning_rate": 6.409366515520792e-05,
      "loss": 0.2679,
      "step": 56940
    },
    {
      "epoch": 56.95,
      "learning_rate": 6.406912734214044e-05,
      "loss": 0.2246,
      "step": 56950
    },
    {
      "epoch": 56.96,
      "learning_rate": 6.404459072445676e-05,
      "loss": 0.3046,
      "step": 56960
    },
    {
      "epoch": 56.97,
      "learning_rate": 6.402005530484016e-05,
      "loss": 0.3287,
      "step": 56970
    },
    {
      "epoch": 56.98,
      "learning_rate": 6.399552108597381e-05,
      "loss": 0.217,
      "step": 56980
    },
    {
      "epoch": 56.99,
      "learning_rate": 6.397098807054074e-05,
      "loss": 0.3021,
      "step": 56990
    },
    {
      "epoch": 57.0,
      "learning_rate": 6.394645626122379e-05,
      "loss": 0.3299,
      "step": 57000
    },
    {
      "epoch": 57.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27351611852645874,
      "eval_runtime": 15.2153,
      "eval_samples_per_second": 131.447,
      "eval_steps_per_second": 16.431,
      "step": 57000
    },
    {
      "epoch": 57.01,
      "learning_rate": 6.392192566070579e-05,
      "loss": 0.2352,
      "step": 57010
    },
    {
      "epoch": 57.02,
      "learning_rate": 6.389739627166936e-05,
      "loss": 0.3275,
      "step": 57020
    },
    {
      "epoch": 57.03,
      "learning_rate": 6.387286809679696e-05,
      "loss": 0.2842,
      "step": 57030
    },
    {
      "epoch": 57.04,
      "learning_rate": 6.384834113877099e-05,
      "loss": 0.3173,
      "step": 57040
    },
    {
      "epoch": 57.05,
      "learning_rate": 6.382381540027367e-05,
      "loss": 0.2669,
      "step": 57050
    },
    {
      "epoch": 57.06,
      "learning_rate": 6.379929088398708e-05,
      "loss": 0.3573,
      "step": 57060
    },
    {
      "epoch": 57.07,
      "learning_rate": 6.377476759259318e-05,
      "loss": 0.3173,
      "step": 57070
    },
    {
      "epoch": 57.08,
      "learning_rate": 6.375024552877384e-05,
      "loss": 0.2766,
      "step": 57080
    },
    {
      "epoch": 57.09,
      "learning_rate": 6.372572469521076e-05,
      "loss": 0.367,
      "step": 57090
    },
    {
      "epoch": 57.1,
      "learning_rate": 6.370120509458546e-05,
      "loss": 0.2616,
      "step": 57100
    },
    {
      "epoch": 57.11,
      "learning_rate": 6.367668672957936e-05,
      "loss": 0.3114,
      "step": 57110
    },
    {
      "epoch": 57.12,
      "learning_rate": 6.36521696028738e-05,
      "loss": 0.2396,
      "step": 57120
    },
    {
      "epoch": 57.13,
      "learning_rate": 6.362765371714989e-05,
      "loss": 0.2817,
      "step": 57130
    },
    {
      "epoch": 57.14,
      "learning_rate": 6.360313907508869e-05,
      "loss": 0.2674,
      "step": 57140
    },
    {
      "epoch": 57.15,
      "learning_rate": 6.357862567937106e-05,
      "loss": 0.2664,
      "step": 57150
    },
    {
      "epoch": 57.16,
      "learning_rate": 6.355411353267775e-05,
      "loss": 0.2496,
      "step": 57160
    },
    {
      "epoch": 57.17,
      "learning_rate": 6.352960263768939e-05,
      "loss": 0.3344,
      "step": 57170
    },
    {
      "epoch": 57.18,
      "learning_rate": 6.350509299708643e-05,
      "loss": 0.3049,
      "step": 57180
    },
    {
      "epoch": 57.19,
      "learning_rate": 6.348058461354919e-05,
      "loss": 0.2761,
      "step": 57190
    },
    {
      "epoch": 57.2,
      "learning_rate": 6.345607748975793e-05,
      "loss": 0.2474,
      "step": 57200
    },
    {
      "epoch": 57.21,
      "learning_rate": 6.343157162839267e-05,
      "loss": 0.2945,
      "step": 57210
    },
    {
      "epoch": 57.22,
      "learning_rate": 6.340706703213337e-05,
      "loss": 0.2696,
      "step": 57220
    },
    {
      "epoch": 57.23,
      "learning_rate": 6.338256370365977e-05,
      "loss": 0.2619,
      "step": 57230
    },
    {
      "epoch": 57.24,
      "learning_rate": 6.335806164565154e-05,
      "loss": 0.2476,
      "step": 57240
    },
    {
      "epoch": 57.25,
      "learning_rate": 6.333356086078818e-05,
      "loss": 0.3116,
      "step": 57250
    },
    {
      "epoch": 57.26,
      "learning_rate": 6.330906135174904e-05,
      "loss": 0.241,
      "step": 57260
    },
    {
      "epoch": 57.27,
      "learning_rate": 6.328456312121341e-05,
      "loss": 0.2335,
      "step": 57270
    },
    {
      "epoch": 57.28,
      "learning_rate": 6.326006617186032e-05,
      "loss": 0.2771,
      "step": 57280
    },
    {
      "epoch": 57.29,
      "learning_rate": 6.323557050636878e-05,
      "loss": 0.1476,
      "step": 57290
    },
    {
      "epoch": 57.3,
      "learning_rate": 6.321107612741752e-05,
      "loss": 0.2701,
      "step": 57300
    },
    {
      "epoch": 57.31,
      "learning_rate": 6.318658303768528e-05,
      "loss": 0.3274,
      "step": 57310
    },
    {
      "epoch": 57.32,
      "learning_rate": 6.316209123985052e-05,
      "loss": 0.3038,
      "step": 57320
    },
    {
      "epoch": 57.33,
      "learning_rate": 6.313760073659169e-05,
      "loss": 0.2777,
      "step": 57330
    },
    {
      "epoch": 57.34,
      "learning_rate": 6.3113111530587e-05,
      "loss": 0.278,
      "step": 57340
    },
    {
      "epoch": 57.35,
      "learning_rate": 6.308862362451458e-05,
      "loss": 0.2493,
      "step": 57350
    },
    {
      "epoch": 57.36,
      "learning_rate": 6.306413702105235e-05,
      "loss": 0.3184,
      "step": 57360
    },
    {
      "epoch": 57.37,
      "learning_rate": 6.303965172287817e-05,
      "loss": 0.291,
      "step": 57370
    },
    {
      "epoch": 57.38,
      "learning_rate": 6.301516773266966e-05,
      "loss": 0.2675,
      "step": 57380
    },
    {
      "epoch": 57.39,
      "learning_rate": 6.299068505310443e-05,
      "loss": 0.22,
      "step": 57390
    },
    {
      "epoch": 57.4,
      "learning_rate": 6.29662036868598e-05,
      "loss": 0.4272,
      "step": 57400
    },
    {
      "epoch": 57.41,
      "learning_rate": 6.294172363661305e-05,
      "loss": 0.2764,
      "step": 57410
    },
    {
      "epoch": 57.42,
      "learning_rate": 6.291724490504128e-05,
      "loss": 0.3233,
      "step": 57420
    },
    {
      "epoch": 57.43,
      "learning_rate": 6.289276749482145e-05,
      "loss": 0.2675,
      "step": 57430
    },
    {
      "epoch": 57.44,
      "learning_rate": 6.286829140863035e-05,
      "loss": 0.223,
      "step": 57440
    },
    {
      "epoch": 57.45,
      "learning_rate": 6.284626406531517e-05,
      "loss": 0.3034,
      "step": 57450
    },
    {
      "epoch": 57.46,
      "learning_rate": 6.282179050215279e-05,
      "loss": 0.2394,
      "step": 57460
    },
    {
      "epoch": 57.47,
      "learning_rate": 6.27973182707811e-05,
      "loss": 0.3008,
      "step": 57470
    },
    {
      "epoch": 57.48,
      "learning_rate": 6.277284737387632e-05,
      "loss": 0.2853,
      "step": 57480
    },
    {
      "epoch": 57.49,
      "learning_rate": 6.274837781411458e-05,
      "loss": 0.2376,
      "step": 57490
    },
    {
      "epoch": 57.5,
      "learning_rate": 6.272390959417182e-05,
      "loss": 0.2396,
      "step": 57500
    },
    {
      "epoch": 57.51,
      "learning_rate": 6.269944271672384e-05,
      "loss": 0.2961,
      "step": 57510
    },
    {
      "epoch": 57.52,
      "learning_rate": 6.267497718444629e-05,
      "loss": 0.2292,
      "step": 57520
    },
    {
      "epoch": 57.53,
      "learning_rate": 6.265051300001473e-05,
      "loss": 0.2296,
      "step": 57530
    },
    {
      "epoch": 57.54,
      "learning_rate": 6.262605016610451e-05,
      "loss": 0.32,
      "step": 57540
    },
    {
      "epoch": 57.55,
      "learning_rate": 6.260158868539083e-05,
      "loss": 0.2952,
      "step": 57550
    },
    {
      "epoch": 57.56,
      "learning_rate": 6.257712856054878e-05,
      "loss": 0.2204,
      "step": 57560
    },
    {
      "epoch": 57.57,
      "learning_rate": 6.255266979425327e-05,
      "loss": 0.3202,
      "step": 57570
    },
    {
      "epoch": 57.58,
      "learning_rate": 6.252821238917905e-05,
      "loss": 0.3176,
      "step": 57580
    },
    {
      "epoch": 57.59,
      "learning_rate": 6.250375634800079e-05,
      "loss": 0.3009,
      "step": 57590
    },
    {
      "epoch": 57.6,
      "learning_rate": 6.247930167339295e-05,
      "loss": 0.2802,
      "step": 57600
    },
    {
      "epoch": 57.61,
      "learning_rate": 6.245484836802986e-05,
      "loss": 0.2162,
      "step": 57610
    },
    {
      "epoch": 57.62,
      "learning_rate": 6.243039643458569e-05,
      "loss": 0.2981,
      "step": 57620
    },
    {
      "epoch": 57.63,
      "learning_rate": 6.240594587573445e-05,
      "loss": 0.2423,
      "step": 57630
    },
    {
      "epoch": 57.64,
      "learning_rate": 6.238149669415005e-05,
      "loss": 0.2693,
      "step": 57640
    },
    {
      "epoch": 57.65,
      "learning_rate": 6.23570488925062e-05,
      "loss": 0.2995,
      "step": 57650
    },
    {
      "epoch": 57.66,
      "learning_rate": 6.233260247347646e-05,
      "loss": 0.2944,
      "step": 57660
    },
    {
      "epoch": 57.67,
      "learning_rate": 6.230815743973428e-05,
      "loss": 0.2502,
      "step": 57670
    },
    {
      "epoch": 57.68,
      "learning_rate": 6.228371379395293e-05,
      "loss": 0.2686,
      "step": 57680
    },
    {
      "epoch": 57.69,
      "learning_rate": 6.225927153880552e-05,
      "loss": 0.2823,
      "step": 57690
    },
    {
      "epoch": 57.7,
      "learning_rate": 6.223483067696501e-05,
      "loss": 0.3395,
      "step": 57700
    },
    {
      "epoch": 57.71,
      "learning_rate": 6.22103912111042e-05,
      "loss": 0.4791,
      "step": 57710
    },
    {
      "epoch": 57.72,
      "learning_rate": 6.21859531438958e-05,
      "loss": 0.2075,
      "step": 57720
    },
    {
      "epoch": 57.73,
      "learning_rate": 6.216151647801231e-05,
      "loss": 0.2687,
      "step": 57730
    },
    {
      "epoch": 57.74,
      "learning_rate": 6.213708121612609e-05,
      "loss": 0.445,
      "step": 57740
    },
    {
      "epoch": 57.75,
      "learning_rate": 6.211264736090931e-05,
      "loss": 0.3263,
      "step": 57750
    },
    {
      "epoch": 57.76,
      "learning_rate": 6.208821491503404e-05,
      "loss": 0.2673,
      "step": 57760
    },
    {
      "epoch": 57.77,
      "learning_rate": 6.206378388117214e-05,
      "loss": 0.3207,
      "step": 57770
    },
    {
      "epoch": 57.78,
      "learning_rate": 6.203935426199542e-05,
      "loss": 0.2805,
      "step": 57780
    },
    {
      "epoch": 57.79,
      "learning_rate": 6.201492606017544e-05,
      "loss": 0.3039,
      "step": 57790
    },
    {
      "epoch": 57.8,
      "learning_rate": 6.199049927838362e-05,
      "loss": 0.3251,
      "step": 57800
    },
    {
      "epoch": 57.81,
      "learning_rate": 6.196607391929123e-05,
      "loss": 0.3169,
      "step": 57810
    },
    {
      "epoch": 57.82,
      "learning_rate": 6.19416499855694e-05,
      "loss": 0.2717,
      "step": 57820
    },
    {
      "epoch": 57.83,
      "learning_rate": 6.191722747988909e-05,
      "loss": 0.3121,
      "step": 57830
    },
    {
      "epoch": 57.84,
      "learning_rate": 6.18928064049211e-05,
      "loss": 0.3129,
      "step": 57840
    },
    {
      "epoch": 57.85,
      "learning_rate": 6.186838676333612e-05,
      "loss": 0.2598,
      "step": 57850
    },
    {
      "epoch": 57.86,
      "learning_rate": 6.184396855780462e-05,
      "loss": 0.2402,
      "step": 57860
    },
    {
      "epoch": 57.87,
      "learning_rate": 6.181955179099691e-05,
      "loss": 0.2344,
      "step": 57870
    },
    {
      "epoch": 57.88,
      "learning_rate": 6.179513646558325e-05,
      "loss": 0.2982,
      "step": 57880
    },
    {
      "epoch": 57.89,
      "learning_rate": 6.177072258423358e-05,
      "loss": 0.2915,
      "step": 57890
    },
    {
      "epoch": 57.9,
      "learning_rate": 6.17463101496178e-05,
      "loss": 0.3257,
      "step": 57900
    },
    {
      "epoch": 57.91,
      "learning_rate": 6.17218991644056e-05,
      "loss": 0.3134,
      "step": 57910
    },
    {
      "epoch": 57.92,
      "learning_rate": 6.169748963126658e-05,
      "loss": 0.33,
      "step": 57920
    },
    {
      "epoch": 57.93,
      "learning_rate": 6.167308155287008e-05,
      "loss": 0.2604,
      "step": 57930
    },
    {
      "epoch": 57.94,
      "learning_rate": 6.164867493188534e-05,
      "loss": 0.3305,
      "step": 57940
    },
    {
      "epoch": 57.95,
      "learning_rate": 6.162426977098144e-05,
      "loss": 0.2309,
      "step": 57950
    },
    {
      "epoch": 57.96,
      "learning_rate": 6.159986607282726e-05,
      "loss": 0.2499,
      "step": 57960
    },
    {
      "epoch": 57.97,
      "learning_rate": 6.157546384009161e-05,
      "loss": 0.2315,
      "step": 57970
    },
    {
      "epoch": 57.98,
      "learning_rate": 6.155106307544306e-05,
      "loss": 0.3371,
      "step": 57980
    },
    {
      "epoch": 57.99,
      "learning_rate": 6.152666378155001e-05,
      "loss": 0.2693,
      "step": 57990
    },
    {
      "epoch": 58.0,
      "learning_rate": 6.150226596108078e-05,
      "loss": 0.2896,
      "step": 58000
    },
    {
      "epoch": 58.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27328380942344666,
      "eval_runtime": 15.2866,
      "eval_samples_per_second": 130.834,
      "eval_steps_per_second": 16.354,
      "step": 58000
    },
    {
      "epoch": 58.01,
      "learning_rate": 6.147786961670343e-05,
      "loss": 0.2426,
      "step": 58010
    },
    {
      "epoch": 58.02,
      "learning_rate": 6.145347475108593e-05,
      "loss": 0.2871,
      "step": 58020
    },
    {
      "epoch": 58.03,
      "learning_rate": 6.142908136689603e-05,
      "loss": 0.243,
      "step": 58030
    },
    {
      "epoch": 58.04,
      "learning_rate": 6.140468946680144e-05,
      "loss": 0.251,
      "step": 58040
    },
    {
      "epoch": 58.05,
      "learning_rate": 6.138029905346955e-05,
      "loss": 0.2952,
      "step": 58050
    },
    {
      "epoch": 58.06,
      "learning_rate": 6.135591012956768e-05,
      "loss": 0.2687,
      "step": 58060
    },
    {
      "epoch": 58.07,
      "learning_rate": 6.133152269776297e-05,
      "loss": 0.2775,
      "step": 58070
    },
    {
      "epoch": 58.08,
      "learning_rate": 6.130713676072238e-05,
      "loss": 0.295,
      "step": 58080
    },
    {
      "epoch": 58.09,
      "learning_rate": 6.128275232111272e-05,
      "loss": 0.2517,
      "step": 58090
    },
    {
      "epoch": 58.1,
      "learning_rate": 6.125836938160065e-05,
      "loss": 0.2766,
      "step": 58100
    },
    {
      "epoch": 58.11,
      "learning_rate": 6.123398794485265e-05,
      "loss": 0.277,
      "step": 58110
    },
    {
      "epoch": 58.12,
      "learning_rate": 6.120960801353502e-05,
      "loss": 0.2867,
      "step": 58120
    },
    {
      "epoch": 58.13,
      "learning_rate": 6.118522959031394e-05,
      "loss": 0.3047,
      "step": 58130
    },
    {
      "epoch": 58.14,
      "learning_rate": 6.116085267785538e-05,
      "loss": 0.2317,
      "step": 58140
    },
    {
      "epoch": 58.15,
      "learning_rate": 6.113647727882516e-05,
      "loss": 0.2679,
      "step": 58150
    },
    {
      "epoch": 58.16,
      "learning_rate": 6.11121033958889e-05,
      "loss": 0.288,
      "step": 58160
    },
    {
      "epoch": 58.17,
      "learning_rate": 6.108773103171218e-05,
      "loss": 0.2753,
      "step": 58170
    },
    {
      "epoch": 58.18,
      "learning_rate": 6.106336018896028e-05,
      "loss": 0.2965,
      "step": 58180
    },
    {
      "epoch": 58.19,
      "learning_rate": 6.103899087029835e-05,
      "loss": 0.2214,
      "step": 58190
    },
    {
      "epoch": 58.2,
      "learning_rate": 6.101462307839139e-05,
      "loss": 0.2972,
      "step": 58200
    },
    {
      "epoch": 58.21,
      "learning_rate": 6.099025681590421e-05,
      "loss": 0.2871,
      "step": 58210
    },
    {
      "epoch": 58.22,
      "learning_rate": 6.096589208550147e-05,
      "loss": 0.2623,
      "step": 58220
    },
    {
      "epoch": 58.23,
      "learning_rate": 6.0941528889847694e-05,
      "loss": 0.2681,
      "step": 58230
    },
    {
      "epoch": 58.24,
      "learning_rate": 6.091716723160718e-05,
      "loss": 0.2775,
      "step": 58240
    },
    {
      "epoch": 58.25,
      "learning_rate": 6.089280711344409e-05,
      "loss": 0.3643,
      "step": 58250
    },
    {
      "epoch": 58.26,
      "learning_rate": 6.08684485380224e-05,
      "loss": 0.3661,
      "step": 58260
    },
    {
      "epoch": 58.27,
      "learning_rate": 6.0844091508005934e-05,
      "loss": 0.2747,
      "step": 58270
    },
    {
      "epoch": 58.28,
      "learning_rate": 6.08197360260583e-05,
      "loss": 0.3721,
      "step": 58280
    },
    {
      "epoch": 58.29,
      "learning_rate": 6.079538209484306e-05,
      "loss": 0.2821,
      "step": 58290
    },
    {
      "epoch": 58.3,
      "learning_rate": 6.0771029717023464e-05,
      "loss": 0.2642,
      "step": 58300
    },
    {
      "epoch": 58.31,
      "learning_rate": 6.074667889526267e-05,
      "loss": 0.3452,
      "step": 58310
    },
    {
      "epoch": 58.32,
      "learning_rate": 6.072232963222364e-05,
      "loss": 0.2218,
      "step": 58320
    },
    {
      "epoch": 58.33,
      "learning_rate": 6.069798193056916e-05,
      "loss": 0.29,
      "step": 58330
    },
    {
      "epoch": 58.34,
      "learning_rate": 6.06736357929619e-05,
      "loss": 0.2675,
      "step": 58340
    },
    {
      "epoch": 58.35,
      "learning_rate": 6.064929122206426e-05,
      "loss": 0.2546,
      "step": 58350
    },
    {
      "epoch": 58.36,
      "learning_rate": 6.0624948220538574e-05,
      "loss": 0.3021,
      "step": 58360
    },
    {
      "epoch": 58.37,
      "learning_rate": 6.060060679104692e-05,
      "loss": 0.2401,
      "step": 58370
    },
    {
      "epoch": 58.38,
      "learning_rate": 6.0576266936251285e-05,
      "loss": 0.2729,
      "step": 58380
    },
    {
      "epoch": 58.39,
      "learning_rate": 6.0551928658813406e-05,
      "loss": 0.2613,
      "step": 58390
    },
    {
      "epoch": 58.4,
      "learning_rate": 6.052759196139489e-05,
      "loss": 0.3481,
      "step": 58400
    },
    {
      "epoch": 58.41,
      "learning_rate": 6.050325684665712e-05,
      "loss": 0.3078,
      "step": 58410
    },
    {
      "epoch": 58.42,
      "learning_rate": 6.047892331726142e-05,
      "loss": 0.2763,
      "step": 58420
    },
    {
      "epoch": 58.43,
      "learning_rate": 6.045459137586884e-05,
      "loss": 0.2576,
      "step": 58430
    },
    {
      "epoch": 58.44,
      "learning_rate": 6.043026102514027e-05,
      "loss": 0.2423,
      "step": 58440
    },
    {
      "epoch": 58.45,
      "learning_rate": 6.0405932267736454e-05,
      "loss": 0.3438,
      "step": 58450
    },
    {
      "epoch": 58.46,
      "learning_rate": 6.038160510631794e-05,
      "loss": 0.3035,
      "step": 58460
    },
    {
      "epoch": 58.47,
      "learning_rate": 6.035727954354508e-05,
      "loss": 0.2703,
      "step": 58470
    },
    {
      "epoch": 58.48,
      "learning_rate": 6.033295558207816e-05,
      "loss": 0.2143,
      "step": 58480
    },
    {
      "epoch": 58.49,
      "learning_rate": 6.030863322457715e-05,
      "loss": 0.2419,
      "step": 58490
    },
    {
      "epoch": 58.5,
      "learning_rate": 6.028431247370192e-05,
      "loss": 0.2948,
      "step": 58500
    },
    {
      "epoch": 58.51,
      "learning_rate": 6.025999333211217e-05,
      "loss": 0.3625,
      "step": 58510
    },
    {
      "epoch": 58.52,
      "learning_rate": 6.0235675802467374e-05,
      "loss": 0.3197,
      "step": 58520
    },
    {
      "epoch": 58.53,
      "learning_rate": 6.021135988742688e-05,
      "loss": 0.1814,
      "step": 58530
    },
    {
      "epoch": 58.54,
      "learning_rate": 6.01870455896498e-05,
      "loss": 0.2125,
      "step": 58540
    },
    {
      "epoch": 58.55,
      "learning_rate": 6.016273291179518e-05,
      "loss": 0.2429,
      "step": 58550
    },
    {
      "epoch": 58.56,
      "learning_rate": 6.0138421856521774e-05,
      "loss": 0.3084,
      "step": 58560
    },
    {
      "epoch": 58.57,
      "learning_rate": 6.011411242648821e-05,
      "loss": 0.2967,
      "step": 58570
    },
    {
      "epoch": 58.58,
      "learning_rate": 6.008980462435292e-05,
      "loss": 0.2436,
      "step": 58580
    },
    {
      "epoch": 58.59,
      "learning_rate": 6.0065498452774195e-05,
      "loss": 0.2512,
      "step": 58590
    },
    {
      "epoch": 58.6,
      "learning_rate": 6.0041193914410086e-05,
      "loss": 0.3037,
      "step": 58600
    },
    {
      "epoch": 58.61,
      "learning_rate": 6.001689101191854e-05,
      "loss": 0.2933,
      "step": 58610
    },
    {
      "epoch": 58.62,
      "learning_rate": 5.999258974795725e-05,
      "loss": 0.2683,
      "step": 58620
    },
    {
      "epoch": 58.63,
      "learning_rate": 5.996829012518379e-05,
      "loss": 0.234,
      "step": 58630
    },
    {
      "epoch": 58.64,
      "learning_rate": 5.994399214625553e-05,
      "loss": 0.2862,
      "step": 58640
    },
    {
      "epoch": 58.65,
      "learning_rate": 5.991969581382966e-05,
      "loss": 0.2978,
      "step": 58650
    },
    {
      "epoch": 58.66,
      "learning_rate": 5.9895401130563134e-05,
      "loss": 0.2768,
      "step": 58660
    },
    {
      "epoch": 58.67,
      "learning_rate": 5.987110809911287e-05,
      "loss": 0.3293,
      "step": 58670
    },
    {
      "epoch": 58.68,
      "learning_rate": 5.9846816722135474e-05,
      "loss": 0.2847,
      "step": 58680
    },
    {
      "epoch": 58.69,
      "learning_rate": 5.982252700228742e-05,
      "loss": 0.2503,
      "step": 58690
    },
    {
      "epoch": 58.7,
      "learning_rate": 5.979823894222501e-05,
      "loss": 0.2871,
      "step": 58700
    },
    {
      "epoch": 58.71,
      "learning_rate": 5.977395254460432e-05,
      "loss": 0.3128,
      "step": 58710
    },
    {
      "epoch": 58.72,
      "learning_rate": 5.974966781208129e-05,
      "loss": 0.2258,
      "step": 58720
    },
    {
      "epoch": 58.73,
      "learning_rate": 5.972538474731162e-05,
      "loss": 0.3121,
      "step": 58730
    },
    {
      "epoch": 58.74,
      "learning_rate": 5.970110335295095e-05,
      "loss": 0.2254,
      "step": 58740
    },
    {
      "epoch": 58.75,
      "learning_rate": 5.967682363165461e-05,
      "loss": 0.2863,
      "step": 58750
    },
    {
      "epoch": 58.76,
      "learning_rate": 5.9652545586077805e-05,
      "loss": 0.3481,
      "step": 58760
    },
    {
      "epoch": 58.77,
      "learning_rate": 5.962826921887554e-05,
      "loss": 0.2778,
      "step": 58770
    },
    {
      "epoch": 58.78,
      "learning_rate": 5.9603994532702636e-05,
      "loss": 0.2557,
      "step": 58780
    },
    {
      "epoch": 58.79,
      "learning_rate": 5.9579721530213716e-05,
      "loss": 0.2405,
      "step": 58790
    },
    {
      "epoch": 58.8,
      "learning_rate": 5.95554502140633e-05,
      "loss": 0.2641,
      "step": 58800
    },
    {
      "epoch": 58.81,
      "learning_rate": 5.953118058690562e-05,
      "loss": 0.3324,
      "step": 58810
    },
    {
      "epoch": 58.82,
      "learning_rate": 5.950691265139478e-05,
      "loss": 0.2886,
      "step": 58820
    },
    {
      "epoch": 58.83,
      "learning_rate": 5.948264641018467e-05,
      "loss": 0.2691,
      "step": 58830
    },
    {
      "epoch": 58.84,
      "learning_rate": 5.9458381865929013e-05,
      "loss": 0.279,
      "step": 58840
    },
    {
      "epoch": 58.85,
      "learning_rate": 5.943411902128137e-05,
      "loss": 0.2601,
      "step": 58850
    },
    {
      "epoch": 58.86,
      "learning_rate": 5.940985787889504e-05,
      "loss": 0.295,
      "step": 58860
    },
    {
      "epoch": 58.87,
      "learning_rate": 5.9385598441423215e-05,
      "loss": 0.243,
      "step": 58870
    },
    {
      "epoch": 58.88,
      "learning_rate": 5.936134071151888e-05,
      "loss": 0.208,
      "step": 58880
    },
    {
      "epoch": 58.89,
      "learning_rate": 5.933708469183482e-05,
      "loss": 0.2851,
      "step": 58890
    },
    {
      "epoch": 58.9,
      "learning_rate": 5.931283038502363e-05,
      "loss": 0.2605,
      "step": 58900
    },
    {
      "epoch": 58.91,
      "learning_rate": 5.928857779373772e-05,
      "loss": 0.2587,
      "step": 58910
    },
    {
      "epoch": 58.92,
      "learning_rate": 5.926432692062929e-05,
      "loss": 0.2507,
      "step": 58920
    },
    {
      "epoch": 58.93,
      "learning_rate": 5.924007776835044e-05,
      "loss": 0.2783,
      "step": 58930
    },
    {
      "epoch": 58.94,
      "learning_rate": 5.921583033955299e-05,
      "loss": 0.3382,
      "step": 58940
    },
    {
      "epoch": 58.95,
      "learning_rate": 5.9191584636888614e-05,
      "loss": 0.3137,
      "step": 58950
    },
    {
      "epoch": 58.96,
      "learning_rate": 5.916734066300875e-05,
      "loss": 0.3002,
      "step": 58960
    },
    {
      "epoch": 58.97,
      "learning_rate": 5.914309842056473e-05,
      "loss": 0.3378,
      "step": 58970
    },
    {
      "epoch": 58.98,
      "learning_rate": 5.911885791220759e-05,
      "loss": 0.2703,
      "step": 58980
    },
    {
      "epoch": 58.99,
      "learning_rate": 5.90946191405883e-05,
      "loss": 0.2606,
      "step": 58990
    },
    {
      "epoch": 59.0,
      "learning_rate": 5.907038210835755e-05,
      "loss": 0.2854,
      "step": 59000
    },
    {
      "epoch": 59.0,
      "eval_accuracy": 0.806,
      "eval_loss": 0.27314624190330505,
      "eval_runtime": 15.1024,
      "eval_samples_per_second": 132.43,
      "eval_steps_per_second": 16.554,
      "step": 59000
    },
    {
      "epoch": 59.01,
      "learning_rate": 5.904614681816585e-05,
      "loss": 0.2862,
      "step": 59010
    },
    {
      "epoch": 59.02,
      "learning_rate": 5.9021913272663565e-05,
      "loss": 0.3633,
      "step": 59020
    },
    {
      "epoch": 59.03,
      "learning_rate": 5.899768147450082e-05,
      "loss": 0.2848,
      "step": 59030
    },
    {
      "epoch": 59.04,
      "learning_rate": 5.8973451426327545e-05,
      "loss": 0.2782,
      "step": 59040
    },
    {
      "epoch": 59.05,
      "learning_rate": 5.894922313079353e-05,
      "loss": 0.2974,
      "step": 59050
    },
    {
      "epoch": 59.06,
      "learning_rate": 5.892499659054836e-05,
      "loss": 0.2938,
      "step": 59060
    },
    {
      "epoch": 59.07,
      "learning_rate": 5.890077180824139e-05,
      "loss": 0.3207,
      "step": 59070
    },
    {
      "epoch": 59.08,
      "learning_rate": 5.88765487865218e-05,
      "loss": 0.2434,
      "step": 59080
    },
    {
      "epoch": 59.09,
      "learning_rate": 5.8852327528038604e-05,
      "loss": 0.2607,
      "step": 59090
    },
    {
      "epoch": 59.1,
      "learning_rate": 5.882810803544059e-05,
      "loss": 0.2781,
      "step": 59100
    },
    {
      "epoch": 59.11,
      "learning_rate": 5.880389031137636e-05,
      "loss": 0.242,
      "step": 59110
    },
    {
      "epoch": 59.12,
      "learning_rate": 5.877967435849432e-05,
      "loss": 0.3358,
      "step": 59120
    },
    {
      "epoch": 59.13,
      "learning_rate": 5.875546017944274e-05,
      "loss": 0.259,
      "step": 59130
    },
    {
      "epoch": 59.14,
      "learning_rate": 5.87312477768696e-05,
      "loss": 0.2561,
      "step": 59140
    },
    {
      "epoch": 59.15,
      "learning_rate": 5.870703715342275e-05,
      "loss": 0.2588,
      "step": 59150
    },
    {
      "epoch": 59.16,
      "learning_rate": 5.8682828311749815e-05,
      "loss": 0.2566,
      "step": 59160
    },
    {
      "epoch": 59.17,
      "learning_rate": 5.865862125449821e-05,
      "loss": 0.2397,
      "step": 59170
    },
    {
      "epoch": 59.18,
      "learning_rate": 5.863441598431525e-05,
      "loss": 0.2777,
      "step": 59180
    },
    {
      "epoch": 59.19,
      "learning_rate": 5.8610212503847956e-05,
      "loss": 0.3081,
      "step": 59190
    },
    {
      "epoch": 59.2,
      "learning_rate": 5.8586010815743176e-05,
      "loss": 0.2321,
      "step": 59200
    },
    {
      "epoch": 59.21,
      "learning_rate": 5.856181092264758e-05,
      "loss": 0.2755,
      "step": 59210
    },
    {
      "epoch": 59.22,
      "learning_rate": 5.8537612827207626e-05,
      "loss": 0.2907,
      "step": 59220
    },
    {
      "epoch": 59.23,
      "learning_rate": 5.8513416532069585e-05,
      "loss": 0.3227,
      "step": 59230
    },
    {
      "epoch": 59.24,
      "learning_rate": 5.848922203987949e-05,
      "loss": 0.2992,
      "step": 59240
    },
    {
      "epoch": 59.25,
      "learning_rate": 5.846502935328327e-05,
      "loss": 0.2663,
      "step": 59250
    },
    {
      "epoch": 59.26,
      "learning_rate": 5.844083847492659e-05,
      "loss": 0.2957,
      "step": 59260
    },
    {
      "epoch": 59.27,
      "learning_rate": 5.8416649407454926e-05,
      "loss": 0.2319,
      "step": 59270
    },
    {
      "epoch": 59.28,
      "learning_rate": 5.839246215351354e-05,
      "loss": 0.2871,
      "step": 59280
    },
    {
      "epoch": 59.29,
      "learning_rate": 5.836827671574751e-05,
      "loss": 0.2516,
      "step": 59290
    },
    {
      "epoch": 59.3,
      "learning_rate": 5.8344093096801734e-05,
      "loss": 0.2595,
      "step": 59300
    },
    {
      "epoch": 59.31,
      "learning_rate": 5.831991129932091e-05,
      "loss": 0.303,
      "step": 59310
    },
    {
      "epoch": 59.32,
      "learning_rate": 5.829573132594951e-05,
      "loss": 0.285,
      "step": 59320
    },
    {
      "epoch": 59.33,
      "learning_rate": 5.82715531793318e-05,
      "loss": 0.3287,
      "step": 59330
    },
    {
      "epoch": 59.34,
      "learning_rate": 5.82473768621119e-05,
      "loss": 0.249,
      "step": 59340
    },
    {
      "epoch": 59.35,
      "learning_rate": 5.8223202376933674e-05,
      "loss": 0.3381,
      "step": 59350
    },
    {
      "epoch": 59.36,
      "learning_rate": 5.819902972644082e-05,
      "loss": 0.3097,
      "step": 59360
    },
    {
      "epoch": 59.37,
      "learning_rate": 5.817485891327678e-05,
      "loss": 0.2515,
      "step": 59370
    },
    {
      "epoch": 59.38,
      "learning_rate": 5.8150689940084906e-05,
      "loss": 0.236,
      "step": 59380
    },
    {
      "epoch": 59.39,
      "learning_rate": 5.812652280950825e-05,
      "loss": 0.2332,
      "step": 59390
    },
    {
      "epoch": 59.4,
      "learning_rate": 5.810235752418969e-05,
      "loss": 0.2173,
      "step": 59400
    },
    {
      "epoch": 59.41,
      "learning_rate": 5.80781940867719e-05,
      "loss": 0.294,
      "step": 59410
    },
    {
      "epoch": 59.42,
      "learning_rate": 5.805403249989736e-05,
      "loss": 0.2759,
      "step": 59420
    },
    {
      "epoch": 59.43,
      "learning_rate": 5.8029872766208326e-05,
      "loss": 0.33,
      "step": 59430
    },
    {
      "epoch": 59.44,
      "learning_rate": 5.800571488834692e-05,
      "loss": 0.2869,
      "step": 59440
    },
    {
      "epoch": 59.45,
      "learning_rate": 5.798155886895499e-05,
      "loss": 0.2755,
      "step": 59450
    },
    {
      "epoch": 59.46,
      "learning_rate": 5.795740471067419e-05,
      "loss": 0.3275,
      "step": 59460
    },
    {
      "epoch": 59.47,
      "learning_rate": 5.7933252416145984e-05,
      "loss": 0.3046,
      "step": 59470
    },
    {
      "epoch": 59.48,
      "learning_rate": 5.790910198801164e-05,
      "loss": 0.2976,
      "step": 59480
    },
    {
      "epoch": 59.49,
      "learning_rate": 5.788495342891217e-05,
      "loss": 0.3184,
      "step": 59490
    },
    {
      "epoch": 59.5,
      "learning_rate": 5.78608067414885e-05,
      "loss": 0.268,
      "step": 59500
    },
    {
      "epoch": 59.51,
      "learning_rate": 5.783666192838123e-05,
      "loss": 0.2881,
      "step": 59510
    },
    {
      "epoch": 59.52,
      "learning_rate": 5.7812518992230805e-05,
      "loss": 0.3037,
      "step": 59520
    },
    {
      "epoch": 59.53,
      "learning_rate": 5.778837793567747e-05,
      "loss": 0.2414,
      "step": 59530
    },
    {
      "epoch": 59.54,
      "learning_rate": 5.776423876136122e-05,
      "loss": 0.3467,
      "step": 59540
    },
    {
      "epoch": 59.55,
      "learning_rate": 5.774010147192193e-05,
      "loss": 0.2617,
      "step": 59550
    },
    {
      "epoch": 59.56,
      "learning_rate": 5.771596606999917e-05,
      "loss": 0.25,
      "step": 59560
    },
    {
      "epoch": 59.57,
      "learning_rate": 5.76918325582324e-05,
      "loss": 0.2311,
      "step": 59570
    },
    {
      "epoch": 59.58,
      "learning_rate": 5.766770093926078e-05,
      "loss": 0.3035,
      "step": 59580
    },
    {
      "epoch": 59.59,
      "learning_rate": 5.764357121572333e-05,
      "loss": 0.3237,
      "step": 59590
    },
    {
      "epoch": 59.6,
      "learning_rate": 5.7619443390258853e-05,
      "loss": 0.2583,
      "step": 59600
    },
    {
      "epoch": 59.61,
      "learning_rate": 5.759531746550592e-05,
      "loss": 0.1982,
      "step": 59610
    },
    {
      "epoch": 59.62,
      "learning_rate": 5.757119344410285e-05,
      "loss": 0.3099,
      "step": 59620
    },
    {
      "epoch": 59.63,
      "learning_rate": 5.754707132868791e-05,
      "loss": 0.2379,
      "step": 59630
    },
    {
      "epoch": 59.64,
      "learning_rate": 5.752295112189899e-05,
      "loss": 0.2271,
      "step": 59640
    },
    {
      "epoch": 59.65,
      "learning_rate": 5.7498832826373875e-05,
      "loss": 0.2852,
      "step": 59650
    },
    {
      "epoch": 59.66,
      "learning_rate": 5.747471644475009e-05,
      "loss": 0.3381,
      "step": 59660
    },
    {
      "epoch": 59.67,
      "learning_rate": 5.7450601979664955e-05,
      "loss": 0.2435,
      "step": 59670
    },
    {
      "epoch": 59.68,
      "learning_rate": 5.742648943375558e-05,
      "loss": 0.3214,
      "step": 59680
    },
    {
      "epoch": 59.69,
      "learning_rate": 5.7402378809658924e-05,
      "loss": 0.261,
      "step": 59690
    },
    {
      "epoch": 59.7,
      "learning_rate": 5.737827011001167e-05,
      "loss": 0.2687,
      "step": 59700
    },
    {
      "epoch": 59.71,
      "learning_rate": 5.7354163337450295e-05,
      "loss": 0.2307,
      "step": 59710
    },
    {
      "epoch": 59.72,
      "learning_rate": 5.73300584946111e-05,
      "loss": 0.2491,
      "step": 59720
    },
    {
      "epoch": 59.73,
      "learning_rate": 5.730595558413013e-05,
      "loss": 0.2923,
      "step": 59730
    },
    {
      "epoch": 59.74,
      "learning_rate": 5.7281854608643255e-05,
      "loss": 0.3297,
      "step": 59740
    },
    {
      "epoch": 59.75,
      "learning_rate": 5.7257755570786104e-05,
      "loss": 0.2705,
      "step": 59750
    },
    {
      "epoch": 59.76,
      "learning_rate": 5.723365847319414e-05,
      "loss": 0.2268,
      "step": 59760
    },
    {
      "epoch": 59.77,
      "learning_rate": 5.720956331850258e-05,
      "loss": 0.3037,
      "step": 59770
    },
    {
      "epoch": 59.78,
      "learning_rate": 5.7185470109346446e-05,
      "loss": 0.2336,
      "step": 59780
    },
    {
      "epoch": 59.79,
      "learning_rate": 5.716137884836048e-05,
      "loss": 0.2841,
      "step": 59790
    },
    {
      "epoch": 59.8,
      "learning_rate": 5.7137289538179326e-05,
      "loss": 0.2062,
      "step": 59800
    },
    {
      "epoch": 59.81,
      "learning_rate": 5.711320218143731e-05,
      "loss": 0.2592,
      "step": 59810
    },
    {
      "epoch": 59.82,
      "learning_rate": 5.708911678076864e-05,
      "loss": 0.258,
      "step": 59820
    },
    {
      "epoch": 59.83,
      "learning_rate": 5.70650333388072e-05,
      "loss": 0.2715,
      "step": 59830
    },
    {
      "epoch": 59.84,
      "learning_rate": 5.7040951858186776e-05,
      "loss": 0.2018,
      "step": 59840
    },
    {
      "epoch": 59.85,
      "learning_rate": 5.701687234154085e-05,
      "loss": 0.3044,
      "step": 59850
    },
    {
      "epoch": 59.86,
      "learning_rate": 5.699279479150274e-05,
      "loss": 0.2974,
      "step": 59860
    },
    {
      "epoch": 59.87,
      "learning_rate": 5.696871921070547e-05,
      "loss": 0.3356,
      "step": 59870
    },
    {
      "epoch": 59.88,
      "learning_rate": 5.6944645601782e-05,
      "loss": 0.2683,
      "step": 59880
    },
    {
      "epoch": 59.89,
      "learning_rate": 5.692057396736493e-05,
      "loss": 0.2506,
      "step": 59890
    },
    {
      "epoch": 59.9,
      "learning_rate": 5.689650431008672e-05,
      "loss": 0.2514,
      "step": 59900
    },
    {
      "epoch": 59.91,
      "learning_rate": 5.687243663257957e-05,
      "loss": 0.3202,
      "step": 59910
    },
    {
      "epoch": 59.92,
      "learning_rate": 5.68483709374755e-05,
      "loss": 0.329,
      "step": 59920
    },
    {
      "epoch": 59.93,
      "learning_rate": 5.68243072274063e-05,
      "loss": 0.2765,
      "step": 59930
    },
    {
      "epoch": 59.94,
      "learning_rate": 5.6800245505003505e-05,
      "loss": 0.3292,
      "step": 59940
    },
    {
      "epoch": 59.95,
      "learning_rate": 5.6776185772898516e-05,
      "loss": 0.3129,
      "step": 59950
    },
    {
      "epoch": 59.96,
      "learning_rate": 5.675212803372246e-05,
      "loss": 0.2584,
      "step": 59960
    },
    {
      "epoch": 59.97,
      "learning_rate": 5.672807229010625e-05,
      "loss": 0.2938,
      "step": 59970
    },
    {
      "epoch": 59.98,
      "learning_rate": 5.670401854468058e-05,
      "loss": 0.3025,
      "step": 59980
    },
    {
      "epoch": 59.99,
      "learning_rate": 5.667996680007593e-05,
      "loss": 0.2865,
      "step": 59990
    },
    {
      "epoch": 60.0,
      "learning_rate": 5.665591705892254e-05,
      "loss": 0.2256,
      "step": 60000
    },
    {
      "epoch": 60.0,
      "eval_accuracy": 0.8015,
      "eval_loss": 0.27394360303878784,
      "eval_runtime": 14.8537,
      "eval_samples_per_second": 134.646,
      "eval_steps_per_second": 16.831,
      "step": 60000
    },
    {
      "epoch": 60.01,
      "learning_rate": 5.6631869323850516e-05,
      "loss": 0.2033,
      "step": 60010
    },
    {
      "epoch": 60.02,
      "learning_rate": 5.6607823597489634e-05,
      "loss": 0.2799,
      "step": 60020
    },
    {
      "epoch": 60.03,
      "learning_rate": 5.658377988246952e-05,
      "loss": 0.2766,
      "step": 60030
    },
    {
      "epoch": 60.04,
      "learning_rate": 5.655973818141954e-05,
      "loss": 0.297,
      "step": 60040
    },
    {
      "epoch": 60.05,
      "learning_rate": 5.653569849696887e-05,
      "loss": 0.1637,
      "step": 60050
    },
    {
      "epoch": 60.06,
      "learning_rate": 5.651166083174646e-05,
      "loss": 0.3541,
      "step": 60060
    },
    {
      "epoch": 60.07,
      "learning_rate": 5.648762518838101e-05,
      "loss": 0.2334,
      "step": 60070
    },
    {
      "epoch": 60.08,
      "learning_rate": 5.6463591569501025e-05,
      "loss": 0.2598,
      "step": 60080
    },
    {
      "epoch": 60.09,
      "learning_rate": 5.643955997773482e-05,
      "loss": 0.2913,
      "step": 60090
    },
    {
      "epoch": 60.1,
      "learning_rate": 5.641553041571044e-05,
      "loss": 0.2958,
      "step": 60100
    },
    {
      "epoch": 60.11,
      "learning_rate": 5.6391502886055704e-05,
      "loss": 0.2433,
      "step": 60110
    },
    {
      "epoch": 60.12,
      "learning_rate": 5.6367477391398234e-05,
      "loss": 0.313,
      "step": 60120
    },
    {
      "epoch": 60.13,
      "learning_rate": 5.634345393436539e-05,
      "loss": 0.2909,
      "step": 60130
    },
    {
      "epoch": 60.14,
      "learning_rate": 5.631943251758441e-05,
      "loss": 0.353,
      "step": 60140
    },
    {
      "epoch": 60.15,
      "learning_rate": 5.6295413143682204e-05,
      "loss": 0.2844,
      "step": 60150
    },
    {
      "epoch": 60.16,
      "learning_rate": 5.62713958152855e-05,
      "loss": 0.2679,
      "step": 60160
    },
    {
      "epoch": 60.17,
      "learning_rate": 5.624738053502078e-05,
      "loss": 0.2379,
      "step": 60170
    },
    {
      "epoch": 60.18,
      "learning_rate": 5.622336730551434e-05,
      "loss": 0.2978,
      "step": 60180
    },
    {
      "epoch": 60.19,
      "learning_rate": 5.619935612939218e-05,
      "loss": 0.3204,
      "step": 60190
    },
    {
      "epoch": 60.2,
      "learning_rate": 5.6175347009280194e-05,
      "loss": 0.3003,
      "step": 60200
    },
    {
      "epoch": 60.21,
      "learning_rate": 5.615133994780397e-05,
      "loss": 0.2531,
      "step": 60210
    },
    {
      "epoch": 60.22,
      "learning_rate": 5.612733494758887e-05,
      "loss": 0.2504,
      "step": 60220
    },
    {
      "epoch": 60.23,
      "learning_rate": 5.610333201126004e-05,
      "loss": 0.2829,
      "step": 60230
    },
    {
      "epoch": 60.24,
      "learning_rate": 5.6079331141442415e-05,
      "loss": 0.3125,
      "step": 60240
    },
    {
      "epoch": 60.25,
      "learning_rate": 5.6055332340760676e-05,
      "loss": 0.2211,
      "step": 60250
    },
    {
      "epoch": 60.26,
      "learning_rate": 5.6031335611839303e-05,
      "loss": 0.3171,
      "step": 60260
    },
    {
      "epoch": 60.27,
      "learning_rate": 5.600734095730256e-05,
      "loss": 0.3244,
      "step": 60270
    },
    {
      "epoch": 60.28,
      "learning_rate": 5.598334837977447e-05,
      "loss": 0.3292,
      "step": 60280
    },
    {
      "epoch": 60.29,
      "learning_rate": 5.5959357881878786e-05,
      "loss": 0.3036,
      "step": 60290
    },
    {
      "epoch": 60.3,
      "learning_rate": 5.593536946623911e-05,
      "loss": 0.2256,
      "step": 60300
    },
    {
      "epoch": 60.31,
      "learning_rate": 5.591138313547877e-05,
      "loss": 0.2896,
      "step": 60310
    },
    {
      "epoch": 60.32,
      "learning_rate": 5.588739889222085e-05,
      "loss": 0.2701,
      "step": 60320
    },
    {
      "epoch": 60.33,
      "learning_rate": 5.5863416739088256e-05,
      "loss": 0.2671,
      "step": 60330
    },
    {
      "epoch": 60.34,
      "learning_rate": 5.5839436678703646e-05,
      "loss": 0.2902,
      "step": 60340
    },
    {
      "epoch": 60.35,
      "learning_rate": 5.581545871368944e-05,
      "loss": 0.2714,
      "step": 60350
    },
    {
      "epoch": 60.36,
      "learning_rate": 5.579148284666783e-05,
      "loss": 0.2899,
      "step": 60360
    },
    {
      "epoch": 60.37,
      "learning_rate": 5.5767509080260765e-05,
      "loss": 0.2533,
      "step": 60370
    },
    {
      "epoch": 60.38,
      "learning_rate": 5.574353741708997e-05,
      "loss": 0.2457,
      "step": 60380
    },
    {
      "epoch": 60.39,
      "learning_rate": 5.5719567859776996e-05,
      "loss": 0.2754,
      "step": 60390
    },
    {
      "epoch": 60.4,
      "learning_rate": 5.569560041094309e-05,
      "loss": 0.2033,
      "step": 60400
    },
    {
      "epoch": 60.41,
      "learning_rate": 5.56716350732093e-05,
      "loss": 0.3542,
      "step": 60410
    },
    {
      "epoch": 60.42,
      "learning_rate": 5.564767184919645e-05,
      "loss": 0.2734,
      "step": 60420
    },
    {
      "epoch": 60.43,
      "learning_rate": 5.56237107415251e-05,
      "loss": 0.2673,
      "step": 60430
    },
    {
      "epoch": 60.44,
      "learning_rate": 5.5599751752815624e-05,
      "loss": 0.2757,
      "step": 60440
    },
    {
      "epoch": 60.45,
      "learning_rate": 5.557579488568809e-05,
      "loss": 0.373,
      "step": 60450
    },
    {
      "epoch": 60.46,
      "learning_rate": 5.5551840142762445e-05,
      "loss": 0.2642,
      "step": 60460
    },
    {
      "epoch": 60.47,
      "learning_rate": 5.552788752665834e-05,
      "loss": 0.3028,
      "step": 60470
    },
    {
      "epoch": 60.48,
      "learning_rate": 5.550393703999516e-05,
      "loss": 0.2958,
      "step": 60480
    },
    {
      "epoch": 60.49,
      "learning_rate": 5.547998868539213e-05,
      "loss": 0.2918,
      "step": 60490
    },
    {
      "epoch": 60.5,
      "learning_rate": 5.5456042465468166e-05,
      "loss": 0.2884,
      "step": 60500
    },
    {
      "epoch": 60.51,
      "learning_rate": 5.5432098382842014e-05,
      "loss": 0.3157,
      "step": 60510
    },
    {
      "epoch": 60.52,
      "learning_rate": 5.540815644013217e-05,
      "loss": 0.2863,
      "step": 60520
    },
    {
      "epoch": 60.53,
      "learning_rate": 5.538421663995688e-05,
      "loss": 0.2855,
      "step": 60530
    },
    {
      "epoch": 60.54,
      "learning_rate": 5.536027898493418e-05,
      "loss": 0.3362,
      "step": 60540
    },
    {
      "epoch": 60.55,
      "learning_rate": 5.5336343477681844e-05,
      "loss": 0.2802,
      "step": 60550
    },
    {
      "epoch": 60.56,
      "learning_rate": 5.531241012081742e-05,
      "loss": 0.2627,
      "step": 60560
    },
    {
      "epoch": 60.57,
      "learning_rate": 5.528847891695818e-05,
      "loss": 0.3123,
      "step": 60570
    },
    {
      "epoch": 60.58,
      "learning_rate": 5.52645498687213e-05,
      "loss": 0.2163,
      "step": 60580
    },
    {
      "epoch": 60.59,
      "learning_rate": 5.5240622978723566e-05,
      "loss": 0.2418,
      "step": 60590
    },
    {
      "epoch": 60.6,
      "learning_rate": 5.5216698249581596e-05,
      "loss": 0.3049,
      "step": 60600
    },
    {
      "epoch": 60.61,
      "learning_rate": 5.519277568391176e-05,
      "loss": 0.2169,
      "step": 60610
    },
    {
      "epoch": 60.62,
      "learning_rate": 5.516885528433019e-05,
      "loss": 0.2199,
      "step": 60620
    },
    {
      "epoch": 60.63,
      "learning_rate": 5.514493705345281e-05,
      "loss": 0.2583,
      "step": 60630
    },
    {
      "epoch": 60.64,
      "learning_rate": 5.512102099389522e-05,
      "loss": 0.2599,
      "step": 60640
    },
    {
      "epoch": 60.65,
      "learning_rate": 5.509710710827291e-05,
      "loss": 0.2618,
      "step": 60650
    },
    {
      "epoch": 60.66,
      "learning_rate": 5.507319539920105e-05,
      "loss": 0.3289,
      "step": 60660
    },
    {
      "epoch": 60.67,
      "learning_rate": 5.504928586929458e-05,
      "loss": 0.2739,
      "step": 60670
    },
    {
      "epoch": 60.68,
      "learning_rate": 5.5025378521168215e-05,
      "loss": 0.3183,
      "step": 60680
    },
    {
      "epoch": 60.69,
      "learning_rate": 5.500147335743642e-05,
      "loss": 0.2114,
      "step": 60690
    },
    {
      "epoch": 60.7,
      "learning_rate": 5.497757038071341e-05,
      "loss": 0.3746,
      "step": 60700
    },
    {
      "epoch": 60.71,
      "learning_rate": 5.4953669593613216e-05,
      "loss": 0.2697,
      "step": 60710
    },
    {
      "epoch": 60.72,
      "learning_rate": 5.492977099874958e-05,
      "loss": 0.2899,
      "step": 60720
    },
    {
      "epoch": 60.73,
      "learning_rate": 5.490587459873602e-05,
      "loss": 0.2074,
      "step": 60730
    },
    {
      "epoch": 60.74,
      "learning_rate": 5.488198039618579e-05,
      "loss": 0.2682,
      "step": 60740
    },
    {
      "epoch": 60.75,
      "learning_rate": 5.4858088393711935e-05,
      "loss": 0.2542,
      "step": 60750
    },
    {
      "epoch": 60.76,
      "learning_rate": 5.4834198593927263e-05,
      "loss": 0.3133,
      "step": 60760
    },
    {
      "epoch": 60.77,
      "learning_rate": 5.4810310999444295e-05,
      "loss": 0.2286,
      "step": 60770
    },
    {
      "epoch": 60.78,
      "learning_rate": 5.4786425612875354e-05,
      "loss": 0.2041,
      "step": 60780
    },
    {
      "epoch": 60.79,
      "learning_rate": 5.476254243683255e-05,
      "loss": 0.3633,
      "step": 60790
    },
    {
      "epoch": 60.8,
      "learning_rate": 5.4738661473927665e-05,
      "loss": 0.3641,
      "step": 60800
    },
    {
      "epoch": 60.81,
      "learning_rate": 5.4714782726772305e-05,
      "loss": 0.2761,
      "step": 60810
    },
    {
      "epoch": 60.82,
      "learning_rate": 5.469090619797781e-05,
      "loss": 0.2861,
      "step": 60820
    },
    {
      "epoch": 60.83,
      "learning_rate": 5.466703189015524e-05,
      "loss": 0.2951,
      "step": 60830
    },
    {
      "epoch": 60.84,
      "learning_rate": 5.464315980591553e-05,
      "loss": 0.2235,
      "step": 60840
    },
    {
      "epoch": 60.85,
      "learning_rate": 5.461928994786925e-05,
      "loss": 0.3094,
      "step": 60850
    },
    {
      "epoch": 60.86,
      "learning_rate": 5.459542231862679e-05,
      "loss": 0.2885,
      "step": 60860
    },
    {
      "epoch": 60.87,
      "learning_rate": 5.4571556920798266e-05,
      "loss": 0.2707,
      "step": 60870
    },
    {
      "epoch": 60.88,
      "learning_rate": 5.454769375699355e-05,
      "loss": 0.2872,
      "step": 60880
    },
    {
      "epoch": 60.89,
      "learning_rate": 5.452383282982228e-05,
      "loss": 0.2453,
      "step": 60890
    },
    {
      "epoch": 60.9,
      "learning_rate": 5.449997414189388e-05,
      "loss": 0.3085,
      "step": 60900
    },
    {
      "epoch": 60.91,
      "learning_rate": 5.447611769581751e-05,
      "loss": 0.2967,
      "step": 60910
    },
    {
      "epoch": 60.92,
      "learning_rate": 5.445226349420203e-05,
      "loss": 0.3034,
      "step": 60920
    },
    {
      "epoch": 60.93,
      "learning_rate": 5.4428411539656135e-05,
      "loss": 0.1951,
      "step": 60930
    },
    {
      "epoch": 60.94,
      "learning_rate": 5.4404561834788216e-05,
      "loss": 0.3287,
      "step": 60940
    },
    {
      "epoch": 60.95,
      "learning_rate": 5.4380714382206444e-05,
      "loss": 0.226,
      "step": 60950
    },
    {
      "epoch": 60.96,
      "learning_rate": 5.435686918451874e-05,
      "loss": 0.3491,
      "step": 60960
    },
    {
      "epoch": 60.97,
      "learning_rate": 5.43330262443328e-05,
      "loss": 0.2732,
      "step": 60970
    },
    {
      "epoch": 60.98,
      "learning_rate": 5.430918556425603e-05,
      "loss": 0.2774,
      "step": 60980
    },
    {
      "epoch": 60.99,
      "learning_rate": 5.4285347146895614e-05,
      "loss": 0.2944,
      "step": 60990
    },
    {
      "epoch": 61.0,
      "learning_rate": 5.426151099485851e-05,
      "loss": 0.2375,
      "step": 61000
    },
    {
      "epoch": 61.0,
      "eval_accuracy": 0.8,
      "eval_loss": 0.27808886766433716,
      "eval_runtime": 15.1825,
      "eval_samples_per_second": 131.731,
      "eval_steps_per_second": 16.466,
      "step": 61000
    },
    {
      "epoch": 61.01,
      "learning_rate": 5.4237677110751375e-05,
      "loss": 0.3147,
      "step": 61010
    },
    {
      "epoch": 61.02,
      "learning_rate": 5.421384549718064e-05,
      "loss": 0.2733,
      "step": 61020
    },
    {
      "epoch": 61.03,
      "learning_rate": 5.419001615675252e-05,
      "loss": 0.2647,
      "step": 61030
    },
    {
      "epoch": 61.04,
      "learning_rate": 5.416618909207295e-05,
      "loss": 0.2929,
      "step": 61040
    },
    {
      "epoch": 61.05,
      "learning_rate": 5.414236430574763e-05,
      "loss": 0.2229,
      "step": 61050
    },
    {
      "epoch": 61.06,
      "learning_rate": 5.411854180038198e-05,
      "loss": 0.2778,
      "step": 61060
    },
    {
      "epoch": 61.07,
      "learning_rate": 5.4094721578581196e-05,
      "loss": 0.3029,
      "step": 61070
    },
    {
      "epoch": 61.08,
      "learning_rate": 5.407090364295021e-05,
      "loss": 0.2456,
      "step": 61080
    },
    {
      "epoch": 61.09,
      "learning_rate": 5.404708799609376e-05,
      "loss": 0.2465,
      "step": 61090
    },
    {
      "epoch": 61.1,
      "learning_rate": 5.4023274640616273e-05,
      "loss": 0.2326,
      "step": 61100
    },
    {
      "epoch": 61.11,
      "learning_rate": 5.3999463579121924e-05,
      "loss": 0.32,
      "step": 61110
    },
    {
      "epoch": 61.12,
      "learning_rate": 5.397565481421468e-05,
      "loss": 0.2615,
      "step": 61120
    },
    {
      "epoch": 61.13,
      "learning_rate": 5.3951848348498206e-05,
      "loss": 0.3297,
      "step": 61130
    },
    {
      "epoch": 61.14,
      "learning_rate": 5.392804418457595e-05,
      "loss": 0.2687,
      "step": 61140
    },
    {
      "epoch": 61.15,
      "learning_rate": 5.3904242325051075e-05,
      "loss": 0.2791,
      "step": 61150
    },
    {
      "epoch": 61.16,
      "learning_rate": 5.388044277252657e-05,
      "loss": 0.2909,
      "step": 61160
    },
    {
      "epoch": 61.17,
      "learning_rate": 5.3856645529605085e-05,
      "loss": 0.204,
      "step": 61170
    },
    {
      "epoch": 61.18,
      "learning_rate": 5.3832850598889056e-05,
      "loss": 0.2717,
      "step": 61180
    },
    {
      "epoch": 61.19,
      "learning_rate": 5.3809057982980667e-05,
      "loss": 0.2593,
      "step": 61190
    },
    {
      "epoch": 61.2,
      "learning_rate": 5.3785267684481813e-05,
      "loss": 0.2722,
      "step": 61200
    },
    {
      "epoch": 61.21,
      "learning_rate": 5.37614797059942e-05,
      "loss": 0.3058,
      "step": 61210
    },
    {
      "epoch": 61.22,
      "learning_rate": 5.373769405011925e-05,
      "loss": 0.289,
      "step": 61220
    },
    {
      "epoch": 61.23,
      "learning_rate": 5.371391071945811e-05,
      "loss": 0.2471,
      "step": 61230
    },
    {
      "epoch": 61.24,
      "learning_rate": 5.369012971661167e-05,
      "loss": 0.2438,
      "step": 61240
    },
    {
      "epoch": 61.25,
      "learning_rate": 5.3666351044180626e-05,
      "loss": 0.2829,
      "step": 61250
    },
    {
      "epoch": 61.26,
      "learning_rate": 5.364257470476536e-05,
      "loss": 0.2891,
      "step": 61260
    },
    {
      "epoch": 61.27,
      "learning_rate": 5.3618800700966e-05,
      "loss": 0.2421,
      "step": 61270
    },
    {
      "epoch": 61.28,
      "learning_rate": 5.359502903538243e-05,
      "loss": 0.1745,
      "step": 61280
    },
    {
      "epoch": 61.29,
      "learning_rate": 5.357125971061433e-05,
      "loss": 0.2894,
      "step": 61290
    },
    {
      "epoch": 61.3,
      "learning_rate": 5.3547492729261046e-05,
      "loss": 0.326,
      "step": 61300
    },
    {
      "epoch": 61.31,
      "learning_rate": 5.352372809392171e-05,
      "loss": 0.283,
      "step": 61310
    },
    {
      "epoch": 61.32,
      "learning_rate": 5.3499965807195175e-05,
      "loss": 0.2417,
      "step": 61320
    },
    {
      "epoch": 61.33,
      "learning_rate": 5.347620587168006e-05,
      "loss": 0.2973,
      "step": 61330
    },
    {
      "epoch": 61.34,
      "learning_rate": 5.3452448289974684e-05,
      "loss": 0.3024,
      "step": 61340
    },
    {
      "epoch": 61.35,
      "learning_rate": 5.342869306467719e-05,
      "loss": 0.2866,
      "step": 61350
    },
    {
      "epoch": 61.36,
      "learning_rate": 5.34049401983854e-05,
      "loss": 0.2852,
      "step": 61360
    },
    {
      "epoch": 61.37,
      "learning_rate": 5.338118969369687e-05,
      "loss": 0.2826,
      "step": 61370
    },
    {
      "epoch": 61.38,
      "learning_rate": 5.335744155320894e-05,
      "loss": 0.2775,
      "step": 61380
    },
    {
      "epoch": 61.39,
      "learning_rate": 5.3333695779518655e-05,
      "loss": 0.2593,
      "step": 61390
    },
    {
      "epoch": 61.4,
      "learning_rate": 5.33099523752228e-05,
      "loss": 0.2502,
      "step": 61400
    },
    {
      "epoch": 61.41,
      "learning_rate": 5.328621134291797e-05,
      "loss": 0.3048,
      "step": 61410
    },
    {
      "epoch": 61.42,
      "learning_rate": 5.326247268520042e-05,
      "loss": 0.2454,
      "step": 61420
    },
    {
      "epoch": 61.43,
      "learning_rate": 5.3238736404666176e-05,
      "loss": 0.3101,
      "step": 61430
    },
    {
      "epoch": 61.44,
      "learning_rate": 5.321500250391101e-05,
      "loss": 0.2825,
      "step": 61440
    },
    {
      "epoch": 61.45,
      "learning_rate": 5.319127098553039e-05,
      "loss": 0.2865,
      "step": 61450
    },
    {
      "epoch": 61.46,
      "learning_rate": 5.3167541852119605e-05,
      "loss": 0.2524,
      "step": 61460
    },
    {
      "epoch": 61.47,
      "learning_rate": 5.3143815106273604e-05,
      "loss": 0.2677,
      "step": 61470
    },
    {
      "epoch": 61.48,
      "learning_rate": 5.3120090750587146e-05,
      "loss": 0.2033,
      "step": 61480
    },
    {
      "epoch": 61.49,
      "learning_rate": 5.309636878765464e-05,
      "loss": 0.2624,
      "step": 61490
    },
    {
      "epoch": 61.5,
      "learning_rate": 5.307264922007033e-05,
      "loss": 0.2814,
      "step": 61500
    },
    {
      "epoch": 61.51,
      "learning_rate": 5.304893205042814e-05,
      "loss": 0.2706,
      "step": 61510
    },
    {
      "epoch": 61.52,
      "learning_rate": 5.3025217281321734e-05,
      "loss": 0.2465,
      "step": 61520
    },
    {
      "epoch": 61.53,
      "learning_rate": 5.3001504915344496e-05,
      "loss": 0.2467,
      "step": 61530
    },
    {
      "epoch": 61.54,
      "learning_rate": 5.297779495508964e-05,
      "loss": 0.2616,
      "step": 61540
    },
    {
      "epoch": 61.55,
      "learning_rate": 5.295408740315001e-05,
      "loss": 0.2873,
      "step": 61550
    },
    {
      "epoch": 61.56,
      "learning_rate": 5.2930382262118237e-05,
      "loss": 0.2992,
      "step": 61560
    },
    {
      "epoch": 61.57,
      "learning_rate": 5.2906679534586686e-05,
      "loss": 0.2438,
      "step": 61570
    },
    {
      "epoch": 61.58,
      "learning_rate": 5.2882979223147446e-05,
      "loss": 0.3268,
      "step": 61580
    },
    {
      "epoch": 61.59,
      "learning_rate": 5.285928133039231e-05,
      "loss": 0.3569,
      "step": 61590
    },
    {
      "epoch": 61.6,
      "learning_rate": 5.28355858589129e-05,
      "loss": 0.295,
      "step": 61600
    },
    {
      "epoch": 61.61,
      "learning_rate": 5.281189281130052e-05,
      "loss": 0.3065,
      "step": 61610
    },
    {
      "epoch": 61.62,
      "learning_rate": 5.2788202190146174e-05,
      "loss": 0.2683,
      "step": 61620
    },
    {
      "epoch": 61.63,
      "learning_rate": 5.2764513998040634e-05,
      "loss": 0.2625,
      "step": 61630
    },
    {
      "epoch": 61.64,
      "learning_rate": 5.274082823757442e-05,
      "loss": 0.2199,
      "step": 61640
    },
    {
      "epoch": 61.65,
      "learning_rate": 5.271714491133776e-05,
      "loss": 0.273,
      "step": 61650
    },
    {
      "epoch": 61.66,
      "learning_rate": 5.26934640219206e-05,
      "loss": 0.3443,
      "step": 61660
    },
    {
      "epoch": 61.67,
      "learning_rate": 5.26697855719127e-05,
      "loss": 0.2078,
      "step": 61670
    },
    {
      "epoch": 61.68,
      "learning_rate": 5.264610956390348e-05,
      "loss": 0.29,
      "step": 61680
    },
    {
      "epoch": 61.69,
      "learning_rate": 5.262243600048213e-05,
      "loss": 0.3042,
      "step": 61690
    },
    {
      "epoch": 61.7,
      "learning_rate": 5.25987648842375e-05,
      "loss": 0.2399,
      "step": 61700
    },
    {
      "epoch": 61.71,
      "learning_rate": 5.257509621775828e-05,
      "loss": 0.299,
      "step": 61710
    },
    {
      "epoch": 61.72,
      "learning_rate": 5.255143000363281e-05,
      "loss": 0.2942,
      "step": 61720
    },
    {
      "epoch": 61.73,
      "learning_rate": 5.252776624444921e-05,
      "loss": 0.1998,
      "step": 61730
    },
    {
      "epoch": 61.74,
      "learning_rate": 5.25041049427953e-05,
      "loss": 0.2762,
      "step": 61740
    },
    {
      "epoch": 61.75,
      "learning_rate": 5.248044610125867e-05,
      "loss": 0.2795,
      "step": 61750
    },
    {
      "epoch": 61.76,
      "learning_rate": 5.2456789722426587e-05,
      "loss": 0.2379,
      "step": 61760
    },
    {
      "epoch": 61.77,
      "learning_rate": 5.24331358088861e-05,
      "loss": 0.248,
      "step": 61770
    },
    {
      "epoch": 61.78,
      "learning_rate": 5.2409484363223906e-05,
      "loss": 0.286,
      "step": 61780
    },
    {
      "epoch": 61.79,
      "learning_rate": 5.2385835388026584e-05,
      "loss": 0.3181,
      "step": 61790
    },
    {
      "epoch": 61.8,
      "learning_rate": 5.2362188885880296e-05,
      "loss": 0.2601,
      "step": 61800
    },
    {
      "epoch": 61.81,
      "learning_rate": 5.2338544859371e-05,
      "loss": 0.3118,
      "step": 61810
    },
    {
      "epoch": 61.82,
      "learning_rate": 5.231490331108436e-05,
      "loss": 0.2642,
      "step": 61820
    },
    {
      "epoch": 61.83,
      "learning_rate": 5.2291264243605795e-05,
      "loss": 0.3324,
      "step": 61830
    },
    {
      "epoch": 61.84,
      "learning_rate": 5.226762765952042e-05,
      "loss": 0.2682,
      "step": 61840
    },
    {
      "epoch": 61.85,
      "learning_rate": 5.224399356141308e-05,
      "loss": 0.3179,
      "step": 61850
    },
    {
      "epoch": 61.86,
      "learning_rate": 5.222036195186843e-05,
      "loss": 0.2393,
      "step": 61860
    },
    {
      "epoch": 61.87,
      "learning_rate": 5.219673283347074e-05,
      "loss": 0.3188,
      "step": 61870
    },
    {
      "epoch": 61.88,
      "learning_rate": 5.2173106208804064e-05,
      "loss": 0.2215,
      "step": 61880
    },
    {
      "epoch": 61.89,
      "learning_rate": 5.214948208045218e-05,
      "loss": 0.2473,
      "step": 61890
    },
    {
      "epoch": 61.9,
      "learning_rate": 5.212586045099858e-05,
      "loss": 0.2939,
      "step": 61900
    },
    {
      "epoch": 61.91,
      "learning_rate": 5.2102241323026446e-05,
      "loss": 0.2796,
      "step": 61910
    },
    {
      "epoch": 61.92,
      "learning_rate": 5.2078624699118815e-05,
      "loss": 0.306,
      "step": 61920
    },
    {
      "epoch": 61.93,
      "learning_rate": 5.205501058185833e-05,
      "loss": 0.3288,
      "step": 61930
    },
    {
      "epoch": 61.94,
      "learning_rate": 5.203139897382738e-05,
      "loss": 0.2673,
      "step": 61940
    },
    {
      "epoch": 61.95,
      "learning_rate": 5.2007789877608096e-05,
      "loss": 0.3421,
      "step": 61950
    },
    {
      "epoch": 61.96,
      "learning_rate": 5.198418329578236e-05,
      "loss": 0.3545,
      "step": 61960
    },
    {
      "epoch": 61.97,
      "learning_rate": 5.196057923093174e-05,
      "loss": 0.2822,
      "step": 61970
    },
    {
      "epoch": 61.98,
      "learning_rate": 5.19369776856375e-05,
      "loss": 0.287,
      "step": 61980
    },
    {
      "epoch": 61.99,
      "learning_rate": 5.191337866248072e-05,
      "loss": 0.3225,
      "step": 61990
    },
    {
      "epoch": 62.0,
      "learning_rate": 5.188978216404216e-05,
      "loss": 0.2837,
      "step": 62000
    },
    {
      "epoch": 62.0,
      "eval_accuracy": 0.803,
      "eval_loss": 0.27541568875312805,
      "eval_runtime": 15.2351,
      "eval_samples_per_second": 131.276,
      "eval_steps_per_second": 16.409,
      "step": 62000
    },
    {
      "epoch": 62.01,
      "learning_rate": 5.186618819290226e-05,
      "loss": 0.2145,
      "step": 62010
    },
    {
      "epoch": 62.02,
      "learning_rate": 5.184259675164125e-05,
      "loss": 0.2734,
      "step": 62020
    },
    {
      "epoch": 62.03,
      "learning_rate": 5.181900784283904e-05,
      "loss": 0.2679,
      "step": 62030
    },
    {
      "epoch": 62.04,
      "learning_rate": 5.179542146907525e-05,
      "loss": 0.2355,
      "step": 62040
    },
    {
      "epoch": 62.05,
      "learning_rate": 5.1771837632929316e-05,
      "loss": 0.2834,
      "step": 62050
    },
    {
      "epoch": 62.06,
      "learning_rate": 5.174825633698029e-05,
      "loss": 0.2309,
      "step": 62060
    },
    {
      "epoch": 62.07,
      "learning_rate": 5.172467758380699e-05,
      "loss": 0.2831,
      "step": 62070
    },
    {
      "epoch": 62.08,
      "learning_rate": 5.170110137598796e-05,
      "loss": 0.2955,
      "step": 62080
    },
    {
      "epoch": 62.09,
      "learning_rate": 5.167752771610145e-05,
      "loss": 0.2516,
      "step": 62090
    },
    {
      "epoch": 62.1,
      "learning_rate": 5.165395660672542e-05,
      "loss": 0.315,
      "step": 62100
    },
    {
      "epoch": 62.11,
      "learning_rate": 5.163038805043762e-05,
      "loss": 0.2655,
      "step": 62110
    },
    {
      "epoch": 62.12,
      "learning_rate": 5.1606822049815446e-05,
      "loss": 0.3059,
      "step": 62120
    },
    {
      "epoch": 62.13,
      "learning_rate": 5.158325860743605e-05,
      "loss": 0.2623,
      "step": 62130
    },
    {
      "epoch": 62.14,
      "learning_rate": 5.155969772587628e-05,
      "loss": 0.226,
      "step": 62140
    },
    {
      "epoch": 62.15,
      "learning_rate": 5.1536139407712725e-05,
      "loss": 0.2684,
      "step": 62150
    },
    {
      "epoch": 62.16,
      "learning_rate": 5.151258365552168e-05,
      "loss": 0.2458,
      "step": 62160
    },
    {
      "epoch": 62.17,
      "learning_rate": 5.148903047187916e-05,
      "loss": 0.2773,
      "step": 62170
    },
    {
      "epoch": 62.18,
      "learning_rate": 5.1465479859360936e-05,
      "loss": 0.323,
      "step": 62180
    },
    {
      "epoch": 62.19,
      "learning_rate": 5.144193182054246e-05,
      "loss": 0.346,
      "step": 62190
    },
    {
      "epoch": 62.2,
      "learning_rate": 5.141838635799887e-05,
      "loss": 0.2014,
      "step": 62200
    },
    {
      "epoch": 62.21,
      "learning_rate": 5.139484347430513e-05,
      "loss": 0.2193,
      "step": 62210
    },
    {
      "epoch": 62.22,
      "learning_rate": 5.137130317203581e-05,
      "loss": 0.3,
      "step": 62220
    },
    {
      "epoch": 62.23,
      "learning_rate": 5.134776545376523e-05,
      "loss": 0.2403,
      "step": 62230
    },
    {
      "epoch": 62.24,
      "learning_rate": 5.132423032206747e-05,
      "loss": 0.238,
      "step": 62240
    },
    {
      "epoch": 62.25,
      "learning_rate": 5.130069777951628e-05,
      "loss": 0.2715,
      "step": 62250
    },
    {
      "epoch": 62.26,
      "learning_rate": 5.127716782868517e-05,
      "loss": 0.265,
      "step": 62260
    },
    {
      "epoch": 62.27,
      "learning_rate": 5.125364047214731e-05,
      "loss": 0.3182,
      "step": 62270
    },
    {
      "epoch": 62.28,
      "learning_rate": 5.1230115712475635e-05,
      "loss": 0.219,
      "step": 62280
    },
    {
      "epoch": 62.29,
      "learning_rate": 5.120659355224272e-05,
      "loss": 0.2876,
      "step": 62290
    },
    {
      "epoch": 62.3,
      "learning_rate": 5.1183073994021e-05,
      "loss": 0.3473,
      "step": 62300
    },
    {
      "epoch": 62.31,
      "learning_rate": 5.1159557040382505e-05,
      "loss": 0.3125,
      "step": 62310
    },
    {
      "epoch": 62.32,
      "learning_rate": 5.1136042693899014e-05,
      "loss": 0.2859,
      "step": 62320
    },
    {
      "epoch": 62.33,
      "learning_rate": 5.1112530957142004e-05,
      "loss": 0.2696,
      "step": 62330
    },
    {
      "epoch": 62.34,
      "learning_rate": 5.1089021832682694e-05,
      "loss": 0.2842,
      "step": 62340
    },
    {
      "epoch": 62.35,
      "learning_rate": 5.106551532309201e-05,
      "loss": 0.2909,
      "step": 62350
    },
    {
      "epoch": 62.36,
      "learning_rate": 5.104201143094056e-05,
      "loss": 0.3471,
      "step": 62360
    },
    {
      "epoch": 62.37,
      "learning_rate": 5.101851015879874e-05,
      "loss": 0.2868,
      "step": 62370
    },
    {
      "epoch": 62.38,
      "learning_rate": 5.0995011509236607e-05,
      "loss": 0.2781,
      "step": 62380
    },
    {
      "epoch": 62.39,
      "learning_rate": 5.097151548482391e-05,
      "loss": 0.3137,
      "step": 62390
    },
    {
      "epoch": 62.4,
      "learning_rate": 5.094802208813016e-05,
      "loss": 0.2904,
      "step": 62400
    },
    {
      "epoch": 62.41,
      "learning_rate": 5.0924531321724535e-05,
      "loss": 0.2261,
      "step": 62410
    },
    {
      "epoch": 62.42,
      "learning_rate": 5.090104318817596e-05,
      "loss": 0.7138,
      "step": 62420
    },
    {
      "epoch": 62.43,
      "learning_rate": 5.087755769005311e-05,
      "loss": 0.2115,
      "step": 62430
    },
    {
      "epoch": 62.44,
      "learning_rate": 5.085407482992426e-05,
      "loss": 0.2875,
      "step": 62440
    },
    {
      "epoch": 62.45,
      "learning_rate": 5.083059461035748e-05,
      "loss": 0.2558,
      "step": 62450
    },
    {
      "epoch": 62.46,
      "learning_rate": 5.080711703392055e-05,
      "loss": 0.289,
      "step": 62460
    },
    {
      "epoch": 62.47,
      "learning_rate": 5.078364210318091e-05,
      "loss": 0.222,
      "step": 62470
    },
    {
      "epoch": 62.48,
      "learning_rate": 5.076016982070578e-05,
      "loss": 0.1931,
      "step": 62480
    },
    {
      "epoch": 62.49,
      "learning_rate": 5.0736700189062e-05,
      "loss": 0.2754,
      "step": 62490
    },
    {
      "epoch": 62.5,
      "learning_rate": 5.071323321081623e-05,
      "loss": 0.2071,
      "step": 62500
    },
    {
      "epoch": 62.51,
      "learning_rate": 5.068976888853478e-05,
      "loss": 0.3156,
      "step": 62510
    },
    {
      "epoch": 62.52,
      "learning_rate": 5.066630722478364e-05,
      "loss": 0.2973,
      "step": 62520
    },
    {
      "epoch": 62.53,
      "learning_rate": 5.064284822212856e-05,
      "loss": 0.2508,
      "step": 62530
    },
    {
      "epoch": 62.54,
      "learning_rate": 5.0619391883134976e-05,
      "loss": 0.2552,
      "step": 62540
    },
    {
      "epoch": 62.55,
      "learning_rate": 5.059593821036802e-05,
      "loss": 0.2336,
      "step": 62550
    },
    {
      "epoch": 62.56,
      "learning_rate": 5.057248720639258e-05,
      "loss": 0.2392,
      "step": 62560
    },
    {
      "epoch": 62.57,
      "learning_rate": 5.054903887377323e-05,
      "loss": 0.2518,
      "step": 62570
    },
    {
      "epoch": 62.58,
      "learning_rate": 5.0525593215074226e-05,
      "loss": 0.2419,
      "step": 62580
    },
    {
      "epoch": 62.59,
      "learning_rate": 5.0502150232859544e-05,
      "loss": 0.2954,
      "step": 62590
    },
    {
      "epoch": 62.6,
      "learning_rate": 5.0478709929692886e-05,
      "loss": 0.269,
      "step": 62600
    },
    {
      "epoch": 62.61,
      "learning_rate": 5.0455272308137604e-05,
      "loss": 0.2856,
      "step": 62610
    },
    {
      "epoch": 62.62,
      "learning_rate": 5.043183737075688e-05,
      "loss": 0.2771,
      "step": 62620
    },
    {
      "epoch": 62.63,
      "learning_rate": 5.0408405120113484e-05,
      "loss": 0.3086,
      "step": 62630
    },
    {
      "epoch": 62.64,
      "learning_rate": 5.038497555876993e-05,
      "loss": 0.3571,
      "step": 62640
    },
    {
      "epoch": 62.65,
      "learning_rate": 5.0361548689288436e-05,
      "loss": 0.293,
      "step": 62650
    },
    {
      "epoch": 62.66,
      "learning_rate": 5.033812451423093e-05,
      "loss": 0.2717,
      "step": 62660
    },
    {
      "epoch": 62.67,
      "learning_rate": 5.0314703036159047e-05,
      "loss": 0.2984,
      "step": 62670
    },
    {
      "epoch": 62.68,
      "learning_rate": 5.0291284257634124e-05,
      "loss": 0.2104,
      "step": 62680
    },
    {
      "epoch": 62.69,
      "learning_rate": 5.026786818121721e-05,
      "loss": 0.2857,
      "step": 62690
    },
    {
      "epoch": 62.7,
      "learning_rate": 5.024445480946904e-05,
      "loss": 0.2963,
      "step": 62700
    },
    {
      "epoch": 62.71,
      "learning_rate": 5.0221044144950085e-05,
      "loss": 0.2992,
      "step": 62710
    },
    {
      "epoch": 62.72,
      "learning_rate": 5.0197636190220487e-05,
      "loss": 0.2016,
      "step": 62720
    },
    {
      "epoch": 62.73,
      "learning_rate": 5.0174230947840114e-05,
      "loss": 0.3077,
      "step": 62730
    },
    {
      "epoch": 62.74,
      "learning_rate": 5.015082842036847e-05,
      "loss": 0.3232,
      "step": 62740
    },
    {
      "epoch": 62.75,
      "learning_rate": 5.0127428610364915e-05,
      "loss": 0.3292,
      "step": 62750
    },
    {
      "epoch": 62.76,
      "learning_rate": 5.010403152038838e-05,
      "loss": 0.3929,
      "step": 62760
    },
    {
      "epoch": 62.77,
      "learning_rate": 5.0080637152997505e-05,
      "loss": 0.2923,
      "step": 62770
    },
    {
      "epoch": 62.78,
      "learning_rate": 5.0057245510750705e-05,
      "loss": 0.3202,
      "step": 62780
    },
    {
      "epoch": 62.79,
      "learning_rate": 5.003385659620603e-05,
      "loss": 0.2226,
      "step": 62790
    },
    {
      "epoch": 62.8,
      "learning_rate": 5.0010470411921226e-05,
      "loss": 0.2633,
      "step": 62800
    },
    {
      "epoch": 62.81,
      "learning_rate": 4.998708696045384e-05,
      "loss": 0.3164,
      "step": 62810
    },
    {
      "epoch": 62.82,
      "learning_rate": 4.9963706244361017e-05,
      "loss": 0.33,
      "step": 62820
    },
    {
      "epoch": 62.83,
      "learning_rate": 4.994032826619963e-05,
      "loss": 0.2552,
      "step": 62830
    },
    {
      "epoch": 62.84,
      "learning_rate": 4.991695302852628e-05,
      "loss": 0.2377,
      "step": 62840
    },
    {
      "epoch": 62.85,
      "learning_rate": 4.989358053389723e-05,
      "loss": 0.3266,
      "step": 62850
    },
    {
      "epoch": 62.86,
      "learning_rate": 4.987021078486846e-05,
      "loss": 0.2339,
      "step": 62860
    },
    {
      "epoch": 62.87,
      "learning_rate": 4.984684378399563e-05,
      "loss": 0.3083,
      "step": 62870
    },
    {
      "epoch": 62.88,
      "learning_rate": 4.9823479533834184e-05,
      "loss": 0.1979,
      "step": 62880
    },
    {
      "epoch": 62.89,
      "learning_rate": 4.980011803693916e-05,
      "loss": 0.3375,
      "step": 62890
    },
    {
      "epoch": 62.9,
      "learning_rate": 4.977675929586533e-05,
      "loss": 0.2386,
      "step": 62900
    },
    {
      "epoch": 62.91,
      "learning_rate": 4.975340331316718e-05,
      "loss": 0.3081,
      "step": 62910
    },
    {
      "epoch": 62.92,
      "learning_rate": 4.973005009139889e-05,
      "loss": 0.2827,
      "step": 62920
    },
    {
      "epoch": 62.93,
      "learning_rate": 4.970669963311432e-05,
      "loss": 0.3153,
      "step": 62930
    },
    {
      "epoch": 62.94,
      "learning_rate": 4.968335194086707e-05,
      "loss": 0.2242,
      "step": 62940
    },
    {
      "epoch": 62.95,
      "learning_rate": 4.966000701721037e-05,
      "loss": 0.3101,
      "step": 62950
    },
    {
      "epoch": 62.96,
      "learning_rate": 4.963666486469721e-05,
      "loss": 0.2133,
      "step": 62960
    },
    {
      "epoch": 62.97,
      "learning_rate": 4.961332548588026e-05,
      "loss": 0.2058,
      "step": 62970
    },
    {
      "epoch": 62.98,
      "learning_rate": 4.958998888331186e-05,
      "loss": 0.3449,
      "step": 62980
    },
    {
      "epoch": 62.99,
      "learning_rate": 4.956665505954405e-05,
      "loss": 0.2792,
      "step": 62990
    },
    {
      "epoch": 63.0,
      "learning_rate": 4.954332401712862e-05,
      "loss": 0.2691,
      "step": 63000
    },
    {
      "epoch": 63.0,
      "eval_accuracy": 0.8085,
      "eval_loss": 0.2824327051639557,
      "eval_runtime": 14.8619,
      "eval_samples_per_second": 134.572,
      "eval_steps_per_second": 16.821,
      "step": 63000
    },
    {
      "epoch": 63.01,
      "learning_rate": 4.951999575861701e-05,
      "loss": 0.261,
      "step": 63010
    },
    {
      "epoch": 63.02,
      "learning_rate": 4.9496670286560355e-05,
      "loss": 0.2851,
      "step": 63020
    },
    {
      "epoch": 63.03,
      "learning_rate": 4.94733476035095e-05,
      "loss": 0.2315,
      "step": 63030
    },
    {
      "epoch": 63.04,
      "learning_rate": 4.9450027712014963e-05,
      "loss": 0.2432,
      "step": 63040
    },
    {
      "epoch": 63.05,
      "learning_rate": 4.942671061462699e-05,
      "loss": 0.2336,
      "step": 63050
    },
    {
      "epoch": 63.06,
      "learning_rate": 4.940339631389545e-05,
      "loss": 0.2867,
      "step": 63060
    },
    {
      "epoch": 63.07,
      "learning_rate": 4.938008481237005e-05,
      "loss": 0.3992,
      "step": 63070
    },
    {
      "epoch": 63.08,
      "learning_rate": 4.935677611260005e-05,
      "loss": 0.2413,
      "step": 63080
    },
    {
      "epoch": 63.09,
      "learning_rate": 4.9333470217134466e-05,
      "loss": 0.2719,
      "step": 63090
    },
    {
      "epoch": 63.1,
      "learning_rate": 4.931016712852198e-05,
      "loss": 0.2894,
      "step": 63100
    },
    {
      "epoch": 63.11,
      "learning_rate": 4.9286866849311e-05,
      "loss": 0.277,
      "step": 63110
    },
    {
      "epoch": 63.12,
      "learning_rate": 4.926356938204958e-05,
      "loss": 0.2881,
      "step": 63120
    },
    {
      "epoch": 63.13,
      "learning_rate": 4.9240274729285534e-05,
      "loss": 0.2112,
      "step": 63130
    },
    {
      "epoch": 63.14,
      "learning_rate": 4.921698289356631e-05,
      "loss": 0.2526,
      "step": 63140
    },
    {
      "epoch": 63.15,
      "learning_rate": 4.919369387743909e-05,
      "loss": 0.3491,
      "step": 63150
    },
    {
      "epoch": 63.16,
      "learning_rate": 4.9170407683450684e-05,
      "loss": 0.3132,
      "step": 63160
    },
    {
      "epoch": 63.17,
      "learning_rate": 4.9147124314147676e-05,
      "loss": 0.2084,
      "step": 63170
    },
    {
      "epoch": 63.18,
      "learning_rate": 4.912384377207629e-05,
      "loss": 0.2841,
      "step": 63180
    },
    {
      "epoch": 63.19,
      "learning_rate": 4.9100566059782416e-05,
      "loss": 0.2386,
      "step": 63190
    },
    {
      "epoch": 63.2,
      "learning_rate": 4.907729117981171e-05,
      "loss": 0.2344,
      "step": 63200
    },
    {
      "epoch": 63.21,
      "learning_rate": 4.905401913470948e-05,
      "loss": 0.2918,
      "step": 63210
    },
    {
      "epoch": 63.22,
      "learning_rate": 4.90307499270207e-05,
      "loss": 0.3362,
      "step": 63220
    },
    {
      "epoch": 63.23,
      "learning_rate": 4.900748355929007e-05,
      "loss": 0.2313,
      "step": 63230
    },
    {
      "epoch": 63.24,
      "learning_rate": 4.898422003406196e-05,
      "loss": 0.2292,
      "step": 63240
    },
    {
      "epoch": 63.25,
      "learning_rate": 4.89609593538804e-05,
      "loss": 0.2734,
      "step": 63250
    },
    {
      "epoch": 63.26,
      "learning_rate": 4.893770152128921e-05,
      "loss": 0.2861,
      "step": 63260
    },
    {
      "epoch": 63.27,
      "learning_rate": 4.891444653883179e-05,
      "loss": 0.248,
      "step": 63270
    },
    {
      "epoch": 63.28,
      "learning_rate": 4.8891194409051286e-05,
      "loss": 0.2817,
      "step": 63280
    },
    {
      "epoch": 63.29,
      "learning_rate": 4.88679451344905e-05,
      "loss": 0.2787,
      "step": 63290
    },
    {
      "epoch": 63.3,
      "learning_rate": 4.884469871769194e-05,
      "loss": 0.2645,
      "step": 63300
    },
    {
      "epoch": 63.31,
      "learning_rate": 4.882145516119779e-05,
      "loss": 0.3407,
      "step": 63310
    },
    {
      "epoch": 63.32,
      "learning_rate": 4.879821446754997e-05,
      "loss": 0.219,
      "step": 63320
    },
    {
      "epoch": 63.33,
      "learning_rate": 4.877497663929002e-05,
      "loss": 0.2731,
      "step": 63330
    },
    {
      "epoch": 63.34,
      "learning_rate": 4.8751741678959196e-05,
      "loss": 0.2913,
      "step": 63340
    },
    {
      "epoch": 63.35,
      "learning_rate": 4.8728509589098436e-05,
      "loss": 0.3027,
      "step": 63350
    },
    {
      "epoch": 63.36,
      "learning_rate": 4.870528037224837e-05,
      "loss": 0.2743,
      "step": 63360
    },
    {
      "epoch": 63.37,
      "learning_rate": 4.868205403094929e-05,
      "loss": 0.3092,
      "step": 63370
    },
    {
      "epoch": 63.38,
      "learning_rate": 4.865883056774122e-05,
      "loss": 0.2301,
      "step": 63380
    },
    {
      "epoch": 63.39,
      "learning_rate": 4.8635609985163845e-05,
      "loss": 0.2517,
      "step": 63390
    },
    {
      "epoch": 63.4,
      "learning_rate": 4.8612392285756526e-05,
      "loss": 0.2654,
      "step": 63400
    },
    {
      "epoch": 63.41,
      "learning_rate": 4.858917747205831e-05,
      "loss": 0.2037,
      "step": 63410
    },
    {
      "epoch": 63.42,
      "learning_rate": 4.8565965546607945e-05,
      "loss": 0.2032,
      "step": 63420
    },
    {
      "epoch": 63.43,
      "learning_rate": 4.854275651194383e-05,
      "loss": 0.3118,
      "step": 63430
    },
    {
      "epoch": 63.44,
      "learning_rate": 4.8519550370604066e-05,
      "loss": 0.2688,
      "step": 63440
    },
    {
      "epoch": 63.45,
      "learning_rate": 4.84963471251265e-05,
      "loss": 0.2641,
      "step": 63450
    },
    {
      "epoch": 63.46,
      "learning_rate": 4.847314677804855e-05,
      "loss": 0.2484,
      "step": 63460
    },
    {
      "epoch": 63.47,
      "learning_rate": 4.84499493319074e-05,
      "loss": 0.2964,
      "step": 63470
    },
    {
      "epoch": 63.48,
      "learning_rate": 4.842675478923986e-05,
      "loss": 0.3428,
      "step": 63480
    },
    {
      "epoch": 63.49,
      "learning_rate": 4.840356315258247e-05,
      "loss": 0.2479,
      "step": 63490
    },
    {
      "epoch": 63.5,
      "learning_rate": 4.838037442447139e-05,
      "loss": 0.3321,
      "step": 63500
    },
    {
      "epoch": 63.51,
      "learning_rate": 4.835718860744258e-05,
      "loss": 0.2346,
      "step": 63510
    },
    {
      "epoch": 63.52,
      "learning_rate": 4.833400570403157e-05,
      "loss": 0.34,
      "step": 63520
    },
    {
      "epoch": 63.53,
      "learning_rate": 4.831082571677359e-05,
      "loss": 0.3277,
      "step": 63530
    },
    {
      "epoch": 63.54,
      "learning_rate": 4.8287648648203604e-05,
      "loss": 0.3364,
      "step": 63540
    },
    {
      "epoch": 63.55,
      "learning_rate": 4.8264474500856186e-05,
      "loss": 0.2742,
      "step": 63550
    },
    {
      "epoch": 63.56,
      "learning_rate": 4.8241303277265634e-05,
      "loss": 0.2624,
      "step": 63560
    },
    {
      "epoch": 63.57,
      "learning_rate": 4.82181349799659e-05,
      "loss": 0.2608,
      "step": 63570
    },
    {
      "epoch": 63.58,
      "learning_rate": 4.81949696114907e-05,
      "loss": 0.3058,
      "step": 63580
    },
    {
      "epoch": 63.59,
      "learning_rate": 4.817180717437332e-05,
      "loss": 0.3064,
      "step": 63590
    },
    {
      "epoch": 63.6,
      "learning_rate": 4.8148647671146756e-05,
      "loss": 0.281,
      "step": 63600
    },
    {
      "epoch": 63.61,
      "learning_rate": 4.8125491104343726e-05,
      "loss": 0.3203,
      "step": 63610
    },
    {
      "epoch": 63.62,
      "learning_rate": 4.8102337476496565e-05,
      "loss": 0.2916,
      "step": 63620
    },
    {
      "epoch": 63.63,
      "learning_rate": 4.807918679013733e-05,
      "loss": 0.1835,
      "step": 63630
    },
    {
      "epoch": 63.64,
      "learning_rate": 4.805603904779779e-05,
      "loss": 0.2979,
      "step": 63640
    },
    {
      "epoch": 63.65,
      "learning_rate": 4.803289425200927e-05,
      "loss": 0.2916,
      "step": 63650
    },
    {
      "epoch": 63.66,
      "learning_rate": 4.800975240530292e-05,
      "loss": 0.2422,
      "step": 63660
    },
    {
      "epoch": 63.67,
      "learning_rate": 4.7986613510209464e-05,
      "loss": 0.2945,
      "step": 63670
    },
    {
      "epoch": 63.68,
      "learning_rate": 4.7963477569259334e-05,
      "loss": 0.2313,
      "step": 63680
    },
    {
      "epoch": 63.69,
      "learning_rate": 4.794034458498262e-05,
      "loss": 0.2474,
      "step": 63690
    },
    {
      "epoch": 63.7,
      "learning_rate": 4.7917214559909176e-05,
      "loss": 0.242,
      "step": 63700
    },
    {
      "epoch": 63.71,
      "learning_rate": 4.789408749656843e-05,
      "loss": 0.2475,
      "step": 63710
    },
    {
      "epoch": 63.72,
      "learning_rate": 4.787096339748952e-05,
      "loss": 0.2823,
      "step": 63720
    },
    {
      "epoch": 63.73,
      "learning_rate": 4.784784226520125e-05,
      "loss": 0.2693,
      "step": 63730
    },
    {
      "epoch": 63.74,
      "learning_rate": 4.782472410223214e-05,
      "loss": 0.2354,
      "step": 63740
    },
    {
      "epoch": 63.75,
      "learning_rate": 4.780160891111035e-05,
      "loss": 0.3186,
      "step": 63750
    },
    {
      "epoch": 63.76,
      "learning_rate": 4.777849669436369e-05,
      "loss": 0.2821,
      "step": 63760
    },
    {
      "epoch": 63.77,
      "learning_rate": 4.7755387454519714e-05,
      "loss": 0.3051,
      "step": 63770
    },
    {
      "epoch": 63.78,
      "learning_rate": 4.773228119410562e-05,
      "loss": 0.3248,
      "step": 63780
    },
    {
      "epoch": 63.79,
      "learning_rate": 4.770917791564826e-05,
      "loss": 0.2606,
      "step": 63790
    },
    {
      "epoch": 63.8,
      "learning_rate": 4.768607762167417e-05,
      "loss": 0.2988,
      "step": 63800
    },
    {
      "epoch": 63.81,
      "learning_rate": 4.766298031470956e-05,
      "loss": 0.2788,
      "step": 63810
    },
    {
      "epoch": 63.82,
      "learning_rate": 4.76398859972803e-05,
      "loss": 0.2317,
      "step": 63820
    },
    {
      "epoch": 63.83,
      "learning_rate": 4.7616794671911994e-05,
      "loss": 0.2621,
      "step": 63830
    },
    {
      "epoch": 63.84,
      "learning_rate": 4.7593706341129856e-05,
      "loss": 0.2376,
      "step": 63840
    },
    {
      "epoch": 63.85,
      "learning_rate": 4.757062100745878e-05,
      "loss": 0.3249,
      "step": 63850
    },
    {
      "epoch": 63.86,
      "learning_rate": 4.754753867342335e-05,
      "loss": 0.3022,
      "step": 63860
    },
    {
      "epoch": 63.87,
      "learning_rate": 4.7524459341547825e-05,
      "loss": 0.2664,
      "step": 63870
    },
    {
      "epoch": 63.88,
      "learning_rate": 4.7501383014356117e-05,
      "loss": 0.3033,
      "step": 63880
    },
    {
      "epoch": 63.89,
      "learning_rate": 4.7478309694371807e-05,
      "loss": 0.1679,
      "step": 63890
    },
    {
      "epoch": 63.9,
      "learning_rate": 4.745523938411816e-05,
      "loss": 0.3293,
      "step": 63900
    },
    {
      "epoch": 63.91,
      "learning_rate": 4.743217208611815e-05,
      "loss": 0.2558,
      "step": 63910
    },
    {
      "epoch": 63.92,
      "learning_rate": 4.7409107802894344e-05,
      "loss": 0.2438,
      "step": 63920
    },
    {
      "epoch": 63.93,
      "learning_rate": 4.738604653696903e-05,
      "loss": 0.3254,
      "step": 63930
    },
    {
      "epoch": 63.94,
      "learning_rate": 4.736298829086415e-05,
      "loss": 0.2919,
      "step": 63940
    },
    {
      "epoch": 63.95,
      "learning_rate": 4.733993306710129e-05,
      "loss": 0.3127,
      "step": 63950
    },
    {
      "epoch": 63.96,
      "learning_rate": 4.731688086820179e-05,
      "loss": 0.2486,
      "step": 63960
    },
    {
      "epoch": 63.97,
      "learning_rate": 4.7293831696686574e-05,
      "loss": 0.2223,
      "step": 63970
    },
    {
      "epoch": 63.98,
      "learning_rate": 4.7270785555076276e-05,
      "loss": 0.2304,
      "step": 63980
    },
    {
      "epoch": 63.99,
      "learning_rate": 4.724774244589119e-05,
      "loss": 0.2345,
      "step": 63990
    },
    {
      "epoch": 64.0,
      "learning_rate": 4.722470237165124e-05,
      "loss": 0.2591,
      "step": 64000
    },
    {
      "epoch": 64.0,
      "eval_accuracy": 0.801,
      "eval_loss": 0.30743321776390076,
      "eval_runtime": 14.9203,
      "eval_samples_per_second": 134.046,
      "eval_steps_per_second": 16.756,
      "step": 64000
    },
    {
      "epoch": 64.01,
      "learning_rate": 4.720166533487606e-05,
      "loss": 0.3398,
      "step": 64010
    },
    {
      "epoch": 64.02,
      "learning_rate": 4.7178631338084996e-05,
      "loss": 0.3178,
      "step": 64020
    },
    {
      "epoch": 64.03,
      "learning_rate": 4.715560038379698e-05,
      "loss": 0.3002,
      "step": 64030
    },
    {
      "epoch": 64.04,
      "learning_rate": 4.7132572474530646e-05,
      "loss": 0.3288,
      "step": 64040
    },
    {
      "epoch": 64.05,
      "learning_rate": 4.7109547612804284e-05,
      "loss": 0.317,
      "step": 64050
    },
    {
      "epoch": 64.06,
      "learning_rate": 4.708652580113586e-05,
      "loss": 0.2451,
      "step": 64060
    },
    {
      "epoch": 64.07,
      "learning_rate": 4.7063507042042995e-05,
      "loss": 0.2301,
      "step": 64070
    },
    {
      "epoch": 64.08,
      "learning_rate": 4.7040491338042996e-05,
      "loss": 0.2085,
      "step": 64080
    },
    {
      "epoch": 64.09,
      "learning_rate": 4.7017478691652845e-05,
      "loss": 0.2875,
      "step": 64090
    },
    {
      "epoch": 64.1,
      "learning_rate": 4.699446910538916e-05,
      "loss": 0.2548,
      "step": 64100
    },
    {
      "epoch": 64.11,
      "learning_rate": 4.69714625817682e-05,
      "loss": 0.244,
      "step": 64110
    },
    {
      "epoch": 64.12,
      "learning_rate": 4.6948459123305975e-05,
      "loss": 0.2915,
      "step": 64120
    },
    {
      "epoch": 64.13,
      "learning_rate": 4.692545873251808e-05,
      "loss": 0.2039,
      "step": 64130
    },
    {
      "epoch": 64.14,
      "learning_rate": 4.690246141191979e-05,
      "loss": 0.2777,
      "step": 64140
    },
    {
      "epoch": 64.15,
      "learning_rate": 4.687946716402609e-05,
      "loss": 0.2944,
      "step": 64150
    },
    {
      "epoch": 64.16,
      "learning_rate": 4.6856475991351586e-05,
      "loss": 0.3431,
      "step": 64160
    },
    {
      "epoch": 64.17,
      "learning_rate": 4.683348789641056e-05,
      "loss": 0.27,
      "step": 64170
    },
    {
      "epoch": 64.18,
      "learning_rate": 4.6810502881716955e-05,
      "loss": 0.2346,
      "step": 64180
    },
    {
      "epoch": 64.19,
      "learning_rate": 4.678752094978436e-05,
      "loss": 0.2806,
      "step": 64190
    },
    {
      "epoch": 64.2,
      "learning_rate": 4.676454210312604e-05,
      "loss": 0.3403,
      "step": 64200
    },
    {
      "epoch": 64.21,
      "learning_rate": 4.674156634425496e-05,
      "loss": 0.289,
      "step": 64210
    },
    {
      "epoch": 64.22,
      "learning_rate": 4.6718593675683716e-05,
      "loss": 0.2967,
      "step": 64220
    },
    {
      "epoch": 64.23,
      "learning_rate": 4.669562409992453e-05,
      "loss": 0.2651,
      "step": 64230
    },
    {
      "epoch": 64.24,
      "learning_rate": 4.6672657619489344e-05,
      "loss": 0.2238,
      "step": 64240
    },
    {
      "epoch": 64.25,
      "learning_rate": 4.664969423688973e-05,
      "loss": 0.2526,
      "step": 64250
    },
    {
      "epoch": 64.26,
      "learning_rate": 4.662673395463693e-05,
      "loss": 0.2686,
      "step": 64260
    },
    {
      "epoch": 64.27,
      "learning_rate": 4.6603776775241826e-05,
      "loss": 0.2538,
      "step": 64270
    },
    {
      "epoch": 64.28,
      "learning_rate": 4.658082270121501e-05,
      "loss": 0.2958,
      "step": 64280
    },
    {
      "epoch": 64.29,
      "learning_rate": 4.6557871735066716e-05,
      "loss": 0.1964,
      "step": 64290
    },
    {
      "epoch": 64.3,
      "learning_rate": 4.6534923879306803e-05,
      "loss": 0.2448,
      "step": 64300
    },
    {
      "epoch": 64.31,
      "learning_rate": 4.651197913644482e-05,
      "loss": 0.2397,
      "step": 64310
    },
    {
      "epoch": 64.32,
      "learning_rate": 4.6489037508989934e-05,
      "loss": 0.309,
      "step": 64320
    },
    {
      "epoch": 64.33,
      "learning_rate": 4.646609899945106e-05,
      "loss": 0.2691,
      "step": 64330
    },
    {
      "epoch": 64.34,
      "learning_rate": 4.644316361033671e-05,
      "loss": 0.295,
      "step": 64340
    },
    {
      "epoch": 64.35,
      "learning_rate": 4.642023134415505e-05,
      "loss": 0.1926,
      "step": 64350
    },
    {
      "epoch": 64.36,
      "learning_rate": 4.639730220341391e-05,
      "loss": 0.3259,
      "step": 64360
    },
    {
      "epoch": 64.37,
      "learning_rate": 4.6374376190620796e-05,
      "loss": 0.2523,
      "step": 64370
    },
    {
      "epoch": 64.38,
      "learning_rate": 4.635145330828289e-05,
      "loss": 0.2887,
      "step": 64380
    },
    {
      "epoch": 64.39,
      "learning_rate": 4.6328533558906964e-05,
      "loss": 0.247,
      "step": 64390
    },
    {
      "epoch": 64.4,
      "learning_rate": 4.630561694499946e-05,
      "loss": 0.2249,
      "step": 64400
    },
    {
      "epoch": 64.41,
      "learning_rate": 4.628270346906659e-05,
      "loss": 0.2576,
      "step": 64410
    },
    {
      "epoch": 64.42,
      "learning_rate": 4.6259793133614096e-05,
      "loss": 0.2442,
      "step": 64420
    },
    {
      "epoch": 64.43,
      "learning_rate": 4.623688594114741e-05,
      "loss": 0.2946,
      "step": 64430
    },
    {
      "epoch": 64.44,
      "learning_rate": 4.621398189417163e-05,
      "loss": 0.3074,
      "step": 64440
    },
    {
      "epoch": 64.45,
      "learning_rate": 4.6191080995191516e-05,
      "loss": 0.2651,
      "step": 64450
    },
    {
      "epoch": 64.46,
      "learning_rate": 4.6168183246711434e-05,
      "loss": 0.3134,
      "step": 64460
    },
    {
      "epoch": 64.47,
      "learning_rate": 4.614528865123552e-05,
      "loss": 0.2888,
      "step": 64470
    },
    {
      "epoch": 64.48,
      "learning_rate": 4.6122397211267455e-05,
      "loss": 0.2971,
      "step": 64480
    },
    {
      "epoch": 64.49,
      "learning_rate": 4.609950892931062e-05,
      "loss": 0.2569,
      "step": 64490
    },
    {
      "epoch": 64.5,
      "learning_rate": 4.6076623807868016e-05,
      "loss": 0.27,
      "step": 64500
    },
    {
      "epoch": 64.51,
      "learning_rate": 4.6053741849442364e-05,
      "loss": 0.2596,
      "step": 64510
    },
    {
      "epoch": 64.52,
      "learning_rate": 4.603086305653596e-05,
      "loss": 0.2257,
      "step": 64520
    },
    {
      "epoch": 64.53,
      "learning_rate": 4.600798743165083e-05,
      "loss": 0.2629,
      "step": 64530
    },
    {
      "epoch": 64.54,
      "learning_rate": 4.5985114977288616e-05,
      "loss": 0.3003,
      "step": 64540
    },
    {
      "epoch": 64.55,
      "learning_rate": 4.596224569595061e-05,
      "loss": 0.3219,
      "step": 64550
    },
    {
      "epoch": 64.56,
      "learning_rate": 4.5939379590137746e-05,
      "loss": 0.1898,
      "step": 64560
    },
    {
      "epoch": 64.57,
      "learning_rate": 4.591651666235063e-05,
      "loss": 0.2726,
      "step": 64570
    },
    {
      "epoch": 64.58,
      "learning_rate": 4.5893656915089534e-05,
      "loss": 0.2365,
      "step": 64580
    },
    {
      "epoch": 64.59,
      "learning_rate": 4.587080035085435e-05,
      "loss": 0.2949,
      "step": 64590
    },
    {
      "epoch": 64.6,
      "learning_rate": 4.584794697214466e-05,
      "loss": 0.2717,
      "step": 64600
    },
    {
      "epoch": 64.61,
      "learning_rate": 4.582509678145963e-05,
      "loss": 0.2337,
      "step": 64610
    },
    {
      "epoch": 64.62,
      "learning_rate": 4.580224978129817e-05,
      "loss": 0.2347,
      "step": 64620
    },
    {
      "epoch": 64.63,
      "learning_rate": 4.5779405974158794e-05,
      "loss": 0.1423,
      "step": 64630
    },
    {
      "epoch": 64.64,
      "learning_rate": 4.5756565362539635e-05,
      "loss": 0.3605,
      "step": 64640
    },
    {
      "epoch": 64.65,
      "learning_rate": 4.5733727948938484e-05,
      "loss": 0.2593,
      "step": 64650
    },
    {
      "epoch": 64.66,
      "learning_rate": 4.571089373585289e-05,
      "loss": 0.3074,
      "step": 64660
    },
    {
      "epoch": 64.67,
      "learning_rate": 4.568806272577992e-05,
      "loss": 0.2407,
      "step": 64670
    },
    {
      "epoch": 64.68,
      "learning_rate": 4.566523492121633e-05,
      "loss": 0.2424,
      "step": 64680
    },
    {
      "epoch": 64.69,
      "learning_rate": 4.564241032465854e-05,
      "loss": 0.2273,
      "step": 64690
    },
    {
      "epoch": 64.7,
      "learning_rate": 4.561958893860263e-05,
      "loss": 0.2788,
      "step": 64700
    },
    {
      "epoch": 64.71,
      "learning_rate": 4.559677076554427e-05,
      "loss": 0.2751,
      "step": 64710
    },
    {
      "epoch": 64.72,
      "learning_rate": 4.557395580797889e-05,
      "loss": 0.2986,
      "step": 64720
    },
    {
      "epoch": 64.73,
      "learning_rate": 4.555114406840144e-05,
      "loss": 0.3431,
      "step": 64730
    },
    {
      "epoch": 64.74,
      "learning_rate": 4.5528335549306624e-05,
      "loss": 0.2936,
      "step": 64740
    },
    {
      "epoch": 64.75,
      "learning_rate": 4.550553025318871e-05,
      "loss": 0.3118,
      "step": 64750
    },
    {
      "epoch": 64.76,
      "learning_rate": 4.548272818254166e-05,
      "loss": 0.367,
      "step": 64760
    },
    {
      "epoch": 64.77,
      "learning_rate": 4.545992933985908e-05,
      "loss": 0.2888,
      "step": 64770
    },
    {
      "epoch": 64.78,
      "learning_rate": 4.543713372763418e-05,
      "loss": 0.2704,
      "step": 64780
    },
    {
      "epoch": 64.79,
      "learning_rate": 4.541434134835992e-05,
      "loss": 0.3157,
      "step": 64790
    },
    {
      "epoch": 64.8,
      "learning_rate": 4.539155220452882e-05,
      "loss": 0.2912,
      "step": 64800
    },
    {
      "epoch": 64.81,
      "learning_rate": 4.5368766298633045e-05,
      "loss": 0.3746,
      "step": 64810
    },
    {
      "epoch": 64.82,
      "learning_rate": 4.5345983633164415e-05,
      "loss": 0.2128,
      "step": 64820
    },
    {
      "epoch": 64.83,
      "learning_rate": 4.5323204210614455e-05,
      "loss": 0.2506,
      "step": 64830
    },
    {
      "epoch": 64.84,
      "learning_rate": 4.530042803347425e-05,
      "loss": 0.2221,
      "step": 64840
    },
    {
      "epoch": 64.85,
      "learning_rate": 4.5277655104234606e-05,
      "loss": 0.1983,
      "step": 64850
    },
    {
      "epoch": 64.86,
      "learning_rate": 4.525488542538589e-05,
      "loss": 0.2871,
      "step": 64860
    },
    {
      "epoch": 64.87,
      "learning_rate": 4.523211899941819e-05,
      "loss": 0.2538,
      "step": 64870
    },
    {
      "epoch": 64.88,
      "learning_rate": 4.5209355828821215e-05,
      "loss": 0.2157,
      "step": 64880
    },
    {
      "epoch": 64.89,
      "learning_rate": 4.5186595916084284e-05,
      "loss": 0.2736,
      "step": 64890
    },
    {
      "epoch": 64.9,
      "learning_rate": 4.5163839263696376e-05,
      "loss": 0.2427,
      "step": 64900
    },
    {
      "epoch": 64.91,
      "learning_rate": 4.514108587414617e-05,
      "loss": 0.2878,
      "step": 64910
    },
    {
      "epoch": 64.92,
      "learning_rate": 4.511833574992194e-05,
      "loss": 0.2378,
      "step": 64920
    },
    {
      "epoch": 64.93,
      "learning_rate": 4.5095588893511566e-05,
      "loss": 0.2593,
      "step": 64930
    },
    {
      "epoch": 64.94,
      "learning_rate": 4.507284530740264e-05,
      "loss": 0.2592,
      "step": 64940
    },
    {
      "epoch": 64.95,
      "learning_rate": 4.505010499408236e-05,
      "loss": 0.226,
      "step": 64950
    },
    {
      "epoch": 64.96,
      "learning_rate": 4.502736795603756e-05,
      "loss": 0.2679,
      "step": 64960
    },
    {
      "epoch": 64.97,
      "learning_rate": 4.500463419575471e-05,
      "loss": 0.1791,
      "step": 64970
    },
    {
      "epoch": 64.98,
      "learning_rate": 4.498190371572e-05,
      "loss": 0.3177,
      "step": 64980
    },
    {
      "epoch": 64.99,
      "learning_rate": 4.4959176518419166e-05,
      "loss": 0.2465,
      "step": 64990
    },
    {
      "epoch": 65.0,
      "learning_rate": 4.493645260633763e-05,
      "loss": 0.2436,
      "step": 65000
    },
    {
      "epoch": 65.0,
      "eval_accuracy": 0.795,
      "eval_loss": 0.2901622951030731,
      "eval_runtime": 14.8201,
      "eval_samples_per_second": 134.952,
      "eval_steps_per_second": 16.869,
      "step": 65000
    },
    {
      "epoch": 65.01,
      "learning_rate": 4.491373198196042e-05,
      "loss": 0.301,
      "step": 65010
    },
    {
      "epoch": 65.02,
      "learning_rate": 4.489101464777225e-05,
      "loss": 0.2838,
      "step": 65020
    },
    {
      "epoch": 65.03,
      "learning_rate": 4.486830060625742e-05,
      "loss": 0.271,
      "step": 65030
    },
    {
      "epoch": 65.04,
      "learning_rate": 4.484558985989998e-05,
      "loss": 0.2062,
      "step": 65040
    },
    {
      "epoch": 65.05,
      "learning_rate": 4.482288241118348e-05,
      "loss": 0.3004,
      "step": 65050
    },
    {
      "epoch": 65.06,
      "learning_rate": 4.4800178262591196e-05,
      "loss": 0.255,
      "step": 65060
    },
    {
      "epoch": 65.07,
      "learning_rate": 4.4777477416606e-05,
      "loss": 0.3531,
      "step": 65070
    },
    {
      "epoch": 65.08,
      "learning_rate": 4.4754779875710443e-05,
      "loss": 0.2273,
      "step": 65080
    },
    {
      "epoch": 65.09,
      "learning_rate": 4.473208564238669e-05,
      "loss": 0.2287,
      "step": 65090
    },
    {
      "epoch": 65.1,
      "learning_rate": 4.470939471911652e-05,
      "loss": 0.2868,
      "step": 65100
    },
    {
      "epoch": 65.11,
      "learning_rate": 4.468670710838141e-05,
      "loss": 0.3108,
      "step": 65110
    },
    {
      "epoch": 65.12,
      "learning_rate": 4.466402281266245e-05,
      "loss": 0.2703,
      "step": 65120
    },
    {
      "epoch": 65.13,
      "learning_rate": 4.4641341834440354e-05,
      "loss": 0.2523,
      "step": 65130
    },
    {
      "epoch": 65.14,
      "learning_rate": 4.461866417619546e-05,
      "loss": 0.2948,
      "step": 65140
    },
    {
      "epoch": 65.15,
      "learning_rate": 4.459598984040777e-05,
      "loss": 0.1872,
      "step": 65150
    },
    {
      "epoch": 65.16,
      "learning_rate": 4.45733188295569e-05,
      "loss": 0.2032,
      "step": 65160
    },
    {
      "epoch": 65.17,
      "learning_rate": 4.4550651146122155e-05,
      "loss": 0.2739,
      "step": 65170
    },
    {
      "epoch": 65.18,
      "learning_rate": 4.452798679258243e-05,
      "loss": 0.3117,
      "step": 65180
    },
    {
      "epoch": 65.19,
      "learning_rate": 4.450532577141627e-05,
      "loss": 0.3575,
      "step": 65190
    },
    {
      "epoch": 65.2,
      "learning_rate": 4.448266808510181e-05,
      "loss": 0.2215,
      "step": 65200
    },
    {
      "epoch": 65.21,
      "learning_rate": 4.44600137361169e-05,
      "loss": 0.2587,
      "step": 65210
    },
    {
      "epoch": 65.22,
      "learning_rate": 4.443736272693893e-05,
      "loss": 0.2468,
      "step": 65220
    },
    {
      "epoch": 65.23,
      "learning_rate": 4.441471506004507e-05,
      "loss": 0.2668,
      "step": 65230
    },
    {
      "epoch": 65.24,
      "learning_rate": 4.439207073791197e-05,
      "loss": 0.3044,
      "step": 65240
    },
    {
      "epoch": 65.25,
      "learning_rate": 4.436942976301601e-05,
      "loss": 0.2745,
      "step": 65250
    },
    {
      "epoch": 65.26,
      "learning_rate": 4.4346792137833143e-05,
      "loss": 0.1606,
      "step": 65260
    },
    {
      "epoch": 65.27,
      "learning_rate": 4.4324157864839003e-05,
      "loss": 0.3203,
      "step": 65270
    },
    {
      "epoch": 65.28,
      "learning_rate": 4.430152694650883e-05,
      "loss": 0.184,
      "step": 65280
    },
    {
      "epoch": 65.29,
      "learning_rate": 4.427889938531752e-05,
      "loss": 0.271,
      "step": 65290
    },
    {
      "epoch": 65.3,
      "learning_rate": 4.4256275183739597e-05,
      "loss": 0.2588,
      "step": 65300
    },
    {
      "epoch": 65.31,
      "learning_rate": 4.423365434424919e-05,
      "loss": 0.2748,
      "step": 65310
    },
    {
      "epoch": 65.32,
      "learning_rate": 4.421103686932008e-05,
      "loss": 0.2373,
      "step": 65320
    },
    {
      "epoch": 65.33,
      "learning_rate": 4.41884227614257e-05,
      "loss": 0.2105,
      "step": 65330
    },
    {
      "epoch": 65.34,
      "learning_rate": 4.416581202303909e-05,
      "loss": 0.1467,
      "step": 65340
    },
    {
      "epoch": 65.35,
      "learning_rate": 4.414320465663289e-05,
      "loss": 0.2071,
      "step": 65350
    },
    {
      "epoch": 65.36,
      "learning_rate": 4.4120600664679445e-05,
      "loss": 0.2722,
      "step": 65360
    },
    {
      "epoch": 65.37,
      "learning_rate": 4.409800004965069e-05,
      "loss": 0.2735,
      "step": 65370
    },
    {
      "epoch": 65.38,
      "learning_rate": 4.40754028140182e-05,
      "loss": 0.2685,
      "step": 65380
    },
    {
      "epoch": 65.39,
      "learning_rate": 4.4052808960253166e-05,
      "loss": 0.2934,
      "step": 65390
    },
    {
      "epoch": 65.4,
      "learning_rate": 4.403021849082641e-05,
      "loss": 0.3361,
      "step": 65400
    },
    {
      "epoch": 65.41,
      "learning_rate": 4.400763140820836e-05,
      "loss": 0.2385,
      "step": 65410
    },
    {
      "epoch": 65.42,
      "learning_rate": 4.3985047714869185e-05,
      "loss": 0.213,
      "step": 65420
    },
    {
      "epoch": 65.43,
      "learning_rate": 4.396246741327856e-05,
      "loss": 0.2755,
      "step": 65430
    },
    {
      "epoch": 65.44,
      "learning_rate": 4.3939890505905825e-05,
      "loss": 0.2676,
      "step": 65440
    },
    {
      "epoch": 65.45,
      "learning_rate": 4.3917316995219977e-05,
      "loss": 0.2984,
      "step": 65450
    },
    {
      "epoch": 65.46,
      "learning_rate": 4.3894746883689597e-05,
      "loss": 0.2714,
      "step": 65460
    },
    {
      "epoch": 65.47,
      "learning_rate": 4.3874436691630204e-05,
      "loss": 0.3792,
      "step": 65470
    },
    {
      "epoch": 65.48,
      "learning_rate": 4.385187304529493e-05,
      "loss": 0.2586,
      "step": 65480
    },
    {
      "epoch": 65.49,
      "learning_rate": 4.382931280527194e-05,
      "loss": 0.2086,
      "step": 65490
    },
    {
      "epoch": 65.5,
      "learning_rate": 4.380675597402849e-05,
      "loss": 0.2501,
      "step": 65500
    },
    {
      "epoch": 65.51,
      "learning_rate": 4.378420255403128e-05,
      "loss": 0.2069,
      "step": 65510
    },
    {
      "epoch": 65.52,
      "learning_rate": 4.376165254774678e-05,
      "loss": 0.3185,
      "step": 65520
    },
    {
      "epoch": 65.53,
      "learning_rate": 4.373910595764095e-05,
      "loss": 0.2568,
      "step": 65530
    },
    {
      "epoch": 65.54,
      "learning_rate": 4.371656278617954e-05,
      "loss": 0.2349,
      "step": 65540
    },
    {
      "epoch": 65.55,
      "learning_rate": 4.369402303582772e-05,
      "loss": 0.2831,
      "step": 65550
    },
    {
      "epoch": 65.56,
      "learning_rate": 4.367148670905053e-05,
      "loss": 0.2367,
      "step": 65560
    },
    {
      "epoch": 65.57,
      "learning_rate": 4.3648953808312435e-05,
      "loss": 0.2968,
      "step": 65570
    },
    {
      "epoch": 65.58,
      "learning_rate": 4.3626424336077634e-05,
      "loss": 0.2324,
      "step": 65580
    },
    {
      "epoch": 65.59,
      "learning_rate": 4.360389829480987e-05,
      "loss": 0.3354,
      "step": 65590
    },
    {
      "epoch": 65.6,
      "learning_rate": 4.358137568697262e-05,
      "loss": 0.2395,
      "step": 65600
    },
    {
      "epoch": 65.61,
      "learning_rate": 4.355885651502882e-05,
      "loss": 0.2222,
      "step": 65610
    },
    {
      "epoch": 65.62,
      "learning_rate": 4.353634078144127e-05,
      "loss": 0.3025,
      "step": 65620
    },
    {
      "epoch": 65.63,
      "learning_rate": 4.351382848867215e-05,
      "loss": 0.2958,
      "step": 65630
    },
    {
      "epoch": 65.64,
      "learning_rate": 4.349131963918345e-05,
      "loss": 0.226,
      "step": 65640
    },
    {
      "epoch": 65.65,
      "learning_rate": 4.3468814235436614e-05,
      "loss": 0.2242,
      "step": 65650
    },
    {
      "epoch": 65.66,
      "learning_rate": 4.3446312279892893e-05,
      "loss": 0.2988,
      "step": 65660
    },
    {
      "epoch": 65.67,
      "learning_rate": 4.342381377501297e-05,
      "loss": 0.2461,
      "step": 65670
    },
    {
      "epoch": 65.68,
      "learning_rate": 4.340131872325732e-05,
      "loss": 0.2425,
      "step": 65680
    },
    {
      "epoch": 65.69,
      "learning_rate": 4.337882712708594e-05,
      "loss": 0.2644,
      "step": 65690
    },
    {
      "epoch": 65.7,
      "learning_rate": 4.335633898895851e-05,
      "loss": 0.1961,
      "step": 65700
    },
    {
      "epoch": 65.71,
      "learning_rate": 4.333385431133424e-05,
      "loss": 0.2591,
      "step": 65710
    },
    {
      "epoch": 65.72,
      "learning_rate": 4.331137309667206e-05,
      "loss": 0.3115,
      "step": 65720
    },
    {
      "epoch": 65.73,
      "learning_rate": 4.328889534743051e-05,
      "loss": 0.2614,
      "step": 65730
    },
    {
      "epoch": 65.74,
      "learning_rate": 4.326642106606765e-05,
      "loss": 0.2751,
      "step": 65740
    },
    {
      "epoch": 65.75,
      "learning_rate": 4.3243950255041266e-05,
      "loss": 0.2265,
      "step": 65750
    },
    {
      "epoch": 65.76,
      "learning_rate": 4.322148291680874e-05,
      "loss": 0.2755,
      "step": 65760
    },
    {
      "epoch": 65.77,
      "learning_rate": 4.31990190538271e-05,
      "loss": 0.2463,
      "step": 65770
    },
    {
      "epoch": 65.78,
      "learning_rate": 4.317655866855289e-05,
      "loss": 0.1856,
      "step": 65780
    },
    {
      "epoch": 65.79,
      "learning_rate": 4.315410176344241e-05,
      "loss": 0.2922,
      "step": 65790
    },
    {
      "epoch": 65.8,
      "learning_rate": 4.3131648340951426e-05,
      "loss": 0.2436,
      "step": 65800
    },
    {
      "epoch": 65.81,
      "learning_rate": 4.3109198403535514e-05,
      "loss": 0.2557,
      "step": 65810
    },
    {
      "epoch": 65.82,
      "learning_rate": 4.3086751953649704e-05,
      "loss": 0.2136,
      "step": 65820
    },
    {
      "epoch": 65.83,
      "learning_rate": 4.306430899374873e-05,
      "loss": 0.2537,
      "step": 65830
    },
    {
      "epoch": 65.84,
      "learning_rate": 4.304186952628689e-05,
      "loss": 0.2858,
      "step": 65840
    },
    {
      "epoch": 65.85,
      "learning_rate": 4.3019433553718184e-05,
      "loss": 0.2803,
      "step": 65850
    },
    {
      "epoch": 65.86,
      "learning_rate": 4.2997001078496106e-05,
      "loss": 0.2307,
      "step": 65860
    },
    {
      "epoch": 65.87,
      "learning_rate": 4.297457210307388e-05,
      "loss": 0.2378,
      "step": 65870
    },
    {
      "epoch": 65.88,
      "learning_rate": 4.2952146629904295e-05,
      "loss": 0.3367,
      "step": 65880
    },
    {
      "epoch": 65.89,
      "learning_rate": 4.29297246614398e-05,
      "loss": 0.2897,
      "step": 65890
    },
    {
      "epoch": 65.9,
      "learning_rate": 4.290730620013237e-05,
      "loss": 0.2725,
      "step": 65900
    },
    {
      "epoch": 65.91,
      "learning_rate": 4.2884891248433715e-05,
      "loss": 0.2992,
      "step": 65910
    },
    {
      "epoch": 65.92,
      "learning_rate": 4.286247980879505e-05,
      "loss": 0.271,
      "step": 65920
    },
    {
      "epoch": 65.93,
      "learning_rate": 4.284007188366726e-05,
      "loss": 0.2734,
      "step": 65930
    },
    {
      "epoch": 65.94,
      "learning_rate": 4.281766747550086e-05,
      "loss": 0.3135,
      "step": 65940
    },
    {
      "epoch": 65.95,
      "learning_rate": 4.279526658674599e-05,
      "loss": 0.1988,
      "step": 65950
    },
    {
      "epoch": 65.96,
      "learning_rate": 4.277286921985231e-05,
      "loss": 0.2707,
      "step": 65960
    },
    {
      "epoch": 65.97,
      "learning_rate": 4.275047537726921e-05,
      "loss": 0.3142,
      "step": 65970
    },
    {
      "epoch": 65.98,
      "learning_rate": 4.272808506144566e-05,
      "loss": 0.3305,
      "step": 65980
    },
    {
      "epoch": 65.99,
      "learning_rate": 4.2705698274830155e-05,
      "loss": 0.1708,
      "step": 65990
    },
    {
      "epoch": 66.0,
      "learning_rate": 4.2683315019870986e-05,
      "loss": 0.2584,
      "step": 66000
    },
    {
      "epoch": 66.0,
      "eval_accuracy": 0.795,
      "eval_loss": 0.32459551095962524,
      "eval_runtime": 15.0425,
      "eval_samples_per_second": 132.956,
      "eval_steps_per_second": 16.62,
      "step": 66000
    },
    {
      "epoch": 66.01,
      "learning_rate": 4.266093529901587e-05,
      "loss": 0.2244,
      "step": 66010
    },
    {
      "epoch": 66.02,
      "learning_rate": 4.263855911471228e-05,
      "loss": 0.2495,
      "step": 66020
    },
    {
      "epoch": 66.03,
      "learning_rate": 4.261618646940719e-05,
      "loss": 0.3225,
      "step": 66030
    },
    {
      "epoch": 66.04,
      "learning_rate": 4.2593817365547265e-05,
      "loss": 0.3877,
      "step": 66040
    },
    {
      "epoch": 66.05,
      "learning_rate": 4.2571451805578745e-05,
      "loss": 0.2117,
      "step": 66050
    },
    {
      "epoch": 66.06,
      "learning_rate": 4.254908979194749e-05,
      "loss": 0.2417,
      "step": 66060
    },
    {
      "epoch": 66.07,
      "learning_rate": 4.252673132709899e-05,
      "loss": 0.2363,
      "step": 66070
    },
    {
      "epoch": 66.08,
      "learning_rate": 4.250437641347836e-05,
      "loss": 0.2851,
      "step": 66080
    },
    {
      "epoch": 66.09,
      "learning_rate": 4.2482025053530225e-05,
      "loss": 0.2452,
      "step": 66090
    },
    {
      "epoch": 66.1,
      "learning_rate": 4.2459677249698984e-05,
      "loss": 0.1771,
      "step": 66100
    },
    {
      "epoch": 66.11,
      "learning_rate": 4.243733300442848e-05,
      "loss": 0.235,
      "step": 66110
    },
    {
      "epoch": 66.12,
      "learning_rate": 4.241499232016229e-05,
      "loss": 0.224,
      "step": 66120
    },
    {
      "epoch": 66.13,
      "learning_rate": 4.2392655199343534e-05,
      "loss": 0.2394,
      "step": 66130
    },
    {
      "epoch": 66.14,
      "learning_rate": 4.237032164441502e-05,
      "loss": 0.2623,
      "step": 66140
    },
    {
      "epoch": 66.15,
      "learning_rate": 4.2347991657819045e-05,
      "loss": 0.317,
      "step": 66150
    },
    {
      "epoch": 66.16,
      "learning_rate": 4.2325665241997636e-05,
      "loss": 0.2147,
      "step": 66160
    },
    {
      "epoch": 66.17,
      "learning_rate": 4.2303342399392325e-05,
      "loss": 0.2693,
      "step": 66170
    },
    {
      "epoch": 66.18,
      "learning_rate": 4.228102313244432e-05,
      "loss": 0.2273,
      "step": 66180
    },
    {
      "epoch": 66.19,
      "learning_rate": 4.225870744359445e-05,
      "loss": 0.2381,
      "step": 66190
    },
    {
      "epoch": 66.2,
      "learning_rate": 4.223639533528309e-05,
      "loss": 0.2944,
      "step": 66200
    },
    {
      "epoch": 66.21,
      "learning_rate": 4.221408680995032e-05,
      "loss": 0.2291,
      "step": 66210
    },
    {
      "epoch": 66.22,
      "learning_rate": 4.219178187003569e-05,
      "loss": 0.2113,
      "step": 66220
    },
    {
      "epoch": 66.23,
      "learning_rate": 4.21694805179785e-05,
      "loss": 0.241,
      "step": 66230
    },
    {
      "epoch": 66.24,
      "learning_rate": 4.214718275621752e-05,
      "loss": 0.3124,
      "step": 66240
    },
    {
      "epoch": 66.25,
      "learning_rate": 4.212488858719126e-05,
      "loss": 0.231,
      "step": 66250
    },
    {
      "epoch": 66.26,
      "learning_rate": 4.210259801333774e-05,
      "loss": 0.257,
      "step": 66260
    },
    {
      "epoch": 66.27,
      "learning_rate": 4.208031103709468e-05,
      "loss": 0.3097,
      "step": 66270
    },
    {
      "epoch": 66.28,
      "learning_rate": 4.2058027660899277e-05,
      "loss": 0.3027,
      "step": 66280
    },
    {
      "epoch": 66.29,
      "learning_rate": 4.203574788718848e-05,
      "loss": 0.2164,
      "step": 66290
    },
    {
      "epoch": 66.3,
      "learning_rate": 4.2013471718398696e-05,
      "loss": 0.2869,
      "step": 66300
    },
    {
      "epoch": 66.31,
      "learning_rate": 4.199119915696604e-05,
      "loss": 0.3065,
      "step": 66310
    },
    {
      "epoch": 66.32,
      "learning_rate": 4.196893020532622e-05,
      "loss": 0.2357,
      "step": 66320
    },
    {
      "epoch": 66.33,
      "learning_rate": 4.194666486591457e-05,
      "loss": 0.2264,
      "step": 66330
    },
    {
      "epoch": 66.34,
      "learning_rate": 4.1924403141165924e-05,
      "loss": 0.3372,
      "step": 66340
    },
    {
      "epoch": 66.35,
      "learning_rate": 4.1902145033514854e-05,
      "loss": 0.2473,
      "step": 66350
    },
    {
      "epoch": 66.36,
      "learning_rate": 4.1879890545395405e-05,
      "loss": 0.2352,
      "step": 66360
    },
    {
      "epoch": 66.37,
      "learning_rate": 4.1857639679241376e-05,
      "loss": 0.1916,
      "step": 66370
    },
    {
      "epoch": 66.38,
      "learning_rate": 4.183539243748596e-05,
      "loss": 0.2057,
      "step": 66380
    },
    {
      "epoch": 66.39,
      "learning_rate": 4.181314882256223e-05,
      "loss": 0.2522,
      "step": 66390
    },
    {
      "epoch": 66.4,
      "learning_rate": 4.1790908836902625e-05,
      "loss": 0.3365,
      "step": 66400
    },
    {
      "epoch": 66.41,
      "learning_rate": 4.1768672482939307e-05,
      "loss": 0.188,
      "step": 66410
    },
    {
      "epoch": 66.42,
      "learning_rate": 4.174643976310403e-05,
      "loss": 0.2637,
      "step": 66420
    },
    {
      "epoch": 66.43,
      "learning_rate": 4.1724210679828064e-05,
      "loss": 0.2983,
      "step": 66430
    },
    {
      "epoch": 66.44,
      "learning_rate": 4.17019852355424e-05,
      "loss": 0.2052,
      "step": 66440
    },
    {
      "epoch": 66.45,
      "learning_rate": 4.1679763432677554e-05,
      "loss": 0.3568,
      "step": 66450
    },
    {
      "epoch": 66.46,
      "learning_rate": 4.165754527366372e-05,
      "loss": 0.2387,
      "step": 66460
    },
    {
      "epoch": 66.47,
      "learning_rate": 4.1635330760930584e-05,
      "loss": 0.2259,
      "step": 66470
    },
    {
      "epoch": 66.48,
      "learning_rate": 4.161311989690753e-05,
      "loss": 0.1692,
      "step": 66480
    },
    {
      "epoch": 66.49,
      "learning_rate": 4.159091268402347e-05,
      "loss": 0.2083,
      "step": 66490
    },
    {
      "epoch": 66.5,
      "learning_rate": 4.1568709124706965e-05,
      "loss": 0.3391,
      "step": 66500
    },
    {
      "epoch": 66.51,
      "learning_rate": 4.1546509221386166e-05,
      "loss": 0.2895,
      "step": 66510
    },
    {
      "epoch": 66.52,
      "learning_rate": 4.152431297648885e-05,
      "loss": 0.2647,
      "step": 66520
    },
    {
      "epoch": 66.53,
      "learning_rate": 4.150212039244231e-05,
      "loss": 0.2294,
      "step": 66530
    },
    {
      "epoch": 66.54,
      "learning_rate": 4.147993147167354e-05,
      "loss": 0.3218,
      "step": 66540
    },
    {
      "epoch": 66.55,
      "learning_rate": 4.145774621660905e-05,
      "loss": 0.248,
      "step": 66550
    },
    {
      "epoch": 66.56,
      "learning_rate": 4.1435564629675025e-05,
      "loss": 0.2639,
      "step": 66560
    },
    {
      "epoch": 66.57,
      "learning_rate": 4.141338671329714e-05,
      "loss": 0.279,
      "step": 66570
    },
    {
      "epoch": 66.58,
      "learning_rate": 4.139121246990084e-05,
      "loss": 0.2064,
      "step": 66580
    },
    {
      "epoch": 66.59,
      "learning_rate": 4.136904190191099e-05,
      "loss": 0.3372,
      "step": 66590
    },
    {
      "epoch": 66.6,
      "learning_rate": 4.1346875011752176e-05,
      "loss": 0.2236,
      "step": 66600
    },
    {
      "epoch": 66.61,
      "learning_rate": 4.132471180184848e-05,
      "loss": 0.2114,
      "step": 66610
    },
    {
      "epoch": 66.62,
      "learning_rate": 4.130255227462369e-05,
      "loss": 0.2833,
      "step": 66620
    },
    {
      "epoch": 66.63,
      "learning_rate": 4.128039643250111e-05,
      "loss": 0.2523,
      "step": 66630
    },
    {
      "epoch": 66.64,
      "learning_rate": 4.12582442779037e-05,
      "loss": 0.2379,
      "step": 66640
    },
    {
      "epoch": 66.65,
      "learning_rate": 4.123609581325394e-05,
      "loss": 0.2671,
      "step": 66650
    },
    {
      "epoch": 66.66,
      "learning_rate": 4.121395104097398e-05,
      "loss": 0.2995,
      "step": 66660
    },
    {
      "epoch": 66.67,
      "learning_rate": 4.119180996348558e-05,
      "loss": 0.2623,
      "step": 66670
    },
    {
      "epoch": 66.68,
      "learning_rate": 4.116967258320997e-05,
      "loss": 0.2753,
      "step": 66680
    },
    {
      "epoch": 66.69,
      "learning_rate": 4.11475389025681e-05,
      "loss": 0.2735,
      "step": 66690
    },
    {
      "epoch": 66.7,
      "learning_rate": 4.112540892398049e-05,
      "loss": 0.2647,
      "step": 66700
    },
    {
      "epoch": 66.71,
      "learning_rate": 4.1105495110508276e-05,
      "loss": 0.3292,
      "step": 66710
    },
    {
      "epoch": 66.72,
      "learning_rate": 4.108337217249078e-05,
      "loss": 0.2665,
      "step": 66720
    },
    {
      "epoch": 66.73,
      "learning_rate": 4.106125294354471e-05,
      "loss": 0.3146,
      "step": 66730
    },
    {
      "epoch": 66.74,
      "learning_rate": 4.103913742608903e-05,
      "loss": 0.2943,
      "step": 66740
    },
    {
      "epoch": 66.75,
      "learning_rate": 4.101702562254218e-05,
      "loss": 0.2863,
      "step": 66750
    },
    {
      "epoch": 66.76,
      "learning_rate": 4.099491753532234e-05,
      "loss": 0.2159,
      "step": 66760
    },
    {
      "epoch": 66.77,
      "learning_rate": 4.097281316684714e-05,
      "loss": 0.3064,
      "step": 66770
    },
    {
      "epoch": 66.78,
      "learning_rate": 4.095071251953399e-05,
      "loss": 0.2187,
      "step": 66780
    },
    {
      "epoch": 66.79,
      "learning_rate": 4.092861559579971e-05,
      "loss": 0.2982,
      "step": 66790
    },
    {
      "epoch": 66.8,
      "learning_rate": 4.0906522398060815e-05,
      "loss": 0.2641,
      "step": 66800
    },
    {
      "epoch": 66.81,
      "learning_rate": 4.0884432928733346e-05,
      "loss": 0.2832,
      "step": 66810
    },
    {
      "epoch": 66.82,
      "learning_rate": 4.0862347190233034e-05,
      "loss": 0.2087,
      "step": 66820
    },
    {
      "epoch": 66.83,
      "learning_rate": 4.084026518497505e-05,
      "loss": 0.272,
      "step": 66830
    },
    {
      "epoch": 66.84,
      "learning_rate": 4.081818691537436e-05,
      "loss": 0.2726,
      "step": 66840
    },
    {
      "epoch": 66.85,
      "learning_rate": 4.079611238384533e-05,
      "loss": 0.2584,
      "step": 66850
    },
    {
      "epoch": 66.86,
      "learning_rate": 4.0774041592802065e-05,
      "loss": 0.2891,
      "step": 66860
    },
    {
      "epoch": 66.87,
      "learning_rate": 4.075197454465811e-05,
      "loss": 0.2612,
      "step": 66870
    },
    {
      "epoch": 66.88,
      "learning_rate": 4.072991124182676e-05,
      "loss": 0.2818,
      "step": 66880
    },
    {
      "epoch": 66.89,
      "learning_rate": 4.070785168672074e-05,
      "loss": 0.2796,
      "step": 66890
    },
    {
      "epoch": 66.9,
      "learning_rate": 4.0685795881752546e-05,
      "loss": 0.241,
      "step": 66900
    },
    {
      "epoch": 66.91,
      "learning_rate": 4.066374382933411e-05,
      "loss": 0.2904,
      "step": 66910
    },
    {
      "epoch": 66.92,
      "learning_rate": 4.064169553187705e-05,
      "loss": 0.3156,
      "step": 66920
    },
    {
      "epoch": 66.93,
      "learning_rate": 4.061965099179249e-05,
      "loss": 0.2861,
      "step": 66930
    },
    {
      "epoch": 66.94,
      "learning_rate": 4.059761021149119e-05,
      "loss": 0.2631,
      "step": 66940
    },
    {
      "epoch": 66.95,
      "learning_rate": 4.057557319338355e-05,
      "loss": 0.2536,
      "step": 66950
    },
    {
      "epoch": 66.96,
      "learning_rate": 4.055353993987944e-05,
      "loss": 0.3403,
      "step": 66960
    },
    {
      "epoch": 66.97,
      "learning_rate": 4.053151045338841e-05,
      "loss": 0.1594,
      "step": 66970
    },
    {
      "epoch": 66.98,
      "learning_rate": 4.050948473631957e-05,
      "loss": 0.261,
      "step": 66980
    },
    {
      "epoch": 66.99,
      "learning_rate": 4.048746279108167e-05,
      "loss": 0.2898,
      "step": 66990
    },
    {
      "epoch": 67.0,
      "learning_rate": 4.0465444620082904e-05,
      "loss": 0.1472,
      "step": 67000
    },
    {
      "epoch": 67.0,
      "eval_accuracy": 0.804,
      "eval_loss": 0.31312620639801025,
      "eval_runtime": 15.176,
      "eval_samples_per_second": 131.787,
      "eval_steps_per_second": 16.473,
      "step": 67000
    },
    {
      "epoch": 67.01,
      "learning_rate": 4.044343022573123e-05,
      "loss": 0.2111,
      "step": 67010
    },
    {
      "epoch": 67.02,
      "learning_rate": 4.042141961043402e-05,
      "loss": 0.2096,
      "step": 67020
    },
    {
      "epoch": 67.03,
      "learning_rate": 4.039941277659842e-05,
      "loss": 0.2271,
      "step": 67030
    },
    {
      "epoch": 67.04,
      "learning_rate": 4.0377409726630983e-05,
      "loss": 0.2243,
      "step": 67040
    },
    {
      "epoch": 67.05,
      "learning_rate": 4.0355410462938e-05,
      "loss": 0.2324,
      "step": 67050
    },
    {
      "epoch": 67.06,
      "learning_rate": 4.033341498792522e-05,
      "loss": 0.208,
      "step": 67060
    },
    {
      "epoch": 67.07,
      "learning_rate": 4.031142330399808e-05,
      "loss": 0.2188,
      "step": 67070
    },
    {
      "epoch": 67.08,
      "learning_rate": 4.0289435413561475e-05,
      "loss": 0.3337,
      "step": 67080
    },
    {
      "epoch": 67.09,
      "learning_rate": 4.0267451319020085e-05,
      "loss": 0.2604,
      "step": 67090
    },
    {
      "epoch": 67.1,
      "learning_rate": 4.0245471022777977e-05,
      "loss": 0.2399,
      "step": 67100
    },
    {
      "epoch": 67.11,
      "learning_rate": 4.0223494527238926e-05,
      "loss": 0.1411,
      "step": 67110
    },
    {
      "epoch": 67.12,
      "learning_rate": 4.02015218348062e-05,
      "loss": 0.3116,
      "step": 67120
    },
    {
      "epoch": 67.13,
      "learning_rate": 4.017955294788275e-05,
      "loss": 0.2208,
      "step": 67130
    },
    {
      "epoch": 67.14,
      "learning_rate": 4.0157587868871016e-05,
      "loss": 0.288,
      "step": 67140
    },
    {
      "epoch": 67.15,
      "learning_rate": 4.013562660017309e-05,
      "loss": 0.171,
      "step": 67150
    },
    {
      "epoch": 67.16,
      "learning_rate": 4.011366914419062e-05,
      "loss": 0.2512,
      "step": 67160
    },
    {
      "epoch": 67.17,
      "learning_rate": 4.0091715503324875e-05,
      "loss": 0.263,
      "step": 67170
    },
    {
      "epoch": 67.18,
      "learning_rate": 4.0069765679976594e-05,
      "loss": 0.1652,
      "step": 67180
    },
    {
      "epoch": 67.19,
      "learning_rate": 4.004781967654623e-05,
      "loss": 0.3083,
      "step": 67190
    },
    {
      "epoch": 67.2,
      "learning_rate": 4.002587749543379e-05,
      "loss": 0.1936,
      "step": 67200
    },
    {
      "epoch": 67.21,
      "learning_rate": 4.000393913903874e-05,
      "loss": 0.3113,
      "step": 67210
    },
    {
      "epoch": 67.22,
      "learning_rate": 3.998200460976036e-05,
      "loss": 0.229,
      "step": 67220
    },
    {
      "epoch": 67.23,
      "learning_rate": 3.996007390999727e-05,
      "loss": 0.2344,
      "step": 67230
    },
    {
      "epoch": 67.24,
      "learning_rate": 3.9938147042147836e-05,
      "loss": 0.2009,
      "step": 67240
    },
    {
      "epoch": 67.25,
      "learning_rate": 3.991622400860991e-05,
      "loss": 0.2801,
      "step": 67250
    },
    {
      "epoch": 67.26,
      "learning_rate": 3.9894304811781e-05,
      "loss": 0.1915,
      "step": 67260
    },
    {
      "epoch": 67.27,
      "learning_rate": 3.987238945405811e-05,
      "loss": 0.3354,
      "step": 67270
    },
    {
      "epoch": 67.28,
      "learning_rate": 3.985047793783789e-05,
      "loss": 0.3373,
      "step": 67280
    },
    {
      "epoch": 67.29,
      "learning_rate": 3.982857026551657e-05,
      "loss": 0.3113,
      "step": 67290
    },
    {
      "epoch": 67.3,
      "learning_rate": 3.980666643948994e-05,
      "loss": 0.2837,
      "step": 67300
    },
    {
      "epoch": 67.31,
      "learning_rate": 3.978476646215333e-05,
      "loss": 0.4044,
      "step": 67310
    },
    {
      "epoch": 67.32,
      "learning_rate": 3.976287033590176e-05,
      "loss": 0.2786,
      "step": 67320
    },
    {
      "epoch": 67.33,
      "learning_rate": 3.974097806312966e-05,
      "loss": 0.2596,
      "step": 67330
    },
    {
      "epoch": 67.34,
      "learning_rate": 3.97190896462312e-05,
      "loss": 0.2792,
      "step": 67340
    },
    {
      "epoch": 67.35,
      "learning_rate": 3.9697205087600056e-05,
      "loss": 0.3195,
      "step": 67350
    },
    {
      "epoch": 67.36,
      "learning_rate": 3.96753243896295e-05,
      "loss": 0.3274,
      "step": 67360
    },
    {
      "epoch": 67.37,
      "learning_rate": 3.9653447554712334e-05,
      "loss": 0.3043,
      "step": 67370
    },
    {
      "epoch": 67.38,
      "learning_rate": 3.963157458524104e-05,
      "loss": 0.2708,
      "step": 67380
    },
    {
      "epoch": 67.39,
      "learning_rate": 3.960970548360754e-05,
      "loss": 0.3179,
      "step": 67390
    },
    {
      "epoch": 67.4,
      "learning_rate": 3.958784025220345e-05,
      "loss": 0.2318,
      "step": 67400
    },
    {
      "epoch": 67.41,
      "learning_rate": 3.9565978893419894e-05,
      "loss": 0.1668,
      "step": 67410
    },
    {
      "epoch": 67.42,
      "learning_rate": 3.9544121409647614e-05,
      "loss": 0.3155,
      "step": 67420
    },
    {
      "epoch": 67.43,
      "learning_rate": 3.952226780327694e-05,
      "loss": 0.1985,
      "step": 67430
    },
    {
      "epoch": 67.44,
      "learning_rate": 3.950041807669769e-05,
      "loss": 0.2625,
      "step": 67440
    },
    {
      "epoch": 67.45,
      "learning_rate": 3.947857223229938e-05,
      "loss": 0.206,
      "step": 67450
    },
    {
      "epoch": 67.46,
      "learning_rate": 3.945673027247096e-05,
      "loss": 0.154,
      "step": 67460
    },
    {
      "epoch": 67.47,
      "learning_rate": 3.9434892199601094e-05,
      "loss": 0.1605,
      "step": 67470
    },
    {
      "epoch": 67.48,
      "learning_rate": 3.941305801607795e-05,
      "loss": 0.2851,
      "step": 67480
    },
    {
      "epoch": 67.49,
      "learning_rate": 3.93912277242893e-05,
      "loss": 0.2874,
      "step": 67490
    },
    {
      "epoch": 67.5,
      "learning_rate": 3.9369401326622415e-05,
      "loss": 0.2897,
      "step": 67500
    },
    {
      "epoch": 67.51,
      "learning_rate": 3.9347578825464265e-05,
      "loss": 0.1857,
      "step": 67510
    },
    {
      "epoch": 67.52,
      "learning_rate": 3.932576022320125e-05,
      "loss": 0.2183,
      "step": 67520
    },
    {
      "epoch": 67.53,
      "learning_rate": 3.930394552221948e-05,
      "loss": 0.365,
      "step": 67530
    },
    {
      "epoch": 67.54,
      "learning_rate": 3.928213472490455e-05,
      "loss": 0.2328,
      "step": 67540
    },
    {
      "epoch": 67.55,
      "learning_rate": 3.92603278336417e-05,
      "loss": 0.2543,
      "step": 67550
    },
    {
      "epoch": 67.56,
      "learning_rate": 3.923852485081563e-05,
      "loss": 0.2591,
      "step": 67560
    },
    {
      "epoch": 67.57,
      "learning_rate": 3.921672577881075e-05,
      "loss": 0.2515,
      "step": 67570
    },
    {
      "epoch": 67.58,
      "learning_rate": 3.919493062001091e-05,
      "loss": 0.2445,
      "step": 67580
    },
    {
      "epoch": 67.59,
      "learning_rate": 3.917313937679962e-05,
      "loss": 0.2949,
      "step": 67590
    },
    {
      "epoch": 67.6,
      "learning_rate": 3.915135205155995e-05,
      "loss": 0.2244,
      "step": 67600
    },
    {
      "epoch": 67.61,
      "learning_rate": 3.912956864667454e-05,
      "loss": 0.2214,
      "step": 67610
    },
    {
      "epoch": 67.62,
      "learning_rate": 3.910778916452556e-05,
      "loss": 0.2911,
      "step": 67620
    },
    {
      "epoch": 67.63,
      "learning_rate": 3.9086013607494775e-05,
      "loss": 0.3,
      "step": 67630
    },
    {
      "epoch": 67.64,
      "learning_rate": 3.9064241977963583e-05,
      "loss": 0.3477,
      "step": 67640
    },
    {
      "epoch": 67.65,
      "learning_rate": 3.904247427831284e-05,
      "loss": 0.2746,
      "step": 67650
    },
    {
      "epoch": 67.66,
      "learning_rate": 3.902071051092304e-05,
      "loss": 0.2457,
      "step": 67660
    },
    {
      "epoch": 67.67,
      "learning_rate": 3.899895067817424e-05,
      "loss": 0.2357,
      "step": 67670
    },
    {
      "epoch": 67.68,
      "learning_rate": 3.89771947824461e-05,
      "loss": 0.2583,
      "step": 67680
    },
    {
      "epoch": 67.69,
      "learning_rate": 3.8955442826117764e-05,
      "loss": 0.2352,
      "step": 67690
    },
    {
      "epoch": 67.7,
      "learning_rate": 3.893369481156802e-05,
      "loss": 0.2526,
      "step": 67700
    },
    {
      "epoch": 67.71,
      "learning_rate": 3.891195074117516e-05,
      "loss": 0.2614,
      "step": 67710
    },
    {
      "epoch": 67.72,
      "learning_rate": 3.8890210617317114e-05,
      "loss": 0.2787,
      "step": 67720
    },
    {
      "epoch": 67.73,
      "learning_rate": 3.886847444237134e-05,
      "loss": 0.2249,
      "step": 67730
    },
    {
      "epoch": 67.74,
      "learning_rate": 3.884674221871491e-05,
      "loss": 0.2572,
      "step": 67740
    },
    {
      "epoch": 67.75,
      "learning_rate": 3.882501394872436e-05,
      "loss": 0.304,
      "step": 67750
    },
    {
      "epoch": 67.76,
      "learning_rate": 3.8803289634775935e-05,
      "loss": 0.2842,
      "step": 67760
    },
    {
      "epoch": 67.77,
      "learning_rate": 3.8781569279245306e-05,
      "loss": 0.2595,
      "step": 67770
    },
    {
      "epoch": 67.78,
      "learning_rate": 3.87598528845078e-05,
      "loss": 0.2945,
      "step": 67780
    },
    {
      "epoch": 67.79,
      "learning_rate": 3.8738140452938296e-05,
      "loss": 0.2775,
      "step": 67790
    },
    {
      "epoch": 67.8,
      "learning_rate": 3.871643198691126e-05,
      "loss": 0.2865,
      "step": 67800
    },
    {
      "epoch": 67.81,
      "learning_rate": 3.869472748880065e-05,
      "loss": 0.1898,
      "step": 67810
    },
    {
      "epoch": 67.82,
      "learning_rate": 3.867302696098009e-05,
      "loss": 0.2344,
      "step": 67820
    },
    {
      "epoch": 67.83,
      "learning_rate": 3.865133040582264e-05,
      "loss": 0.2947,
      "step": 67830
    },
    {
      "epoch": 67.84,
      "learning_rate": 3.8629637825701054e-05,
      "loss": 0.2764,
      "step": 67840
    },
    {
      "epoch": 67.85,
      "learning_rate": 3.86079492229876e-05,
      "loss": 0.1998,
      "step": 67850
    },
    {
      "epoch": 67.86,
      "learning_rate": 3.8586264600054134e-05,
      "loss": 0.2602,
      "step": 67860
    },
    {
      "epoch": 67.87,
      "learning_rate": 3.856458395927199e-05,
      "loss": 0.2707,
      "step": 67870
    },
    {
      "epoch": 67.88,
      "learning_rate": 3.854290730301216e-05,
      "loss": 0.2553,
      "step": 67880
    },
    {
      "epoch": 67.89,
      "learning_rate": 3.85212346336452e-05,
      "loss": 0.3056,
      "step": 67890
    },
    {
      "epoch": 67.9,
      "learning_rate": 3.8499565953541165e-05,
      "loss": 0.2335,
      "step": 67900
    },
    {
      "epoch": 67.91,
      "learning_rate": 3.8477901265069714e-05,
      "loss": 0.2731,
      "step": 67910
    },
    {
      "epoch": 67.92,
      "learning_rate": 3.8456240570600054e-05,
      "loss": 0.2404,
      "step": 67920
    },
    {
      "epoch": 67.93,
      "learning_rate": 3.8434583872501025e-05,
      "loss": 0.214,
      "step": 67930
    },
    {
      "epoch": 67.94,
      "learning_rate": 3.8412931173140905e-05,
      "loss": 0.2139,
      "step": 67940
    },
    {
      "epoch": 67.95,
      "learning_rate": 3.8391282474887636e-05,
      "loss": 0.3472,
      "step": 67950
    },
    {
      "epoch": 67.96,
      "learning_rate": 3.8369637780108665e-05,
      "loss": 0.1816,
      "step": 67960
    },
    {
      "epoch": 67.97,
      "learning_rate": 3.8347997091171046e-05,
      "loss": 0.2055,
      "step": 67970
    },
    {
      "epoch": 67.98,
      "learning_rate": 3.832636041044131e-05,
      "loss": 0.1941,
      "step": 67980
    },
    {
      "epoch": 67.99,
      "learning_rate": 3.8304727740285715e-05,
      "loss": 0.2703,
      "step": 67990
    },
    {
      "epoch": 68.0,
      "learning_rate": 3.828309908306991e-05,
      "loss": 0.3056,
      "step": 68000
    },
    {
      "epoch": 68.0,
      "eval_accuracy": 0.809,
      "eval_loss": 0.3372575044631958,
      "eval_runtime": 14.8953,
      "eval_samples_per_second": 134.271,
      "eval_steps_per_second": 16.784,
      "step": 68000
    },
    {
      "epoch": 68.01,
      "learning_rate": 3.8261474441159196e-05,
      "loss": 0.2077,
      "step": 68010
    },
    {
      "epoch": 68.02,
      "learning_rate": 3.8239853816918376e-05,
      "loss": 0.1844,
      "step": 68020
    },
    {
      "epoch": 68.03,
      "learning_rate": 3.821823721271191e-05,
      "loss": 0.2447,
      "step": 68030
    },
    {
      "epoch": 68.04,
      "learning_rate": 3.819662463090366e-05,
      "loss": 0.2991,
      "step": 68040
    },
    {
      "epoch": 68.05,
      "learning_rate": 3.8175016073857265e-05,
      "loss": 0.2734,
      "step": 68050
    },
    {
      "epoch": 68.06,
      "learning_rate": 3.815341154393572e-05,
      "loss": 0.2034,
      "step": 68060
    },
    {
      "epoch": 68.07,
      "learning_rate": 3.8131811043501725e-05,
      "loss": 0.2883,
      "step": 68070
    },
    {
      "epoch": 68.08,
      "learning_rate": 3.811021457491741e-05,
      "loss": 0.2653,
      "step": 68080
    },
    {
      "epoch": 68.09,
      "learning_rate": 3.8088622140544565e-05,
      "loss": 0.2573,
      "step": 68090
    },
    {
      "epoch": 68.1,
      "learning_rate": 3.8067033742744506e-05,
      "loss": 0.2,
      "step": 68100
    },
    {
      "epoch": 68.11,
      "learning_rate": 3.804544938387814e-05,
      "loss": 0.2885,
      "step": 68110
    },
    {
      "epoch": 68.12,
      "learning_rate": 3.8023869066305836e-05,
      "loss": 0.3182,
      "step": 68120
    },
    {
      "epoch": 68.13,
      "learning_rate": 3.8002292792387625e-05,
      "loss": 0.3713,
      "step": 68130
    },
    {
      "epoch": 68.14,
      "learning_rate": 3.798072056448307e-05,
      "loss": 0.2091,
      "step": 68140
    },
    {
      "epoch": 68.15,
      "learning_rate": 3.795915238495123e-05,
      "loss": 0.17,
      "step": 68150
    },
    {
      "epoch": 68.16,
      "learning_rate": 3.7937588256150835e-05,
      "loss": 0.2611,
      "step": 68160
    },
    {
      "epoch": 68.17,
      "learning_rate": 3.791602818043999e-05,
      "loss": 0.2438,
      "step": 68170
    },
    {
      "epoch": 68.18,
      "learning_rate": 3.789447216017662e-05,
      "loss": 0.3143,
      "step": 68180
    },
    {
      "epoch": 68.19,
      "learning_rate": 3.787292019771795e-05,
      "loss": 0.2428,
      "step": 68190
    },
    {
      "epoch": 68.2,
      "learning_rate": 3.785137229542094e-05,
      "loss": 0.2016,
      "step": 68200
    },
    {
      "epoch": 68.21,
      "learning_rate": 3.782982845564198e-05,
      "loss": 0.2763,
      "step": 68210
    },
    {
      "epoch": 68.22,
      "learning_rate": 3.780828868073711e-05,
      "loss": 0.3231,
      "step": 68220
    },
    {
      "epoch": 68.23,
      "learning_rate": 3.7786752973061825e-05,
      "loss": 0.252,
      "step": 68230
    },
    {
      "epoch": 68.24,
      "learning_rate": 3.776522133497135e-05,
      "loss": 0.218,
      "step": 68240
    },
    {
      "epoch": 68.25,
      "learning_rate": 3.7743693768820246e-05,
      "loss": 0.2484,
      "step": 68250
    },
    {
      "epoch": 68.26,
      "learning_rate": 3.7722170276962813e-05,
      "loss": 0.2647,
      "step": 68260
    },
    {
      "epoch": 68.27,
      "learning_rate": 3.770065086175277e-05,
      "loss": 0.2368,
      "step": 68270
    },
    {
      "epoch": 68.28,
      "learning_rate": 3.767913552554348e-05,
      "loss": 0.1913,
      "step": 68280
    },
    {
      "epoch": 68.29,
      "learning_rate": 3.765762427068777e-05,
      "loss": 0.222,
      "step": 68290
    },
    {
      "epoch": 68.3,
      "learning_rate": 3.7636117099538186e-05,
      "loss": 0.2559,
      "step": 68300
    },
    {
      "epoch": 68.31,
      "learning_rate": 3.761461401444663e-05,
      "loss": 0.2527,
      "step": 68310
    },
    {
      "epoch": 68.32,
      "learning_rate": 3.759311501776471e-05,
      "loss": 0.2358,
      "step": 68320
    },
    {
      "epoch": 68.33,
      "learning_rate": 3.757162011184346e-05,
      "loss": 0.2229,
      "step": 68330
    },
    {
      "epoch": 68.34,
      "learning_rate": 3.755012929903356e-05,
      "loss": 0.2608,
      "step": 68340
    },
    {
      "epoch": 68.35,
      "learning_rate": 3.752864258168524e-05,
      "loss": 0.2283,
      "step": 68350
    },
    {
      "epoch": 68.36,
      "learning_rate": 3.7507159962148215e-05,
      "loss": 0.2274,
      "step": 68360
    },
    {
      "epoch": 68.37,
      "learning_rate": 3.748568144277179e-05,
      "loss": 0.2401,
      "step": 68370
    },
    {
      "epoch": 68.38,
      "learning_rate": 3.7464207025904855e-05,
      "loss": 0.326,
      "step": 68380
    },
    {
      "epoch": 68.39,
      "learning_rate": 3.744273671389582e-05,
      "loss": 0.2303,
      "step": 68390
    },
    {
      "epoch": 68.4,
      "learning_rate": 3.742127050909261e-05,
      "loss": 0.2848,
      "step": 68400
    },
    {
      "epoch": 68.41,
      "learning_rate": 3.739980841384279e-05,
      "loss": 0.204,
      "step": 68410
    },
    {
      "epoch": 68.42,
      "learning_rate": 3.7378350430493326e-05,
      "loss": 0.2393,
      "step": 68420
    },
    {
      "epoch": 68.43,
      "learning_rate": 3.7356896561390964e-05,
      "loss": 0.3341,
      "step": 68430
    },
    {
      "epoch": 68.44,
      "learning_rate": 3.7335446808881764e-05,
      "loss": 0.3459,
      "step": 68440
    },
    {
      "epoch": 68.45,
      "learning_rate": 3.73140011753115e-05,
      "loss": 0.2634,
      "step": 68450
    },
    {
      "epoch": 68.46,
      "learning_rate": 3.7292559663025384e-05,
      "loss": 0.249,
      "step": 68460
    },
    {
      "epoch": 68.47,
      "learning_rate": 3.7271122274368266e-05,
      "loss": 0.2249,
      "step": 68470
    },
    {
      "epoch": 68.48,
      "learning_rate": 3.7249689011684474e-05,
      "loss": 0.2363,
      "step": 68480
    },
    {
      "epoch": 68.49,
      "learning_rate": 3.722825987731794e-05,
      "loss": 0.2401,
      "step": 68490
    },
    {
      "epoch": 68.5,
      "learning_rate": 3.7206834873612107e-05,
      "loss": 0.1884,
      "step": 68500
    },
    {
      "epoch": 68.51,
      "learning_rate": 3.718541400291002e-05,
      "loss": 0.2413,
      "step": 68510
    },
    {
      "epoch": 68.52,
      "learning_rate": 3.7163997267554185e-05,
      "loss": 0.272,
      "step": 68520
    },
    {
      "epoch": 68.53,
      "learning_rate": 3.7142584669886735e-05,
      "loss": 0.2209,
      "step": 68530
    },
    {
      "epoch": 68.54,
      "learning_rate": 3.712117621224929e-05,
      "loss": 0.2175,
      "step": 68540
    },
    {
      "epoch": 68.55,
      "learning_rate": 3.7099771896983064e-05,
      "loss": 0.227,
      "step": 68550
    },
    {
      "epoch": 68.56,
      "learning_rate": 3.707837172642881e-05,
      "loss": 0.2175,
      "step": 68560
    },
    {
      "epoch": 68.57,
      "learning_rate": 3.705697570292683e-05,
      "loss": 0.271,
      "step": 68570
    },
    {
      "epoch": 68.58,
      "learning_rate": 3.703558382881691e-05,
      "loss": 0.2358,
      "step": 68580
    },
    {
      "epoch": 68.59,
      "learning_rate": 3.701419610643846e-05,
      "loss": 0.2425,
      "step": 68590
    },
    {
      "epoch": 68.6,
      "learning_rate": 3.6992812538130455e-05,
      "loss": 0.1677,
      "step": 68600
    },
    {
      "epoch": 68.61,
      "learning_rate": 3.697143312623129e-05,
      "loss": 0.2735,
      "step": 68610
    },
    {
      "epoch": 68.62,
      "learning_rate": 3.695005787307902e-05,
      "loss": 0.2153,
      "step": 68620
    },
    {
      "epoch": 68.63,
      "learning_rate": 3.6928686781011214e-05,
      "loss": 0.2356,
      "step": 68630
    },
    {
      "epoch": 68.64,
      "learning_rate": 3.6907319852365016e-05,
      "loss": 0.3037,
      "step": 68640
    },
    {
      "epoch": 68.65,
      "learning_rate": 3.688595708947702e-05,
      "loss": 0.2305,
      "step": 68650
    },
    {
      "epoch": 68.66,
      "learning_rate": 3.686459849468348e-05,
      "loss": 0.3354,
      "step": 68660
    },
    {
      "epoch": 68.67,
      "learning_rate": 3.6843244070320086e-05,
      "loss": 0.2881,
      "step": 68670
    },
    {
      "epoch": 68.68,
      "learning_rate": 3.6821893818722146e-05,
      "loss": 0.1177,
      "step": 68680
    },
    {
      "epoch": 68.69,
      "learning_rate": 3.680054774222451e-05,
      "loss": 0.1782,
      "step": 68690
    },
    {
      "epoch": 68.7,
      "learning_rate": 3.677920584316156e-05,
      "loss": 0.2256,
      "step": 68700
    },
    {
      "epoch": 68.71,
      "learning_rate": 3.6757868123867166e-05,
      "loss": 0.2492,
      "step": 68710
    },
    {
      "epoch": 68.72,
      "learning_rate": 3.673653458667485e-05,
      "loss": 0.2073,
      "step": 68720
    },
    {
      "epoch": 68.73,
      "learning_rate": 3.671520523391755e-05,
      "loss": 0.2934,
      "step": 68730
    },
    {
      "epoch": 68.74,
      "learning_rate": 3.6693880067927844e-05,
      "loss": 0.1861,
      "step": 68740
    },
    {
      "epoch": 68.75,
      "learning_rate": 3.6672559091037834e-05,
      "loss": 0.2164,
      "step": 68750
    },
    {
      "epoch": 68.76,
      "learning_rate": 3.665124230557916e-05,
      "loss": 0.3184,
      "step": 68760
    },
    {
      "epoch": 68.77,
      "learning_rate": 3.662992971388293e-05,
      "loss": 0.2736,
      "step": 68770
    },
    {
      "epoch": 68.78,
      "learning_rate": 3.660862131827994e-05,
      "loss": 0.2854,
      "step": 68780
    },
    {
      "epoch": 68.79,
      "learning_rate": 3.6587317121100376e-05,
      "loss": 0.2598,
      "step": 68790
    },
    {
      "epoch": 68.8,
      "learning_rate": 3.656601712467405e-05,
      "loss": 0.2125,
      "step": 68800
    },
    {
      "epoch": 68.81,
      "learning_rate": 3.6544721331330314e-05,
      "loss": 0.274,
      "step": 68810
    },
    {
      "epoch": 68.82,
      "learning_rate": 3.6523429743398056e-05,
      "loss": 0.2657,
      "step": 68820
    },
    {
      "epoch": 68.83,
      "learning_rate": 3.650214236320565e-05,
      "loss": 0.2729,
      "step": 68830
    },
    {
      "epoch": 68.84,
      "learning_rate": 3.648085919308107e-05,
      "loss": 0.2622,
      "step": 68840
    },
    {
      "epoch": 68.85,
      "learning_rate": 3.6459580235351856e-05,
      "loss": 0.2494,
      "step": 68850
    },
    {
      "epoch": 68.86,
      "learning_rate": 3.643830549234496e-05,
      "loss": 0.2712,
      "step": 68860
    },
    {
      "epoch": 68.87,
      "learning_rate": 3.6417034966387005e-05,
      "loss": 0.3,
      "step": 68870
    },
    {
      "epoch": 68.88,
      "learning_rate": 3.63957686598041e-05,
      "loss": 0.2663,
      "step": 68880
    },
    {
      "epoch": 68.89,
      "learning_rate": 3.6374506574921924e-05,
      "loss": 0.2407,
      "step": 68890
    },
    {
      "epoch": 68.9,
      "learning_rate": 3.63532487140656e-05,
      "loss": 0.2582,
      "step": 68900
    },
    {
      "epoch": 68.91,
      "learning_rate": 3.6331995079559924e-05,
      "loss": 0.2377,
      "step": 68910
    },
    {
      "epoch": 68.92,
      "learning_rate": 3.63107456737291e-05,
      "loss": 0.2577,
      "step": 68920
    },
    {
      "epoch": 68.93,
      "learning_rate": 3.628950049889697e-05,
      "loss": 0.2545,
      "step": 68930
    },
    {
      "epoch": 68.94,
      "learning_rate": 3.6268259557386854e-05,
      "loss": 0.2399,
      "step": 68940
    },
    {
      "epoch": 68.95,
      "learning_rate": 3.6247022851521674e-05,
      "loss": 0.2803,
      "step": 68950
    },
    {
      "epoch": 68.96,
      "learning_rate": 3.622579038362378e-05,
      "loss": 0.3222,
      "step": 68960
    },
    {
      "epoch": 68.97,
      "learning_rate": 3.620456215601518e-05,
      "loss": 0.2927,
      "step": 68970
    },
    {
      "epoch": 68.98,
      "learning_rate": 3.618333817101731e-05,
      "loss": 0.2957,
      "step": 68980
    },
    {
      "epoch": 68.99,
      "learning_rate": 3.6162118430951214e-05,
      "loss": 0.2347,
      "step": 68990
    },
    {
      "epoch": 69.0,
      "learning_rate": 3.614090293813746e-05,
      "loss": 0.2631,
      "step": 69000
    },
    {
      "epoch": 69.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.3057746887207031,
      "eval_runtime": 14.9358,
      "eval_samples_per_second": 133.907,
      "eval_steps_per_second": 16.738,
      "step": 69000
    },
    {
      "epoch": 69.01,
      "learning_rate": 3.611969169489616e-05,
      "loss": 0.3098,
      "step": 69010
    },
    {
      "epoch": 69.02,
      "learning_rate": 3.60984847035469e-05,
      "loss": 0.1824,
      "step": 69020
    },
    {
      "epoch": 69.03,
      "learning_rate": 3.607728196640888e-05,
      "loss": 0.2306,
      "step": 69030
    },
    {
      "epoch": 69.04,
      "learning_rate": 3.605608348580077e-05,
      "loss": 0.2434,
      "step": 69040
    },
    {
      "epoch": 69.05,
      "learning_rate": 3.60348892640408e-05,
      "loss": 0.2923,
      "step": 69050
    },
    {
      "epoch": 69.06,
      "learning_rate": 3.601369930344678e-05,
      "loss": 0.2485,
      "step": 69060
    },
    {
      "epoch": 69.07,
      "learning_rate": 3.5992513606336006e-05,
      "loss": 0.2155,
      "step": 69070
    },
    {
      "epoch": 69.08,
      "learning_rate": 3.5971332175025264e-05,
      "loss": 0.2989,
      "step": 69080
    },
    {
      "epoch": 69.09,
      "learning_rate": 3.5950155011830974e-05,
      "loss": 0.2461,
      "step": 69090
    },
    {
      "epoch": 69.1,
      "learning_rate": 3.592898211906903e-05,
      "loss": 0.3085,
      "step": 69100
    },
    {
      "epoch": 69.11,
      "learning_rate": 3.5907813499054836e-05,
      "loss": 0.2573,
      "step": 69110
    },
    {
      "epoch": 69.12,
      "learning_rate": 3.58866491541034e-05,
      "loss": 0.2332,
      "step": 69120
    },
    {
      "epoch": 69.13,
      "learning_rate": 3.586548908652919e-05,
      "loss": 0.3096,
      "step": 69130
    },
    {
      "epoch": 69.14,
      "learning_rate": 3.584433329864628e-05,
      "loss": 0.3557,
      "step": 69140
    },
    {
      "epoch": 69.15,
      "learning_rate": 3.582318179276819e-05,
      "loss": 0.3221,
      "step": 69150
    },
    {
      "epoch": 69.16,
      "learning_rate": 3.5802034571208066e-05,
      "loss": 0.2782,
      "step": 69160
    },
    {
      "epoch": 69.17,
      "learning_rate": 3.578089163627848e-05,
      "loss": 0.1995,
      "step": 69170
    },
    {
      "epoch": 69.18,
      "learning_rate": 3.575975299029165e-05,
      "loss": 0.3275,
      "step": 69180
    },
    {
      "epoch": 69.19,
      "learning_rate": 3.573861863555917e-05,
      "loss": 0.2607,
      "step": 69190
    },
    {
      "epoch": 69.2,
      "learning_rate": 3.571748857439239e-05,
      "loss": 0.3463,
      "step": 69200
    },
    {
      "epoch": 69.21,
      "learning_rate": 3.569636280910198e-05,
      "loss": 0.2441,
      "step": 69210
    },
    {
      "epoch": 69.22,
      "learning_rate": 3.567524134199826e-05,
      "loss": 0.2372,
      "step": 69220
    },
    {
      "epoch": 69.23,
      "learning_rate": 3.5654124175391e-05,
      "loss": 0.1765,
      "step": 69230
    },
    {
      "epoch": 69.24,
      "learning_rate": 3.563301131158958e-05,
      "loss": 0.2511,
      "step": 69240
    },
    {
      "epoch": 69.25,
      "learning_rate": 3.561190275290281e-05,
      "loss": 0.2069,
      "step": 69250
    },
    {
      "epoch": 69.26,
      "learning_rate": 3.559079850163919e-05,
      "loss": 0.2041,
      "step": 69260
    },
    {
      "epoch": 69.27,
      "learning_rate": 3.556969856010656e-05,
      "loss": 0.2085,
      "step": 69270
    },
    {
      "epoch": 69.28,
      "learning_rate": 3.554860293061245e-05,
      "loss": 0.3202,
      "step": 69280
    },
    {
      "epoch": 69.29,
      "learning_rate": 3.552751161546378e-05,
      "loss": 0.2411,
      "step": 69290
    },
    {
      "epoch": 69.3,
      "learning_rate": 3.550642461696709e-05,
      "loss": 0.2917,
      "step": 69300
    },
    {
      "epoch": 69.31,
      "learning_rate": 3.5485341937428435e-05,
      "loss": 0.2703,
      "step": 69310
    },
    {
      "epoch": 69.32,
      "learning_rate": 3.5464263579153395e-05,
      "loss": 0.2585,
      "step": 69320
    },
    {
      "epoch": 69.33,
      "learning_rate": 3.5443189544447025e-05,
      "loss": 0.2023,
      "step": 69330
    },
    {
      "epoch": 69.34,
      "learning_rate": 3.5422119835613974e-05,
      "loss": 0.2218,
      "step": 69340
    },
    {
      "epoch": 69.35,
      "learning_rate": 3.540105445495842e-05,
      "loss": 0.166,
      "step": 69350
    },
    {
      "epoch": 69.36,
      "learning_rate": 3.5379993404783985e-05,
      "loss": 0.2875,
      "step": 69360
    },
    {
      "epoch": 69.37,
      "learning_rate": 3.5358936687393925e-05,
      "loss": 0.2593,
      "step": 69370
    },
    {
      "epoch": 69.38,
      "learning_rate": 3.533788430509091e-05,
      "loss": 0.2521,
      "step": 69380
    },
    {
      "epoch": 69.39,
      "learning_rate": 3.531683626017728e-05,
      "loss": 0.2668,
      "step": 69390
    },
    {
      "epoch": 69.4,
      "learning_rate": 3.529579255495474e-05,
      "loss": 0.2133,
      "step": 69400
    },
    {
      "epoch": 69.41,
      "learning_rate": 3.5274753191724676e-05,
      "loss": 0.19,
      "step": 69410
    },
    {
      "epoch": 69.42,
      "learning_rate": 3.5253718172787844e-05,
      "loss": 0.2618,
      "step": 69420
    },
    {
      "epoch": 69.43,
      "learning_rate": 3.523268750044466e-05,
      "loss": 0.281,
      "step": 69430
    },
    {
      "epoch": 69.44,
      "learning_rate": 3.521166117699493e-05,
      "loss": 0.2081,
      "step": 69440
    },
    {
      "epoch": 69.45,
      "learning_rate": 3.5190639204738165e-05,
      "loss": 0.2269,
      "step": 69450
    },
    {
      "epoch": 69.46,
      "learning_rate": 3.516962158597321e-05,
      "loss": 0.2331,
      "step": 69460
    },
    {
      "epoch": 69.47,
      "learning_rate": 3.514860832299859e-05,
      "loss": 0.3113,
      "step": 69470
    },
    {
      "epoch": 69.48,
      "learning_rate": 3.512759941811222e-05,
      "loss": 0.3928,
      "step": 69480
    },
    {
      "epoch": 69.49,
      "learning_rate": 3.510659487361166e-05,
      "loss": 0.1932,
      "step": 69490
    },
    {
      "epoch": 69.5,
      "learning_rate": 3.508559469179385e-05,
      "loss": 0.2738,
      "step": 69500
    },
    {
      "epoch": 69.51,
      "learning_rate": 3.506459887495545e-05,
      "loss": 0.2043,
      "step": 69510
    },
    {
      "epoch": 69.52,
      "learning_rate": 3.504360742539244e-05,
      "loss": 0.1982,
      "step": 69520
    },
    {
      "epoch": 69.53,
      "learning_rate": 3.502262034540048e-05,
      "loss": 0.2681,
      "step": 69530
    },
    {
      "epoch": 69.54,
      "learning_rate": 3.5001637637274625e-05,
      "loss": 0.2457,
      "step": 69540
    },
    {
      "epoch": 69.55,
      "learning_rate": 3.4980659303309545e-05,
      "loss": 0.1735,
      "step": 69550
    },
    {
      "epoch": 69.56,
      "learning_rate": 3.495968534579942e-05,
      "loss": 0.1801,
      "step": 69560
    },
    {
      "epoch": 69.57,
      "learning_rate": 3.493871576703788e-05,
      "loss": 0.2511,
      "step": 69570
    },
    {
      "epoch": 69.58,
      "learning_rate": 3.491775056931815e-05,
      "loss": 0.2621,
      "step": 69580
    },
    {
      "epoch": 69.59,
      "learning_rate": 3.489678975493296e-05,
      "loss": 0.1884,
      "step": 69590
    },
    {
      "epoch": 69.6,
      "learning_rate": 3.487583332617458e-05,
      "loss": 0.198,
      "step": 69600
    },
    {
      "epoch": 69.61,
      "learning_rate": 3.4854881285334695e-05,
      "loss": 0.2821,
      "step": 69610
    },
    {
      "epoch": 69.62,
      "learning_rate": 3.483393363470468e-05,
      "loss": 0.2654,
      "step": 69620
    },
    {
      "epoch": 69.63,
      "learning_rate": 3.481299037657523e-05,
      "loss": 0.2312,
      "step": 69630
    },
    {
      "epoch": 69.64,
      "learning_rate": 3.479205151323679e-05,
      "loss": 0.1545,
      "step": 69640
    },
    {
      "epoch": 69.65,
      "learning_rate": 3.477111704697912e-05,
      "loss": 0.1321,
      "step": 69650
    },
    {
      "epoch": 69.66,
      "learning_rate": 3.475018698009163e-05,
      "loss": 0.1125,
      "step": 69660
    },
    {
      "epoch": 69.67,
      "learning_rate": 3.472926131486315e-05,
      "loss": 0.177,
      "step": 69670
    },
    {
      "epoch": 69.68,
      "learning_rate": 3.470834005358214e-05,
      "loss": 0.2698,
      "step": 69680
    },
    {
      "epoch": 69.69,
      "learning_rate": 3.4687423198536424e-05,
      "loss": 0.1479,
      "step": 69690
    },
    {
      "epoch": 69.7,
      "learning_rate": 3.4666510752013555e-05,
      "loss": 0.2362,
      "step": 69700
    },
    {
      "epoch": 69.71,
      "learning_rate": 3.46456027163004e-05,
      "loss": 0.3648,
      "step": 69710
    },
    {
      "epoch": 69.72,
      "learning_rate": 3.462469909368349e-05,
      "loss": 0.2471,
      "step": 69720
    },
    {
      "epoch": 69.73,
      "learning_rate": 3.460379988644876e-05,
      "loss": 0.2425,
      "step": 69730
    },
    {
      "epoch": 69.74,
      "learning_rate": 3.4582905096881756e-05,
      "loss": 0.2076,
      "step": 69740
    },
    {
      "epoch": 69.75,
      "learning_rate": 3.4562014727267466e-05,
      "loss": 0.2259,
      "step": 69750
    },
    {
      "epoch": 69.76,
      "learning_rate": 3.454112877989044e-05,
      "loss": 0.1894,
      "step": 69760
    },
    {
      "epoch": 69.77,
      "learning_rate": 3.452024725703475e-05,
      "loss": 0.2915,
      "step": 69770
    },
    {
      "epoch": 69.78,
      "learning_rate": 3.449937016098398e-05,
      "loss": 0.1821,
      "step": 69780
    },
    {
      "epoch": 69.79,
      "learning_rate": 3.447849749402117e-05,
      "loss": 0.4115,
      "step": 69790
    },
    {
      "epoch": 69.8,
      "learning_rate": 3.445762925842896e-05,
      "loss": 0.3447,
      "step": 69800
    },
    {
      "epoch": 69.81,
      "learning_rate": 3.4436765456489474e-05,
      "loss": 0.1547,
      "step": 69810
    },
    {
      "epoch": 69.82,
      "learning_rate": 3.4415906090484315e-05,
      "loss": 0.2428,
      "step": 69820
    },
    {
      "epoch": 69.83,
      "learning_rate": 3.4395051162694644e-05,
      "loss": 0.2795,
      "step": 69830
    },
    {
      "epoch": 69.84,
      "learning_rate": 3.437420067540113e-05,
      "loss": 0.3824,
      "step": 69840
    },
    {
      "epoch": 69.85,
      "learning_rate": 3.435335463088398e-05,
      "loss": 0.2217,
      "step": 69850
    },
    {
      "epoch": 69.86,
      "learning_rate": 3.433251303142283e-05,
      "loss": 0.1775,
      "step": 69860
    },
    {
      "epoch": 69.87,
      "learning_rate": 3.431167587929694e-05,
      "loss": 0.2536,
      "step": 69870
    },
    {
      "epoch": 69.88,
      "learning_rate": 3.429084317678497e-05,
      "loss": 0.2104,
      "step": 69880
    },
    {
      "epoch": 69.89,
      "learning_rate": 3.4270014926165185e-05,
      "loss": 0.2237,
      "step": 69890
    },
    {
      "epoch": 69.9,
      "learning_rate": 3.424919112971533e-05,
      "loss": 0.3358,
      "step": 69900
    },
    {
      "epoch": 69.91,
      "learning_rate": 3.4228371789712696e-05,
      "loss": 0.2598,
      "step": 69910
    },
    {
      "epoch": 69.92,
      "learning_rate": 3.4207556908433993e-05,
      "loss": 0.2959,
      "step": 69920
    },
    {
      "epoch": 69.93,
      "learning_rate": 3.4186746488155565e-05,
      "loss": 0.2348,
      "step": 69930
    },
    {
      "epoch": 69.94,
      "learning_rate": 3.416594053115315e-05,
      "loss": 0.2596,
      "step": 69940
    },
    {
      "epoch": 69.95,
      "learning_rate": 3.414513903970209e-05,
      "loss": 0.2737,
      "step": 69950
    },
    {
      "epoch": 69.96,
      "learning_rate": 3.4124342016077196e-05,
      "loss": 0.2509,
      "step": 69960
    },
    {
      "epoch": 69.97,
      "learning_rate": 3.410354946255283e-05,
      "loss": 0.2592,
      "step": 69970
    },
    {
      "epoch": 69.98,
      "learning_rate": 3.408276138140279e-05,
      "loss": 0.239,
      "step": 69980
    },
    {
      "epoch": 69.99,
      "learning_rate": 3.406197777490046e-05,
      "loss": 0.2536,
      "step": 69990
    },
    {
      "epoch": 70.0,
      "learning_rate": 3.404119864531867e-05,
      "loss": 0.2258,
      "step": 70000
    },
    {
      "epoch": 70.0,
      "eval_accuracy": 0.805,
      "eval_loss": 0.33878594636917114,
      "eval_runtime": 14.8702,
      "eval_samples_per_second": 134.497,
      "eval_steps_per_second": 16.812,
      "step": 70000
    },
    {
      "epoch": 70.01,
      "learning_rate": 3.402042399492982e-05,
      "loss": 0.1941,
      "step": 70010
    },
    {
      "epoch": 70.02,
      "learning_rate": 3.3999653826005785e-05,
      "loss": 0.239,
      "step": 70020
    },
    {
      "epoch": 70.03,
      "learning_rate": 3.3978888140817996e-05,
      "loss": 0.2417,
      "step": 70030
    },
    {
      "epoch": 70.04,
      "learning_rate": 3.395812694163729e-05,
      "loss": 0.1613,
      "step": 70040
    },
    {
      "epoch": 70.05,
      "learning_rate": 3.393737023073412e-05,
      "loss": 0.2808,
      "step": 70050
    },
    {
      "epoch": 70.06,
      "learning_rate": 3.391661801037844e-05,
      "loss": 0.2809,
      "step": 70060
    },
    {
      "epoch": 70.07,
      "learning_rate": 3.3895870282839615e-05,
      "loss": 0.2041,
      "step": 70070
    },
    {
      "epoch": 70.08,
      "learning_rate": 3.387512705038661e-05,
      "loss": 0.2493,
      "step": 70080
    },
    {
      "epoch": 70.09,
      "learning_rate": 3.385438831528789e-05,
      "loss": 0.2223,
      "step": 70090
    },
    {
      "epoch": 70.1,
      "learning_rate": 3.3833654079811424e-05,
      "loss": 0.2554,
      "step": 70100
    },
    {
      "epoch": 70.11,
      "learning_rate": 3.381292434622463e-05,
      "loss": 0.2404,
      "step": 70110
    },
    {
      "epoch": 70.12,
      "learning_rate": 3.379219911679453e-05,
      "loss": 0.2148,
      "step": 70120
    },
    {
      "epoch": 70.13,
      "learning_rate": 3.3771478393787555e-05,
      "loss": 0.3193,
      "step": 70130
    },
    {
      "epoch": 70.14,
      "learning_rate": 3.375076217946971e-05,
      "loss": 0.213,
      "step": 70140
    },
    {
      "epoch": 70.15,
      "learning_rate": 3.373005047610651e-05,
      "loss": 0.3042,
      "step": 70150
    },
    {
      "epoch": 70.16,
      "learning_rate": 3.370934328596296e-05,
      "loss": 0.2191,
      "step": 70160
    },
    {
      "epoch": 70.17,
      "learning_rate": 3.3688640611303526e-05,
      "loss": 0.2204,
      "step": 70170
    },
    {
      "epoch": 70.18,
      "learning_rate": 3.366794245439226e-05,
      "loss": 0.2436,
      "step": 70180
    },
    {
      "epoch": 70.19,
      "learning_rate": 3.364724881749264e-05,
      "loss": 0.2276,
      "step": 70190
    },
    {
      "epoch": 70.2,
      "learning_rate": 3.362655970286773e-05,
      "loss": 0.2359,
      "step": 70200
    },
    {
      "epoch": 70.21,
      "learning_rate": 3.360587511278004e-05,
      "loss": 0.2207,
      "step": 70210
    },
    {
      "epoch": 70.22,
      "learning_rate": 3.358519504949164e-05,
      "loss": 0.1794,
      "step": 70220
    },
    {
      "epoch": 70.23,
      "learning_rate": 3.3564519515264005e-05,
      "loss": 0.2455,
      "step": 70230
    },
    {
      "epoch": 70.24,
      "learning_rate": 3.354384851235826e-05,
      "loss": 0.1961,
      "step": 70240
    },
    {
      "epoch": 70.25,
      "learning_rate": 3.3523182043034886e-05,
      "loss": 0.3277,
      "step": 70250
    },
    {
      "epoch": 70.26,
      "learning_rate": 3.350252010955395e-05,
      "loss": 0.273,
      "step": 70260
    },
    {
      "epoch": 70.27,
      "learning_rate": 3.3481862714175035e-05,
      "loss": 0.2284,
      "step": 70270
    },
    {
      "epoch": 70.28,
      "learning_rate": 3.346120985915722e-05,
      "loss": 0.248,
      "step": 70280
    },
    {
      "epoch": 70.29,
      "learning_rate": 3.3440561546759015e-05,
      "loss": 0.2663,
      "step": 70290
    },
    {
      "epoch": 70.3,
      "learning_rate": 3.341991777923851e-05,
      "loss": 0.2849,
      "step": 70300
    },
    {
      "epoch": 70.31,
      "learning_rate": 3.3399278558853315e-05,
      "loss": 0.2914,
      "step": 70310
    },
    {
      "epoch": 70.32,
      "learning_rate": 3.337864388786044e-05,
      "loss": 0.2737,
      "step": 70320
    },
    {
      "epoch": 70.33,
      "learning_rate": 3.335801376851649e-05,
      "loss": 0.19,
      "step": 70330
    },
    {
      "epoch": 70.34,
      "learning_rate": 3.3337388203077556e-05,
      "loss": 0.2882,
      "step": 70340
    },
    {
      "epoch": 70.35,
      "learning_rate": 3.331676719379923e-05,
      "loss": 0.2358,
      "step": 70350
    },
    {
      "epoch": 70.36,
      "learning_rate": 3.329615074293655e-05,
      "loss": 0.159,
      "step": 70360
    },
    {
      "epoch": 70.37,
      "learning_rate": 3.3275538852744146e-05,
      "loss": 0.1998,
      "step": 70370
    },
    {
      "epoch": 70.38,
      "learning_rate": 3.3254931525476056e-05,
      "loss": 0.358,
      "step": 70380
    },
    {
      "epoch": 70.39,
      "learning_rate": 3.323432876338593e-05,
      "loss": 0.2483,
      "step": 70390
    },
    {
      "epoch": 70.4,
      "learning_rate": 3.3213730568726746e-05,
      "loss": 0.2479,
      "step": 70400
    },
    {
      "epoch": 70.41,
      "learning_rate": 3.3193136943751226e-05,
      "loss": 0.2041,
      "step": 70410
    },
    {
      "epoch": 70.42,
      "learning_rate": 3.3172547890711356e-05,
      "loss": 0.2398,
      "step": 70420
    },
    {
      "epoch": 70.43,
      "learning_rate": 3.3151963411858796e-05,
      "loss": 0.2658,
      "step": 70430
    },
    {
      "epoch": 70.44,
      "learning_rate": 3.313138350944458e-05,
      "loss": 0.2338,
      "step": 70440
    },
    {
      "epoch": 70.45,
      "learning_rate": 3.311080818571933e-05,
      "loss": 0.2702,
      "step": 70450
    },
    {
      "epoch": 70.46,
      "learning_rate": 3.309023744293306e-05,
      "loss": 0.1814,
      "step": 70460
    },
    {
      "epoch": 70.47,
      "learning_rate": 3.306967128333549e-05,
      "loss": 0.175,
      "step": 70470
    },
    {
      "epoch": 70.48,
      "learning_rate": 3.3049109709175584e-05,
      "loss": 0.2279,
      "step": 70480
    },
    {
      "epoch": 70.49,
      "learning_rate": 3.3028552722701995e-05,
      "loss": 0.2037,
      "step": 70490
    },
    {
      "epoch": 70.5,
      "learning_rate": 3.300800032616275e-05,
      "loss": 0.2557,
      "step": 70500
    },
    {
      "epoch": 70.51,
      "learning_rate": 3.298745252180546e-05,
      "loss": 0.3557,
      "step": 70510
    },
    {
      "epoch": 70.52,
      "learning_rate": 3.296690931187719e-05,
      "loss": 0.2619,
      "step": 70520
    },
    {
      "epoch": 70.53,
      "learning_rate": 3.294637069862455e-05,
      "loss": 0.1912,
      "step": 70530
    },
    {
      "epoch": 70.54,
      "learning_rate": 3.2925836684293565e-05,
      "loss": 0.2761,
      "step": 70540
    },
    {
      "epoch": 70.55,
      "learning_rate": 3.2905307271129816e-05,
      "loss": 0.2403,
      "step": 70550
    },
    {
      "epoch": 70.56,
      "learning_rate": 3.2884782461378404e-05,
      "loss": 0.3019,
      "step": 70560
    },
    {
      "epoch": 70.57,
      "learning_rate": 3.286426225728383e-05,
      "loss": 0.253,
      "step": 70570
    },
    {
      "epoch": 70.58,
      "learning_rate": 3.284374666109022e-05,
      "loss": 0.2627,
      "step": 70580
    },
    {
      "epoch": 70.59,
      "learning_rate": 3.282323567504104e-05,
      "loss": 0.2305,
      "step": 70590
    },
    {
      "epoch": 70.6,
      "learning_rate": 3.280272930137945e-05,
      "loss": 0.2216,
      "step": 70600
    },
    {
      "epoch": 70.61,
      "learning_rate": 3.278222754234791e-05,
      "loss": 0.1856,
      "step": 70610
    },
    {
      "epoch": 70.62,
      "learning_rate": 3.2761730400188526e-05,
      "loss": 0.2677,
      "step": 70620
    },
    {
      "epoch": 70.63,
      "learning_rate": 3.2741237877142765e-05,
      "loss": 0.1979,
      "step": 70630
    },
    {
      "epoch": 70.64,
      "learning_rate": 3.272074997545172e-05,
      "loss": 0.2975,
      "step": 70640
    },
    {
      "epoch": 70.65,
      "learning_rate": 3.2700266697355845e-05,
      "loss": 0.3827,
      "step": 70650
    },
    {
      "epoch": 70.66,
      "learning_rate": 3.267978804509526e-05,
      "loss": 0.311,
      "step": 70660
    },
    {
      "epoch": 70.67,
      "learning_rate": 3.26593140209094e-05,
      "loss": 0.1904,
      "step": 70670
    },
    {
      "epoch": 70.68,
      "learning_rate": 3.2638844627037326e-05,
      "loss": 0.2742,
      "step": 70680
    },
    {
      "epoch": 70.69,
      "learning_rate": 3.2618379865717486e-05,
      "loss": 0.2903,
      "step": 70690
    },
    {
      "epoch": 70.7,
      "learning_rate": 3.2597919739187934e-05,
      "loss": 0.17,
      "step": 70700
    },
    {
      "epoch": 70.71,
      "learning_rate": 3.2577464249686074e-05,
      "loss": 0.2391,
      "step": 70710
    },
    {
      "epoch": 70.72,
      "learning_rate": 3.255905827564203e-05,
      "loss": 0.3101,
      "step": 70720
    },
    {
      "epoch": 70.73,
      "learning_rate": 3.253861160265541e-05,
      "loss": 0.3285,
      "step": 70730
    },
    {
      "epoch": 70.74,
      "learning_rate": 3.2518169573182355e-05,
      "loss": 0.2231,
      "step": 70740
    },
    {
      "epoch": 70.75,
      "learning_rate": 3.2497732189458434e-05,
      "loss": 0.2096,
      "step": 70750
    },
    {
      "epoch": 70.76,
      "learning_rate": 3.24772994537186e-05,
      "loss": 0.2696,
      "step": 70760
    },
    {
      "epoch": 70.77,
      "learning_rate": 3.2456871368197346e-05,
      "loss": 0.2202,
      "step": 70770
    },
    {
      "epoch": 70.78,
      "learning_rate": 3.243644793512869e-05,
      "loss": 0.1979,
      "step": 70780
    },
    {
      "epoch": 70.79,
      "learning_rate": 3.241602915674611e-05,
      "loss": 0.364,
      "step": 70790
    },
    {
      "epoch": 70.8,
      "learning_rate": 3.239561503528255e-05,
      "loss": 0.1701,
      "step": 70800
    },
    {
      "epoch": 70.81,
      "learning_rate": 3.2375205572970465e-05,
      "loss": 0.2938,
      "step": 70810
    },
    {
      "epoch": 70.82,
      "learning_rate": 3.2354800772041845e-05,
      "loss": 0.2085,
      "step": 70820
    },
    {
      "epoch": 70.83,
      "learning_rate": 3.233440063472806e-05,
      "loss": 0.1575,
      "step": 70830
    },
    {
      "epoch": 70.84,
      "learning_rate": 3.231400516326011e-05,
      "loss": 0.2807,
      "step": 70840
    },
    {
      "epoch": 70.85,
      "learning_rate": 3.2293614359868314e-05,
      "loss": 0.136,
      "step": 70850
    },
    {
      "epoch": 70.86,
      "learning_rate": 3.22732282267827e-05,
      "loss": 0.1235,
      "step": 70860
    },
    {
      "epoch": 70.87,
      "learning_rate": 3.225284676623259e-05,
      "loss": 0.3014,
      "step": 70870
    },
    {
      "epoch": 70.88,
      "learning_rate": 3.2232469980446907e-05,
      "loss": 0.2456,
      "step": 70880
    },
    {
      "epoch": 70.89,
      "learning_rate": 3.221209787165398e-05,
      "loss": 0.3098,
      "step": 70890
    },
    {
      "epoch": 70.9,
      "learning_rate": 3.2191730442081736e-05,
      "loss": 0.1937,
      "step": 70900
    },
    {
      "epoch": 70.91,
      "learning_rate": 3.217136769395742e-05,
      "loss": 0.1495,
      "step": 70910
    },
    {
      "epoch": 70.92,
      "learning_rate": 3.215100962950801e-05,
      "loss": 0.3524,
      "step": 70920
    },
    {
      "epoch": 70.93,
      "learning_rate": 3.213065625095973e-05,
      "loss": 0.2173,
      "step": 70930
    },
    {
      "epoch": 70.94,
      "learning_rate": 3.211030756053846e-05,
      "loss": 0.2297,
      "step": 70940
    },
    {
      "epoch": 70.95,
      "learning_rate": 3.208996356046944e-05,
      "loss": 0.2089,
      "step": 70950
    },
    {
      "epoch": 70.96,
      "learning_rate": 3.2069624252977524e-05,
      "loss": 0.2832,
      "step": 70960
    },
    {
      "epoch": 70.97,
      "learning_rate": 3.204928964028692e-05,
      "loss": 0.2635,
      "step": 70970
    },
    {
      "epoch": 70.98,
      "learning_rate": 3.202895972462143e-05,
      "loss": 0.2228,
      "step": 70980
    },
    {
      "epoch": 70.99,
      "learning_rate": 3.20086345082043e-05,
      "loss": 0.2056,
      "step": 70990
    },
    {
      "epoch": 71.0,
      "learning_rate": 3.198831399325829e-05,
      "loss": 0.2298,
      "step": 71000
    },
    {
      "epoch": 71.0,
      "eval_accuracy": 0.804,
      "eval_loss": 0.37880194187164307,
      "eval_runtime": 14.9457,
      "eval_samples_per_second": 133.818,
      "eval_steps_per_second": 16.727,
      "step": 71000
    },
    {
      "epoch": 71.01,
      "learning_rate": 3.1967998182005565e-05,
      "loss": 0.1914,
      "step": 71010
    },
    {
      "epoch": 71.02,
      "learning_rate": 3.1947687076667856e-05,
      "loss": 0.1125,
      "step": 71020
    },
    {
      "epoch": 71.03,
      "learning_rate": 3.19273806794664e-05,
      "loss": 0.2202,
      "step": 71030
    },
    {
      "epoch": 71.04,
      "learning_rate": 3.1907078992621795e-05,
      "loss": 0.3037,
      "step": 71040
    },
    {
      "epoch": 71.05,
      "learning_rate": 3.188678201835425e-05,
      "loss": 0.2821,
      "step": 71050
    },
    {
      "epoch": 71.06,
      "learning_rate": 3.18664897588834e-05,
      "loss": 0.3631,
      "step": 71060
    },
    {
      "epoch": 71.07,
      "learning_rate": 3.18462022164284e-05,
      "loss": 0.1874,
      "step": 71070
    },
    {
      "epoch": 71.08,
      "learning_rate": 3.182591939320783e-05,
      "loss": 0.2301,
      "step": 71080
    },
    {
      "epoch": 71.09,
      "learning_rate": 3.1805641291439824e-05,
      "loss": 0.1788,
      "step": 71090
    },
    {
      "epoch": 71.1,
      "learning_rate": 3.1785367913341904e-05,
      "loss": 0.1761,
      "step": 71100
    },
    {
      "epoch": 71.11,
      "learning_rate": 3.176509926113122e-05,
      "loss": 0.1929,
      "step": 71110
    },
    {
      "epoch": 71.12,
      "learning_rate": 3.174483533702424e-05,
      "loss": 0.1685,
      "step": 71120
    },
    {
      "epoch": 71.13,
      "learning_rate": 3.172457614323708e-05,
      "loss": 0.2113,
      "step": 71130
    },
    {
      "epoch": 71.14,
      "learning_rate": 3.170432168198517e-05,
      "loss": 0.2863,
      "step": 71140
    },
    {
      "epoch": 71.15,
      "learning_rate": 3.168407195548358e-05,
      "loss": 0.2401,
      "step": 71150
    },
    {
      "epoch": 71.16,
      "learning_rate": 3.166382696594673e-05,
      "loss": 0.2018,
      "step": 71160
    },
    {
      "epoch": 71.17,
      "learning_rate": 3.164358671558861e-05,
      "loss": 0.2601,
      "step": 71170
    },
    {
      "epoch": 71.18,
      "learning_rate": 3.162335120662265e-05,
      "loss": 0.1519,
      "step": 71180
    },
    {
      "epoch": 71.19,
      "learning_rate": 3.1603120441261824e-05,
      "loss": 0.3237,
      "step": 71190
    },
    {
      "epoch": 71.2,
      "learning_rate": 3.158289442171847e-05,
      "loss": 0.3374,
      "step": 71200
    },
    {
      "epoch": 71.21,
      "learning_rate": 3.156267315020454e-05,
      "loss": 0.3164,
      "step": 71210
    },
    {
      "epoch": 71.22,
      "learning_rate": 3.1542456628931326e-05,
      "loss": 0.2201,
      "step": 71220
    },
    {
      "epoch": 71.23,
      "learning_rate": 3.152224486010972e-05,
      "loss": 0.1695,
      "step": 71230
    },
    {
      "epoch": 71.24,
      "learning_rate": 3.150203784595005e-05,
      "loss": 0.229,
      "step": 71240
    },
    {
      "epoch": 71.25,
      "learning_rate": 3.148183558866215e-05,
      "loss": 0.2569,
      "step": 71250
    },
    {
      "epoch": 71.26,
      "learning_rate": 3.1461638090455266e-05,
      "loss": 0.252,
      "step": 71260
    },
    {
      "epoch": 71.27,
      "learning_rate": 3.144144535353817e-05,
      "loss": 0.1634,
      "step": 71270
    },
    {
      "epoch": 71.28,
      "learning_rate": 3.1421257380119146e-05,
      "loss": 0.2858,
      "step": 71280
    },
    {
      "epoch": 71.29,
      "learning_rate": 3.1401074172405874e-05,
      "loss": 0.2266,
      "step": 71290
    },
    {
      "epoch": 71.3,
      "learning_rate": 3.138089573260558e-05,
      "loss": 0.2031,
      "step": 71300
    },
    {
      "epoch": 71.31,
      "learning_rate": 3.136072206292495e-05,
      "loss": 0.2307,
      "step": 71310
    },
    {
      "epoch": 71.32,
      "learning_rate": 3.134055316557017e-05,
      "loss": 0.4561,
      "step": 71320
    },
    {
      "epoch": 71.33,
      "learning_rate": 3.132038904274682e-05,
      "loss": 0.3012,
      "step": 71330
    },
    {
      "epoch": 71.34,
      "learning_rate": 3.130022969666009e-05,
      "loss": 0.2329,
      "step": 71340
    },
    {
      "epoch": 71.35,
      "learning_rate": 3.1280075129514506e-05,
      "loss": 0.1964,
      "step": 71350
    },
    {
      "epoch": 71.36,
      "learning_rate": 3.125992534351418e-05,
      "loss": 0.29,
      "step": 71360
    },
    {
      "epoch": 71.37,
      "learning_rate": 3.123978034086265e-05,
      "loss": 0.2224,
      "step": 71370
    },
    {
      "epoch": 71.38,
      "learning_rate": 3.121964012376298e-05,
      "loss": 0.2286,
      "step": 71380
    },
    {
      "epoch": 71.39,
      "learning_rate": 3.1199504694417616e-05,
      "loss": 0.2212,
      "step": 71390
    },
    {
      "epoch": 71.4,
      "learning_rate": 3.117937405502859e-05,
      "loss": 0.2277,
      "step": 71400
    },
    {
      "epoch": 71.41,
      "learning_rate": 3.115924820779731e-05,
      "loss": 0.1831,
      "step": 71410
    },
    {
      "epoch": 71.42,
      "learning_rate": 3.1139127154924734e-05,
      "loss": 0.2675,
      "step": 71420
    },
    {
      "epoch": 71.43,
      "learning_rate": 3.111901089861127e-05,
      "loss": 0.2569,
      "step": 71430
    },
    {
      "epoch": 71.44,
      "learning_rate": 3.109889944105682e-05,
      "loss": 0.2788,
      "step": 71440
    },
    {
      "epoch": 71.45,
      "learning_rate": 3.1078792784460695e-05,
      "loss": 0.2411,
      "step": 71450
    },
    {
      "epoch": 71.46,
      "learning_rate": 3.105869093102179e-05,
      "loss": 0.2445,
      "step": 71460
    },
    {
      "epoch": 71.47,
      "learning_rate": 3.103859388293835e-05,
      "loss": 0.2643,
      "step": 71470
    },
    {
      "epoch": 71.48,
      "learning_rate": 3.101850164240819e-05,
      "loss": 0.2394,
      "step": 71480
    },
    {
      "epoch": 71.49,
      "learning_rate": 3.0998414211628556e-05,
      "loss": 0.1876,
      "step": 71490
    },
    {
      "epoch": 71.5,
      "learning_rate": 3.0978331592796224e-05,
      "loss": 0.2369,
      "step": 71500
    },
    {
      "epoch": 71.51,
      "learning_rate": 3.0958253788107335e-05,
      "loss": 0.2456,
      "step": 71510
    },
    {
      "epoch": 71.52,
      "learning_rate": 3.09381807997576e-05,
      "loss": 0.2208,
      "step": 71520
    },
    {
      "epoch": 71.53,
      "learning_rate": 3.091811262994218e-05,
      "loss": 0.1778,
      "step": 71530
    },
    {
      "epoch": 71.54,
      "learning_rate": 3.0898049280855677e-05,
      "loss": 0.2177,
      "step": 71540
    },
    {
      "epoch": 71.55,
      "learning_rate": 3.0877990754692184e-05,
      "loss": 0.1753,
      "step": 71550
    },
    {
      "epoch": 71.56,
      "learning_rate": 3.0857937053645296e-05,
      "loss": 0.3213,
      "step": 71560
    },
    {
      "epoch": 71.57,
      "learning_rate": 3.083788817990807e-05,
      "loss": 0.2321,
      "step": 71570
    },
    {
      "epoch": 71.58,
      "learning_rate": 3.081784413567297e-05,
      "loss": 0.2386,
      "step": 71580
    },
    {
      "epoch": 71.59,
      "learning_rate": 3.079780492313203e-05,
      "loss": 0.1668,
      "step": 71590
    },
    {
      "epoch": 71.6,
      "learning_rate": 3.077777054447666e-05,
      "loss": 0.2782,
      "step": 71600
    },
    {
      "epoch": 71.61,
      "learning_rate": 3.075774100189782e-05,
      "loss": 0.2142,
      "step": 71610
    },
    {
      "epoch": 71.62,
      "learning_rate": 3.073771629758591e-05,
      "loss": 0.2413,
      "step": 71620
    },
    {
      "epoch": 71.63,
      "learning_rate": 3.071769643373082e-05,
      "loss": 0.2793,
      "step": 71630
    },
    {
      "epoch": 71.64,
      "learning_rate": 3.069768141252184e-05,
      "loss": 0.1604,
      "step": 71640
    },
    {
      "epoch": 71.65,
      "learning_rate": 3.0677671236147846e-05,
      "loss": 0.2364,
      "step": 71650
    },
    {
      "epoch": 71.66,
      "learning_rate": 3.065766590679706e-05,
      "loss": 0.3102,
      "step": 71660
    },
    {
      "epoch": 71.67,
      "learning_rate": 3.063766542665728e-05,
      "loss": 0.321,
      "step": 71670
    },
    {
      "epoch": 71.68,
      "learning_rate": 3.0617669797915674e-05,
      "loss": 0.2633,
      "step": 71680
    },
    {
      "epoch": 71.69,
      "learning_rate": 3.059767902275902e-05,
      "loss": 0.197,
      "step": 71690
    },
    {
      "epoch": 71.7,
      "learning_rate": 3.05776931033734e-05,
      "loss": 0.2517,
      "step": 71700
    },
    {
      "epoch": 71.71,
      "learning_rate": 3.0557712041944496e-05,
      "loss": 0.2361,
      "step": 71710
    },
    {
      "epoch": 71.72,
      "learning_rate": 3.053773584065737e-05,
      "loss": 0.1293,
      "step": 71720
    },
    {
      "epoch": 71.73,
      "learning_rate": 3.0517764501696594e-05,
      "loss": 0.287,
      "step": 71730
    },
    {
      "epoch": 71.74,
      "learning_rate": 3.0497798027246217e-05,
      "loss": 0.2242,
      "step": 71740
    },
    {
      "epoch": 71.75,
      "learning_rate": 3.047783641948977e-05,
      "loss": 0.1485,
      "step": 71750
    },
    {
      "epoch": 71.76,
      "learning_rate": 3.0457879680610168e-05,
      "loss": 0.261,
      "step": 71760
    },
    {
      "epoch": 71.77,
      "learning_rate": 3.043792781278987e-05,
      "loss": 0.3384,
      "step": 71770
    },
    {
      "epoch": 71.78,
      "learning_rate": 3.0417980818210823e-05,
      "loss": 0.3262,
      "step": 71780
    },
    {
      "epoch": 71.79,
      "learning_rate": 3.0398038699054336e-05,
      "loss": 0.1967,
      "step": 71790
    },
    {
      "epoch": 71.8,
      "learning_rate": 3.037810145750127e-05,
      "loss": 0.2875,
      "step": 71800
    },
    {
      "epoch": 71.81,
      "learning_rate": 3.0358169095731954e-05,
      "loss": 0.2572,
      "step": 71810
    },
    {
      "epoch": 71.82,
      "learning_rate": 3.0338241615926166e-05,
      "loss": 0.2463,
      "step": 71820
    },
    {
      "epoch": 71.83,
      "learning_rate": 3.0318319020263098e-05,
      "loss": 0.1489,
      "step": 71830
    },
    {
      "epoch": 71.84,
      "learning_rate": 3.0298401310921523e-05,
      "loss": 0.1679,
      "step": 71840
    },
    {
      "epoch": 71.85,
      "learning_rate": 3.0278488490079533e-05,
      "loss": 0.2375,
      "step": 71850
    },
    {
      "epoch": 71.86,
      "learning_rate": 3.0258580559914833e-05,
      "loss": 0.1386,
      "step": 71860
    },
    {
      "epoch": 71.87,
      "learning_rate": 3.0238677522604447e-05,
      "loss": 0.2342,
      "step": 71870
    },
    {
      "epoch": 71.88,
      "learning_rate": 3.021877938032504e-05,
      "loss": 0.1981,
      "step": 71880
    },
    {
      "epoch": 71.89,
      "learning_rate": 3.0198886135252566e-05,
      "loss": 0.2203,
      "step": 71890
    },
    {
      "epoch": 71.9,
      "learning_rate": 3.0178997789562574e-05,
      "loss": 0.2561,
      "step": 71900
    },
    {
      "epoch": 71.91,
      "learning_rate": 3.0159114345429976e-05,
      "loss": 0.2719,
      "step": 71910
    },
    {
      "epoch": 71.92,
      "learning_rate": 3.013923580502923e-05,
      "loss": 0.2363,
      "step": 71920
    },
    {
      "epoch": 71.93,
      "learning_rate": 3.0119362170534168e-05,
      "loss": 0.1513,
      "step": 71930
    },
    {
      "epoch": 71.94,
      "learning_rate": 3.0099493444118222e-05,
      "loss": 0.2808,
      "step": 71940
    },
    {
      "epoch": 71.95,
      "learning_rate": 3.007962962795415e-05,
      "loss": 0.3803,
      "step": 71950
    },
    {
      "epoch": 71.96,
      "learning_rate": 3.005977072421427e-05,
      "loss": 0.2214,
      "step": 71960
    },
    {
      "epoch": 71.97,
      "learning_rate": 3.003991673507027e-05,
      "loss": 0.2561,
      "step": 71970
    },
    {
      "epoch": 71.98,
      "learning_rate": 3.002006766269337e-05,
      "loss": 0.2851,
      "step": 71980
    },
    {
      "epoch": 71.99,
      "learning_rate": 3.0000223509254254e-05,
      "loss": 0.2382,
      "step": 71990
    },
    {
      "epoch": 72.0,
      "learning_rate": 2.9980384276923068e-05,
      "loss": 0.2515,
      "step": 72000
    },
    {
      "epoch": 72.0,
      "eval_accuracy": 0.799,
      "eval_loss": 0.36211875081062317,
      "eval_runtime": 14.3885,
      "eval_samples_per_second": 139.0,
      "eval_steps_per_second": 17.375,
      "step": 72000
    },
    {
      "epoch": 72.01,
      "learning_rate": 2.996054996786934e-05,
      "loss": 0.1909,
      "step": 72010
    },
    {
      "epoch": 72.02,
      "learning_rate": 2.994072058426215e-05,
      "loss": 0.177,
      "step": 72020
    },
    {
      "epoch": 72.03,
      "learning_rate": 2.9920896128270037e-05,
      "loss": 0.2059,
      "step": 72030
    },
    {
      "epoch": 72.04,
      "learning_rate": 2.9901076602060927e-05,
      "loss": 0.2983,
      "step": 72040
    },
    {
      "epoch": 72.05,
      "learning_rate": 2.98812620078023e-05,
      "loss": 0.2214,
      "step": 72050
    },
    {
      "epoch": 72.06,
      "learning_rate": 2.9861452347660967e-05,
      "loss": 0.1257,
      "step": 72060
    },
    {
      "epoch": 72.07,
      "learning_rate": 2.98416476238034e-05,
      "loss": 0.3302,
      "step": 72070
    },
    {
      "epoch": 72.08,
      "learning_rate": 2.9821847838395324e-05,
      "loss": 0.256,
      "step": 72080
    },
    {
      "epoch": 72.09,
      "learning_rate": 2.9802052993602074e-05,
      "loss": 0.2164,
      "step": 72090
    },
    {
      "epoch": 72.1,
      "learning_rate": 2.9782263091588327e-05,
      "loss": 0.2473,
      "step": 72100
    },
    {
      "epoch": 72.11,
      "learning_rate": 2.9762478134518324e-05,
      "loss": 0.2341,
      "step": 72110
    },
    {
      "epoch": 72.12,
      "learning_rate": 2.9742698124555646e-05,
      "loss": 0.2274,
      "step": 72120
    },
    {
      "epoch": 72.13,
      "learning_rate": 2.9722923063863522e-05,
      "loss": 0.1603,
      "step": 72130
    },
    {
      "epoch": 72.14,
      "learning_rate": 2.9703152954604426e-05,
      "loss": 0.2157,
      "step": 72140
    },
    {
      "epoch": 72.15,
      "learning_rate": 2.9683387798940448e-05,
      "loss": 0.2349,
      "step": 72150
    },
    {
      "epoch": 72.16,
      "learning_rate": 2.9663627599033016e-05,
      "loss": 0.2498,
      "step": 72160
    },
    {
      "epoch": 72.17,
      "learning_rate": 2.9643872357043136e-05,
      "loss": 0.2195,
      "step": 72170
    },
    {
      "epoch": 72.18,
      "learning_rate": 2.9624122075131162e-05,
      "loss": 0.1711,
      "step": 72180
    },
    {
      "epoch": 72.19,
      "learning_rate": 2.9604376755456968e-05,
      "loss": 0.2272,
      "step": 72190
    },
    {
      "epoch": 72.2,
      "learning_rate": 2.9584636400179886e-05,
      "loss": 0.2567,
      "step": 72200
    },
    {
      "epoch": 72.21,
      "learning_rate": 2.9564901011458717e-05,
      "loss": 0.1785,
      "step": 72210
    },
    {
      "epoch": 72.22,
      "learning_rate": 2.9545170591451632e-05,
      "loss": 0.2849,
      "step": 72220
    },
    {
      "epoch": 72.23,
      "learning_rate": 2.952544514231634e-05,
      "loss": 0.2528,
      "step": 72230
    },
    {
      "epoch": 72.24,
      "learning_rate": 2.950572466621004e-05,
      "loss": 0.2354,
      "step": 72240
    },
    {
      "epoch": 72.25,
      "learning_rate": 2.9486009165289257e-05,
      "loss": 0.2533,
      "step": 72250
    },
    {
      "epoch": 72.26,
      "learning_rate": 2.9466298641710085e-05,
      "loss": 0.2835,
      "step": 72260
    },
    {
      "epoch": 72.27,
      "learning_rate": 2.9446593097628036e-05,
      "loss": 0.2027,
      "step": 72270
    },
    {
      "epoch": 72.28,
      "learning_rate": 2.9426892535198102e-05,
      "loss": 0.2331,
      "step": 72280
    },
    {
      "epoch": 72.29,
      "learning_rate": 2.940719695657465e-05,
      "loss": 0.178,
      "step": 72290
    },
    {
      "epoch": 72.3,
      "learning_rate": 2.938750636391162e-05,
      "loss": 0.2193,
      "step": 72300
    },
    {
      "epoch": 72.31,
      "learning_rate": 2.9367820759362274e-05,
      "loss": 0.1433,
      "step": 72310
    },
    {
      "epoch": 72.32,
      "learning_rate": 2.9348140145079482e-05,
      "loss": 0.3102,
      "step": 72320
    },
    {
      "epoch": 72.33,
      "learning_rate": 2.9328464523215427e-05,
      "loss": 0.1937,
      "step": 72330
    },
    {
      "epoch": 72.34,
      "learning_rate": 2.9308793895921857e-05,
      "loss": 0.294,
      "step": 72340
    },
    {
      "epoch": 72.35,
      "learning_rate": 2.9289128265349853e-05,
      "loss": 0.292,
      "step": 72350
    },
    {
      "epoch": 72.36,
      "learning_rate": 2.9269467633650092e-05,
      "loss": 0.3363,
      "step": 72360
    },
    {
      "epoch": 72.37,
      "learning_rate": 2.9249812002972562e-05,
      "loss": 0.2614,
      "step": 72370
    },
    {
      "epoch": 72.38,
      "learning_rate": 2.9230161375466815e-05,
      "loss": 0.1396,
      "step": 72380
    },
    {
      "epoch": 72.39,
      "learning_rate": 2.92105157532818e-05,
      "loss": 0.1886,
      "step": 72390
    },
    {
      "epoch": 72.4,
      "learning_rate": 2.919087513856597e-05,
      "loss": 0.19,
      "step": 72400
    },
    {
      "epoch": 72.41,
      "learning_rate": 2.9171239533467133e-05,
      "loss": 0.1753,
      "step": 72410
    },
    {
      "epoch": 72.42,
      "learning_rate": 2.915160894013266e-05,
      "loss": 0.3041,
      "step": 72420
    },
    {
      "epoch": 72.43,
      "learning_rate": 2.913198336070928e-05,
      "loss": 0.1791,
      "step": 72430
    },
    {
      "epoch": 72.44,
      "learning_rate": 2.9112362797343235e-05,
      "loss": 0.2444,
      "step": 72440
    },
    {
      "epoch": 72.45,
      "learning_rate": 2.9092747252180213e-05,
      "loss": 0.3451,
      "step": 72450
    },
    {
      "epoch": 72.46,
      "learning_rate": 2.9073136727365352e-05,
      "loss": 0.2381,
      "step": 72460
    },
    {
      "epoch": 72.47,
      "learning_rate": 2.9053531225043176e-05,
      "loss": 0.2727,
      "step": 72470
    },
    {
      "epoch": 72.48,
      "learning_rate": 2.9033930747357754e-05,
      "loss": 0.259,
      "step": 72480
    },
    {
      "epoch": 72.49,
      "learning_rate": 2.901433529645258e-05,
      "loss": 0.3443,
      "step": 72490
    },
    {
      "epoch": 72.5,
      "learning_rate": 2.8994744874470525e-05,
      "loss": 0.2067,
      "step": 72500
    },
    {
      "epoch": 72.51,
      "learning_rate": 2.8975159483554018e-05,
      "loss": 0.1805,
      "step": 72510
    },
    {
      "epoch": 72.52,
      "learning_rate": 2.895557912584486e-05,
      "loss": 0.22,
      "step": 72520
    },
    {
      "epoch": 72.53,
      "learning_rate": 2.8936003803484375e-05,
      "loss": 0.2009,
      "step": 72530
    },
    {
      "epoch": 72.54,
      "learning_rate": 2.8916433518613225e-05,
      "loss": 0.2923,
      "step": 72540
    },
    {
      "epoch": 72.55,
      "learning_rate": 2.8896868273371654e-05,
      "loss": 0.1756,
      "step": 72550
    },
    {
      "epoch": 72.56,
      "learning_rate": 2.887730806989922e-05,
      "loss": 0.2812,
      "step": 72560
    },
    {
      "epoch": 72.57,
      "learning_rate": 2.8857752910335032e-05,
      "loss": 0.2651,
      "step": 72570
    },
    {
      "epoch": 72.58,
      "learning_rate": 2.883820279681762e-05,
      "loss": 0.2397,
      "step": 72580
    },
    {
      "epoch": 72.59,
      "learning_rate": 2.8818657731484966e-05,
      "loss": 0.1736,
      "step": 72590
    },
    {
      "epoch": 72.6,
      "learning_rate": 2.8799117716474443e-05,
      "loss": 0.223,
      "step": 72600
    },
    {
      "epoch": 72.61,
      "learning_rate": 2.8779582753922978e-05,
      "loss": 0.2082,
      "step": 72610
    },
    {
      "epoch": 72.62,
      "learning_rate": 2.8760052845966822e-05,
      "loss": 0.2573,
      "step": 72620
    },
    {
      "epoch": 72.63,
      "learning_rate": 2.8740527994741765e-05,
      "loss": 0.2421,
      "step": 72630
    },
    {
      "epoch": 72.64,
      "learning_rate": 2.8721008202383012e-05,
      "loss": 0.2698,
      "step": 72640
    },
    {
      "epoch": 72.65,
      "learning_rate": 2.8701493471025258e-05,
      "loss": 0.2398,
      "step": 72650
    },
    {
      "epoch": 72.66,
      "learning_rate": 2.8681983802802534e-05,
      "loss": 0.1876,
      "step": 72660
    },
    {
      "epoch": 72.67,
      "learning_rate": 2.8662479199848453e-05,
      "loss": 0.3191,
      "step": 72670
    },
    {
      "epoch": 72.68,
      "learning_rate": 2.8642979664295956e-05,
      "loss": 0.2593,
      "step": 72680
    },
    {
      "epoch": 72.69,
      "learning_rate": 2.86234851982775e-05,
      "loss": 0.1984,
      "step": 72690
    },
    {
      "epoch": 72.7,
      "learning_rate": 2.8603995803924983e-05,
      "loss": 0.1529,
      "step": 72700
    },
    {
      "epoch": 72.71,
      "learning_rate": 2.858451148336975e-05,
      "loss": 0.2593,
      "step": 72710
    },
    {
      "epoch": 72.72,
      "learning_rate": 2.8565032238742534e-05,
      "loss": 0.2252,
      "step": 72720
    },
    {
      "epoch": 72.73,
      "learning_rate": 2.8545558072173582e-05,
      "loss": 0.2398,
      "step": 72730
    },
    {
      "epoch": 72.74,
      "learning_rate": 2.852608898579258e-05,
      "loss": 0.3436,
      "step": 72740
    },
    {
      "epoch": 72.75,
      "learning_rate": 2.8508571153370058e-05,
      "loss": 0.2341,
      "step": 72750
    },
    {
      "epoch": 72.76,
      "learning_rate": 2.8489111725211325e-05,
      "loss": 0.2625,
      "step": 72760
    },
    {
      "epoch": 72.77,
      "learning_rate": 2.84696573834134e-05,
      "loss": 0.2031,
      "step": 72770
    },
    {
      "epoch": 72.78,
      "learning_rate": 2.8450208130103796e-05,
      "loss": 0.0903,
      "step": 72780
    },
    {
      "epoch": 72.79,
      "learning_rate": 2.8430763967409466e-05,
      "loss": 0.2301,
      "step": 72790
    },
    {
      "epoch": 72.8,
      "learning_rate": 2.8411324897456753e-05,
      "loss": 0.2686,
      "step": 72800
    },
    {
      "epoch": 72.81,
      "learning_rate": 2.8391890922371518e-05,
      "loss": 0.2636,
      "step": 72810
    },
    {
      "epoch": 72.82,
      "learning_rate": 2.8372462044279006e-05,
      "loss": 0.2319,
      "step": 72820
    },
    {
      "epoch": 72.83,
      "learning_rate": 2.8353038265303928e-05,
      "loss": 0.2129,
      "step": 72830
    },
    {
      "epoch": 72.84,
      "learning_rate": 2.833361958757046e-05,
      "loss": 0.3144,
      "step": 72840
    },
    {
      "epoch": 72.85,
      "learning_rate": 2.831420601320222e-05,
      "loss": 0.3577,
      "step": 72850
    },
    {
      "epoch": 72.86,
      "learning_rate": 2.829479754432219e-05,
      "loss": 0.3217,
      "step": 72860
    },
    {
      "epoch": 72.87,
      "learning_rate": 2.8275394183052904e-05,
      "loss": 0.1888,
      "step": 72870
    },
    {
      "epoch": 72.88,
      "learning_rate": 2.825599593151624e-05,
      "loss": 0.181,
      "step": 72880
    },
    {
      "epoch": 72.89,
      "learning_rate": 2.8236602791833574e-05,
      "loss": 0.2113,
      "step": 72890
    },
    {
      "epoch": 72.9,
      "learning_rate": 2.8217214766125725e-05,
      "loss": 0.2009,
      "step": 72900
    },
    {
      "epoch": 72.91,
      "learning_rate": 2.8197831856512958e-05,
      "loss": 0.296,
      "step": 72910
    },
    {
      "epoch": 72.92,
      "learning_rate": 2.817845406511491e-05,
      "loss": 0.2302,
      "step": 72920
    },
    {
      "epoch": 72.93,
      "learning_rate": 2.8159081394050753e-05,
      "loss": 0.2787,
      "step": 72930
    },
    {
      "epoch": 72.94,
      "learning_rate": 2.8139713845439007e-05,
      "loss": 0.4011,
      "step": 72940
    },
    {
      "epoch": 72.95,
      "learning_rate": 2.8120351421397697e-05,
      "loss": 0.2527,
      "step": 72950
    },
    {
      "epoch": 72.96,
      "learning_rate": 2.8100994124044276e-05,
      "loss": 0.1511,
      "step": 72960
    },
    {
      "epoch": 72.97,
      "learning_rate": 2.8081641955495646e-05,
      "loss": 0.2035,
      "step": 72970
    },
    {
      "epoch": 72.98,
      "learning_rate": 2.8062294917868094e-05,
      "loss": 0.2298,
      "step": 72980
    },
    {
      "epoch": 72.99,
      "learning_rate": 2.8042953013277398e-05,
      "loss": 0.2177,
      "step": 72990
    },
    {
      "epoch": 73.0,
      "learning_rate": 2.8023616243838787e-05,
      "loss": 0.2112,
      "step": 73000
    },
    {
      "epoch": 73.0,
      "eval_accuracy": 0.8055,
      "eval_loss": 0.41027092933654785,
      "eval_runtime": 14.9162,
      "eval_samples_per_second": 134.083,
      "eval_steps_per_second": 16.76,
      "step": 73000
    },
    {
      "epoch": 73.01,
      "learning_rate": 2.8004284611666847e-05,
      "loss": 0.2073,
      "step": 73010
    },
    {
      "epoch": 73.02,
      "learning_rate": 2.7984958118875686e-05,
      "loss": 0.2599,
      "step": 73020
    },
    {
      "epoch": 73.03,
      "learning_rate": 2.7965636767578814e-05,
      "loss": 0.2845,
      "step": 73030
    },
    {
      "epoch": 73.04,
      "learning_rate": 2.7946320559889224e-05,
      "loss": 0.2074,
      "step": 73040
    },
    {
      "epoch": 73.05,
      "learning_rate": 2.792700949791924e-05,
      "loss": 0.2669,
      "step": 73050
    },
    {
      "epoch": 73.06,
      "learning_rate": 2.7907703583780764e-05,
      "loss": 0.262,
      "step": 73060
    },
    {
      "epoch": 73.07,
      "learning_rate": 2.788840281958498e-05,
      "loss": 0.1548,
      "step": 73070
    },
    {
      "epoch": 73.08,
      "learning_rate": 2.786910720744264e-05,
      "loss": 0.2437,
      "step": 73080
    },
    {
      "epoch": 73.09,
      "learning_rate": 2.7849816749463875e-05,
      "loss": 0.3046,
      "step": 73090
    },
    {
      "epoch": 73.1,
      "learning_rate": 2.7830531447758288e-05,
      "loss": 0.2738,
      "step": 73100
    },
    {
      "epoch": 73.11,
      "learning_rate": 2.7811251304434834e-05,
      "loss": 0.2059,
      "step": 73110
    },
    {
      "epoch": 73.12,
      "learning_rate": 2.7791976321602024e-05,
      "loss": 0.2579,
      "step": 73120
    },
    {
      "epoch": 73.13,
      "learning_rate": 2.7772706501367674e-05,
      "loss": 0.2809,
      "step": 73130
    },
    {
      "epoch": 73.14,
      "learning_rate": 2.7753441845839166e-05,
      "loss": 0.2492,
      "step": 73140
    },
    {
      "epoch": 73.15,
      "learning_rate": 2.773418235712317e-05,
      "loss": 0.1566,
      "step": 73150
    },
    {
      "epoch": 73.16,
      "learning_rate": 2.771492803732597e-05,
      "loss": 0.2499,
      "step": 73160
    },
    {
      "epoch": 73.17,
      "learning_rate": 2.7695678888553137e-05,
      "loss": 0.1813,
      "step": 73170
    },
    {
      "epoch": 73.18,
      "learning_rate": 2.7676434912909764e-05,
      "loss": 0.1614,
      "step": 73180
    },
    {
      "epoch": 73.19,
      "learning_rate": 2.7657196112500286e-05,
      "loss": 0.1842,
      "step": 73190
    },
    {
      "epoch": 73.2,
      "learning_rate": 2.7637962489428662e-05,
      "loss": 0.1758,
      "step": 73200
    },
    {
      "epoch": 73.21,
      "learning_rate": 2.7618734045798262e-05,
      "loss": 0.2562,
      "step": 73210
    },
    {
      "epoch": 73.22,
      "learning_rate": 2.7599510783711884e-05,
      "loss": 0.2611,
      "step": 73220
    },
    {
      "epoch": 73.23,
      "learning_rate": 2.758029270527172e-05,
      "loss": 0.2759,
      "step": 73230
    },
    {
      "epoch": 73.24,
      "learning_rate": 2.7561079812579454e-05,
      "loss": 0.1574,
      "step": 73240
    },
    {
      "epoch": 73.25,
      "learning_rate": 2.7541872107736206e-05,
      "loss": 0.1527,
      "step": 73250
    },
    {
      "epoch": 73.26,
      "learning_rate": 2.7522669592842434e-05,
      "loss": 0.2954,
      "step": 73260
    },
    {
      "epoch": 73.27,
      "learning_rate": 2.750347226999817e-05,
      "loss": 0.2607,
      "step": 73270
    },
    {
      "epoch": 73.28,
      "learning_rate": 2.7484280141302716e-05,
      "loss": 0.1634,
      "step": 73280
    },
    {
      "epoch": 73.29,
      "learning_rate": 2.7465093208854997e-05,
      "loss": 0.2634,
      "step": 73290
    },
    {
      "epoch": 73.3,
      "learning_rate": 2.744591147475319e-05,
      "loss": 0.1468,
      "step": 73300
    },
    {
      "epoch": 73.31,
      "learning_rate": 2.742673494109503e-05,
      "loss": 0.1975,
      "step": 73310
    },
    {
      "epoch": 73.32,
      "learning_rate": 2.7407563609977587e-05,
      "loss": 0.2384,
      "step": 73320
    },
    {
      "epoch": 73.33,
      "learning_rate": 2.7388397483497464e-05,
      "loss": 0.1433,
      "step": 73330
    },
    {
      "epoch": 73.34,
      "learning_rate": 2.7369236563750554e-05,
      "loss": 0.249,
      "step": 73340
    },
    {
      "epoch": 73.35,
      "learning_rate": 2.7350080852832378e-05,
      "loss": 0.2393,
      "step": 73350
    },
    {
      "epoch": 73.36,
      "learning_rate": 2.7330930352837688e-05,
      "loss": 0.2264,
      "step": 73360
    },
    {
      "epoch": 73.37,
      "learning_rate": 2.7311785065860814e-05,
      "loss": 0.1169,
      "step": 73370
    },
    {
      "epoch": 73.38,
      "learning_rate": 2.72926449939954e-05,
      "loss": 0.222,
      "step": 73380
    },
    {
      "epoch": 73.39,
      "learning_rate": 2.727351013933463e-05,
      "loss": 0.2107,
      "step": 73390
    },
    {
      "epoch": 73.4,
      "learning_rate": 2.7254380503970986e-05,
      "loss": 0.1994,
      "step": 73400
    },
    {
      "epoch": 73.41,
      "learning_rate": 2.7235256089996556e-05,
      "loss": 0.2492,
      "step": 73410
    },
    {
      "epoch": 73.42,
      "learning_rate": 2.721613689950267e-05,
      "loss": 0.2902,
      "step": 73420
    },
    {
      "epoch": 73.43,
      "learning_rate": 2.7197022934580247e-05,
      "loss": 0.2159,
      "step": 73430
    },
    {
      "epoch": 73.44,
      "learning_rate": 2.7177914197319504e-05,
      "loss": 0.2648,
      "step": 73440
    },
    {
      "epoch": 73.45,
      "learning_rate": 2.7158810689810157e-05,
      "loss": 0.1908,
      "step": 73450
    },
    {
      "epoch": 73.46,
      "learning_rate": 2.713971241414137e-05,
      "loss": 0.302,
      "step": 73460
    },
    {
      "epoch": 73.47,
      "learning_rate": 2.712061937240165e-05,
      "loss": 0.1843,
      "step": 73470
    },
    {
      "epoch": 73.48,
      "learning_rate": 2.7101531566679017e-05,
      "loss": 0.2328,
      "step": 73480
    },
    {
      "epoch": 73.49,
      "learning_rate": 2.7082448999060875e-05,
      "loss": 0.2553,
      "step": 73490
    },
    {
      "epoch": 73.5,
      "learning_rate": 2.7063371671634087e-05,
      "loss": 0.1801,
      "step": 73500
    },
    {
      "epoch": 73.51,
      "learning_rate": 2.704429958648488e-05,
      "loss": 0.2485,
      "step": 73510
    },
    {
      "epoch": 73.52,
      "learning_rate": 2.7025232745699e-05,
      "loss": 0.1647,
      "step": 73520
    },
    {
      "epoch": 73.53,
      "learning_rate": 2.7006171151361477e-05,
      "loss": 0.247,
      "step": 73530
    },
    {
      "epoch": 73.54,
      "learning_rate": 2.6987114805556982e-05,
      "loss": 0.2875,
      "step": 73540
    },
    {
      "epoch": 73.55,
      "learning_rate": 2.696806371036939e-05,
      "loss": 0.2337,
      "step": 73550
    },
    {
      "epoch": 73.56,
      "learning_rate": 2.694901786788217e-05,
      "loss": 0.2365,
      "step": 73560
    },
    {
      "epoch": 73.57,
      "learning_rate": 2.692997728017808e-05,
      "loss": 0.1815,
      "step": 73570
    },
    {
      "epoch": 73.58,
      "learning_rate": 2.6910941949339425e-05,
      "loss": 0.2725,
      "step": 73580
    },
    {
      "epoch": 73.59,
      "learning_rate": 2.6891911877447816e-05,
      "loss": 0.2596,
      "step": 73590
    },
    {
      "epoch": 73.6,
      "learning_rate": 2.6872887066584446e-05,
      "loss": 0.1567,
      "step": 73600
    },
    {
      "epoch": 73.61,
      "learning_rate": 2.6853867518829754e-05,
      "loss": 0.2413,
      "step": 73610
    },
    {
      "epoch": 73.62,
      "learning_rate": 2.683485323626375e-05,
      "loss": 0.2536,
      "step": 73620
    },
    {
      "epoch": 73.63,
      "learning_rate": 2.681584422096576e-05,
      "loss": 0.2688,
      "step": 73630
    },
    {
      "epoch": 73.64,
      "learning_rate": 2.6796840475014627e-05,
      "loss": 0.2339,
      "step": 73640
    },
    {
      "epoch": 73.65,
      "learning_rate": 2.6777842000488526e-05,
      "loss": 0.195,
      "step": 73650
    },
    {
      "epoch": 73.66,
      "learning_rate": 2.6758848799465115e-05,
      "loss": 0.1308,
      "step": 73660
    },
    {
      "epoch": 73.67,
      "learning_rate": 2.6739860874021472e-05,
      "loss": 0.1979,
      "step": 73670
    },
    {
      "epoch": 73.68,
      "learning_rate": 2.6720878226234115e-05,
      "loss": 0.1931,
      "step": 73680
    },
    {
      "epoch": 73.69,
      "learning_rate": 2.6701900858178897e-05,
      "loss": 0.214,
      "step": 73690
    },
    {
      "epoch": 73.7,
      "learning_rate": 2.6682928771931193e-05,
      "loss": 0.1948,
      "step": 73700
    },
    {
      "epoch": 73.71,
      "learning_rate": 2.6663961969565774e-05,
      "loss": 0.2495,
      "step": 73710
    },
    {
      "epoch": 73.72,
      "learning_rate": 2.6645000453156772e-05,
      "loss": 0.3891,
      "step": 73720
    },
    {
      "epoch": 73.73,
      "learning_rate": 2.6626044224777834e-05,
      "loss": 0.2232,
      "step": 73730
    },
    {
      "epoch": 73.74,
      "learning_rate": 2.660709328650196e-05,
      "loss": 0.2221,
      "step": 73740
    },
    {
      "epoch": 73.75,
      "learning_rate": 2.6588147640401634e-05,
      "loss": 0.251,
      "step": 73750
    },
    {
      "epoch": 73.76,
      "learning_rate": 2.656920728854867e-05,
      "loss": 0.2321,
      "step": 73760
    },
    {
      "epoch": 73.77,
      "learning_rate": 2.6550272233014412e-05,
      "loss": 0.2441,
      "step": 73770
    },
    {
      "epoch": 73.78,
      "learning_rate": 2.6531342475869486e-05,
      "loss": 0.3081,
      "step": 73780
    },
    {
      "epoch": 73.79,
      "learning_rate": 2.6512418019184124e-05,
      "loss": 0.2526,
      "step": 73790
    },
    {
      "epoch": 73.8,
      "learning_rate": 2.649349886502781e-05,
      "loss": 0.2508,
      "step": 73800
    },
    {
      "epoch": 73.81,
      "learning_rate": 2.647458501546955e-05,
      "loss": 0.1735,
      "step": 73810
    },
    {
      "epoch": 73.82,
      "learning_rate": 2.6455676472577685e-05,
      "loss": 0.2373,
      "step": 73820
    },
    {
      "epoch": 73.83,
      "learning_rate": 2.6436773238420093e-05,
      "loss": 0.1379,
      "step": 73830
    },
    {
      "epoch": 73.84,
      "learning_rate": 2.641787531506393e-05,
      "loss": 0.2389,
      "step": 73840
    },
    {
      "epoch": 73.85,
      "learning_rate": 2.639898270457589e-05,
      "loss": 0.2642,
      "step": 73850
    },
    {
      "epoch": 73.86,
      "learning_rate": 2.6380095409022024e-05,
      "loss": 0.2309,
      "step": 73860
    },
    {
      "epoch": 73.87,
      "learning_rate": 2.6361213430467856e-05,
      "loss": 0.2888,
      "step": 73870
    },
    {
      "epoch": 73.88,
      "learning_rate": 2.6342336770978227e-05,
      "loss": 0.215,
      "step": 73880
    },
    {
      "epoch": 73.89,
      "learning_rate": 2.632346543261753e-05,
      "loss": 0.2286,
      "step": 73890
    },
    {
      "epoch": 73.9,
      "learning_rate": 2.6304599417449434e-05,
      "loss": 0.2215,
      "step": 73900
    },
    {
      "epoch": 73.91,
      "learning_rate": 2.6285738727537133e-05,
      "loss": 0.1892,
      "step": 73910
    },
    {
      "epoch": 73.92,
      "learning_rate": 2.626688336494321e-05,
      "loss": 0.2723,
      "step": 73920
    },
    {
      "epoch": 73.93,
      "learning_rate": 2.6248033331729677e-05,
      "loss": 0.1081,
      "step": 73930
    },
    {
      "epoch": 73.94,
      "learning_rate": 2.6229188629957895e-05,
      "loss": 0.1624,
      "step": 73940
    },
    {
      "epoch": 73.95,
      "learning_rate": 2.621034926168871e-05,
      "loss": 0.2173,
      "step": 73950
    },
    {
      "epoch": 73.96,
      "learning_rate": 2.6191515228982414e-05,
      "loss": 0.3487,
      "step": 73960
    },
    {
      "epoch": 73.97,
      "learning_rate": 2.6172686533898598e-05,
      "loss": 0.2914,
      "step": 73970
    },
    {
      "epoch": 73.98,
      "learning_rate": 2.6153863178496374e-05,
      "loss": 0.2787,
      "step": 73980
    },
    {
      "epoch": 73.99,
      "learning_rate": 2.613504516483423e-05,
      "loss": 0.2592,
      "step": 73990
    },
    {
      "epoch": 74.0,
      "learning_rate": 2.611623249497011e-05,
      "loss": 0.2171,
      "step": 74000
    },
    {
      "epoch": 74.0,
      "eval_accuracy": 0.7965,
      "eval_loss": 0.4172610640525818,
      "eval_runtime": 14.7868,
      "eval_samples_per_second": 135.255,
      "eval_steps_per_second": 16.907,
      "step": 74000
    },
    {
      "epoch": 74.01,
      "learning_rate": 2.609742517096128e-05,
      "loss": 0.2938,
      "step": 74010
    },
    {
      "epoch": 74.02,
      "learning_rate": 2.6078623194864538e-05,
      "loss": 0.3613,
      "step": 74020
    },
    {
      "epoch": 74.03,
      "learning_rate": 2.6059826568735985e-05,
      "loss": 0.2133,
      "step": 74030
    },
    {
      "epoch": 74.04,
      "learning_rate": 2.6041035294631218e-05,
      "loss": 0.2123,
      "step": 74040
    },
    {
      "epoch": 74.05,
      "learning_rate": 2.6022249374605217e-05,
      "loss": 0.2415,
      "step": 74050
    },
    {
      "epoch": 74.06,
      "learning_rate": 2.600346881071242e-05,
      "loss": 0.1577,
      "step": 74060
    },
    {
      "epoch": 74.07,
      "learning_rate": 2.598469360500658e-05,
      "loss": 0.1523,
      "step": 74070
    },
    {
      "epoch": 74.08,
      "learning_rate": 2.596592375954098e-05,
      "loss": 0.1976,
      "step": 74080
    },
    {
      "epoch": 74.09,
      "learning_rate": 2.594715927636821e-05,
      "loss": 0.2064,
      "step": 74090
    },
    {
      "epoch": 74.1,
      "learning_rate": 2.5928400157540356e-05,
      "loss": 0.2533,
      "step": 74100
    },
    {
      "epoch": 74.11,
      "learning_rate": 2.5909646405108875e-05,
      "loss": 0.3235,
      "step": 74110
    },
    {
      "epoch": 74.12,
      "learning_rate": 2.589089802112469e-05,
      "loss": 0.1232,
      "step": 74120
    },
    {
      "epoch": 74.13,
      "learning_rate": 2.5872155007638035e-05,
      "loss": 0.2663,
      "step": 74130
    },
    {
      "epoch": 74.14,
      "learning_rate": 2.585341736669867e-05,
      "loss": 0.3318,
      "step": 74140
    },
    {
      "epoch": 74.15,
      "learning_rate": 2.5834685100355665e-05,
      "loss": 0.1378,
      "step": 74150
    },
    {
      "epoch": 74.16,
      "learning_rate": 2.5815958210657582e-05,
      "loss": 0.2034,
      "step": 74160
    },
    {
      "epoch": 74.17,
      "learning_rate": 2.5797236699652355e-05,
      "loss": 0.2127,
      "step": 74170
    },
    {
      "epoch": 74.18,
      "learning_rate": 2.5778520569387374e-05,
      "loss": 0.2048,
      "step": 74180
    },
    {
      "epoch": 74.19,
      "learning_rate": 2.575980982190936e-05,
      "loss": 0.1571,
      "step": 74190
    },
    {
      "epoch": 74.2,
      "learning_rate": 2.5741104459264504e-05,
      "loss": 0.2629,
      "step": 74200
    },
    {
      "epoch": 74.21,
      "learning_rate": 2.5722404483498438e-05,
      "loss": 0.156,
      "step": 74210
    },
    {
      "epoch": 74.22,
      "learning_rate": 2.5703709896656102e-05,
      "loss": 0.307,
      "step": 74220
    },
    {
      "epoch": 74.23,
      "learning_rate": 2.568502070078194e-05,
      "loss": 0.2358,
      "step": 74230
    },
    {
      "epoch": 74.24,
      "learning_rate": 2.5666336897919763e-05,
      "loss": 0.28,
      "step": 74240
    },
    {
      "epoch": 74.25,
      "learning_rate": 2.5647658490112837e-05,
      "loss": 0.2839,
      "step": 74250
    },
    {
      "epoch": 74.26,
      "learning_rate": 2.562898547940376e-05,
      "loss": 0.1966,
      "step": 74260
    },
    {
      "epoch": 74.27,
      "learning_rate": 2.561031786783462e-05,
      "loss": 0.2875,
      "step": 74270
    },
    {
      "epoch": 74.28,
      "learning_rate": 2.5591655657446843e-05,
      "loss": 0.2248,
      "step": 74280
    },
    {
      "epoch": 74.29,
      "learning_rate": 2.557299885028132e-05,
      "loss": 0.2231,
      "step": 74290
    },
    {
      "epoch": 74.3,
      "learning_rate": 2.5554347448378326e-05,
      "loss": 0.1706,
      "step": 74300
    },
    {
      "epoch": 74.31,
      "learning_rate": 2.553570145377758e-05,
      "loss": 0.2071,
      "step": 74310
    },
    {
      "epoch": 74.32,
      "learning_rate": 2.5517060868518125e-05,
      "loss": 0.1712,
      "step": 74320
    },
    {
      "epoch": 74.33,
      "learning_rate": 2.549842569463853e-05,
      "loss": 0.2468,
      "step": 74330
    },
    {
      "epoch": 74.34,
      "learning_rate": 2.547979593417665e-05,
      "loss": 0.1448,
      "step": 74340
    },
    {
      "epoch": 74.35,
      "learning_rate": 2.5461171589169853e-05,
      "loss": 0.1953,
      "step": 74350
    },
    {
      "epoch": 74.36,
      "learning_rate": 2.5442552661654804e-05,
      "loss": 0.1344,
      "step": 74360
    },
    {
      "epoch": 74.37,
      "learning_rate": 2.542393915366774e-05,
      "loss": 0.2394,
      "step": 74370
    },
    {
      "epoch": 74.38,
      "learning_rate": 2.5405331067244127e-05,
      "loss": 0.3599,
      "step": 74380
    },
    {
      "epoch": 74.39,
      "learning_rate": 2.5386728404418973e-05,
      "loss": 0.2079,
      "step": 74390
    },
    {
      "epoch": 74.4,
      "learning_rate": 2.5368131167226577e-05,
      "loss": 0.1711,
      "step": 74400
    },
    {
      "epoch": 74.41,
      "learning_rate": 2.534953935770073e-05,
      "loss": 0.2107,
      "step": 74410
    },
    {
      "epoch": 74.42,
      "learning_rate": 2.533095297787463e-05,
      "loss": 0.2011,
      "step": 74420
    },
    {
      "epoch": 74.43,
      "learning_rate": 2.5312372029780843e-05,
      "loss": 0.2422,
      "step": 74430
    },
    {
      "epoch": 74.44,
      "learning_rate": 2.5293796515451326e-05,
      "loss": 0.3029,
      "step": 74440
    },
    {
      "epoch": 74.45,
      "learning_rate": 2.5275226436917496e-05,
      "loss": 0.1298,
      "step": 74450
    },
    {
      "epoch": 74.46,
      "learning_rate": 2.5256661796210162e-05,
      "loss": 0.1648,
      "step": 74460
    },
    {
      "epoch": 74.47,
      "learning_rate": 2.5238102595359486e-05,
      "loss": 0.2065,
      "step": 74470
    },
    {
      "epoch": 74.48,
      "learning_rate": 2.5219548836395117e-05,
      "loss": 0.2542,
      "step": 74480
    },
    {
      "epoch": 74.49,
      "learning_rate": 2.5201000521345992e-05,
      "loss": 0.2968,
      "step": 74490
    },
    {
      "epoch": 74.5,
      "learning_rate": 2.5182457652240622e-05,
      "loss": 0.2368,
      "step": 74500
    },
    {
      "epoch": 74.51,
      "learning_rate": 2.516392023110677e-05,
      "loss": 0.2594,
      "step": 74510
    },
    {
      "epoch": 74.52,
      "learning_rate": 2.514538825997169e-05,
      "loss": 0.2539,
      "step": 74520
    },
    {
      "epoch": 74.53,
      "learning_rate": 2.5126861740861977e-05,
      "loss": 0.2549,
      "step": 74530
    },
    {
      "epoch": 74.54,
      "learning_rate": 2.51083406758037e-05,
      "loss": 0.2919,
      "step": 74540
    },
    {
      "epoch": 74.55,
      "learning_rate": 2.508982506682223e-05,
      "loss": 0.2669,
      "step": 74550
    },
    {
      "epoch": 74.56,
      "learning_rate": 2.5071314915942506e-05,
      "loss": 0.2103,
      "step": 74560
    },
    {
      "epoch": 74.57,
      "learning_rate": 2.5052810225188682e-05,
      "loss": 0.1667,
      "step": 74570
    },
    {
      "epoch": 74.58,
      "learning_rate": 2.5034310996584467e-05,
      "loss": 0.18,
      "step": 74580
    },
    {
      "epoch": 74.59,
      "learning_rate": 2.5015817232152857e-05,
      "loss": 0.1244,
      "step": 74590
    },
    {
      "epoch": 74.6,
      "learning_rate": 2.4997328933916344e-05,
      "loss": 0.2585,
      "step": 74600
    },
    {
      "epoch": 74.61,
      "learning_rate": 2.497884610389671e-05,
      "loss": 0.3035,
      "step": 74610
    },
    {
      "epoch": 74.62,
      "learning_rate": 2.4960368744115315e-05,
      "loss": 0.14,
      "step": 74620
    },
    {
      "epoch": 74.63,
      "learning_rate": 2.494189685659273e-05,
      "loss": 0.1723,
      "step": 74630
    },
    {
      "epoch": 74.64,
      "learning_rate": 2.4923430443349077e-05,
      "loss": 0.2557,
      "step": 74640
    },
    {
      "epoch": 74.65,
      "learning_rate": 2.4904969506403745e-05,
      "loss": 0.1897,
      "step": 74650
    },
    {
      "epoch": 74.66,
      "learning_rate": 2.488651404777564e-05,
      "loss": 0.2229,
      "step": 74660
    },
    {
      "epoch": 74.67,
      "learning_rate": 2.4868064069483036e-05,
      "loss": 0.1905,
      "step": 74670
    },
    {
      "epoch": 74.68,
      "learning_rate": 2.4849619573543554e-05,
      "loss": 0.2842,
      "step": 74680
    },
    {
      "epoch": 74.69,
      "learning_rate": 2.4831180561974274e-05,
      "loss": 0.2944,
      "step": 74690
    },
    {
      "epoch": 74.7,
      "learning_rate": 2.481274703679165e-05,
      "loss": 0.2454,
      "step": 74700
    },
    {
      "epoch": 74.71,
      "learning_rate": 2.479431900001159e-05,
      "loss": 0.148,
      "step": 74710
    },
    {
      "epoch": 74.72,
      "learning_rate": 2.4775896453649288e-05,
      "loss": 0.35,
      "step": 74720
    },
    {
      "epoch": 74.73,
      "learning_rate": 2.475747939971947e-05,
      "loss": 0.3229,
      "step": 74730
    },
    {
      "epoch": 74.74,
      "learning_rate": 2.473906784023612e-05,
      "loss": 0.1963,
      "step": 74740
    },
    {
      "epoch": 74.75,
      "learning_rate": 2.4720661777212786e-05,
      "loss": 0.1181,
      "step": 74750
    },
    {
      "epoch": 74.76,
      "learning_rate": 2.4702261212662264e-05,
      "loss": 0.2114,
      "step": 74760
    },
    {
      "epoch": 74.77,
      "learning_rate": 2.4685705407424217e-05,
      "loss": 0.3033,
      "step": 74770
    },
    {
      "epoch": 74.78,
      "learning_rate": 2.466731529551538e-05,
      "loss": 0.1661,
      "step": 74780
    },
    {
      "epoch": 74.79,
      "learning_rate": 2.4648930687913247e-05,
      "loss": 0.263,
      "step": 74790
    },
    {
      "epoch": 74.8,
      "learning_rate": 2.4630551586628372e-05,
      "loss": 0.3494,
      "step": 74800
    },
    {
      "epoch": 74.81,
      "learning_rate": 2.461217799367059e-05,
      "loss": 0.1356,
      "step": 74810
    },
    {
      "epoch": 74.82,
      "learning_rate": 2.4593809911049325e-05,
      "loss": 0.1074,
      "step": 74820
    },
    {
      "epoch": 74.83,
      "learning_rate": 2.4575447340773197e-05,
      "loss": 0.2877,
      "step": 74830
    },
    {
      "epoch": 74.84,
      "learning_rate": 2.4557090284850358e-05,
      "loss": 0.2212,
      "step": 74840
    },
    {
      "epoch": 74.85,
      "learning_rate": 2.4538738745288264e-05,
      "loss": 0.1662,
      "step": 74850
    },
    {
      "epoch": 74.86,
      "learning_rate": 2.4520392724093858e-05,
      "loss": 0.2846,
      "step": 74860
    },
    {
      "epoch": 74.87,
      "learning_rate": 2.4502052223273357e-05,
      "loss": 0.2894,
      "step": 74870
    },
    {
      "epoch": 74.88,
      "learning_rate": 2.4483717244832553e-05,
      "loss": 0.19,
      "step": 74880
    },
    {
      "epoch": 74.89,
      "learning_rate": 2.4465387790776457e-05,
      "loss": 0.1661,
      "step": 74890
    },
    {
      "epoch": 74.9,
      "learning_rate": 2.44470638631096e-05,
      "loss": 0.2276,
      "step": 74900
    },
    {
      "epoch": 74.91,
      "learning_rate": 2.442874546383581e-05,
      "loss": 0.2097,
      "step": 74910
    },
    {
      "epoch": 74.92,
      "learning_rate": 2.441043259495838e-05,
      "loss": 0.3165,
      "step": 74920
    },
    {
      "epoch": 74.93,
      "learning_rate": 2.4392125258480003e-05,
      "loss": 0.2465,
      "step": 74930
    },
    {
      "epoch": 74.94,
      "learning_rate": 2.4373823456402704e-05,
      "loss": 0.2915,
      "step": 74940
    },
    {
      "epoch": 74.95,
      "learning_rate": 2.4355527190727952e-05,
      "loss": 0.2095,
      "step": 74950
    },
    {
      "epoch": 74.96,
      "learning_rate": 2.43372364634566e-05,
      "loss": 0.2194,
      "step": 74960
    },
    {
      "epoch": 74.97,
      "learning_rate": 2.431895127658892e-05,
      "loss": 0.2311,
      "step": 74970
    },
    {
      "epoch": 74.98,
      "learning_rate": 2.430067163212452e-05,
      "loss": 0.1986,
      "step": 74980
    },
    {
      "epoch": 74.99,
      "learning_rate": 2.428239753206246e-05,
      "loss": 0.152,
      "step": 74990
    },
    {
      "epoch": 75.0,
      "learning_rate": 2.42641289784011e-05,
      "loss": 0.2337,
      "step": 75000
    },
    {
      "epoch": 75.0,
      "eval_accuracy": 0.7955,
      "eval_loss": 0.39187130331993103,
      "eval_runtime": 15.2838,
      "eval_samples_per_second": 130.857,
      "eval_steps_per_second": 16.357,
      "step": 75000
    },
    {
      "epoch": 75.01,
      "learning_rate": 2.4245865973138374e-05,
      "loss": 0.2583,
      "step": 75010
    },
    {
      "epoch": 75.02,
      "learning_rate": 2.4227608518271403e-05,
      "loss": 0.1858,
      "step": 75020
    },
    {
      "epoch": 75.03,
      "learning_rate": 2.4209356615796865e-05,
      "loss": 0.2293,
      "step": 75030
    },
    {
      "epoch": 75.04,
      "learning_rate": 2.4191110267710692e-05,
      "loss": 0.2217,
      "step": 75040
    },
    {
      "epoch": 75.05,
      "learning_rate": 2.4172869476008337e-05,
      "loss": 0.2312,
      "step": 75050
    },
    {
      "epoch": 75.06,
      "learning_rate": 2.4154634242684535e-05,
      "loss": 0.1731,
      "step": 75060
    },
    {
      "epoch": 75.07,
      "learning_rate": 2.4136404569733482e-05,
      "loss": 0.1208,
      "step": 75070
    },
    {
      "epoch": 75.08,
      "learning_rate": 2.411818045914876e-05,
      "loss": 0.1176,
      "step": 75080
    },
    {
      "epoch": 75.09,
      "learning_rate": 2.4099961912923342e-05,
      "loss": 0.2085,
      "step": 75090
    },
    {
      "epoch": 75.1,
      "learning_rate": 2.4081748933049544e-05,
      "loss": 0.244,
      "step": 75100
    },
    {
      "epoch": 75.11,
      "learning_rate": 2.406354152151915e-05,
      "loss": 0.178,
      "step": 75110
    },
    {
      "epoch": 75.12,
      "learning_rate": 2.404533968032324e-05,
      "loss": 0.261,
      "step": 75120
    },
    {
      "epoch": 75.13,
      "learning_rate": 2.4027143411452383e-05,
      "loss": 0.2767,
      "step": 75130
    },
    {
      "epoch": 75.14,
      "learning_rate": 2.4008952716896488e-05,
      "loss": 0.2104,
      "step": 75140
    },
    {
      "epoch": 75.15,
      "learning_rate": 2.3990767598644883e-05,
      "loss": 0.267,
      "step": 75150
    },
    {
      "epoch": 75.16,
      "learning_rate": 2.3972588058686216e-05,
      "loss": 0.2751,
      "step": 75160
    },
    {
      "epoch": 75.17,
      "learning_rate": 2.39544140990086e-05,
      "loss": 0.2172,
      "step": 75170
    },
    {
      "epoch": 75.18,
      "learning_rate": 2.3936245721599534e-05,
      "loss": 0.2639,
      "step": 75180
    },
    {
      "epoch": 75.19,
      "learning_rate": 2.3918082928445842e-05,
      "loss": 0.1909,
      "step": 75190
    },
    {
      "epoch": 75.2,
      "learning_rate": 2.38999257215338e-05,
      "loss": 0.2039,
      "step": 75200
    },
    {
      "epoch": 75.21,
      "learning_rate": 2.3881774102849052e-05,
      "loss": 0.294,
      "step": 75210
    },
    {
      "epoch": 75.22,
      "learning_rate": 2.386362807437666e-05,
      "loss": 0.1662,
      "step": 75220
    },
    {
      "epoch": 75.23,
      "learning_rate": 2.3845487638100993e-05,
      "loss": 0.1581,
      "step": 75230
    },
    {
      "epoch": 75.24,
      "learning_rate": 2.382735279600591e-05,
      "loss": 0.2978,
      "step": 75240
    },
    {
      "epoch": 75.25,
      "learning_rate": 2.380922355007457e-05,
      "loss": 0.191,
      "step": 75250
    },
    {
      "epoch": 75.26,
      "learning_rate": 2.3791099902289572e-05,
      "loss": 0.2835,
      "step": 75260
    },
    {
      "epoch": 75.27,
      "learning_rate": 2.37729818546329e-05,
      "loss": 0.1594,
      "step": 75270
    },
    {
      "epoch": 75.28,
      "learning_rate": 2.375486940908594e-05,
      "loss": 0.2384,
      "step": 75280
    },
    {
      "epoch": 75.29,
      "learning_rate": 2.3736762567629388e-05,
      "loss": 0.178,
      "step": 75290
    },
    {
      "epoch": 75.3,
      "learning_rate": 2.371866133224344e-05,
      "loss": 0.1763,
      "step": 75300
    },
    {
      "epoch": 75.31,
      "learning_rate": 2.3700565704907553e-05,
      "loss": 0.2339,
      "step": 75310
    },
    {
      "epoch": 75.32,
      "learning_rate": 2.3682475687600676e-05,
      "loss": 0.2357,
      "step": 75320
    },
    {
      "epoch": 75.33,
      "learning_rate": 2.3664391282301108e-05,
      "loss": 0.1347,
      "step": 75330
    },
    {
      "epoch": 75.34,
      "learning_rate": 2.364631249098655e-05,
      "loss": 0.3464,
      "step": 75340
    },
    {
      "epoch": 75.35,
      "learning_rate": 2.3628239315634023e-05,
      "loss": 0.2511,
      "step": 75350
    },
    {
      "epoch": 75.36,
      "learning_rate": 2.3610171758220035e-05,
      "loss": 0.3666,
      "step": 75360
    },
    {
      "epoch": 75.37,
      "learning_rate": 2.359210982072037e-05,
      "loss": 0.2428,
      "step": 75370
    },
    {
      "epoch": 75.38,
      "learning_rate": 2.3574053505110287e-05,
      "loss": 0.2299,
      "step": 75380
    },
    {
      "epoch": 75.39,
      "learning_rate": 2.35560028133644e-05,
      "loss": 0.2152,
      "step": 75390
    },
    {
      "epoch": 75.4,
      "learning_rate": 2.353795774745672e-05,
      "loss": 0.203,
      "step": 75400
    },
    {
      "epoch": 75.41,
      "learning_rate": 2.3519918309360587e-05,
      "loss": 0.2033,
      "step": 75410
    },
    {
      "epoch": 75.42,
      "learning_rate": 2.3501884501048783e-05,
      "loss": 0.1765,
      "step": 75420
    },
    {
      "epoch": 75.43,
      "learning_rate": 2.3483856324493494e-05,
      "loss": 0.2284,
      "step": 75430
    },
    {
      "epoch": 75.44,
      "learning_rate": 2.3465833781666197e-05,
      "loss": 0.2804,
      "step": 75440
    },
    {
      "epoch": 75.45,
      "learning_rate": 2.3447816874537838e-05,
      "loss": 0.1627,
      "step": 75450
    },
    {
      "epoch": 75.46,
      "learning_rate": 2.3429805605078715e-05,
      "loss": 0.1709,
      "step": 75460
    },
    {
      "epoch": 75.47,
      "learning_rate": 2.3411799975258545e-05,
      "loss": 0.1828,
      "step": 75470
    },
    {
      "epoch": 75.48,
      "learning_rate": 2.3393799987046345e-05,
      "loss": 0.2083,
      "step": 75480
    },
    {
      "epoch": 75.49,
      "learning_rate": 2.3375805642410605e-05,
      "loss": 0.128,
      "step": 75490
    },
    {
      "epoch": 75.5,
      "learning_rate": 2.335781694331913e-05,
      "loss": 0.182,
      "step": 75500
    },
    {
      "epoch": 75.51,
      "learning_rate": 2.3339833891739146e-05,
      "loss": 0.0614,
      "step": 75510
    },
    {
      "epoch": 75.52,
      "learning_rate": 2.3321856489637266e-05,
      "loss": 0.2502,
      "step": 75520
    },
    {
      "epoch": 75.53,
      "learning_rate": 2.3303884738979477e-05,
      "loss": 0.2048,
      "step": 75530
    },
    {
      "epoch": 75.54,
      "learning_rate": 2.3285918641731107e-05,
      "loss": 0.1972,
      "step": 75540
    },
    {
      "epoch": 75.55,
      "learning_rate": 2.326795819985695e-05,
      "loss": 0.3773,
      "step": 75550
    },
    {
      "epoch": 75.56,
      "learning_rate": 2.325000341532108e-05,
      "loss": 0.1555,
      "step": 75560
    },
    {
      "epoch": 75.57,
      "learning_rate": 2.3232054290087027e-05,
      "loss": 0.2529,
      "step": 75570
    },
    {
      "epoch": 75.58,
      "learning_rate": 2.321411082611769e-05,
      "loss": 0.2329,
      "step": 75580
    },
    {
      "epoch": 75.59,
      "learning_rate": 2.3196173025375358e-05,
      "loss": 0.2827,
      "step": 75590
    },
    {
      "epoch": 75.6,
      "learning_rate": 2.3178240889821637e-05,
      "loss": 0.2061,
      "step": 75600
    },
    {
      "epoch": 75.61,
      "learning_rate": 2.3160314421417605e-05,
      "loss": 0.2428,
      "step": 75610
    },
    {
      "epoch": 75.62,
      "learning_rate": 2.3142393622123614e-05,
      "loss": 0.2303,
      "step": 75620
    },
    {
      "epoch": 75.63,
      "learning_rate": 2.3124478493899502e-05,
      "loss": 0.138,
      "step": 75630
    },
    {
      "epoch": 75.64,
      "learning_rate": 2.3106569038704424e-05,
      "loss": 0.1894,
      "step": 75640
    },
    {
      "epoch": 75.65,
      "learning_rate": 2.3088665258496955e-05,
      "loss": 0.1498,
      "step": 75650
    },
    {
      "epoch": 75.66,
      "learning_rate": 2.3070767155234985e-05,
      "loss": 0.3009,
      "step": 75660
    },
    {
      "epoch": 75.67,
      "learning_rate": 2.3052874730875846e-05,
      "loss": 0.1595,
      "step": 75670
    },
    {
      "epoch": 75.68,
      "learning_rate": 2.3034987987376237e-05,
      "loss": 0.193,
      "step": 75680
    },
    {
      "epoch": 75.69,
      "learning_rate": 2.30171069266922e-05,
      "loss": 0.2645,
      "step": 75690
    },
    {
      "epoch": 75.7,
      "learning_rate": 2.29992315507792e-05,
      "loss": 0.16,
      "step": 75700
    },
    {
      "epoch": 75.71,
      "learning_rate": 2.2981361861592044e-05,
      "loss": 0.2252,
      "step": 75710
    },
    {
      "epoch": 75.72,
      "learning_rate": 2.296349786108498e-05,
      "loss": 0.1279,
      "step": 75720
    },
    {
      "epoch": 75.73,
      "learning_rate": 2.2945639551211525e-05,
      "loss": 0.3224,
      "step": 75730
    },
    {
      "epoch": 75.74,
      "learning_rate": 2.292778693392469e-05,
      "loss": 0.2668,
      "step": 75740
    },
    {
      "epoch": 75.75,
      "learning_rate": 2.2909940011176764e-05,
      "loss": 0.2537,
      "step": 75750
    },
    {
      "epoch": 75.76,
      "learning_rate": 2.2892098784919498e-05,
      "loss": 0.323,
      "step": 75760
    },
    {
      "epoch": 75.77,
      "learning_rate": 2.2874263257103926e-05,
      "loss": 0.1604,
      "step": 75770
    },
    {
      "epoch": 75.78,
      "learning_rate": 2.2856433429680607e-05,
      "loss": 0.1691,
      "step": 75780
    },
    {
      "epoch": 75.79,
      "learning_rate": 2.2838609304599302e-05,
      "loss": 0.143,
      "step": 75790
    },
    {
      "epoch": 75.8,
      "learning_rate": 2.2820790883809284e-05,
      "loss": 0.3061,
      "step": 75800
    },
    {
      "epoch": 75.81,
      "learning_rate": 2.28029781692591e-05,
      "loss": 0.1724,
      "step": 75810
    },
    {
      "epoch": 75.82,
      "learning_rate": 2.278517116289677e-05,
      "loss": 0.1383,
      "step": 75820
    },
    {
      "epoch": 75.83,
      "learning_rate": 2.276736986666957e-05,
      "loss": 0.2161,
      "step": 75830
    },
    {
      "epoch": 75.84,
      "learning_rate": 2.2749574282524318e-05,
      "loss": 0.2583,
      "step": 75840
    },
    {
      "epoch": 75.85,
      "learning_rate": 2.2731784412407045e-05,
      "loss": 0.3783,
      "step": 75850
    },
    {
      "epoch": 75.86,
      "learning_rate": 2.2714000258263266e-05,
      "loss": 0.2919,
      "step": 75860
    },
    {
      "epoch": 75.87,
      "learning_rate": 2.2696221822037783e-05,
      "loss": 0.2199,
      "step": 75870
    },
    {
      "epoch": 75.88,
      "learning_rate": 2.267844910567484e-05,
      "loss": 0.1929,
      "step": 75880
    },
    {
      "epoch": 75.89,
      "learning_rate": 2.2660682111118046e-05,
      "loss": 0.1693,
      "step": 75890
    },
    {
      "epoch": 75.9,
      "learning_rate": 2.2642920840310387e-05,
      "loss": 0.18,
      "step": 75900
    },
    {
      "epoch": 75.91,
      "learning_rate": 2.2625165295194163e-05,
      "loss": 0.2808,
      "step": 75910
    },
    {
      "epoch": 75.92,
      "learning_rate": 2.2607415477711113e-05,
      "loss": 0.3148,
      "step": 75920
    },
    {
      "epoch": 75.93,
      "learning_rate": 2.2589671389802372e-05,
      "loss": 0.2183,
      "step": 75930
    },
    {
      "epoch": 75.94,
      "learning_rate": 2.2571933033408335e-05,
      "loss": 0.2312,
      "step": 75940
    },
    {
      "epoch": 75.95,
      "learning_rate": 2.2554200410468902e-05,
      "loss": 0.2037,
      "step": 75950
    },
    {
      "epoch": 75.96,
      "learning_rate": 2.2536473522923216e-05,
      "loss": 0.1211,
      "step": 75960
    },
    {
      "epoch": 75.97,
      "learning_rate": 2.2518752372709954e-05,
      "loss": 0.2455,
      "step": 75970
    },
    {
      "epoch": 75.98,
      "learning_rate": 2.2501036961767004e-05,
      "loss": 0.3041,
      "step": 75980
    },
    {
      "epoch": 75.99,
      "learning_rate": 2.248332729203175e-05,
      "loss": 0.2933,
      "step": 75990
    },
    {
      "epoch": 76.0,
      "learning_rate": 2.246562336544084e-05,
      "loss": 0.2496,
      "step": 76000
    },
    {
      "epoch": 76.0,
      "eval_accuracy": 0.801,
      "eval_loss": 0.4111284017562866,
      "eval_runtime": 14.9576,
      "eval_samples_per_second": 133.711,
      "eval_steps_per_second": 16.714,
      "step": 76000
    },
    {
      "epoch": 76.01,
      "learning_rate": 2.2447925183930396e-05,
      "loss": 0.1658,
      "step": 76010
    },
    {
      "epoch": 76.02,
      "learning_rate": 2.2430232749435793e-05,
      "loss": 0.1676,
      "step": 76020
    },
    {
      "epoch": 76.03,
      "learning_rate": 2.2412546063891944e-05,
      "loss": 0.1993,
      "step": 76030
    },
    {
      "epoch": 76.04,
      "learning_rate": 2.2394865129232974e-05,
      "loss": 0.195,
      "step": 76040
    },
    {
      "epoch": 76.05,
      "learning_rate": 2.2377189947392494e-05,
      "loss": 0.1988,
      "step": 76050
    },
    {
      "epoch": 76.06,
      "learning_rate": 2.235952052030337e-05,
      "loss": 0.3557,
      "step": 76060
    },
    {
      "epoch": 76.07,
      "learning_rate": 2.234185684989797e-05,
      "loss": 0.2566,
      "step": 76070
    },
    {
      "epoch": 76.08,
      "learning_rate": 2.2324198938107875e-05,
      "loss": 0.1642,
      "step": 76080
    },
    {
      "epoch": 76.09,
      "learning_rate": 2.230654678686425e-05,
      "loss": 0.1482,
      "step": 76090
    },
    {
      "epoch": 76.1,
      "learning_rate": 2.228890039809741e-05,
      "loss": 0.313,
      "step": 76100
    },
    {
      "epoch": 76.11,
      "learning_rate": 2.2271259773737203e-05,
      "loss": 0.2845,
      "step": 76110
    },
    {
      "epoch": 76.12,
      "learning_rate": 2.2253624915712725e-05,
      "loss": 0.2366,
      "step": 76120
    },
    {
      "epoch": 76.13,
      "learning_rate": 2.223599582595252e-05,
      "loss": 0.2169,
      "step": 76130
    },
    {
      "epoch": 76.14,
      "learning_rate": 2.2218372506384506e-05,
      "loss": 0.1842,
      "step": 76140
    },
    {
      "epoch": 76.15,
      "learning_rate": 2.2200754958935893e-05,
      "loss": 0.1744,
      "step": 76150
    },
    {
      "epoch": 76.16,
      "learning_rate": 2.2183143185533343e-05,
      "loss": 0.1059,
      "step": 76160
    },
    {
      "epoch": 76.17,
      "learning_rate": 2.216553718810284e-05,
      "loss": 0.1754,
      "step": 76170
    },
    {
      "epoch": 76.18,
      "learning_rate": 2.2147936968569775e-05,
      "loss": 0.209,
      "step": 76180
    },
    {
      "epoch": 76.19,
      "learning_rate": 2.2130342528858843e-05,
      "loss": 0.2467,
      "step": 76190
    },
    {
      "epoch": 76.2,
      "learning_rate": 2.211275387089419e-05,
      "loss": 0.1346,
      "step": 76200
    },
    {
      "epoch": 76.21,
      "learning_rate": 2.209517099659921e-05,
      "loss": 0.1048,
      "step": 76210
    },
    {
      "epoch": 76.22,
      "learning_rate": 2.2077593907896833e-05,
      "loss": 0.2786,
      "step": 76220
    },
    {
      "epoch": 76.23,
      "learning_rate": 2.2060022606709198e-05,
      "loss": 0.2624,
      "step": 76230
    },
    {
      "epoch": 76.24,
      "learning_rate": 2.2042457094957916e-05,
      "loss": 0.1703,
      "step": 76240
    },
    {
      "epoch": 76.25,
      "learning_rate": 2.2024897374563887e-05,
      "loss": 0.1791,
      "step": 76250
    },
    {
      "epoch": 76.26,
      "learning_rate": 2.200734344744745e-05,
      "loss": 0.266,
      "step": 76260
    },
    {
      "epoch": 76.27,
      "learning_rate": 2.1989795315528244e-05,
      "loss": 0.2009,
      "step": 76270
    },
    {
      "epoch": 76.28,
      "learning_rate": 2.1972252980725316e-05,
      "loss": 0.326,
      "step": 76280
    },
    {
      "epoch": 76.29,
      "learning_rate": 2.1954716444957082e-05,
      "loss": 0.1913,
      "step": 76290
    },
    {
      "epoch": 76.3,
      "learning_rate": 2.1937185710141333e-05,
      "loss": 0.265,
      "step": 76300
    },
    {
      "epoch": 76.31,
      "learning_rate": 2.1919660778195146e-05,
      "loss": 0.123,
      "step": 76310
    },
    {
      "epoch": 76.32,
      "learning_rate": 2.1902141651035073e-05,
      "loss": 0.3022,
      "step": 76320
    },
    {
      "epoch": 76.33,
      "learning_rate": 2.188462833057694e-05,
      "loss": 0.2021,
      "step": 76330
    },
    {
      "epoch": 76.34,
      "learning_rate": 2.1867120818735983e-05,
      "loss": 0.18,
      "step": 76340
    },
    {
      "epoch": 76.35,
      "learning_rate": 2.1849619117426817e-05,
      "loss": 0.1999,
      "step": 76350
    },
    {
      "epoch": 76.36,
      "learning_rate": 2.1832123228563425e-05,
      "loss": 0.0918,
      "step": 76360
    },
    {
      "epoch": 76.37,
      "learning_rate": 2.181463315405907e-05,
      "loss": 0.2693,
      "step": 76370
    },
    {
      "epoch": 76.38,
      "learning_rate": 2.179714889582647e-05,
      "loss": 0.3115,
      "step": 76380
    },
    {
      "epoch": 76.39,
      "learning_rate": 2.1779670455777694e-05,
      "loss": 0.1702,
      "step": 76390
    },
    {
      "epoch": 76.4,
      "learning_rate": 2.1762197835824128e-05,
      "loss": 0.0699,
      "step": 76400
    },
    {
      "epoch": 76.41,
      "learning_rate": 2.1744731037876562e-05,
      "loss": 0.3427,
      "step": 76410
    },
    {
      "epoch": 76.42,
      "learning_rate": 2.1727270063845138e-05,
      "loss": 0.1504,
      "step": 76420
    },
    {
      "epoch": 76.43,
      "learning_rate": 2.1709814915639392e-05,
      "loss": 0.2102,
      "step": 76430
    },
    {
      "epoch": 76.44,
      "learning_rate": 2.1692365595168144e-05,
      "loss": 0.4061,
      "step": 76440
    },
    {
      "epoch": 76.45,
      "learning_rate": 2.167492210433967e-05,
      "loss": 0.2462,
      "step": 76450
    },
    {
      "epoch": 76.46,
      "learning_rate": 2.1657484445061516e-05,
      "loss": 0.1297,
      "step": 76460
    },
    {
      "epoch": 76.47,
      "learning_rate": 2.164005261924067e-05,
      "loss": 0.2136,
      "step": 76470
    },
    {
      "epoch": 76.48,
      "learning_rate": 2.162262662878344e-05,
      "loss": 0.203,
      "step": 76480
    },
    {
      "epoch": 76.49,
      "learning_rate": 2.160520647559553e-05,
      "loss": 0.2206,
      "step": 76490
    },
    {
      "epoch": 76.5,
      "learning_rate": 2.1587792161581945e-05,
      "loss": 0.2487,
      "step": 76500
    },
    {
      "epoch": 76.51,
      "learning_rate": 2.1570383688647123e-05,
      "loss": 0.3186,
      "step": 76510
    },
    {
      "epoch": 76.52,
      "learning_rate": 2.1552981058694792e-05,
      "loss": 0.2583,
      "step": 76520
    },
    {
      "epoch": 76.53,
      "learning_rate": 2.153558427362809e-05,
      "loss": 0.1298,
      "step": 76530
    },
    {
      "epoch": 76.54,
      "learning_rate": 2.1518193335349516e-05,
      "loss": 0.3306,
      "step": 76540
    },
    {
      "epoch": 76.55,
      "learning_rate": 2.1500808245760932e-05,
      "loss": 0.2063,
      "step": 76550
    },
    {
      "epoch": 76.56,
      "learning_rate": 2.1483429006763498e-05,
      "loss": 0.1517,
      "step": 76560
    },
    {
      "epoch": 76.57,
      "learning_rate": 2.146605562025783e-05,
      "loss": 0.1609,
      "step": 76570
    },
    {
      "epoch": 76.58,
      "learning_rate": 2.1448688088143808e-05,
      "loss": 0.2314,
      "step": 76580
    },
    {
      "epoch": 76.59,
      "learning_rate": 2.1431326412320748e-05,
      "loss": 0.3087,
      "step": 76590
    },
    {
      "epoch": 76.6,
      "learning_rate": 2.1413970594687287e-05,
      "loss": 0.1968,
      "step": 76600
    },
    {
      "epoch": 76.61,
      "learning_rate": 2.139662063714146e-05,
      "loss": 0.2104,
      "step": 76610
    },
    {
      "epoch": 76.62,
      "learning_rate": 2.1379276541580586e-05,
      "loss": 0.1348,
      "step": 76620
    },
    {
      "epoch": 76.63,
      "learning_rate": 2.136193830990142e-05,
      "loss": 0.3381,
      "step": 76630
    },
    {
      "epoch": 76.64,
      "learning_rate": 2.134460594400005e-05,
      "loss": 0.2587,
      "step": 76640
    },
    {
      "epoch": 76.65,
      "learning_rate": 2.1327279445771882e-05,
      "loss": 0.2602,
      "step": 76650
    },
    {
      "epoch": 76.66,
      "learning_rate": 2.130995881711174e-05,
      "loss": 0.2993,
      "step": 76660
    },
    {
      "epoch": 76.67,
      "learning_rate": 2.129264405991378e-05,
      "loss": 0.1975,
      "step": 76670
    },
    {
      "epoch": 76.68,
      "learning_rate": 2.127533517607154e-05,
      "loss": 0.233,
      "step": 76680
    },
    {
      "epoch": 76.69,
      "learning_rate": 2.1258032167477858e-05,
      "loss": 0.2401,
      "step": 76690
    },
    {
      "epoch": 76.7,
      "learning_rate": 2.1240735036024986e-05,
      "loss": 0.1206,
      "step": 76700
    },
    {
      "epoch": 76.71,
      "learning_rate": 2.1223443783604493e-05,
      "loss": 0.1929,
      "step": 76710
    },
    {
      "epoch": 76.72,
      "learning_rate": 2.120615841210733e-05,
      "loss": 0.2538,
      "step": 76720
    },
    {
      "epoch": 76.73,
      "learning_rate": 2.118887892342381e-05,
      "loss": 0.2393,
      "step": 76730
    },
    {
      "epoch": 76.74,
      "learning_rate": 2.117160531944361e-05,
      "loss": 0.1825,
      "step": 76740
    },
    {
      "epoch": 76.75,
      "learning_rate": 2.1154337602055687e-05,
      "loss": 0.2316,
      "step": 76750
    },
    {
      "epoch": 76.76,
      "learning_rate": 2.113707577314849e-05,
      "loss": 0.3078,
      "step": 76760
    },
    {
      "epoch": 76.77,
      "learning_rate": 2.1119819834609663e-05,
      "loss": 0.2077,
      "step": 76770
    },
    {
      "epoch": 76.78,
      "learning_rate": 2.110256978832634e-05,
      "loss": 0.2291,
      "step": 76780
    },
    {
      "epoch": 76.79,
      "learning_rate": 2.1085325636184957e-05,
      "loss": 0.1096,
      "step": 76790
    },
    {
      "epoch": 76.8,
      "learning_rate": 2.1068087380071317e-05,
      "loss": 0.2278,
      "step": 76800
    },
    {
      "epoch": 76.81,
      "learning_rate": 2.1050855021870542e-05,
      "loss": 0.2285,
      "step": 76810
    },
    {
      "epoch": 76.82,
      "learning_rate": 2.103362856346717e-05,
      "loss": 0.2357,
      "step": 76820
    },
    {
      "epoch": 76.83,
      "learning_rate": 2.101640800674501e-05,
      "loss": 0.1929,
      "step": 76830
    },
    {
      "epoch": 76.84,
      "learning_rate": 2.099919335358731e-05,
      "loss": 0.1977,
      "step": 76840
    },
    {
      "epoch": 76.85,
      "learning_rate": 2.098198460587664e-05,
      "loss": 0.231,
      "step": 76850
    },
    {
      "epoch": 76.86,
      "learning_rate": 2.096478176549492e-05,
      "loss": 0.192,
      "step": 76860
    },
    {
      "epoch": 76.87,
      "learning_rate": 2.0947584834323447e-05,
      "loss": 0.1413,
      "step": 76870
    },
    {
      "epoch": 76.88,
      "learning_rate": 2.0930393814242807e-05,
      "loss": 0.1534,
      "step": 76880
    },
    {
      "epoch": 76.89,
      "learning_rate": 2.0913208707133032e-05,
      "loss": 0.1957,
      "step": 76890
    },
    {
      "epoch": 76.9,
      "learning_rate": 2.0896029514873406e-05,
      "loss": 0.2422,
      "step": 76900
    },
    {
      "epoch": 76.91,
      "learning_rate": 2.0878856239342645e-05,
      "loss": 0.177,
      "step": 76910
    },
    {
      "epoch": 76.92,
      "learning_rate": 2.0861688882418807e-05,
      "loss": 0.2662,
      "step": 76920
    },
    {
      "epoch": 76.93,
      "learning_rate": 2.0844527445979293e-05,
      "loss": 0.2109,
      "step": 76930
    },
    {
      "epoch": 76.94,
      "learning_rate": 2.082737193190081e-05,
      "loss": 0.2749,
      "step": 76940
    },
    {
      "epoch": 76.95,
      "learning_rate": 2.0810222342059517e-05,
      "loss": 0.2554,
      "step": 76950
    },
    {
      "epoch": 76.96,
      "learning_rate": 2.079307867833081e-05,
      "loss": 0.2085,
      "step": 76960
    },
    {
      "epoch": 76.97,
      "learning_rate": 2.0775940942589538e-05,
      "loss": 0.2491,
      "step": 76970
    },
    {
      "epoch": 76.98,
      "learning_rate": 2.0758809136709796e-05,
      "loss": 0.3065,
      "step": 76980
    },
    {
      "epoch": 76.99,
      "learning_rate": 2.0741683262565186e-05,
      "loss": 0.232,
      "step": 76990
    },
    {
      "epoch": 77.0,
      "learning_rate": 2.072456332202849e-05,
      "loss": 0.1957,
      "step": 77000
    },
    {
      "epoch": 77.0,
      "eval_accuracy": 0.797,
      "eval_loss": 0.4254101514816284,
      "eval_runtime": 15.1514,
      "eval_samples_per_second": 132.001,
      "eval_steps_per_second": 16.5,
      "step": 77000
    },
    {
      "epoch": 77.01,
      "learning_rate": 2.0707449316971975e-05,
      "loss": 0.2018,
      "step": 77010
    },
    {
      "epoch": 77.02,
      "learning_rate": 2.0690341249267152e-05,
      "loss": 0.1348,
      "step": 77020
    },
    {
      "epoch": 77.03,
      "learning_rate": 2.0673239120784978e-05,
      "loss": 0.1867,
      "step": 77030
    },
    {
      "epoch": 77.04,
      "learning_rate": 2.0656142933395646e-05,
      "loss": 0.1287,
      "step": 77040
    },
    {
      "epoch": 77.05,
      "learning_rate": 2.0639052688968863e-05,
      "loss": 0.1808,
      "step": 77050
    },
    {
      "epoch": 77.06,
      "learning_rate": 2.062196838937353e-05,
      "loss": 0.1858,
      "step": 77060
    },
    {
      "epoch": 77.07,
      "learning_rate": 2.060659760411281e-05,
      "loss": 0.1736,
      "step": 77070
    },
    {
      "epoch": 77.08,
      "learning_rate": 2.0589524604843953e-05,
      "loss": 0.2153,
      "step": 77080
    },
    {
      "epoch": 77.09,
      "learning_rate": 2.0572457555822856e-05,
      "loss": 0.2238,
      "step": 77090
    },
    {
      "epoch": 77.1,
      "learning_rate": 2.055539645891597e-05,
      "loss": 0.3536,
      "step": 77100
    },
    {
      "epoch": 77.11,
      "learning_rate": 2.0538341315989075e-05,
      "loss": 0.2101,
      "step": 77110
    },
    {
      "epoch": 77.12,
      "learning_rate": 2.0521292128907306e-05,
      "loss": 0.2035,
      "step": 77120
    },
    {
      "epoch": 77.13,
      "learning_rate": 2.0504248899535106e-05,
      "loss": 0.216,
      "step": 77130
    },
    {
      "epoch": 77.14,
      "learning_rate": 2.0487211629736314e-05,
      "loss": 0.2277,
      "step": 77140
    },
    {
      "epoch": 77.15,
      "learning_rate": 2.0470180321374117e-05,
      "loss": 0.197,
      "step": 77150
    },
    {
      "epoch": 77.16,
      "learning_rate": 2.0453154976311e-05,
      "loss": 0.1366,
      "step": 77160
    },
    {
      "epoch": 77.17,
      "learning_rate": 2.0436135596408836e-05,
      "loss": 0.2812,
      "step": 77170
    },
    {
      "epoch": 77.18,
      "learning_rate": 2.041912218352885e-05,
      "loss": 0.2636,
      "step": 77180
    },
    {
      "epoch": 77.19,
      "learning_rate": 2.040211473953163e-05,
      "loss": 0.0798,
      "step": 77190
    },
    {
      "epoch": 77.2,
      "learning_rate": 2.0385113266277026e-05,
      "loss": 0.2487,
      "step": 77200
    },
    {
      "epoch": 77.21,
      "learning_rate": 2.0368117765624352e-05,
      "loss": 0.2538,
      "step": 77210
    },
    {
      "epoch": 77.22,
      "learning_rate": 2.035112823943215e-05,
      "loss": 0.2666,
      "step": 77220
    },
    {
      "epoch": 77.23,
      "learning_rate": 2.0334144689558426e-05,
      "loss": 0.1961,
      "step": 77230
    },
    {
      "epoch": 77.24,
      "learning_rate": 2.0317167117860405e-05,
      "loss": 0.197,
      "step": 77240
    },
    {
      "epoch": 77.25,
      "learning_rate": 2.030019552619482e-05,
      "loss": 0.3037,
      "step": 77250
    },
    {
      "epoch": 77.26,
      "learning_rate": 2.0283229916417595e-05,
      "loss": 0.328,
      "step": 77260
    },
    {
      "epoch": 77.27,
      "learning_rate": 2.0266270290384095e-05,
      "loss": 0.1191,
      "step": 77270
    },
    {
      "epoch": 77.28,
      "learning_rate": 2.0249316649948963e-05,
      "loss": 0.1599,
      "step": 77280
    },
    {
      "epoch": 77.29,
      "learning_rate": 2.0232368996966272e-05,
      "loss": 0.1682,
      "step": 77290
    },
    {
      "epoch": 77.3,
      "learning_rate": 2.0215427333289325e-05,
      "loss": 0.2745,
      "step": 77300
    },
    {
      "epoch": 77.31,
      "learning_rate": 2.0198491660770912e-05,
      "loss": 0.1843,
      "step": 77310
    },
    {
      "epoch": 77.32,
      "learning_rate": 2.0181561981263038e-05,
      "loss": 0.1702,
      "step": 77320
    },
    {
      "epoch": 77.33,
      "learning_rate": 2.0164638296617156e-05,
      "loss": 0.1734,
      "step": 77330
    },
    {
      "epoch": 77.34,
      "learning_rate": 2.0147720608683956e-05,
      "loss": 0.2009,
      "step": 77340
    },
    {
      "epoch": 77.35,
      "learning_rate": 2.013080891931357e-05,
      "loss": 0.2649,
      "step": 77350
    },
    {
      "epoch": 77.36,
      "learning_rate": 2.0113903230355444e-05,
      "loss": 0.1641,
      "step": 77360
    },
    {
      "epoch": 77.37,
      "learning_rate": 2.0097003543658315e-05,
      "loss": 0.1879,
      "step": 77370
    },
    {
      "epoch": 77.38,
      "learning_rate": 2.0080109861070335e-05,
      "loss": 0.2102,
      "step": 77380
    },
    {
      "epoch": 77.39,
      "learning_rate": 2.006322218443897e-05,
      "loss": 0.2065,
      "step": 77390
    },
    {
      "epoch": 77.4,
      "learning_rate": 2.0046340515611053e-05,
      "loss": 0.3065,
      "step": 77400
    },
    {
      "epoch": 77.41,
      "learning_rate": 2.00294648564327e-05,
      "loss": 0.2794,
      "step": 77410
    },
    {
      "epoch": 77.42,
      "learning_rate": 2.0012595208749435e-05,
      "loss": 0.2826,
      "step": 77420
    },
    {
      "epoch": 77.43,
      "learning_rate": 1.999573157440605e-05,
      "loss": 0.2093,
      "step": 77430
    },
    {
      "epoch": 77.44,
      "learning_rate": 1.9978873955246806e-05,
      "loss": 0.1544,
      "step": 77440
    },
    {
      "epoch": 77.45,
      "learning_rate": 1.9962022353115154e-05,
      "loss": 0.2769,
      "step": 77450
    },
    {
      "epoch": 77.46,
      "learning_rate": 1.9945176769854013e-05,
      "loss": 0.131,
      "step": 77460
    },
    {
      "epoch": 77.47,
      "learning_rate": 1.992833720730555e-05,
      "loss": 0.1127,
      "step": 77470
    },
    {
      "epoch": 77.48,
      "learning_rate": 1.9911503667311342e-05,
      "loss": 0.1742,
      "step": 77480
    },
    {
      "epoch": 77.49,
      "learning_rate": 1.9894676151712236e-05,
      "loss": 0.1846,
      "step": 77490
    },
    {
      "epoch": 77.5,
      "learning_rate": 1.987785466234854e-05,
      "loss": 0.2531,
      "step": 77500
    },
    {
      "epoch": 77.51,
      "learning_rate": 1.9861039201059755e-05,
      "loss": 0.243,
      "step": 77510
    },
    {
      "epoch": 77.52,
      "learning_rate": 1.984422976968485e-05,
      "loss": 0.0723,
      "step": 77520
    },
    {
      "epoch": 77.53,
      "learning_rate": 1.9827426370062024e-05,
      "loss": 0.3902,
      "step": 77530
    },
    {
      "epoch": 77.54,
      "learning_rate": 1.9810629004028928e-05,
      "loss": 0.3068,
      "step": 77540
    },
    {
      "epoch": 77.55,
      "learning_rate": 1.979383767342244e-05,
      "loss": 0.2733,
      "step": 77550
    },
    {
      "epoch": 77.56,
      "learning_rate": 1.9777052380078865e-05,
      "loss": 0.1419,
      "step": 77560
    },
    {
      "epoch": 77.57,
      "learning_rate": 1.976027312583382e-05,
      "loss": 0.2385,
      "step": 77570
    },
    {
      "epoch": 77.58,
      "learning_rate": 1.974349991252227e-05,
      "loss": 0.1478,
      "step": 77580
    },
    {
      "epoch": 77.59,
      "learning_rate": 1.9726732741978473e-05,
      "loss": 0.2928,
      "step": 77590
    },
    {
      "epoch": 77.6,
      "learning_rate": 1.9709971616036078e-05,
      "loss": 0.1051,
      "step": 77600
    },
    {
      "epoch": 77.61,
      "learning_rate": 1.969321653652809e-05,
      "loss": 0.3331,
      "step": 77610
    },
    {
      "epoch": 77.62,
      "learning_rate": 1.967646750528676e-05,
      "loss": 0.1718,
      "step": 77620
    },
    {
      "epoch": 77.63,
      "learning_rate": 1.965972452414377e-05,
      "loss": 0.2601,
      "step": 77630
    },
    {
      "epoch": 77.64,
      "learning_rate": 1.96429875949301e-05,
      "loss": 0.1748,
      "step": 77640
    },
    {
      "epoch": 77.65,
      "learning_rate": 1.9626256719476103e-05,
      "loss": 0.1717,
      "step": 77650
    },
    {
      "epoch": 77.66,
      "learning_rate": 1.9609531899611393e-05,
      "loss": 0.1897,
      "step": 77660
    },
    {
      "epoch": 77.67,
      "learning_rate": 1.959281313716502e-05,
      "loss": 0.0792,
      "step": 77670
    },
    {
      "epoch": 77.68,
      "learning_rate": 1.957610043396526e-05,
      "loss": 0.1698,
      "step": 77680
    },
    {
      "epoch": 77.69,
      "learning_rate": 1.9559393791839866e-05,
      "loss": 0.189,
      "step": 77690
    },
    {
      "epoch": 77.7,
      "learning_rate": 1.9542693212615786e-05,
      "loss": 0.1779,
      "step": 77700
    },
    {
      "epoch": 77.71,
      "learning_rate": 1.9525998698119426e-05,
      "loss": 0.1602,
      "step": 77710
    },
    {
      "epoch": 77.72,
      "learning_rate": 1.9509310250176423e-05,
      "loss": 0.1516,
      "step": 77720
    },
    {
      "epoch": 77.73,
      "learning_rate": 1.949262787061184e-05,
      "loss": 0.1761,
      "step": 77730
    },
    {
      "epoch": 77.74,
      "learning_rate": 1.9475951561250005e-05,
      "loss": 0.1693,
      "step": 77740
    },
    {
      "epoch": 77.75,
      "learning_rate": 1.946094807435499e-05,
      "loss": 0.2314,
      "step": 77750
    },
    {
      "epoch": 77.76,
      "learning_rate": 1.9444283303402153e-05,
      "loss": 0.2698,
      "step": 77760
    },
    {
      "epoch": 77.77,
      "learning_rate": 1.942762460793895e-05,
      "loss": 0.1667,
      "step": 77770
    },
    {
      "epoch": 77.78,
      "learning_rate": 1.9410971989787183e-05,
      "loss": 0.2498,
      "step": 77780
    },
    {
      "epoch": 77.79,
      "learning_rate": 1.9394325450767922e-05,
      "loss": 0.1772,
      "step": 77790
    },
    {
      "epoch": 77.8,
      "learning_rate": 1.9377684992701654e-05,
      "loss": 0.2344,
      "step": 77800
    },
    {
      "epoch": 77.81,
      "learning_rate": 1.9361050617408102e-05,
      "loss": 0.1628,
      "step": 77810
    },
    {
      "epoch": 77.82,
      "learning_rate": 1.934442232670641e-05,
      "loss": 0.2167,
      "step": 77820
    },
    {
      "epoch": 77.83,
      "learning_rate": 1.9327800122415006e-05,
      "loss": 0.467,
      "step": 77830
    },
    {
      "epoch": 77.84,
      "learning_rate": 1.93111840063517e-05,
      "loss": 0.1988,
      "step": 77840
    },
    {
      "epoch": 77.85,
      "learning_rate": 1.929457398033357e-05,
      "loss": 0.3409,
      "step": 77850
    },
    {
      "epoch": 77.86,
      "learning_rate": 1.927797004617707e-05,
      "loss": 0.2882,
      "step": 77860
    },
    {
      "epoch": 77.87,
      "learning_rate": 1.9261372205698013e-05,
      "loss": 0.1004,
      "step": 77870
    },
    {
      "epoch": 77.88,
      "learning_rate": 1.924478046071147e-05,
      "loss": 0.239,
      "step": 77880
    },
    {
      "epoch": 77.89,
      "learning_rate": 1.9228194813031913e-05,
      "loss": 0.1494,
      "step": 77890
    },
    {
      "epoch": 77.9,
      "learning_rate": 1.9211615264473114e-05,
      "loss": 0.2024,
      "step": 77900
    },
    {
      "epoch": 77.91,
      "learning_rate": 1.9195041816848217e-05,
      "loss": 0.1649,
      "step": 77910
    },
    {
      "epoch": 77.92,
      "learning_rate": 1.917847447196962e-05,
      "loss": 0.1486,
      "step": 77920
    },
    {
      "epoch": 77.93,
      "learning_rate": 1.9161913231649155e-05,
      "loss": 0.1543,
      "step": 77930
    },
    {
      "epoch": 77.94,
      "learning_rate": 1.914535809769788e-05,
      "loss": 0.1677,
      "step": 77940
    },
    {
      "epoch": 77.95,
      "learning_rate": 1.9128809071926274e-05,
      "loss": 0.2594,
      "step": 77950
    },
    {
      "epoch": 77.96,
      "learning_rate": 1.9112266156144104e-05,
      "loss": 0.2104,
      "step": 77960
    },
    {
      "epoch": 77.97,
      "learning_rate": 1.90957293521605e-05,
      "loss": 0.1854,
      "step": 77970
    },
    {
      "epoch": 77.98,
      "learning_rate": 1.9079198661783863e-05,
      "loss": 0.2307,
      "step": 77980
    },
    {
      "epoch": 77.99,
      "learning_rate": 1.9062674086822014e-05,
      "loss": 0.3076,
      "step": 77990
    },
    {
      "epoch": 78.0,
      "learning_rate": 1.9046155629081993e-05,
      "loss": 0.3467,
      "step": 78000
    },
    {
      "epoch": 78.0,
      "eval_accuracy": 0.7985,
      "eval_loss": 0.4892384111881256,
      "eval_runtime": 14.9211,
      "eval_samples_per_second": 134.038,
      "eval_steps_per_second": 16.755,
      "step": 78000
    },
    {
      "epoch": 78.01,
      "learning_rate": 1.9029643290370276e-05,
      "loss": 0.2257,
      "step": 78010
    },
    {
      "epoch": 78.02,
      "learning_rate": 1.9013137072492614e-05,
      "loss": 0.1254,
      "step": 78020
    },
    {
      "epoch": 78.03,
      "learning_rate": 1.8996636977254128e-05,
      "loss": 0.1975,
      "step": 78030
    },
    {
      "epoch": 78.04,
      "learning_rate": 1.8980143006459205e-05,
      "loss": 0.1638,
      "step": 78040
    },
    {
      "epoch": 78.05,
      "learning_rate": 1.8963655161911635e-05,
      "loss": 0.0738,
      "step": 78050
    },
    {
      "epoch": 78.06,
      "learning_rate": 1.8947173445414464e-05,
      "loss": 0.2694,
      "step": 78060
    },
    {
      "epoch": 78.07,
      "learning_rate": 1.8930697858770134e-05,
      "loss": 0.1396,
      "step": 78070
    },
    {
      "epoch": 78.08,
      "learning_rate": 1.8914228403780388e-05,
      "loss": 0.1846,
      "step": 78080
    },
    {
      "epoch": 78.09,
      "learning_rate": 1.8897765082246328e-05,
      "loss": 0.1777,
      "step": 78090
    },
    {
      "epoch": 78.1,
      "learning_rate": 1.8881307895968295e-05,
      "loss": 0.1242,
      "step": 78100
    },
    {
      "epoch": 78.11,
      "learning_rate": 1.8864856846746067e-05,
      "loss": 0.1602,
      "step": 78110
    },
    {
      "epoch": 78.12,
      "learning_rate": 1.8848411936378715e-05,
      "loss": 0.1462,
      "step": 78120
    },
    {
      "epoch": 78.13,
      "learning_rate": 1.883197316666459e-05,
      "loss": 0.1532,
      "step": 78130
    },
    {
      "epoch": 78.14,
      "learning_rate": 1.881554053940143e-05,
      "loss": 0.3378,
      "step": 78140
    },
    {
      "epoch": 78.15,
      "learning_rate": 1.8799114056386288e-05,
      "loss": 0.1864,
      "step": 78150
    },
    {
      "epoch": 78.16,
      "learning_rate": 1.8782693719415555e-05,
      "loss": 0.2655,
      "step": 78160
    },
    {
      "epoch": 78.17,
      "learning_rate": 1.8766279530284888e-05,
      "loss": 0.2145,
      "step": 78170
    },
    {
      "epoch": 78.18,
      "learning_rate": 1.8749871490789374e-05,
      "loss": 0.2214,
      "step": 78180
    },
    {
      "epoch": 78.19,
      "learning_rate": 1.8733469602723327e-05,
      "loss": 0.2099,
      "step": 78190
    },
    {
      "epoch": 78.2,
      "learning_rate": 1.8717073867880437e-05,
      "loss": 0.1408,
      "step": 78200
    },
    {
      "epoch": 78.21,
      "learning_rate": 1.870068428805373e-05,
      "loss": 0.1006,
      "step": 78210
    },
    {
      "epoch": 78.22,
      "learning_rate": 1.8684300865035575e-05,
      "loss": 0.4688,
      "step": 78220
    },
    {
      "epoch": 78.23,
      "learning_rate": 1.8667923600617582e-05,
      "loss": 0.2008,
      "step": 78230
    },
    {
      "epoch": 78.24,
      "learning_rate": 1.8651552496590794e-05,
      "loss": 0.1503,
      "step": 78240
    },
    {
      "epoch": 78.25,
      "learning_rate": 1.8635187554745477e-05,
      "loss": 0.325,
      "step": 78250
    },
    {
      "epoch": 78.26,
      "learning_rate": 1.8618828776871313e-05,
      "loss": 0.338,
      "step": 78260
    },
    {
      "epoch": 78.27,
      "learning_rate": 1.8602476164757267e-05,
      "loss": 0.1961,
      "step": 78270
    },
    {
      "epoch": 78.28,
      "learning_rate": 1.8586129720191655e-05,
      "loss": 0.2248,
      "step": 78280
    },
    {
      "epoch": 78.29,
      "learning_rate": 1.8569789444962057e-05,
      "loss": 0.2742,
      "step": 78290
    },
    {
      "epoch": 78.3,
      "learning_rate": 1.855345534085546e-05,
      "loss": 0.1945,
      "step": 78300
    },
    {
      "epoch": 78.31,
      "learning_rate": 1.853712740965811e-05,
      "loss": 0.2451,
      "step": 78310
    },
    {
      "epoch": 78.32,
      "learning_rate": 1.8520805653155604e-05,
      "loss": 0.2489,
      "step": 78320
    },
    {
      "epoch": 78.33,
      "learning_rate": 1.8504490073132887e-05,
      "loss": 0.2555,
      "step": 78330
    },
    {
      "epoch": 78.34,
      "learning_rate": 1.848818067137421e-05,
      "loss": 0.1885,
      "step": 78340
    },
    {
      "epoch": 78.35,
      "learning_rate": 1.8471877449663112e-05,
      "loss": 0.1828,
      "step": 78350
    },
    {
      "epoch": 78.36,
      "learning_rate": 1.8455580409782507e-05,
      "loss": 0.1054,
      "step": 78360
    },
    {
      "epoch": 78.37,
      "learning_rate": 1.843928955351464e-05,
      "loss": 0.2108,
      "step": 78370
    },
    {
      "epoch": 78.38,
      "learning_rate": 1.8423004882641003e-05,
      "loss": 0.2349,
      "step": 78380
    },
    {
      "epoch": 78.39,
      "learning_rate": 1.84067263989425e-05,
      "loss": 0.2416,
      "step": 78390
    },
    {
      "epoch": 78.4,
      "learning_rate": 1.8390454104199297e-05,
      "loss": 0.1944,
      "step": 78400
    },
    {
      "epoch": 78.41,
      "learning_rate": 1.8374188000190946e-05,
      "loss": 0.207,
      "step": 78410
    },
    {
      "epoch": 78.42,
      "learning_rate": 1.835792808869625e-05,
      "loss": 0.0949,
      "step": 78420
    },
    {
      "epoch": 78.43,
      "learning_rate": 1.834167437149339e-05,
      "loss": 0.1983,
      "step": 78430
    },
    {
      "epoch": 78.44,
      "learning_rate": 1.832542685035982e-05,
      "loss": 0.1937,
      "step": 78440
    },
    {
      "epoch": 78.45,
      "learning_rate": 1.8309185527072353e-05,
      "loss": 0.2262,
      "step": 78450
    },
    {
      "epoch": 78.46,
      "learning_rate": 1.8292950403407128e-05,
      "loss": 0.1652,
      "step": 78460
    },
    {
      "epoch": 78.47,
      "learning_rate": 1.8276721481139615e-05,
      "loss": 0.1417,
      "step": 78470
    },
    {
      "epoch": 78.48,
      "learning_rate": 1.8260498762044525e-05,
      "loss": 0.2098,
      "step": 78480
    },
    {
      "epoch": 78.49,
      "learning_rate": 1.824428224789601e-05,
      "loss": 0.1637,
      "step": 78490
    },
    {
      "epoch": 78.5,
      "learning_rate": 1.8228071940467444e-05,
      "loss": 0.273,
      "step": 78500
    },
    {
      "epoch": 78.51,
      "learning_rate": 1.8211867841531594e-05,
      "loss": 0.3382,
      "step": 78510
    },
    {
      "epoch": 78.52,
      "learning_rate": 1.819566995286045e-05,
      "loss": 0.2875,
      "step": 78520
    },
    {
      "epoch": 78.53,
      "learning_rate": 1.8179478276225478e-05,
      "loss": 0.2044,
      "step": 78530
    },
    {
      "epoch": 78.54,
      "learning_rate": 1.816329281339731e-05,
      "loss": 0.2158,
      "step": 78540
    },
    {
      "epoch": 78.55,
      "learning_rate": 1.8147113566146014e-05,
      "loss": 0.1814,
      "step": 78550
    },
    {
      "epoch": 78.56,
      "learning_rate": 1.813094053624088e-05,
      "loss": 0.1535,
      "step": 78560
    },
    {
      "epoch": 78.57,
      "learning_rate": 1.8114773725450588e-05,
      "loss": 0.193,
      "step": 78570
    },
    {
      "epoch": 78.58,
      "learning_rate": 1.809861313554312e-05,
      "loss": 0.2306,
      "step": 78580
    },
    {
      "epoch": 78.59,
      "learning_rate": 1.808245876828578e-05,
      "loss": 0.2711,
      "step": 78590
    },
    {
      "epoch": 78.6,
      "learning_rate": 1.806631062544516e-05,
      "loss": 0.1823,
      "step": 78600
    },
    {
      "epoch": 78.61,
      "learning_rate": 1.8050168708787207e-05,
      "loss": 0.1366,
      "step": 78610
    },
    {
      "epoch": 78.62,
      "learning_rate": 1.803403302007721e-05,
      "loss": 0.2405,
      "step": 78620
    },
    {
      "epoch": 78.63,
      "learning_rate": 1.8017903561079683e-05,
      "loss": 0.3217,
      "step": 78630
    },
    {
      "epoch": 78.64,
      "learning_rate": 1.8001780333558583e-05,
      "loss": 0.2785,
      "step": 78640
    },
    {
      "epoch": 78.65,
      "learning_rate": 1.798566333927704e-05,
      "loss": 0.1845,
      "step": 78650
    },
    {
      "epoch": 78.66,
      "learning_rate": 1.796955257999768e-05,
      "loss": 0.163,
      "step": 78660
    },
    {
      "epoch": 78.67,
      "learning_rate": 1.795344805748229e-05,
      "loss": 0.2321,
      "step": 78670
    },
    {
      "epoch": 78.68,
      "learning_rate": 1.7937349773492062e-05,
      "loss": 0.1865,
      "step": 78680
    },
    {
      "epoch": 78.69,
      "learning_rate": 1.792125772978746e-05,
      "loss": 0.0989,
      "step": 78690
    },
    {
      "epoch": 78.7,
      "learning_rate": 1.790517192812831e-05,
      "loss": 0.2427,
      "step": 78700
    },
    {
      "epoch": 78.71,
      "learning_rate": 1.7889092370273683e-05,
      "loss": 0.2008,
      "step": 78710
    },
    {
      "epoch": 78.72,
      "learning_rate": 1.7873019057982084e-05,
      "loss": 0.2385,
      "step": 78720
    },
    {
      "epoch": 78.73,
      "learning_rate": 1.785695199301121e-05,
      "loss": 0.1874,
      "step": 78730
    },
    {
      "epoch": 78.74,
      "learning_rate": 1.7840891177118173e-05,
      "loss": 0.249,
      "step": 78740
    },
    {
      "epoch": 78.75,
      "learning_rate": 1.7824836612059324e-05,
      "loss": 0.223,
      "step": 78750
    },
    {
      "epoch": 78.76,
      "learning_rate": 1.7808788299590402e-05,
      "loss": 0.2752,
      "step": 78760
    },
    {
      "epoch": 78.77,
      "learning_rate": 1.779274624146636e-05,
      "loss": 0.2169,
      "step": 78770
    },
    {
      "epoch": 78.78,
      "learning_rate": 1.777671043944163e-05,
      "loss": 0.3617,
      "step": 78780
    },
    {
      "epoch": 78.79,
      "learning_rate": 1.7760680895269782e-05,
      "loss": 0.0943,
      "step": 78790
    },
    {
      "epoch": 78.8,
      "learning_rate": 1.7744657610703835e-05,
      "loss": 0.1922,
      "step": 78800
    },
    {
      "epoch": 78.81,
      "learning_rate": 1.7728640587496036e-05,
      "loss": 0.1548,
      "step": 78810
    },
    {
      "epoch": 78.82,
      "learning_rate": 1.7712629827397988e-05,
      "loss": 0.1341,
      "step": 78820
    },
    {
      "epoch": 78.83,
      "learning_rate": 1.7696625332160634e-05,
      "loss": 0.236,
      "step": 78830
    },
    {
      "epoch": 78.84,
      "learning_rate": 1.768062710353416e-05,
      "loss": 0.1508,
      "step": 78840
    },
    {
      "epoch": 78.85,
      "learning_rate": 1.766463514326813e-05,
      "loss": 0.2481,
      "step": 78850
    },
    {
      "epoch": 78.86,
      "learning_rate": 1.7648649453111398e-05,
      "loss": 0.2957,
      "step": 78860
    },
    {
      "epoch": 78.87,
      "learning_rate": 1.7632670034812152e-05,
      "loss": 0.2905,
      "step": 78870
    },
    {
      "epoch": 78.88,
      "learning_rate": 1.7616696890117843e-05,
      "loss": 0.2016,
      "step": 78880
    },
    {
      "epoch": 78.89,
      "learning_rate": 1.7600730020775307e-05,
      "loss": 0.0501,
      "step": 78890
    },
    {
      "epoch": 78.9,
      "learning_rate": 1.7584769428530594e-05,
      "loss": 0.1891,
      "step": 78900
    },
    {
      "epoch": 78.91,
      "learning_rate": 1.7568815115129218e-05,
      "loss": 0.1067,
      "step": 78910
    },
    {
      "epoch": 78.92,
      "learning_rate": 1.755286708231585e-05,
      "loss": 0.2348,
      "step": 78920
    },
    {
      "epoch": 78.93,
      "learning_rate": 1.7536925331834596e-05,
      "loss": 0.2477,
      "step": 78930
    },
    {
      "epoch": 78.94,
      "learning_rate": 1.7520989865428765e-05,
      "loss": 0.2334,
      "step": 78940
    },
    {
      "epoch": 78.95,
      "learning_rate": 1.7505060684841086e-05,
      "loss": 0.2125,
      "step": 78950
    },
    {
      "epoch": 78.96,
      "learning_rate": 1.748913779181349e-05,
      "loss": 0.1612,
      "step": 78960
    },
    {
      "epoch": 78.97,
      "learning_rate": 1.7473221188087364e-05,
      "loss": 0.3047,
      "step": 78970
    },
    {
      "epoch": 78.98,
      "learning_rate": 1.745731087540325e-05,
      "loss": 0.3522,
      "step": 78980
    },
    {
      "epoch": 78.99,
      "learning_rate": 1.7441406855501124e-05,
      "loss": 0.17,
      "step": 78990
    },
    {
      "epoch": 79.0,
      "learning_rate": 1.742550913012019e-05,
      "loss": 0.1909,
      "step": 79000
    },
    {
      "epoch": 79.0,
      "eval_accuracy": 0.799,
      "eval_loss": 0.4924173951148987,
      "eval_runtime": 14.8403,
      "eval_samples_per_second": 134.768,
      "eval_steps_per_second": 16.846,
      "step": 79000
    },
    {
      "epoch": 79.01,
      "learning_rate": 1.740961770099904e-05,
      "loss": 0.3579,
      "step": 79010
    },
    {
      "epoch": 79.02,
      "learning_rate": 1.7393732569875486e-05,
      "loss": 0.14,
      "step": 79020
    },
    {
      "epoch": 79.03,
      "learning_rate": 1.737785373848673e-05,
      "loss": 0.1112,
      "step": 79030
    },
    {
      "epoch": 79.04,
      "learning_rate": 1.7361981208569255e-05,
      "loss": 0.2075,
      "step": 79040
    },
    {
      "epoch": 79.05,
      "learning_rate": 1.7346114981858876e-05,
      "loss": 0.1995,
      "step": 79050
    },
    {
      "epoch": 79.06,
      "learning_rate": 1.733025506009066e-05,
      "loss": 0.2069,
      "step": 79060
    },
    {
      "epoch": 79.07,
      "learning_rate": 1.7314401444999053e-05,
      "loss": 0.2407,
      "step": 79070
    },
    {
      "epoch": 79.08,
      "learning_rate": 1.7298554138317785e-05,
      "loss": 0.1616,
      "step": 79080
    },
    {
      "epoch": 79.09,
      "learning_rate": 1.7282713141779853e-05,
      "loss": 0.293,
      "step": 79090
    },
    {
      "epoch": 79.1,
      "learning_rate": 1.7266878457117666e-05,
      "loss": 0.2108,
      "step": 79100
    },
    {
      "epoch": 79.11,
      "learning_rate": 1.725105008606284e-05,
      "loss": 0.2712,
      "step": 79110
    },
    {
      "epoch": 79.12,
      "learning_rate": 1.7235228030346372e-05,
      "loss": 0.1567,
      "step": 79120
    },
    {
      "epoch": 79.13,
      "learning_rate": 1.7219412291698492e-05,
      "loss": 0.182,
      "step": 79130
    },
    {
      "epoch": 79.14,
      "learning_rate": 1.7203602871848832e-05,
      "loss": 0.1472,
      "step": 79140
    },
    {
      "epoch": 79.15,
      "learning_rate": 1.7187799772526248e-05,
      "loss": 0.1808,
      "step": 79150
    },
    {
      "epoch": 79.16,
      "learning_rate": 1.7172002995458967e-05,
      "loss": 0.2667,
      "step": 79160
    },
    {
      "epoch": 79.17,
      "learning_rate": 1.715621254237449e-05,
      "loss": 0.1673,
      "step": 79170
    },
    {
      "epoch": 79.18,
      "learning_rate": 1.7140428414999662e-05,
      "loss": 0.2172,
      "step": 79180
    },
    {
      "epoch": 79.19,
      "learning_rate": 1.7124650615060573e-05,
      "loss": 0.2395,
      "step": 79190
    },
    {
      "epoch": 79.2,
      "learning_rate": 1.71088791442827e-05,
      "loss": 0.1153,
      "step": 79200
    },
    {
      "epoch": 79.21,
      "learning_rate": 1.7093114004390747e-05,
      "loss": 0.2773,
      "step": 79210
    },
    {
      "epoch": 79.22,
      "learning_rate": 1.707735519710878e-05,
      "loss": 0.1782,
      "step": 79220
    },
    {
      "epoch": 79.23,
      "learning_rate": 1.7061602724160164e-05,
      "loss": 0.1645,
      "step": 79230
    },
    {
      "epoch": 79.24,
      "learning_rate": 1.7045856587267585e-05,
      "loss": 0.1473,
      "step": 79240
    },
    {
      "epoch": 79.25,
      "learning_rate": 1.703011678815298e-05,
      "loss": 0.1744,
      "step": 79250
    },
    {
      "epoch": 79.26,
      "learning_rate": 1.701438332853766e-05,
      "loss": 0.1696,
      "step": 79260
    },
    {
      "epoch": 79.27,
      "learning_rate": 1.6998656210142186e-05,
      "loss": 0.2603,
      "step": 79270
    },
    {
      "epoch": 79.28,
      "learning_rate": 1.698293543468647e-05,
      "loss": 0.0782,
      "step": 79280
    },
    {
      "epoch": 79.29,
      "learning_rate": 1.6967221003889697e-05,
      "loss": 0.1409,
      "step": 79290
    },
    {
      "epoch": 79.3,
      "learning_rate": 1.6951512919470383e-05,
      "loss": 0.126,
      "step": 79300
    },
    {
      "epoch": 79.31,
      "learning_rate": 1.693581118314637e-05,
      "loss": 0.3136,
      "step": 79310
    },
    {
      "epoch": 79.32,
      "learning_rate": 1.6920115796634723e-05,
      "loss": 0.2355,
      "step": 79320
    },
    {
      "epoch": 79.33,
      "learning_rate": 1.6904426761651912e-05,
      "loss": 0.2499,
      "step": 79330
    },
    {
      "epoch": 79.34,
      "learning_rate": 1.6888744079913625e-05,
      "loss": 0.1133,
      "step": 79340
    },
    {
      "epoch": 79.35,
      "learning_rate": 1.687306775313492e-05,
      "loss": 0.1911,
      "step": 79350
    },
    {
      "epoch": 79.36,
      "learning_rate": 1.6857397783030125e-05,
      "loss": 0.1953,
      "step": 79360
    },
    {
      "epoch": 79.37,
      "learning_rate": 1.6841734171312916e-05,
      "loss": 0.1612,
      "step": 79370
    },
    {
      "epoch": 79.38,
      "learning_rate": 1.6826076919696206e-05,
      "loss": 0.2848,
      "step": 79380
    },
    {
      "epoch": 79.39,
      "learning_rate": 1.681042602989227e-05,
      "loss": 0.1784,
      "step": 79390
    },
    {
      "epoch": 79.4,
      "learning_rate": 1.679478150361264e-05,
      "loss": 0.1348,
      "step": 79400
    },
    {
      "epoch": 79.41,
      "learning_rate": 1.6779143342568192e-05,
      "loss": 0.2082,
      "step": 79410
    },
    {
      "epoch": 79.42,
      "learning_rate": 1.6763511548469097e-05,
      "loss": 0.2633,
      "step": 79420
    },
    {
      "epoch": 79.43,
      "learning_rate": 1.674788612302485e-05,
      "loss": 0.1931,
      "step": 79430
    },
    {
      "epoch": 79.44,
      "learning_rate": 1.673226706794416e-05,
      "loss": 0.1771,
      "step": 79440
    },
    {
      "epoch": 79.45,
      "learning_rate": 1.671665438493517e-05,
      "loss": 0.0931,
      "step": 79450
    },
    {
      "epoch": 79.46,
      "learning_rate": 1.6701048075705206e-05,
      "loss": 0.3771,
      "step": 79460
    },
    {
      "epoch": 79.47,
      "learning_rate": 1.6685448141960976e-05,
      "loss": 0.2156,
      "step": 79470
    },
    {
      "epoch": 79.48,
      "learning_rate": 1.6669854585408453e-05,
      "loss": 0.1841,
      "step": 79480
    },
    {
      "epoch": 79.49,
      "learning_rate": 1.6654267407752964e-05,
      "loss": 0.2197,
      "step": 79490
    },
    {
      "epoch": 79.5,
      "learning_rate": 1.6638686610699048e-05,
      "loss": 0.1835,
      "step": 79500
    },
    {
      "epoch": 79.51,
      "learning_rate": 1.6623112195950616e-05,
      "loss": 0.33,
      "step": 79510
    },
    {
      "epoch": 79.52,
      "learning_rate": 1.660754416521089e-05,
      "loss": 0.2372,
      "step": 79520
    },
    {
      "epoch": 79.53,
      "learning_rate": 1.6591982520182324e-05,
      "loss": 0.1484,
      "step": 79530
    },
    {
      "epoch": 79.54,
      "learning_rate": 1.657642726256673e-05,
      "loss": 0.2137,
      "step": 79540
    },
    {
      "epoch": 79.55,
      "learning_rate": 1.6560878394065208e-05,
      "loss": 0.1708,
      "step": 79550
    },
    {
      "epoch": 79.56,
      "learning_rate": 1.6545335916378188e-05,
      "loss": 0.2063,
      "step": 79560
    },
    {
      "epoch": 79.57,
      "learning_rate": 1.652979983120533e-05,
      "loss": 0.2154,
      "step": 79570
    },
    {
      "epoch": 79.58,
      "learning_rate": 1.651427014024567e-05,
      "loss": 0.1399,
      "step": 79580
    },
    {
      "epoch": 79.59,
      "learning_rate": 1.649874684519748e-05,
      "loss": 0.1632,
      "step": 79590
    },
    {
      "epoch": 79.6,
      "learning_rate": 1.648322994775837e-05,
      "loss": 0.1591,
      "step": 79600
    },
    {
      "epoch": 79.61,
      "learning_rate": 1.6467719449625265e-05,
      "loss": 0.1613,
      "step": 79610
    },
    {
      "epoch": 79.62,
      "learning_rate": 1.645221535249437e-05,
      "loss": 0.1866,
      "step": 79620
    },
    {
      "epoch": 79.63,
      "learning_rate": 1.6436717658061162e-05,
      "loss": 0.1969,
      "step": 79630
    },
    {
      "epoch": 79.64,
      "learning_rate": 1.6421226368020483e-05,
      "loss": 0.153,
      "step": 79640
    },
    {
      "epoch": 79.65,
      "learning_rate": 1.6405741484066397e-05,
      "loss": 0.1775,
      "step": 79650
    },
    {
      "epoch": 79.66,
      "learning_rate": 1.6390263007892324e-05,
      "loss": 0.1111,
      "step": 79660
    },
    {
      "epoch": 79.67,
      "learning_rate": 1.637479094119098e-05,
      "loss": 0.1285,
      "step": 79670
    },
    {
      "epoch": 79.68,
      "learning_rate": 1.6359325285654366e-05,
      "loss": 0.314,
      "step": 79680
    },
    {
      "epoch": 79.69,
      "learning_rate": 1.634386604297376e-05,
      "loss": 0.1566,
      "step": 79690
    },
    {
      "epoch": 79.7,
      "learning_rate": 1.632841321483979e-05,
      "loss": 0.2292,
      "step": 79700
    },
    {
      "epoch": 79.71,
      "learning_rate": 1.6312966802942326e-05,
      "loss": 0.1695,
      "step": 79710
    },
    {
      "epoch": 79.72,
      "learning_rate": 1.6297526808970572e-05,
      "loss": 0.1127,
      "step": 79720
    },
    {
      "epoch": 79.73,
      "learning_rate": 1.628209323461303e-05,
      "loss": 0.1563,
      "step": 79730
    },
    {
      "epoch": 79.74,
      "learning_rate": 1.6266666081557514e-05,
      "loss": 0.2329,
      "step": 79740
    },
    {
      "epoch": 79.75,
      "learning_rate": 1.6251245351491064e-05,
      "loss": 0.2525,
      "step": 79750
    },
    {
      "epoch": 79.76,
      "learning_rate": 1.6235831046100103e-05,
      "loss": 0.2123,
      "step": 79760
    },
    {
      "epoch": 79.77,
      "learning_rate": 1.622042316707032e-05,
      "loss": 0.2708,
      "step": 79770
    },
    {
      "epoch": 79.78,
      "learning_rate": 1.6205021716086674e-05,
      "loss": 0.1818,
      "step": 79780
    },
    {
      "epoch": 79.79,
      "learning_rate": 1.6189626694833452e-05,
      "loss": 0.3533,
      "step": 79790
    },
    {
      "epoch": 79.8,
      "learning_rate": 1.617423810499423e-05,
      "loss": 0.2643,
      "step": 79800
    },
    {
      "epoch": 79.81,
      "learning_rate": 1.6158855948251913e-05,
      "loss": 0.2514,
      "step": 79810
    },
    {
      "epoch": 79.82,
      "learning_rate": 1.6143480226288624e-05,
      "loss": 0.1729,
      "step": 79820
    },
    {
      "epoch": 79.83,
      "learning_rate": 1.6128110940785867e-05,
      "loss": 0.307,
      "step": 79830
    },
    {
      "epoch": 79.84,
      "learning_rate": 1.611274809342436e-05,
      "loss": 0.153,
      "step": 79840
    },
    {
      "epoch": 79.85,
      "learning_rate": 1.6097391685884205e-05,
      "loss": 0.2004,
      "step": 79850
    },
    {
      "epoch": 79.86,
      "learning_rate": 1.60820417198447e-05,
      "loss": 0.2686,
      "step": 79860
    },
    {
      "epoch": 79.87,
      "learning_rate": 1.606669819698457e-05,
      "loss": 0.4049,
      "step": 79870
    },
    {
      "epoch": 79.88,
      "learning_rate": 1.6051361118981705e-05,
      "loss": 0.1448,
      "step": 79880
    },
    {
      "epoch": 79.89,
      "learning_rate": 1.6036030487513376e-05,
      "loss": 0.229,
      "step": 79890
    },
    {
      "epoch": 79.9,
      "learning_rate": 1.602070630425608e-05,
      "loss": 0.3252,
      "step": 79900
    },
    {
      "epoch": 79.91,
      "learning_rate": 1.6005388570885693e-05,
      "loss": 0.2325,
      "step": 79910
    },
    {
      "epoch": 79.92,
      "learning_rate": 1.5990077289077266e-05,
      "loss": 0.2257,
      "step": 79920
    },
    {
      "epoch": 79.93,
      "learning_rate": 1.5974772460505317e-05,
      "loss": 0.188,
      "step": 79930
    },
    {
      "epoch": 79.94,
      "learning_rate": 1.5959474086843484e-05,
      "loss": 0.1588,
      "step": 79940
    },
    {
      "epoch": 79.95,
      "learning_rate": 1.5944182169764823e-05,
      "loss": 0.2342,
      "step": 79950
    },
    {
      "epoch": 79.96,
      "learning_rate": 1.592889671094158e-05,
      "loss": 0.1888,
      "step": 79960
    },
    {
      "epoch": 79.97,
      "learning_rate": 1.591361771204539e-05,
      "loss": 0.1576,
      "step": 79970
    },
    {
      "epoch": 79.98,
      "learning_rate": 1.5898345174747135e-05,
      "loss": 0.129,
      "step": 79980
    },
    {
      "epoch": 79.99,
      "learning_rate": 1.5883079100717e-05,
      "loss": 0.3704,
      "step": 79990
    },
    {
      "epoch": 80.0,
      "learning_rate": 1.5867819491624448e-05,
      "loss": 0.2579,
      "step": 80000
    },
    {
      "epoch": 80.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.5151867866516113,
      "eval_runtime": 14.6653,
      "eval_samples_per_second": 136.376,
      "eval_steps_per_second": 17.047,
      "step": 80000
    },
    {
      "epoch": 80.01,
      "learning_rate": 1.5852566349138245e-05,
      "loss": 0.3344,
      "step": 80010
    },
    {
      "epoch": 80.02,
      "learning_rate": 1.583731967492648e-05,
      "loss": 0.2557,
      "step": 80020
    },
    {
      "epoch": 80.03,
      "learning_rate": 1.5822079470656464e-05,
      "loss": 0.1411,
      "step": 80030
    },
    {
      "epoch": 80.04,
      "learning_rate": 1.5806845737994893e-05,
      "loss": 0.148,
      "step": 80040
    },
    {
      "epoch": 80.05,
      "learning_rate": 1.5791618478607628e-05,
      "loss": 0.0894,
      "step": 80050
    },
    {
      "epoch": 80.06,
      "learning_rate": 1.5776397694159986e-05,
      "loss": 0.2958,
      "step": 80060
    },
    {
      "epoch": 80.07,
      "learning_rate": 1.5761183386316434e-05,
      "loss": 0.1365,
      "step": 80070
    },
    {
      "epoch": 80.08,
      "learning_rate": 1.5745975556740827e-05,
      "loss": 0.2131,
      "step": 80080
    },
    {
      "epoch": 80.09,
      "learning_rate": 1.5730774207096222e-05,
      "loss": 0.2708,
      "step": 80090
    },
    {
      "epoch": 80.1,
      "learning_rate": 1.571557933904506e-05,
      "loss": 0.0631,
      "step": 80100
    },
    {
      "epoch": 80.11,
      "learning_rate": 1.5700390954248967e-05,
      "loss": 0.1639,
      "step": 80110
    },
    {
      "epoch": 80.12,
      "learning_rate": 1.5685209054369003e-05,
      "loss": 0.1671,
      "step": 80120
    },
    {
      "epoch": 80.13,
      "learning_rate": 1.567003364106538e-05,
      "loss": 0.3368,
      "step": 80130
    },
    {
      "epoch": 80.14,
      "learning_rate": 1.56548647159977e-05,
      "loss": 0.2335,
      "step": 80140
    },
    {
      "epoch": 80.15,
      "learning_rate": 1.563970228082477e-05,
      "loss": 0.1366,
      "step": 80150
    },
    {
      "epoch": 80.16,
      "learning_rate": 1.562454633720477e-05,
      "loss": 0.1936,
      "step": 80160
    },
    {
      "epoch": 80.17,
      "learning_rate": 1.5610911539594377e-05,
      "loss": 0.2508,
      "step": 80170
    },
    {
      "epoch": 80.18,
      "learning_rate": 1.5595767934490502e-05,
      "loss": 0.1504,
      "step": 80180
    },
    {
      "epoch": 80.19,
      "learning_rate": 1.558063082574418e-05,
      "loss": 0.1255,
      "step": 80190
    },
    {
      "epoch": 80.2,
      "learning_rate": 1.5565500215010703e-05,
      "loss": 0.1265,
      "step": 80200
    },
    {
      "epoch": 80.21,
      "learning_rate": 1.5550376103944797e-05,
      "loss": 0.0811,
      "step": 80210
    },
    {
      "epoch": 80.22,
      "learning_rate": 1.5535258494200355e-05,
      "loss": 0.1332,
      "step": 80220
    },
    {
      "epoch": 80.23,
      "learning_rate": 1.5520147387430657e-05,
      "loss": 0.2474,
      "step": 80230
    },
    {
      "epoch": 80.24,
      "learning_rate": 1.5505042785288192e-05,
      "loss": 0.2677,
      "step": 80240
    },
    {
      "epoch": 80.25,
      "learning_rate": 1.5489944689424804e-05,
      "loss": 0.2395,
      "step": 80250
    },
    {
      "epoch": 80.26,
      "learning_rate": 1.5474853101491594e-05,
      "loss": 0.1786,
      "step": 80260
    },
    {
      "epoch": 80.27,
      "learning_rate": 1.5459768023138975e-05,
      "loss": 0.1036,
      "step": 80270
    },
    {
      "epoch": 80.28,
      "learning_rate": 1.5444689456016584e-05,
      "loss": 0.2225,
      "step": 80280
    },
    {
      "epoch": 80.29,
      "learning_rate": 1.5429617401773414e-05,
      "loss": 0.2242,
      "step": 80290
    },
    {
      "epoch": 80.3,
      "learning_rate": 1.5414551862057745e-05,
      "loss": 0.2167,
      "step": 80300
    },
    {
      "epoch": 80.31,
      "learning_rate": 1.539949283851705e-05,
      "loss": 0.2489,
      "step": 80310
    },
    {
      "epoch": 80.32,
      "learning_rate": 1.5384440332798263e-05,
      "loss": 0.1155,
      "step": 80320
    },
    {
      "epoch": 80.33,
      "learning_rate": 1.5369394346547422e-05,
      "loss": 0.2019,
      "step": 80330
    },
    {
      "epoch": 80.34,
      "learning_rate": 1.5354354881409983e-05,
      "loss": 0.2588,
      "step": 80340
    },
    {
      "epoch": 80.35,
      "learning_rate": 1.5339321939030603e-05,
      "loss": 0.1426,
      "step": 80350
    },
    {
      "epoch": 80.36,
      "learning_rate": 1.532429552105329e-05,
      "loss": 0.2318,
      "step": 80360
    },
    {
      "epoch": 80.37,
      "learning_rate": 1.5309275629121264e-05,
      "loss": 0.2753,
      "step": 80370
    },
    {
      "epoch": 80.38,
      "learning_rate": 1.5294262264877146e-05,
      "loss": 0.2532,
      "step": 80380
    },
    {
      "epoch": 80.39,
      "learning_rate": 1.527925542996272e-05,
      "loss": 0.2282,
      "step": 80390
    },
    {
      "epoch": 80.4,
      "learning_rate": 1.5264255126019162e-05,
      "loss": 0.2274,
      "step": 80400
    },
    {
      "epoch": 80.41,
      "learning_rate": 1.524926135468682e-05,
      "loss": 0.1738,
      "step": 80410
    },
    {
      "epoch": 80.42,
      "learning_rate": 1.5234274117605452e-05,
      "loss": 0.1099,
      "step": 80420
    },
    {
      "epoch": 80.43,
      "learning_rate": 1.521929341641398e-05,
      "loss": 0.2876,
      "step": 80430
    },
    {
      "epoch": 80.44,
      "learning_rate": 1.520431925275071e-05,
      "loss": 0.1276,
      "step": 80440
    },
    {
      "epoch": 80.45,
      "learning_rate": 1.5189351628253182e-05,
      "loss": 0.2686,
      "step": 80450
    },
    {
      "epoch": 80.46,
      "learning_rate": 1.5174390544558254e-05,
      "loss": 0.145,
      "step": 80460
    },
    {
      "epoch": 80.47,
      "learning_rate": 1.5159436003302008e-05,
      "loss": 0.2096,
      "step": 80470
    },
    {
      "epoch": 80.48,
      "learning_rate": 1.5144488006119895e-05,
      "loss": 0.1253,
      "step": 80480
    },
    {
      "epoch": 80.49,
      "learning_rate": 1.5129546554646566e-05,
      "loss": 0.1974,
      "step": 80490
    },
    {
      "epoch": 80.5,
      "learning_rate": 1.5114611650516004e-05,
      "loss": 0.1894,
      "step": 80500
    },
    {
      "epoch": 80.51,
      "learning_rate": 1.5099683295361479e-05,
      "loss": 0.2383,
      "step": 80510
    },
    {
      "epoch": 80.52,
      "learning_rate": 1.5084761490815533e-05,
      "loss": 0.2483,
      "step": 80520
    },
    {
      "epoch": 80.53,
      "learning_rate": 1.5069846238510006e-05,
      "loss": 0.1882,
      "step": 80530
    },
    {
      "epoch": 80.54,
      "learning_rate": 1.5054937540075973e-05,
      "loss": 0.2133,
      "step": 80540
    },
    {
      "epoch": 80.55,
      "learning_rate": 1.5040035397143865e-05,
      "loss": 0.1918,
      "step": 80550
    },
    {
      "epoch": 80.56,
      "learning_rate": 1.5025139811343295e-05,
      "loss": 0.1214,
      "step": 80560
    },
    {
      "epoch": 80.57,
      "learning_rate": 1.50102507843033e-05,
      "loss": 0.2835,
      "step": 80570
    },
    {
      "epoch": 80.58,
      "learning_rate": 1.4995368317652073e-05,
      "loss": 0.1761,
      "step": 80580
    },
    {
      "epoch": 80.59,
      "learning_rate": 1.4980492413017168e-05,
      "loss": 0.1211,
      "step": 80590
    },
    {
      "epoch": 80.6,
      "learning_rate": 1.4965623072025357e-05,
      "loss": 0.1465,
      "step": 80600
    },
    {
      "epoch": 80.61,
      "learning_rate": 1.4950760296302767e-05,
      "loss": 0.1953,
      "step": 80610
    },
    {
      "epoch": 80.62,
      "learning_rate": 1.493590408747472e-05,
      "loss": 0.2228,
      "step": 80620
    },
    {
      "epoch": 80.63,
      "learning_rate": 1.4921054447165904e-05,
      "loss": 0.2639,
      "step": 80630
    },
    {
      "epoch": 80.64,
      "learning_rate": 1.490621137700025e-05,
      "loss": 0.1069,
      "step": 80640
    },
    {
      "epoch": 80.65,
      "learning_rate": 1.4891374878600984e-05,
      "loss": 0.2433,
      "step": 80650
    },
    {
      "epoch": 80.66,
      "learning_rate": 1.4876544953590569e-05,
      "loss": 0.1568,
      "step": 80660
    },
    {
      "epoch": 80.67,
      "learning_rate": 1.4861721603590822e-05,
      "loss": 0.1193,
      "step": 80670
    },
    {
      "epoch": 80.68,
      "learning_rate": 1.4846904830222775e-05,
      "loss": 0.1445,
      "step": 80680
    },
    {
      "epoch": 80.69,
      "learning_rate": 1.483209463510677e-05,
      "loss": 0.1657,
      "step": 80690
    },
    {
      "epoch": 80.7,
      "learning_rate": 1.481729101986243e-05,
      "loss": 0.2599,
      "step": 80700
    },
    {
      "epoch": 80.71,
      "learning_rate": 1.4802493986108683e-05,
      "loss": 0.1423,
      "step": 80710
    },
    {
      "epoch": 80.72,
      "learning_rate": 1.4787703535463677e-05,
      "loss": 0.2252,
      "step": 80720
    },
    {
      "epoch": 80.73,
      "learning_rate": 1.4772919669544878e-05,
      "loss": 0.3461,
      "step": 80730
    },
    {
      "epoch": 80.74,
      "learning_rate": 1.475814238996905e-05,
      "loss": 0.237,
      "step": 80740
    },
    {
      "epoch": 80.75,
      "learning_rate": 1.4743371698352183e-05,
      "loss": 0.1091,
      "step": 80750
    },
    {
      "epoch": 80.76,
      "learning_rate": 1.4728607596309586e-05,
      "loss": 0.1001,
      "step": 80760
    },
    {
      "epoch": 80.77,
      "learning_rate": 1.471385008545585e-05,
      "loss": 0.1667,
      "step": 80770
    },
    {
      "epoch": 80.78,
      "learning_rate": 1.4699099167404851e-05,
      "loss": 0.1508,
      "step": 80780
    },
    {
      "epoch": 80.79,
      "learning_rate": 1.4684354843769682e-05,
      "loss": 0.296,
      "step": 80790
    },
    {
      "epoch": 80.8,
      "learning_rate": 1.4669617116162812e-05,
      "loss": 0.2194,
      "step": 80800
    },
    {
      "epoch": 80.81,
      "learning_rate": 1.4654885986195886e-05,
      "loss": 0.2906,
      "step": 80810
    },
    {
      "epoch": 80.82,
      "learning_rate": 1.4640161455479896e-05,
      "loss": 0.3395,
      "step": 80820
    },
    {
      "epoch": 80.83,
      "learning_rate": 1.4625443525625104e-05,
      "loss": 0.2073,
      "step": 80830
    },
    {
      "epoch": 80.84,
      "learning_rate": 1.4610732198241051e-05,
      "loss": 0.1357,
      "step": 80840
    },
    {
      "epoch": 80.85,
      "learning_rate": 1.4596027474936514e-05,
      "loss": 0.2068,
      "step": 80850
    },
    {
      "epoch": 80.86,
      "learning_rate": 1.4581329357319624e-05,
      "loss": 0.1781,
      "step": 80860
    },
    {
      "epoch": 80.87,
      "learning_rate": 1.4566637846997687e-05,
      "loss": 0.2497,
      "step": 80870
    },
    {
      "epoch": 80.88,
      "learning_rate": 1.4551952945577383e-05,
      "loss": 0.1895,
      "step": 80880
    },
    {
      "epoch": 80.89,
      "learning_rate": 1.4537274654664614e-05,
      "loss": 0.2143,
      "step": 80890
    },
    {
      "epoch": 80.9,
      "learning_rate": 1.4522602975864608e-05,
      "loss": 0.2184,
      "step": 80900
    },
    {
      "epoch": 80.91,
      "learning_rate": 1.4507937910781794e-05,
      "loss": 0.2127,
      "step": 80910
    },
    {
      "epoch": 80.92,
      "learning_rate": 1.4493279461019963e-05,
      "loss": 0.1891,
      "step": 80920
    },
    {
      "epoch": 80.93,
      "learning_rate": 1.44786276281821e-05,
      "loss": 0.2433,
      "step": 80930
    },
    {
      "epoch": 80.94,
      "learning_rate": 1.446398241387052e-05,
      "loss": 0.2613,
      "step": 80940
    },
    {
      "epoch": 80.95,
      "learning_rate": 1.444934381968682e-05,
      "loss": 0.1894,
      "step": 80950
    },
    {
      "epoch": 80.96,
      "learning_rate": 1.4434711847231854e-05,
      "loss": 0.2628,
      "step": 80960
    },
    {
      "epoch": 80.97,
      "learning_rate": 1.4420086498105729e-05,
      "loss": 0.0992,
      "step": 80970
    },
    {
      "epoch": 80.98,
      "learning_rate": 1.440546777390786e-05,
      "loss": 0.2513,
      "step": 80980
    },
    {
      "epoch": 80.99,
      "learning_rate": 1.4390855676236954e-05,
      "loss": 0.183,
      "step": 80990
    },
    {
      "epoch": 81.0,
      "learning_rate": 1.4376250206690928e-05,
      "loss": 0.1915,
      "step": 81000
    },
    {
      "epoch": 81.0,
      "eval_accuracy": 0.796,
      "eval_loss": 0.5152688026428223,
      "eval_runtime": 14.3672,
      "eval_samples_per_second": 139.206,
      "eval_steps_per_second": 17.401,
      "step": 81000
    },
    {
      "epoch": 81.01,
      "learning_rate": 1.4361651366867025e-05,
      "loss": 0.2139,
      "step": 81010
    },
    {
      "epoch": 81.02,
      "learning_rate": 1.4347059158361773e-05,
      "loss": 0.1267,
      "step": 81020
    },
    {
      "epoch": 81.03,
      "learning_rate": 1.4332473582770948e-05,
      "loss": 0.147,
      "step": 81030
    },
    {
      "epoch": 81.04,
      "learning_rate": 1.431789464168959e-05,
      "loss": 0.2249,
      "step": 81040
    },
    {
      "epoch": 81.05,
      "learning_rate": 1.4303322336712055e-05,
      "loss": 0.2031,
      "step": 81050
    },
    {
      "epoch": 81.06,
      "learning_rate": 1.4288756669431915e-05,
      "loss": 0.1363,
      "step": 81060
    },
    {
      "epoch": 81.07,
      "learning_rate": 1.4274197641442064e-05,
      "loss": 0.1996,
      "step": 81070
    },
    {
      "epoch": 81.08,
      "learning_rate": 1.425964525433466e-05,
      "loss": 0.214,
      "step": 81080
    },
    {
      "epoch": 81.09,
      "learning_rate": 1.424509950970115e-05,
      "loss": 0.0785,
      "step": 81090
    },
    {
      "epoch": 81.1,
      "learning_rate": 1.4230560409132197e-05,
      "loss": 0.2218,
      "step": 81100
    },
    {
      "epoch": 81.11,
      "learning_rate": 1.4217480900609488e-05,
      "loss": 0.3258,
      "step": 81110
    },
    {
      "epoch": 81.12,
      "learning_rate": 1.4202954428143015e-05,
      "loss": 0.1085,
      "step": 81120
    },
    {
      "epoch": 81.13,
      "learning_rate": 1.418843460435003e-05,
      "loss": 0.244,
      "step": 81130
    },
    {
      "epoch": 81.14,
      "learning_rate": 1.4173921430818403e-05,
      "loss": 0.0875,
      "step": 81140
    },
    {
      "epoch": 81.15,
      "learning_rate": 1.4159414909135272e-05,
      "loss": 0.3744,
      "step": 81150
    },
    {
      "epoch": 81.16,
      "learning_rate": 1.4144915040887087e-05,
      "loss": 0.1601,
      "step": 81160
    },
    {
      "epoch": 81.17,
      "learning_rate": 1.413042182765947e-05,
      "loss": 0.1693,
      "step": 81170
    },
    {
      "epoch": 81.18,
      "learning_rate": 1.4115935271037427e-05,
      "loss": 0.2661,
      "step": 81180
    },
    {
      "epoch": 81.19,
      "learning_rate": 1.4101455372605142e-05,
      "loss": 0.196,
      "step": 81190
    },
    {
      "epoch": 81.2,
      "learning_rate": 1.4086982133946165e-05,
      "loss": 0.175,
      "step": 81200
    },
    {
      "epoch": 81.21,
      "learning_rate": 1.4072515556643196e-05,
      "loss": 0.3056,
      "step": 81210
    },
    {
      "epoch": 81.22,
      "learning_rate": 1.4058055642278362e-05,
      "loss": 0.117,
      "step": 81220
    },
    {
      "epoch": 81.23,
      "learning_rate": 1.4043602392432924e-05,
      "loss": 0.1808,
      "step": 81230
    },
    {
      "epoch": 81.24,
      "learning_rate": 1.4029155808687498e-05,
      "loss": 0.2242,
      "step": 81240
    },
    {
      "epoch": 81.25,
      "learning_rate": 1.4014715892621898e-05,
      "loss": 0.2345,
      "step": 81250
    },
    {
      "epoch": 81.26,
      "learning_rate": 1.4000282645815283e-05,
      "loss": 0.1012,
      "step": 81260
    },
    {
      "epoch": 81.27,
      "learning_rate": 1.3985856069846051e-05,
      "loss": 0.1516,
      "step": 81270
    },
    {
      "epoch": 81.28,
      "learning_rate": 1.3971436166291883e-05,
      "loss": 0.3243,
      "step": 81280
    },
    {
      "epoch": 81.29,
      "learning_rate": 1.3957022936729681e-05,
      "loss": 0.188,
      "step": 81290
    },
    {
      "epoch": 81.3,
      "learning_rate": 1.3942616382735669e-05,
      "loss": 0.1498,
      "step": 81300
    },
    {
      "epoch": 81.31,
      "learning_rate": 1.3928216505885353e-05,
      "loss": 0.2937,
      "step": 81310
    },
    {
      "epoch": 81.32,
      "learning_rate": 1.3913823307753441e-05,
      "loss": 0.0613,
      "step": 81320
    },
    {
      "epoch": 81.33,
      "learning_rate": 1.3899436789913973e-05,
      "loss": 0.2413,
      "step": 81330
    },
    {
      "epoch": 81.34,
      "learning_rate": 1.3885056953940233e-05,
      "loss": 0.229,
      "step": 81340
    },
    {
      "epoch": 81.35,
      "learning_rate": 1.3870683801404795e-05,
      "loss": 0.1185,
      "step": 81350
    },
    {
      "epoch": 81.36,
      "learning_rate": 1.3856317333879452e-05,
      "loss": 0.1874,
      "step": 81360
    },
    {
      "epoch": 81.37,
      "learning_rate": 1.384195755293534e-05,
      "loss": 0.1017,
      "step": 81370
    },
    {
      "epoch": 81.38,
      "learning_rate": 1.3827604460142777e-05,
      "loss": 0.2446,
      "step": 81380
    },
    {
      "epoch": 81.39,
      "learning_rate": 1.381325805707144e-05,
      "loss": 0.1618,
      "step": 81390
    },
    {
      "epoch": 81.4,
      "learning_rate": 1.3798918345290177e-05,
      "loss": 0.2194,
      "step": 81400
    },
    {
      "epoch": 81.41,
      "learning_rate": 1.3784585326367223e-05,
      "loss": 0.0977,
      "step": 81410
    },
    {
      "epoch": 81.42,
      "learning_rate": 1.3770259001869958e-05,
      "loss": 0.1776,
      "step": 81420
    },
    {
      "epoch": 81.43,
      "learning_rate": 1.3755939373365135e-05,
      "loss": 0.2402,
      "step": 81430
    },
    {
      "epoch": 81.44,
      "learning_rate": 1.374162644241868e-05,
      "loss": 0.2164,
      "step": 81440
    },
    {
      "epoch": 81.45,
      "learning_rate": 1.372732021059588e-05,
      "loss": 0.2959,
      "step": 81450
    },
    {
      "epoch": 81.46,
      "learning_rate": 1.3713020679461176e-05,
      "loss": 0.278,
      "step": 81460
    },
    {
      "epoch": 81.47,
      "learning_rate": 1.3698727850578434e-05,
      "loss": 0.09,
      "step": 81470
    },
    {
      "epoch": 81.48,
      "learning_rate": 1.368444172551062e-05,
      "loss": 0.1268,
      "step": 81480
    },
    {
      "epoch": 81.49,
      "learning_rate": 1.3670162305820101e-05,
      "loss": 0.1889,
      "step": 81490
    },
    {
      "epoch": 81.5,
      "learning_rate": 1.3655889593068394e-05,
      "loss": 0.1104,
      "step": 81500
    },
    {
      "epoch": 81.51,
      "learning_rate": 1.3641623588816378e-05,
      "loss": 0.3152,
      "step": 81510
    },
    {
      "epoch": 81.52,
      "learning_rate": 1.3627364294624177e-05,
      "loss": 0.1453,
      "step": 81520
    },
    {
      "epoch": 81.53,
      "learning_rate": 1.3613111712051103e-05,
      "loss": 0.1746,
      "step": 81530
    },
    {
      "epoch": 81.54,
      "learning_rate": 1.3598865842655876e-05,
      "loss": 0.2067,
      "step": 81540
    },
    {
      "epoch": 81.55,
      "learning_rate": 1.358462668799635e-05,
      "loss": 0.1351,
      "step": 81550
    },
    {
      "epoch": 81.56,
      "learning_rate": 1.3570394249629729e-05,
      "loss": 0.3386,
      "step": 81560
    },
    {
      "epoch": 81.57,
      "learning_rate": 1.355616852911241e-05,
      "loss": 0.1788,
      "step": 81570
    },
    {
      "epoch": 81.58,
      "learning_rate": 1.3541949528000148e-05,
      "loss": 0.2658,
      "step": 81580
    },
    {
      "epoch": 81.59,
      "learning_rate": 1.352773724784785e-05,
      "loss": 0.079,
      "step": 81590
    },
    {
      "epoch": 81.6,
      "learning_rate": 1.3513531690209813e-05,
      "loss": 0.1716,
      "step": 81600
    },
    {
      "epoch": 81.61,
      "learning_rate": 1.3499332856639489e-05,
      "loss": 0.2054,
      "step": 81610
    },
    {
      "epoch": 81.62,
      "learning_rate": 1.3485140748689683e-05,
      "loss": 0.097,
      "step": 81620
    },
    {
      "epoch": 81.63,
      "learning_rate": 1.3470955367912378e-05,
      "loss": 0.319,
      "step": 81630
    },
    {
      "epoch": 81.64,
      "learning_rate": 1.3456776715858902e-05,
      "loss": 0.0806,
      "step": 81640
    },
    {
      "epoch": 81.65,
      "learning_rate": 1.3442604794079764e-05,
      "loss": 0.1423,
      "step": 81650
    },
    {
      "epoch": 81.66,
      "learning_rate": 1.3428439604124849e-05,
      "loss": 0.2794,
      "step": 81660
    },
    {
      "epoch": 81.67,
      "learning_rate": 1.3414281147543193e-05,
      "loss": 0.1146,
      "step": 81670
    },
    {
      "epoch": 81.68,
      "learning_rate": 1.3400129425883173e-05,
      "loss": 0.1622,
      "step": 81680
    },
    {
      "epoch": 81.69,
      "learning_rate": 1.3385984440692364e-05,
      "loss": 0.4092,
      "step": 81690
    },
    {
      "epoch": 81.7,
      "learning_rate": 1.337184619351768e-05,
      "loss": 0.1177,
      "step": 81700
    },
    {
      "epoch": 81.71,
      "learning_rate": 1.3357714685905221e-05,
      "loss": 0.1903,
      "step": 81710
    },
    {
      "epoch": 81.72,
      "learning_rate": 1.334358991940041e-05,
      "loss": 0.3352,
      "step": 81720
    },
    {
      "epoch": 81.73,
      "learning_rate": 1.332947189554791e-05,
      "loss": 0.1624,
      "step": 81730
    },
    {
      "epoch": 81.74,
      "learning_rate": 1.3315360615891637e-05,
      "loss": 0.2025,
      "step": 81740
    },
    {
      "epoch": 81.75,
      "learning_rate": 1.3301256081974807e-05,
      "loss": 0.2463,
      "step": 81750
    },
    {
      "epoch": 81.76,
      "learning_rate": 1.3287158295339825e-05,
      "loss": 0.0892,
      "step": 81760
    },
    {
      "epoch": 81.77,
      "learning_rate": 1.3273067257528453e-05,
      "loss": 0.1459,
      "step": 81770
    },
    {
      "epoch": 81.78,
      "learning_rate": 1.3258982970081597e-05,
      "loss": 0.1532,
      "step": 81780
    },
    {
      "epoch": 81.79,
      "learning_rate": 1.3244905434539577e-05,
      "loss": 0.1743,
      "step": 81790
    },
    {
      "epoch": 81.8,
      "learning_rate": 1.3230834652441836e-05,
      "loss": 0.2332,
      "step": 81800
    },
    {
      "epoch": 81.81,
      "learning_rate": 1.3216770625327167e-05,
      "loss": 0.2294,
      "step": 81810
    },
    {
      "epoch": 81.82,
      "learning_rate": 1.320271335473355e-05,
      "loss": 0.1932,
      "step": 81820
    },
    {
      "epoch": 81.83,
      "learning_rate": 1.3188662842198311e-05,
      "loss": 0.1827,
      "step": 81830
    },
    {
      "epoch": 81.84,
      "learning_rate": 1.317461908925794e-05,
      "loss": 0.235,
      "step": 81840
    },
    {
      "epoch": 81.85,
      "learning_rate": 1.31605820974483e-05,
      "loss": 0.2066,
      "step": 81850
    },
    {
      "epoch": 81.86,
      "learning_rate": 1.3146551868304411e-05,
      "loss": 0.1918,
      "step": 81860
    },
    {
      "epoch": 81.87,
      "learning_rate": 1.313252840336064e-05,
      "loss": 0.2458,
      "step": 81870
    },
    {
      "epoch": 81.88,
      "learning_rate": 1.3118511704150517e-05,
      "loss": 0.2899,
      "step": 81880
    },
    {
      "epoch": 81.89,
      "learning_rate": 1.310450177220694e-05,
      "loss": 0.2294,
      "step": 81890
    },
    {
      "epoch": 81.9,
      "learning_rate": 1.3090498609061977e-05,
      "loss": 0.1588,
      "step": 81900
    },
    {
      "epoch": 81.91,
      "learning_rate": 1.3076502216247003e-05,
      "loss": 0.4276,
      "step": 81910
    },
    {
      "epoch": 81.92,
      "learning_rate": 1.3062512595292643e-05,
      "loss": 0.1814,
      "step": 81920
    },
    {
      "epoch": 81.93,
      "learning_rate": 1.3048529747728805e-05,
      "loss": 0.2236,
      "step": 81930
    },
    {
      "epoch": 81.94,
      "learning_rate": 1.3034553675084593e-05,
      "loss": 0.1574,
      "step": 81940
    },
    {
      "epoch": 81.95,
      "learning_rate": 1.3020584378888427e-05,
      "loss": 0.3225,
      "step": 81950
    },
    {
      "epoch": 81.96,
      "learning_rate": 1.300662186066799e-05,
      "loss": 0.2384,
      "step": 81960
    },
    {
      "epoch": 81.97,
      "learning_rate": 1.2992666121950155e-05,
      "loss": 0.2369,
      "step": 81970
    },
    {
      "epoch": 81.98,
      "learning_rate": 1.2978717164261132e-05,
      "loss": 0.2332,
      "step": 81980
    },
    {
      "epoch": 81.99,
      "learning_rate": 1.2964774989126353e-05,
      "loss": 0.1814,
      "step": 81990
    },
    {
      "epoch": 82.0,
      "learning_rate": 1.2950839598070531e-05,
      "loss": 0.2906,
      "step": 82000
    },
    {
      "epoch": 82.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.4787410795688629,
      "eval_runtime": 14.7966,
      "eval_samples_per_second": 135.166,
      "eval_steps_per_second": 16.896,
      "step": 82000
    },
    {
      "epoch": 82.01,
      "learning_rate": 1.2936910992617581e-05,
      "loss": 0.2089,
      "step": 82010
    },
    {
      "epoch": 82.02,
      "learning_rate": 1.2922989174290749e-05,
      "loss": 0.1657,
      "step": 82020
    },
    {
      "epoch": 82.03,
      "learning_rate": 1.2909074144612477e-05,
      "loss": 0.399,
      "step": 82030
    },
    {
      "epoch": 82.04,
      "learning_rate": 1.2895165905104499e-05,
      "loss": 0.1931,
      "step": 82040
    },
    {
      "epoch": 82.05,
      "learning_rate": 1.2881264457287804e-05,
      "loss": 0.2028,
      "step": 82050
    },
    {
      "epoch": 82.06,
      "learning_rate": 1.2867369802682661e-05,
      "loss": 0.2382,
      "step": 82060
    },
    {
      "epoch": 82.07,
      "learning_rate": 1.2853481942808514e-05,
      "loss": 0.1432,
      "step": 82070
    },
    {
      "epoch": 82.08,
      "learning_rate": 1.283960087918417e-05,
      "loss": 0.1308,
      "step": 82080
    },
    {
      "epoch": 82.09,
      "learning_rate": 1.2825726613327591e-05,
      "loss": 0.1022,
      "step": 82090
    },
    {
      "epoch": 82.1,
      "learning_rate": 1.2811859146756081e-05,
      "loss": 0.1887,
      "step": 82100
    },
    {
      "epoch": 82.11,
      "learning_rate": 1.2797998480986153e-05,
      "loss": 0.2219,
      "step": 82110
    },
    {
      "epoch": 82.12,
      "learning_rate": 1.2784144617533606e-05,
      "loss": 0.1323,
      "step": 82120
    },
    {
      "epoch": 82.13,
      "learning_rate": 1.277029755791345e-05,
      "loss": 0.216,
      "step": 82130
    },
    {
      "epoch": 82.14,
      "learning_rate": 1.2756457303640013e-05,
      "loss": 0.1219,
      "step": 82140
    },
    {
      "epoch": 82.15,
      "learning_rate": 1.2742623856226802e-05,
      "loss": 0.1961,
      "step": 82150
    },
    {
      "epoch": 82.16,
      "learning_rate": 1.272879721718664e-05,
      "loss": 0.1816,
      "step": 82160
    },
    {
      "epoch": 82.17,
      "learning_rate": 1.2714977388031592e-05,
      "loss": 0.1584,
      "step": 82170
    },
    {
      "epoch": 82.18,
      "learning_rate": 1.2701164370272998e-05,
      "loss": 0.2001,
      "step": 82180
    },
    {
      "epoch": 82.19,
      "learning_rate": 1.2687358165421377e-05,
      "loss": 0.1402,
      "step": 82190
    },
    {
      "epoch": 82.2,
      "learning_rate": 1.2673558774986587e-05,
      "loss": 0.2464,
      "step": 82200
    },
    {
      "epoch": 82.21,
      "learning_rate": 1.265976620047772e-05,
      "loss": 0.1282,
      "step": 82210
    },
    {
      "epoch": 82.22,
      "learning_rate": 1.264598044340307e-05,
      "loss": 0.1405,
      "step": 82220
    },
    {
      "epoch": 82.23,
      "learning_rate": 1.2632201505270256e-05,
      "loss": 0.1981,
      "step": 82230
    },
    {
      "epoch": 82.24,
      "learning_rate": 1.2618429387586116e-05,
      "loss": 0.1139,
      "step": 82240
    },
    {
      "epoch": 82.25,
      "learning_rate": 1.2604664091856767e-05,
      "loss": 0.1395,
      "step": 82250
    },
    {
      "epoch": 82.26,
      "learning_rate": 1.2590905619587523e-05,
      "loss": 0.0821,
      "step": 82260
    },
    {
      "epoch": 82.27,
      "learning_rate": 1.2577153972283033e-05,
      "loss": 0.2136,
      "step": 82270
    },
    {
      "epoch": 82.28,
      "learning_rate": 1.2563409151447115e-05,
      "loss": 0.3633,
      "step": 82280
    },
    {
      "epoch": 82.29,
      "learning_rate": 1.2549671158582894e-05,
      "loss": 0.0983,
      "step": 82290
    },
    {
      "epoch": 82.3,
      "learning_rate": 1.2535939995192743e-05,
      "loss": 0.1819,
      "step": 82300
    },
    {
      "epoch": 82.31,
      "learning_rate": 1.2522215662778302e-05,
      "loss": 0.1501,
      "step": 82310
    },
    {
      "epoch": 82.32,
      "learning_rate": 1.2508498162840402e-05,
      "loss": 0.1292,
      "step": 82320
    },
    {
      "epoch": 82.33,
      "learning_rate": 1.2494787496879214e-05,
      "loss": 0.1835,
      "step": 82330
    },
    {
      "epoch": 82.34,
      "learning_rate": 1.2481083666394067e-05,
      "loss": 0.0871,
      "step": 82340
    },
    {
      "epoch": 82.35,
      "learning_rate": 1.2467386672883609e-05,
      "loss": 0.2608,
      "step": 82350
    },
    {
      "epoch": 82.36,
      "learning_rate": 1.2453696517845737e-05,
      "loss": 0.2505,
      "step": 82360
    },
    {
      "epoch": 82.37,
      "learning_rate": 1.244001320277759e-05,
      "loss": 0.2855,
      "step": 82370
    },
    {
      "epoch": 82.38,
      "learning_rate": 1.2426336729175521e-05,
      "loss": 0.3115,
      "step": 82380
    },
    {
      "epoch": 82.39,
      "learning_rate": 1.2412667098535214e-05,
      "loss": 0.2199,
      "step": 82390
    },
    {
      "epoch": 82.4,
      "learning_rate": 1.2399004312351509e-05,
      "loss": 0.2515,
      "step": 82400
    },
    {
      "epoch": 82.41,
      "learning_rate": 1.2385348372118578e-05,
      "loss": 0.2124,
      "step": 82410
    },
    {
      "epoch": 82.42,
      "learning_rate": 1.2371699279329808e-05,
      "loss": 0.1965,
      "step": 82420
    },
    {
      "epoch": 82.43,
      "learning_rate": 1.2358057035477863e-05,
      "loss": 0.1384,
      "step": 82430
    },
    {
      "epoch": 82.44,
      "learning_rate": 1.2344421642054603e-05,
      "loss": 0.2552,
      "step": 82440
    },
    {
      "epoch": 82.45,
      "learning_rate": 1.233079310055119e-05,
      "loss": 0.2059,
      "step": 82450
    },
    {
      "epoch": 82.46,
      "learning_rate": 1.231717141245804e-05,
      "loss": 0.307,
      "step": 82460
    },
    {
      "epoch": 82.47,
      "learning_rate": 1.2303556579264765e-05,
      "loss": 0.1552,
      "step": 82470
    },
    {
      "epoch": 82.48,
      "learning_rate": 1.2289948602460278e-05,
      "loss": 0.1865,
      "step": 82480
    },
    {
      "epoch": 82.49,
      "learning_rate": 1.2276347483532725e-05,
      "loss": 0.1442,
      "step": 82490
    },
    {
      "epoch": 82.5,
      "learning_rate": 1.2262753223969532e-05,
      "loss": 0.1661,
      "step": 82500
    },
    {
      "epoch": 82.51,
      "learning_rate": 1.2249165825257301e-05,
      "loss": 0.2628,
      "step": 82510
    },
    {
      "epoch": 82.52,
      "learning_rate": 1.2235585288881968e-05,
      "loss": 0.2668,
      "step": 82520
    },
    {
      "epoch": 82.53,
      "learning_rate": 1.2222011616328648e-05,
      "loss": 0.1203,
      "step": 82530
    },
    {
      "epoch": 82.54,
      "learning_rate": 1.220844480908175e-05,
      "loss": 0.1984,
      "step": 82540
    },
    {
      "epoch": 82.55,
      "learning_rate": 1.2194884868624929e-05,
      "loss": 0.1543,
      "step": 82550
    },
    {
      "epoch": 82.56,
      "learning_rate": 1.2181331796441085e-05,
      "loss": 0.1601,
      "step": 82560
    },
    {
      "epoch": 82.57,
      "learning_rate": 1.216778559401233e-05,
      "loss": 0.2733,
      "step": 82570
    },
    {
      "epoch": 82.58,
      "learning_rate": 1.2154246262820089e-05,
      "loss": 0.1927,
      "step": 82580
    },
    {
      "epoch": 82.59,
      "learning_rate": 1.2140713804344985e-05,
      "loss": 0.1809,
      "step": 82590
    },
    {
      "epoch": 82.6,
      "learning_rate": 1.2127188220066917e-05,
      "loss": 0.1227,
      "step": 82600
    },
    {
      "epoch": 82.61,
      "learning_rate": 1.2113669511464984e-05,
      "loss": 0.1389,
      "step": 82610
    },
    {
      "epoch": 82.62,
      "learning_rate": 1.210015768001765e-05,
      "loss": 0.2083,
      "step": 82620
    },
    {
      "epoch": 82.63,
      "learning_rate": 1.2086652727202479e-05,
      "loss": 0.1155,
      "step": 82630
    },
    {
      "epoch": 82.64,
      "learning_rate": 1.207315465449639e-05,
      "loss": 0.1947,
      "step": 82640
    },
    {
      "epoch": 82.65,
      "learning_rate": 1.2059663463375486e-05,
      "loss": 0.1979,
      "step": 82650
    },
    {
      "epoch": 82.66,
      "learning_rate": 1.204617915531516e-05,
      "loss": 0.1613,
      "step": 82660
    },
    {
      "epoch": 82.67,
      "learning_rate": 1.2032701731790029e-05,
      "loss": 0.2772,
      "step": 82670
    },
    {
      "epoch": 82.68,
      "learning_rate": 1.2019231194273984e-05,
      "loss": 0.1571,
      "step": 82680
    },
    {
      "epoch": 82.69,
      "learning_rate": 1.2005767544240108e-05,
      "loss": 0.1765,
      "step": 82690
    },
    {
      "epoch": 82.7,
      "learning_rate": 1.199231078316078e-05,
      "loss": 0.2309,
      "step": 82700
    },
    {
      "epoch": 82.71,
      "learning_rate": 1.1978860912507632e-05,
      "loss": 0.1481,
      "step": 82710
    },
    {
      "epoch": 82.72,
      "learning_rate": 1.1965417933751486e-05,
      "loss": 0.1264,
      "step": 82720
    },
    {
      "epoch": 82.73,
      "learning_rate": 1.1951981848362486e-05,
      "loss": 0.2447,
      "step": 82730
    },
    {
      "epoch": 82.74,
      "learning_rate": 1.1938552657809919e-05,
      "loss": 0.2354,
      "step": 82740
    },
    {
      "epoch": 82.75,
      "learning_rate": 1.1925130363562463e-05,
      "loss": 0.1727,
      "step": 82750
    },
    {
      "epoch": 82.76,
      "learning_rate": 1.1911714967087902e-05,
      "loss": 0.2466,
      "step": 82760
    },
    {
      "epoch": 82.77,
      "learning_rate": 1.1898306469853352e-05,
      "loss": 0.1939,
      "step": 82770
    },
    {
      "epoch": 82.78,
      "learning_rate": 1.1884904873325119e-05,
      "loss": 0.1861,
      "step": 82780
    },
    {
      "epoch": 82.79,
      "learning_rate": 1.187151017896881e-05,
      "loss": 0.0828,
      "step": 82790
    },
    {
      "epoch": 82.8,
      "learning_rate": 1.1858122388249206e-05,
      "loss": 0.1927,
      "step": 82800
    },
    {
      "epoch": 82.81,
      "learning_rate": 1.1844741502630443e-05,
      "loss": 0.2088,
      "step": 82810
    },
    {
      "epoch": 82.82,
      "learning_rate": 1.1831367523575774e-05,
      "loss": 0.1769,
      "step": 82820
    },
    {
      "epoch": 82.83,
      "learning_rate": 1.1818000452547799e-05,
      "loss": 0.1254,
      "step": 82830
    },
    {
      "epoch": 82.84,
      "learning_rate": 1.1804640291008288e-05,
      "loss": 0.1051,
      "step": 82840
    },
    {
      "epoch": 82.85,
      "learning_rate": 1.1791287040418315e-05,
      "loss": 0.2484,
      "step": 82850
    },
    {
      "epoch": 82.86,
      "learning_rate": 1.177794070223812e-05,
      "loss": 0.1363,
      "step": 82860
    },
    {
      "epoch": 82.87,
      "learning_rate": 1.176460127792732e-05,
      "loss": 0.176,
      "step": 82870
    },
    {
      "epoch": 82.88,
      "learning_rate": 1.1751268768944627e-05,
      "loss": 0.3093,
      "step": 82880
    },
    {
      "epoch": 82.89,
      "learning_rate": 1.1737943176748113e-05,
      "loss": 0.215,
      "step": 82890
    },
    {
      "epoch": 82.9,
      "learning_rate": 1.1724624502794993e-05,
      "loss": 0.1513,
      "step": 82900
    },
    {
      "epoch": 82.91,
      "learning_rate": 1.1711312748541813e-05,
      "loss": 0.1287,
      "step": 82910
    },
    {
      "epoch": 82.92,
      "learning_rate": 1.169800791544433e-05,
      "loss": 0.2154,
      "step": 82920
    },
    {
      "epoch": 82.93,
      "learning_rate": 1.1684710004957515e-05,
      "loss": 0.1748,
      "step": 82930
    },
    {
      "epoch": 82.94,
      "learning_rate": 1.1671419018535614e-05,
      "loss": 0.2087,
      "step": 82940
    },
    {
      "epoch": 82.95,
      "learning_rate": 1.165813495763212e-05,
      "loss": 0.2381,
      "step": 82950
    },
    {
      "epoch": 82.96,
      "learning_rate": 1.1644857823699775e-05,
      "loss": 0.2224,
      "step": 82960
    },
    {
      "epoch": 82.97,
      "learning_rate": 1.1631587618190505e-05,
      "loss": 0.2354,
      "step": 82970
    },
    {
      "epoch": 82.98,
      "learning_rate": 1.1618324342555551e-05,
      "loss": 0.2139,
      "step": 82980
    },
    {
      "epoch": 82.99,
      "learning_rate": 1.160506799824533e-05,
      "loss": 0.2517,
      "step": 82990
    },
    {
      "epoch": 83.0,
      "learning_rate": 1.1591818586709586e-05,
      "loss": 0.2058,
      "step": 83000
    },
    {
      "epoch": 83.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.5142842531204224,
      "eval_runtime": 15.2503,
      "eval_samples_per_second": 131.145,
      "eval_steps_per_second": 16.393,
      "step": 83000
    },
    {
      "epoch": 83.01,
      "learning_rate": 1.1578576109397214e-05,
      "loss": 0.1311,
      "step": 83010
    },
    {
      "epoch": 83.02,
      "learning_rate": 1.1565340567756429e-05,
      "loss": 0.12,
      "step": 83020
    },
    {
      "epoch": 83.03,
      "learning_rate": 1.1552111963234606e-05,
      "loss": 0.0941,
      "step": 83030
    },
    {
      "epoch": 83.04,
      "learning_rate": 1.1538890297278439e-05,
      "loss": 0.2156,
      "step": 83040
    },
    {
      "epoch": 83.05,
      "learning_rate": 1.1525675571333786e-05,
      "loss": 0.0913,
      "step": 83050
    },
    {
      "epoch": 83.06,
      "learning_rate": 1.1512467786845852e-05,
      "loss": 0.0881,
      "step": 83060
    },
    {
      "epoch": 83.07,
      "learning_rate": 1.1499266945258981e-05,
      "loss": 0.197,
      "step": 83070
    },
    {
      "epoch": 83.08,
      "learning_rate": 1.1486073048016808e-05,
      "loss": 0.3035,
      "step": 83080
    },
    {
      "epoch": 83.09,
      "learning_rate": 1.147288609656219e-05,
      "loss": 0.0878,
      "step": 83090
    },
    {
      "epoch": 83.1,
      "learning_rate": 1.1459706092337245e-05,
      "loss": 0.0897,
      "step": 83100
    },
    {
      "epoch": 83.11,
      "learning_rate": 1.1446533036783298e-05,
      "loss": 0.1686,
      "step": 83110
    },
    {
      "epoch": 83.12,
      "learning_rate": 1.1433366931340945e-05,
      "loss": 0.1234,
      "step": 83120
    },
    {
      "epoch": 83.13,
      "learning_rate": 1.142020777745002e-05,
      "loss": 0.2414,
      "step": 83130
    },
    {
      "epoch": 83.14,
      "learning_rate": 1.1407055576549592e-05,
      "loss": 0.2687,
      "step": 83140
    },
    {
      "epoch": 83.15,
      "learning_rate": 1.1393910330077932e-05,
      "loss": 0.076,
      "step": 83150
    },
    {
      "epoch": 83.16,
      "learning_rate": 1.1380772039472621e-05,
      "loss": 0.2373,
      "step": 83160
    },
    {
      "epoch": 83.17,
      "learning_rate": 1.1367640706170437e-05,
      "loss": 0.2708,
      "step": 83170
    },
    {
      "epoch": 83.18,
      "learning_rate": 1.1354516331607385e-05,
      "loss": 0.2,
      "step": 83180
    },
    {
      "epoch": 83.19,
      "learning_rate": 1.1341398917218738e-05,
      "loss": 0.2941,
      "step": 83190
    },
    {
      "epoch": 83.2,
      "learning_rate": 1.1328288464438988e-05,
      "loss": 0.3272,
      "step": 83200
    },
    {
      "epoch": 83.21,
      "learning_rate": 1.1315184974701908e-05,
      "loss": 0.2135,
      "step": 83210
    },
    {
      "epoch": 83.22,
      "learning_rate": 1.130208844944043e-05,
      "loss": 0.322,
      "step": 83220
    },
    {
      "epoch": 83.23,
      "learning_rate": 1.1288998890086811e-05,
      "loss": 0.2149,
      "step": 83230
    },
    {
      "epoch": 83.24,
      "learning_rate": 1.1275916298072465e-05,
      "loss": 0.1925,
      "step": 83240
    },
    {
      "epoch": 83.25,
      "learning_rate": 1.1262840674828106e-05,
      "loss": 0.2773,
      "step": 83250
    },
    {
      "epoch": 83.26,
      "learning_rate": 1.1249772021783662e-05,
      "loss": 0.2837,
      "step": 83260
    },
    {
      "epoch": 83.27,
      "learning_rate": 1.1236710340368319e-05,
      "loss": 0.2214,
      "step": 83270
    },
    {
      "epoch": 83.28,
      "learning_rate": 1.1223655632010448e-05,
      "loss": 0.1022,
      "step": 83280
    },
    {
      "epoch": 83.29,
      "learning_rate": 1.1210607898137733e-05,
      "loss": 0.241,
      "step": 83290
    },
    {
      "epoch": 83.3,
      "learning_rate": 1.1197567140177008e-05,
      "loss": 0.1179,
      "step": 83300
    },
    {
      "epoch": 83.31,
      "learning_rate": 1.1184533359554424e-05,
      "loss": 0.1511,
      "step": 83310
    },
    {
      "epoch": 83.32,
      "learning_rate": 1.1171506557695323e-05,
      "loss": 0.1444,
      "step": 83320
    },
    {
      "epoch": 83.33,
      "learning_rate": 1.1158486736024316e-05,
      "loss": 0.1417,
      "step": 83330
    },
    {
      "epoch": 83.34,
      "learning_rate": 1.1145473895965198e-05,
      "loss": 0.2819,
      "step": 83340
    },
    {
      "epoch": 83.35,
      "learning_rate": 1.1132468038941072e-05,
      "loss": 0.2913,
      "step": 83350
    },
    {
      "epoch": 83.36,
      "learning_rate": 1.1119469166374192e-05,
      "loss": 0.1181,
      "step": 83360
    },
    {
      "epoch": 83.37,
      "learning_rate": 1.110647727968613e-05,
      "loss": 0.1442,
      "step": 83370
    },
    {
      "epoch": 83.38,
      "learning_rate": 1.1093492380297647e-05,
      "loss": 0.1434,
      "step": 83380
    },
    {
      "epoch": 83.39,
      "learning_rate": 1.1080514469628768e-05,
      "loss": 0.2174,
      "step": 83390
    },
    {
      "epoch": 83.4,
      "learning_rate": 1.1067543549098715e-05,
      "loss": 0.1155,
      "step": 83400
    },
    {
      "epoch": 83.41,
      "learning_rate": 1.1054579620125979e-05,
      "loss": 0.2712,
      "step": 83410
    },
    {
      "epoch": 83.42,
      "learning_rate": 1.104162268412829e-05,
      "loss": 0.2438,
      "step": 83420
    },
    {
      "epoch": 83.43,
      "learning_rate": 1.102867274252256e-05,
      "loss": 0.2045,
      "step": 83430
    },
    {
      "epoch": 83.44,
      "learning_rate": 1.1015729796725012e-05,
      "loss": 0.1576,
      "step": 83440
    },
    {
      "epoch": 83.45,
      "learning_rate": 1.1002793848151048e-05,
      "loss": 0.1197,
      "step": 83450
    },
    {
      "epoch": 83.46,
      "learning_rate": 1.0989864898215345e-05,
      "loss": 0.2582,
      "step": 83460
    },
    {
      "epoch": 83.47,
      "learning_rate": 1.0976942948331764e-05,
      "loss": 0.1806,
      "step": 83470
    },
    {
      "epoch": 83.48,
      "learning_rate": 1.0964027999913464e-05,
      "loss": 0.2301,
      "step": 83480
    },
    {
      "epoch": 83.49,
      "learning_rate": 1.0951120054372767e-05,
      "loss": 0.2363,
      "step": 83490
    },
    {
      "epoch": 83.5,
      "learning_rate": 1.0938219113121286e-05,
      "loss": 0.2396,
      "step": 83500
    },
    {
      "epoch": 83.51,
      "learning_rate": 1.0925325177569841e-05,
      "loss": 0.1904,
      "step": 83510
    },
    {
      "epoch": 83.52,
      "learning_rate": 1.0912438249128522e-05,
      "loss": 0.3522,
      "step": 83520
    },
    {
      "epoch": 83.53,
      "learning_rate": 1.0899558329206583e-05,
      "loss": 0.292,
      "step": 83530
    },
    {
      "epoch": 83.54,
      "learning_rate": 1.0886685419212593e-05,
      "loss": 0.2174,
      "step": 83540
    },
    {
      "epoch": 83.55,
      "learning_rate": 1.0873819520554272e-05,
      "loss": 0.1886,
      "step": 83550
    },
    {
      "epoch": 83.56,
      "learning_rate": 1.0860960634638638e-05,
      "loss": 0.192,
      "step": 83560
    },
    {
      "epoch": 83.57,
      "learning_rate": 1.0848108762871915e-05,
      "loss": 0.2802,
      "step": 83570
    },
    {
      "epoch": 83.58,
      "learning_rate": 1.083526390665959e-05,
      "loss": 0.162,
      "step": 83580
    },
    {
      "epoch": 83.59,
      "learning_rate": 1.0822426067406309e-05,
      "loss": 0.1982,
      "step": 83590
    },
    {
      "epoch": 83.6,
      "learning_rate": 1.0809595246516044e-05,
      "loss": 0.2548,
      "step": 83600
    },
    {
      "epoch": 83.61,
      "learning_rate": 1.0796771445391916e-05,
      "loss": 0.1094,
      "step": 83610
    },
    {
      "epoch": 83.62,
      "learning_rate": 1.0783954665436334e-05,
      "loss": 0.3036,
      "step": 83620
    },
    {
      "epoch": 83.63,
      "learning_rate": 1.0771144908050918e-05,
      "loss": 0.17,
      "step": 83630
    },
    {
      "epoch": 83.64,
      "learning_rate": 1.0758342174636559e-05,
      "loss": 0.2099,
      "step": 83640
    },
    {
      "epoch": 83.65,
      "learning_rate": 1.0745546466593283e-05,
      "loss": 0.1843,
      "step": 83650
    },
    {
      "epoch": 83.66,
      "learning_rate": 1.0732757785320448e-05,
      "loss": 0.1868,
      "step": 83660
    },
    {
      "epoch": 83.67,
      "learning_rate": 1.071997613221661e-05,
      "loss": 0.2732,
      "step": 83670
    },
    {
      "epoch": 83.68,
      "learning_rate": 1.0707201508679525e-05,
      "loss": 0.1574,
      "step": 83680
    },
    {
      "epoch": 83.69,
      "learning_rate": 1.0694433916106218e-05,
      "loss": 0.2027,
      "step": 83690
    },
    {
      "epoch": 83.7,
      "learning_rate": 1.0681673355892938e-05,
      "loss": 0.2026,
      "step": 83700
    },
    {
      "epoch": 83.71,
      "learning_rate": 1.0668919829435171e-05,
      "loss": 0.1792,
      "step": 83710
    },
    {
      "epoch": 83.72,
      "learning_rate": 1.06561733381276e-05,
      "loss": 0.2052,
      "step": 83720
    },
    {
      "epoch": 83.73,
      "learning_rate": 1.0643433883364192e-05,
      "loss": 0.2295,
      "step": 83730
    },
    {
      "epoch": 83.74,
      "learning_rate": 1.0630701466538074e-05,
      "loss": 0.3003,
      "step": 83740
    },
    {
      "epoch": 83.75,
      "learning_rate": 1.061797608904166e-05,
      "loss": 0.2472,
      "step": 83750
    },
    {
      "epoch": 83.76,
      "learning_rate": 1.0605257752266593e-05,
      "loss": 0.1186,
      "step": 83760
    },
    {
      "epoch": 83.77,
      "learning_rate": 1.0592546457603737e-05,
      "loss": 0.1672,
      "step": 83770
    },
    {
      "epoch": 83.78,
      "learning_rate": 1.0579842206443146e-05,
      "loss": 0.1152,
      "step": 83780
    },
    {
      "epoch": 83.79,
      "learning_rate": 1.0567145000174183e-05,
      "loss": 0.2156,
      "step": 83790
    },
    {
      "epoch": 83.8,
      "learning_rate": 1.0554454840185344e-05,
      "loss": 0.2206,
      "step": 83800
    },
    {
      "epoch": 83.81,
      "learning_rate": 1.0541771727864448e-05,
      "loss": 0.1637,
      "step": 83810
    },
    {
      "epoch": 83.82,
      "learning_rate": 1.052909566459845e-05,
      "loss": 0.1601,
      "step": 83820
    },
    {
      "epoch": 83.83,
      "learning_rate": 1.0516426651773658e-05,
      "loss": 0.1383,
      "step": 83830
    },
    {
      "epoch": 83.84,
      "learning_rate": 1.050376469077548e-05,
      "loss": 0.0895,
      "step": 83840
    },
    {
      "epoch": 83.85,
      "learning_rate": 1.049110978298864e-05,
      "loss": 0.1708,
      "step": 83850
    },
    {
      "epoch": 83.86,
      "learning_rate": 1.0478461929797028e-05,
      "loss": 0.0638,
      "step": 83860
    },
    {
      "epoch": 83.87,
      "learning_rate": 1.0465821132583816e-05,
      "loss": 0.1451,
      "step": 83870
    },
    {
      "epoch": 83.88,
      "learning_rate": 1.0453187392731383e-05,
      "loss": 0.2885,
      "step": 83880
    },
    {
      "epoch": 83.89,
      "learning_rate": 1.0440560711621341e-05,
      "loss": 0.1563,
      "step": 83890
    },
    {
      "epoch": 83.9,
      "learning_rate": 1.0427941090634508e-05,
      "loss": 0.1892,
      "step": 83900
    },
    {
      "epoch": 83.91,
      "learning_rate": 1.0415328531150951e-05,
      "loss": 0.2355,
      "step": 83910
    },
    {
      "epoch": 83.92,
      "learning_rate": 1.0402723034549982e-05,
      "loss": 0.0479,
      "step": 83920
    },
    {
      "epoch": 83.93,
      "learning_rate": 1.039012460221008e-05,
      "loss": 0.1522,
      "step": 83930
    },
    {
      "epoch": 83.94,
      "learning_rate": 1.0377533235509034e-05,
      "loss": 0.1981,
      "step": 83940
    },
    {
      "epoch": 83.95,
      "learning_rate": 1.0364948935823753e-05,
      "loss": 0.0801,
      "step": 83950
    },
    {
      "epoch": 83.96,
      "learning_rate": 1.0352371704530518e-05,
      "loss": 0.2408,
      "step": 83960
    },
    {
      "epoch": 83.97,
      "learning_rate": 1.0339801543004706e-05,
      "loss": 0.1756,
      "step": 83970
    },
    {
      "epoch": 83.98,
      "learning_rate": 1.0327238452620989e-05,
      "loss": 0.1364,
      "step": 83980
    },
    {
      "epoch": 83.99,
      "learning_rate": 1.031468243475323e-05,
      "loss": 0.1317,
      "step": 83990
    },
    {
      "epoch": 84.0,
      "learning_rate": 1.0302133490774562e-05,
      "loss": 0.1368,
      "step": 84000
    },
    {
      "epoch": 84.0,
      "eval_accuracy": 0.8,
      "eval_loss": 0.5829029679298401,
      "eval_runtime": 15.1501,
      "eval_samples_per_second": 132.012,
      "eval_steps_per_second": 16.502,
      "step": 84000
    },
    {
      "epoch": 84.01,
      "learning_rate": 1.0290845490503157e-05,
      "loss": 0.1866,
      "step": 84010
    },
    {
      "epoch": 84.02,
      "learning_rate": 1.0278309990693842e-05,
      "loss": 0.1899,
      "step": 84020
    },
    {
      "epoch": 84.03,
      "learning_rate": 1.026578156875127e-05,
      "loss": 0.1323,
      "step": 84030
    },
    {
      "epoch": 84.04,
      "learning_rate": 1.0253260226045485e-05,
      "loss": 0.1098,
      "step": 84040
    },
    {
      "epoch": 84.05,
      "learning_rate": 1.0240745963945835e-05,
      "loss": 0.2598,
      "step": 84050
    },
    {
      "epoch": 84.06,
      "learning_rate": 1.0228238783820817e-05,
      "loss": 0.1188,
      "step": 84060
    },
    {
      "epoch": 84.07,
      "learning_rate": 1.0215738687038244e-05,
      "loss": 0.1566,
      "step": 84070
    },
    {
      "epoch": 84.08,
      "learning_rate": 1.0203245674965049e-05,
      "loss": 0.2022,
      "step": 84080
    },
    {
      "epoch": 84.09,
      "learning_rate": 1.019075974896753e-05,
      "loss": 0.1491,
      "step": 84090
    },
    {
      "epoch": 84.1,
      "learning_rate": 1.0178280910411063e-05,
      "loss": 0.2026,
      "step": 84100
    },
    {
      "epoch": 84.11,
      "learning_rate": 1.0165809160660354e-05,
      "loss": 0.3411,
      "step": 84110
    },
    {
      "epoch": 84.12,
      "learning_rate": 1.0153344501079264e-05,
      "loss": 0.2748,
      "step": 84120
    },
    {
      "epoch": 84.13,
      "learning_rate": 1.0140886933030918e-05,
      "loss": 0.1386,
      "step": 84130
    },
    {
      "epoch": 84.14,
      "learning_rate": 1.0128436457877667e-05,
      "loss": 0.08,
      "step": 84140
    },
    {
      "epoch": 84.15,
      "learning_rate": 1.011599307698109e-05,
      "loss": 0.1429,
      "step": 84150
    },
    {
      "epoch": 84.16,
      "learning_rate": 1.0103556791701942e-05,
      "loss": 0.0448,
      "step": 84160
    },
    {
      "epoch": 84.17,
      "learning_rate": 1.0091127603400249e-05,
      "loss": 0.2862,
      "step": 84170
    },
    {
      "epoch": 84.18,
      "learning_rate": 1.0078705513435265e-05,
      "loss": 0.0607,
      "step": 84180
    },
    {
      "epoch": 84.19,
      "learning_rate": 1.0066290523165429e-05,
      "loss": 0.2393,
      "step": 84190
    },
    {
      "epoch": 84.2,
      "learning_rate": 1.0053882633948448e-05,
      "loss": 0.1644,
      "step": 84200
    },
    {
      "epoch": 84.21,
      "learning_rate": 1.0041481847141186e-05,
      "loss": 0.1454,
      "step": 84210
    },
    {
      "epoch": 84.22,
      "learning_rate": 1.002908816409984e-05,
      "loss": 0.1471,
      "step": 84220
    },
    {
      "epoch": 84.23,
      "learning_rate": 1.0016701586179713e-05,
      "loss": 0.2044,
      "step": 84230
    },
    {
      "epoch": 84.24,
      "learning_rate": 1.0004322114735416e-05,
      "loss": 0.2103,
      "step": 84240
    },
    {
      "epoch": 84.25,
      "learning_rate": 9.99194975112072e-06,
      "loss": 0.2027,
      "step": 84250
    },
    {
      "epoch": 84.26,
      "learning_rate": 9.979584496688675e-06,
      "loss": 0.1449,
      "step": 84260
    },
    {
      "epoch": 84.27,
      "learning_rate": 9.967226352791473e-06,
      "loss": 0.1512,
      "step": 84270
    },
    {
      "epoch": 84.28,
      "learning_rate": 9.95487532078066e-06,
      "loss": 0.1453,
      "step": 84280
    },
    {
      "epoch": 84.29,
      "learning_rate": 9.942531402006873e-06,
      "loss": 0.4124,
      "step": 84290
    },
    {
      "epoch": 84.3,
      "learning_rate": 9.930194597820054e-06,
      "loss": 0.2066,
      "step": 84300
    },
    {
      "epoch": 84.31,
      "learning_rate": 9.917864909569309e-06,
      "loss": 0.1949,
      "step": 84310
    },
    {
      "epoch": 84.32,
      "learning_rate": 9.905542338603017e-06,
      "loss": 0.163,
      "step": 84320
    },
    {
      "epoch": 84.33,
      "learning_rate": 9.893226886268718e-06,
      "loss": 0.1682,
      "step": 84330
    },
    {
      "epoch": 84.34,
      "learning_rate": 9.880918553913276e-06,
      "loss": 0.2735,
      "step": 84340
    },
    {
      "epoch": 84.35,
      "learning_rate": 9.868617342882663e-06,
      "loss": 0.2325,
      "step": 84350
    },
    {
      "epoch": 84.36,
      "learning_rate": 9.856323254522144e-06,
      "loss": 0.106,
      "step": 84360
    },
    {
      "epoch": 84.37,
      "learning_rate": 9.844036290176155e-06,
      "loss": 0.2231,
      "step": 84370
    },
    {
      "epoch": 84.38,
      "learning_rate": 9.831756451188394e-06,
      "loss": 0.0778,
      "step": 84380
    },
    {
      "epoch": 84.39,
      "learning_rate": 9.819483738901787e-06,
      "loss": 0.1595,
      "step": 84390
    },
    {
      "epoch": 84.4,
      "learning_rate": 9.807218154658427e-06,
      "loss": 0.2239,
      "step": 84400
    },
    {
      "epoch": 84.41,
      "learning_rate": 9.794959699799676e-06,
      "loss": 0.1915,
      "step": 84410
    },
    {
      "epoch": 84.42,
      "learning_rate": 9.782708375666092e-06,
      "loss": 0.1983,
      "step": 84420
    },
    {
      "epoch": 84.43,
      "learning_rate": 9.77046418359749e-06,
      "loss": 0.1864,
      "step": 84430
    },
    {
      "epoch": 84.44,
      "learning_rate": 9.75822712493283e-06,
      "loss": 0.1898,
      "step": 84440
    },
    {
      "epoch": 84.45,
      "learning_rate": 9.745997201010383e-06,
      "loss": 0.2624,
      "step": 84450
    },
    {
      "epoch": 84.46,
      "learning_rate": 9.733774413167539e-06,
      "loss": 0.1692,
      "step": 84460
    },
    {
      "epoch": 84.47,
      "learning_rate": 9.721558762741036e-06,
      "loss": 0.2865,
      "step": 84470
    },
    {
      "epoch": 84.48,
      "learning_rate": 9.709350251066705e-06,
      "loss": 0.0959,
      "step": 84480
    },
    {
      "epoch": 84.49,
      "learning_rate": 9.69714887947968e-06,
      "loss": 0.1715,
      "step": 84490
    },
    {
      "epoch": 84.5,
      "learning_rate": 9.684954649314258e-06,
      "loss": 0.1824,
      "step": 84500
    },
    {
      "epoch": 84.51,
      "learning_rate": 9.672767561904015e-06,
      "loss": 0.1604,
      "step": 84510
    },
    {
      "epoch": 84.52,
      "learning_rate": 9.66058761858167e-06,
      "loss": 0.2461,
      "step": 84520
    },
    {
      "epoch": 84.53,
      "learning_rate": 9.648414820679229e-06,
      "loss": 0.163,
      "step": 84530
    },
    {
      "epoch": 84.54,
      "learning_rate": 9.636249169527896e-06,
      "loss": 0.1814,
      "step": 84540
    },
    {
      "epoch": 84.55,
      "learning_rate": 9.62409066645809e-06,
      "loss": 0.1041,
      "step": 84550
    },
    {
      "epoch": 84.56,
      "learning_rate": 9.611939312799422e-06,
      "loss": 0.1302,
      "step": 84560
    },
    {
      "epoch": 84.57,
      "learning_rate": 9.599795109880779e-06,
      "loss": 0.1157,
      "step": 84570
    },
    {
      "epoch": 84.58,
      "learning_rate": 9.587658059030199e-06,
      "loss": 0.1772,
      "step": 84580
    },
    {
      "epoch": 84.59,
      "learning_rate": 9.575528161574985e-06,
      "loss": 0.1607,
      "step": 84590
    },
    {
      "epoch": 84.6,
      "learning_rate": 9.563405418841647e-06,
      "loss": 0.219,
      "step": 84600
    },
    {
      "epoch": 84.61,
      "learning_rate": 9.551289832155928e-06,
      "loss": 0.1037,
      "step": 84610
    },
    {
      "epoch": 84.62,
      "learning_rate": 9.539181402842739e-06,
      "loss": 0.2351,
      "step": 84620
    },
    {
      "epoch": 84.63,
      "learning_rate": 9.52708013222625e-06,
      "loss": 0.222,
      "step": 84630
    },
    {
      "epoch": 84.64,
      "learning_rate": 9.514986021629855e-06,
      "loss": 0.2755,
      "step": 84640
    },
    {
      "epoch": 84.65,
      "learning_rate": 9.502899072376122e-06,
      "loss": 0.1206,
      "step": 84650
    },
    {
      "epoch": 84.66,
      "learning_rate": 9.490819285786866e-06,
      "loss": 0.2615,
      "step": 84660
    },
    {
      "epoch": 84.67,
      "learning_rate": 9.478746663183123e-06,
      "loss": 0.2041,
      "step": 84670
    },
    {
      "epoch": 84.68,
      "learning_rate": 9.466681205885154e-06,
      "loss": 0.2148,
      "step": 84680
    },
    {
      "epoch": 84.69,
      "learning_rate": 9.454622915212387e-06,
      "loss": 0.2326,
      "step": 84690
    },
    {
      "epoch": 84.7,
      "learning_rate": 9.442571792483525e-06,
      "loss": 0.1681,
      "step": 84700
    },
    {
      "epoch": 84.71,
      "learning_rate": 9.43052783901643e-06,
      "loss": 0.2102,
      "step": 84710
    },
    {
      "epoch": 84.72,
      "learning_rate": 9.418491056128233e-06,
      "loss": 0.164,
      "step": 84720
    },
    {
      "epoch": 84.73,
      "learning_rate": 9.406461445135247e-06,
      "loss": 0.1885,
      "step": 84730
    },
    {
      "epoch": 84.74,
      "learning_rate": 9.394439007353036e-06,
      "loss": 0.2954,
      "step": 84740
    },
    {
      "epoch": 84.75,
      "learning_rate": 9.382423744096323e-06,
      "loss": 0.2537,
      "step": 84750
    },
    {
      "epoch": 84.76,
      "learning_rate": 9.370415656679116e-06,
      "loss": 0.2101,
      "step": 84760
    },
    {
      "epoch": 84.77,
      "learning_rate": 9.358414746414566e-06,
      "loss": 0.1369,
      "step": 84770
    },
    {
      "epoch": 84.78,
      "learning_rate": 9.346421014615079e-06,
      "loss": 0.0751,
      "step": 84780
    },
    {
      "epoch": 84.79,
      "learning_rate": 9.334434462592292e-06,
      "loss": 0.16,
      "step": 84790
    },
    {
      "epoch": 84.8,
      "learning_rate": 9.322455091657028e-06,
      "loss": 0.1954,
      "step": 84800
    },
    {
      "epoch": 84.81,
      "learning_rate": 9.310482903119323e-06,
      "loss": 0.2287,
      "step": 84810
    },
    {
      "epoch": 84.82,
      "learning_rate": 9.298517898288465e-06,
      "loss": 0.2823,
      "step": 84820
    },
    {
      "epoch": 84.83,
      "learning_rate": 9.286560078472882e-06,
      "loss": 0.3122,
      "step": 84830
    },
    {
      "epoch": 84.84,
      "learning_rate": 9.274609444980303e-06,
      "loss": 0.1354,
      "step": 84840
    },
    {
      "epoch": 84.85,
      "learning_rate": 9.262665999117606e-06,
      "loss": 0.0977,
      "step": 84850
    },
    {
      "epoch": 84.86,
      "learning_rate": 9.250729742190947e-06,
      "loss": 0.2263,
      "step": 84860
    },
    {
      "epoch": 84.87,
      "learning_rate": 9.238800675505606e-06,
      "loss": 0.2223,
      "step": 84870
    },
    {
      "epoch": 84.88,
      "learning_rate": 9.226878800366158e-06,
      "loss": 0.1394,
      "step": 84880
    },
    {
      "epoch": 84.89,
      "learning_rate": 9.214964118076368e-06,
      "loss": 0.1641,
      "step": 84890
    },
    {
      "epoch": 84.9,
      "learning_rate": 9.203056629939185e-06,
      "loss": 0.3147,
      "step": 84900
    },
    {
      "epoch": 84.91,
      "learning_rate": 9.1911563372568e-06,
      "loss": 0.1631,
      "step": 84910
    },
    {
      "epoch": 84.92,
      "learning_rate": 9.179263241330623e-06,
      "loss": 0.2256,
      "step": 84920
    },
    {
      "epoch": 84.93,
      "learning_rate": 9.167377343461262e-06,
      "loss": 0.3108,
      "step": 84930
    },
    {
      "epoch": 84.94,
      "learning_rate": 9.15549864494853e-06,
      "loss": 0.1411,
      "step": 84940
    },
    {
      "epoch": 84.95,
      "learning_rate": 9.143627147091487e-06,
      "loss": 0.1149,
      "step": 84950
    },
    {
      "epoch": 84.96,
      "learning_rate": 9.131762851188342e-06,
      "loss": 0.0979,
      "step": 84960
    },
    {
      "epoch": 84.97,
      "learning_rate": 9.119905758536586e-06,
      "loss": 0.185,
      "step": 84970
    },
    {
      "epoch": 84.98,
      "learning_rate": 9.108055870432887e-06,
      "loss": 0.1231,
      "step": 84980
    },
    {
      "epoch": 84.99,
      "learning_rate": 9.096213188173143e-06,
      "loss": 0.2308,
      "step": 84990
    },
    {
      "epoch": 85.0,
      "learning_rate": 9.084377713052426e-06,
      "loss": 0.1468,
      "step": 85000
    },
    {
      "epoch": 85.0,
      "eval_accuracy": 0.796,
      "eval_loss": 0.5700901746749878,
      "eval_runtime": 14.7984,
      "eval_samples_per_second": 135.15,
      "eval_steps_per_second": 16.894,
      "step": 85000
    },
    {
      "epoch": 85.01,
      "learning_rate": 9.072549446365076e-06,
      "loss": 0.1749,
      "step": 85010
    },
    {
      "epoch": 85.02,
      "learning_rate": 9.060728389404584e-06,
      "loss": 0.2105,
      "step": 85020
    },
    {
      "epoch": 85.03,
      "learning_rate": 9.048914543463714e-06,
      "loss": 0.2336,
      "step": 85030
    },
    {
      "epoch": 85.04,
      "learning_rate": 9.03710790983436e-06,
      "loss": 0.1938,
      "step": 85040
    },
    {
      "epoch": 85.05,
      "learning_rate": 9.025308489807745e-06,
      "loss": 0.1157,
      "step": 85050
    },
    {
      "epoch": 85.06,
      "learning_rate": 9.01351628467418e-06,
      "loss": 0.1808,
      "step": 85060
    },
    {
      "epoch": 85.07,
      "learning_rate": 9.001731295723283e-06,
      "loss": 0.2688,
      "step": 85070
    },
    {
      "epoch": 85.08,
      "learning_rate": 8.989953524243806e-06,
      "loss": 0.2667,
      "step": 85080
    },
    {
      "epoch": 85.09,
      "learning_rate": 8.978182971523779e-06,
      "loss": 0.3273,
      "step": 85090
    },
    {
      "epoch": 85.1,
      "learning_rate": 8.966419638850387e-06,
      "loss": 0.07,
      "step": 85100
    },
    {
      "epoch": 85.11,
      "learning_rate": 8.954663527510084e-06,
      "loss": 0.1558,
      "step": 85110
    },
    {
      "epoch": 85.12,
      "learning_rate": 8.942914638788468e-06,
      "loss": 0.2648,
      "step": 85120
    },
    {
      "epoch": 85.13,
      "learning_rate": 8.931172973970386e-06,
      "loss": 0.154,
      "step": 85130
    },
    {
      "epoch": 85.14,
      "learning_rate": 8.91943853433991e-06,
      "loss": 0.184,
      "step": 85140
    },
    {
      "epoch": 85.15,
      "learning_rate": 8.907711321180272e-06,
      "loss": 0.2625,
      "step": 85150
    },
    {
      "epoch": 85.16,
      "learning_rate": 8.895991335773955e-06,
      "loss": 0.1663,
      "step": 85160
    },
    {
      "epoch": 85.17,
      "learning_rate": 8.884278579402642e-06,
      "loss": 0.1591,
      "step": 85170
    },
    {
      "epoch": 85.18,
      "learning_rate": 8.872573053347234e-06,
      "loss": 0.1311,
      "step": 85180
    },
    {
      "epoch": 85.19,
      "learning_rate": 8.860874758887798e-06,
      "loss": 0.1566,
      "step": 85190
    },
    {
      "epoch": 85.2,
      "learning_rate": 8.849183697303677e-06,
      "loss": 0.1838,
      "step": 85200
    },
    {
      "epoch": 85.21,
      "learning_rate": 8.837499869873357e-06,
      "loss": 0.1593,
      "step": 85210
    },
    {
      "epoch": 85.22,
      "learning_rate": 8.825823277874592e-06,
      "loss": 0.1133,
      "step": 85220
    },
    {
      "epoch": 85.23,
      "learning_rate": 8.814153922584265e-06,
      "loss": 0.1391,
      "step": 85230
    },
    {
      "epoch": 85.24,
      "learning_rate": 8.802491805278595e-06,
      "loss": 0.1024,
      "step": 85240
    },
    {
      "epoch": 85.25,
      "learning_rate": 8.790836927232872e-06,
      "loss": 0.1432,
      "step": 85250
    },
    {
      "epoch": 85.26,
      "learning_rate": 8.779189289721706e-06,
      "loss": 0.2946,
      "step": 85260
    },
    {
      "epoch": 85.27,
      "learning_rate": 8.767548894018808e-06,
      "loss": 0.2269,
      "step": 85270
    },
    {
      "epoch": 85.28,
      "learning_rate": 8.755915741397213e-06,
      "loss": 0.1585,
      "step": 85280
    },
    {
      "epoch": 85.29,
      "learning_rate": 8.744289833129034e-06,
      "loss": 0.2198,
      "step": 85290
    },
    {
      "epoch": 85.3,
      "learning_rate": 8.73267117048574e-06,
      "loss": 0.2489,
      "step": 85300
    },
    {
      "epoch": 85.31,
      "learning_rate": 8.721059754737877e-06,
      "loss": 0.1712,
      "step": 85310
    },
    {
      "epoch": 85.32,
      "learning_rate": 8.709455587155293e-06,
      "loss": 0.1901,
      "step": 85320
    },
    {
      "epoch": 85.33,
      "learning_rate": 8.697858669006961e-06,
      "loss": 0.1319,
      "step": 85330
    },
    {
      "epoch": 85.34,
      "learning_rate": 8.686269001561116e-06,
      "loss": 0.2481,
      "step": 85340
    },
    {
      "epoch": 85.35,
      "learning_rate": 8.674686586085197e-06,
      "loss": 0.1126,
      "step": 85350
    },
    {
      "epoch": 85.36,
      "learning_rate": 8.663111423845848e-06,
      "loss": 0.1773,
      "step": 85360
    },
    {
      "epoch": 85.37,
      "learning_rate": 8.65154351610888e-06,
      "loss": 0.132,
      "step": 85370
    },
    {
      "epoch": 85.38,
      "learning_rate": 8.639982864139367e-06,
      "loss": 0.1446,
      "step": 85380
    },
    {
      "epoch": 85.39,
      "learning_rate": 8.62842946920157e-06,
      "loss": 0.217,
      "step": 85390
    },
    {
      "epoch": 85.4,
      "learning_rate": 8.616883332558922e-06,
      "loss": 0.2233,
      "step": 85400
    },
    {
      "epoch": 85.41,
      "learning_rate": 8.60534445547412e-06,
      "loss": 0.161,
      "step": 85410
    },
    {
      "epoch": 85.42,
      "learning_rate": 8.593812839208997e-06,
      "loss": 0.1542,
      "step": 85420
    },
    {
      "epoch": 85.43,
      "learning_rate": 8.582288485024686e-06,
      "loss": 0.134,
      "step": 85430
    },
    {
      "epoch": 85.44,
      "learning_rate": 8.570771394181436e-06,
      "loss": 0.2181,
      "step": 85440
    },
    {
      "epoch": 85.45,
      "learning_rate": 8.559261567938774e-06,
      "loss": 0.1509,
      "step": 85450
    },
    {
      "epoch": 85.46,
      "learning_rate": 8.547759007555352e-06,
      "loss": 0.1475,
      "step": 85460
    },
    {
      "epoch": 85.47,
      "learning_rate": 8.536263714289112e-06,
      "loss": 0.095,
      "step": 85470
    },
    {
      "epoch": 85.48,
      "learning_rate": 8.524775689397117e-06,
      "loss": 0.3251,
      "step": 85480
    },
    {
      "epoch": 85.49,
      "learning_rate": 8.513294934135745e-06,
      "loss": 0.1846,
      "step": 85490
    },
    {
      "epoch": 85.5,
      "learning_rate": 8.501821449760458e-06,
      "loss": 0.1548,
      "step": 85500
    },
    {
      "epoch": 85.51,
      "learning_rate": 8.490355237526009e-06,
      "loss": 0.1465,
      "step": 85510
    },
    {
      "epoch": 85.52,
      "learning_rate": 8.478896298686304e-06,
      "loss": 0.1415,
      "step": 85520
    },
    {
      "epoch": 85.53,
      "learning_rate": 8.467444634494502e-06,
      "loss": 0.1038,
      "step": 85530
    },
    {
      "epoch": 85.54,
      "learning_rate": 8.456000246202891e-06,
      "loss": 0.1193,
      "step": 85540
    },
    {
      "epoch": 85.55,
      "learning_rate": 8.444563135063075e-06,
      "loss": 0.1525,
      "step": 85550
    },
    {
      "epoch": 85.56,
      "learning_rate": 8.433133302325767e-06,
      "loss": 0.0927,
      "step": 85560
    },
    {
      "epoch": 85.57,
      "learning_rate": 8.421710749240923e-06,
      "loss": 0.1765,
      "step": 85570
    },
    {
      "epoch": 85.58,
      "learning_rate": 8.410295477057676e-06,
      "loss": 0.0872,
      "step": 85580
    },
    {
      "epoch": 85.59,
      "learning_rate": 8.398887487024405e-06,
      "loss": 0.1287,
      "step": 85590
    },
    {
      "epoch": 85.6,
      "learning_rate": 8.387486780388685e-06,
      "loss": 0.2164,
      "step": 85600
    },
    {
      "epoch": 85.61,
      "learning_rate": 8.376093358397238e-06,
      "loss": 0.0854,
      "step": 85610
    },
    {
      "epoch": 85.62,
      "learning_rate": 8.364707222296056e-06,
      "loss": 0.3015,
      "step": 85620
    },
    {
      "epoch": 85.63,
      "learning_rate": 8.3533283733303e-06,
      "loss": 0.2626,
      "step": 85630
    },
    {
      "epoch": 85.64,
      "learning_rate": 8.34195681274438e-06,
      "loss": 0.0783,
      "step": 85640
    },
    {
      "epoch": 85.65,
      "learning_rate": 8.330592541781822e-06,
      "loss": 0.234,
      "step": 85650
    },
    {
      "epoch": 85.66,
      "learning_rate": 8.319235561685442e-06,
      "loss": 0.1021,
      "step": 85660
    },
    {
      "epoch": 85.67,
      "learning_rate": 8.307885873697178e-06,
      "loss": 0.3111,
      "step": 85670
    },
    {
      "epoch": 85.68,
      "learning_rate": 8.296543479058274e-06,
      "loss": 0.3281,
      "step": 85680
    },
    {
      "epoch": 85.69,
      "learning_rate": 8.285208379009075e-06,
      "loss": 0.129,
      "step": 85690
    },
    {
      "epoch": 85.7,
      "learning_rate": 8.273880574789193e-06,
      "loss": 0.1334,
      "step": 85700
    },
    {
      "epoch": 85.71,
      "learning_rate": 8.262560067637402e-06,
      "loss": 0.106,
      "step": 85710
    },
    {
      "epoch": 85.72,
      "learning_rate": 8.251246858791713e-06,
      "loss": 0.1763,
      "step": 85720
    },
    {
      "epoch": 85.73,
      "learning_rate": 8.239940949489302e-06,
      "loss": 0.2323,
      "step": 85730
    },
    {
      "epoch": 85.74,
      "learning_rate": 8.22864234096658e-06,
      "loss": 0.0479,
      "step": 85740
    },
    {
      "epoch": 85.75,
      "learning_rate": 8.217351034459133e-06,
      "loss": 0.2233,
      "step": 85750
    },
    {
      "epoch": 85.76,
      "learning_rate": 8.20606703120179e-06,
      "loss": 0.3634,
      "step": 85760
    },
    {
      "epoch": 85.77,
      "learning_rate": 8.194790332428525e-06,
      "loss": 0.1315,
      "step": 85770
    },
    {
      "epoch": 85.78,
      "learning_rate": 8.183520939372556e-06,
      "loss": 0.2417,
      "step": 85780
    },
    {
      "epoch": 85.79,
      "learning_rate": 8.172258853266268e-06,
      "loss": 0.3032,
      "step": 85790
    },
    {
      "epoch": 85.8,
      "learning_rate": 8.161004075341271e-06,
      "loss": 0.1981,
      "step": 85800
    },
    {
      "epoch": 85.81,
      "learning_rate": 8.149756606828384e-06,
      "loss": 0.2352,
      "step": 85810
    },
    {
      "epoch": 85.82,
      "learning_rate": 8.138516448957622e-06,
      "loss": 0.1815,
      "step": 85820
    },
    {
      "epoch": 85.83,
      "learning_rate": 8.12728360295816e-06,
      "loss": 0.1355,
      "step": 85830
    },
    {
      "epoch": 85.84,
      "learning_rate": 8.116058070058424e-06,
      "loss": 0.193,
      "step": 85840
    },
    {
      "epoch": 85.85,
      "learning_rate": 8.10483985148603e-06,
      "loss": 0.1801,
      "step": 85850
    },
    {
      "epoch": 85.86,
      "learning_rate": 8.09362894846776e-06,
      "loss": 0.2292,
      "step": 85860
    },
    {
      "epoch": 85.87,
      "learning_rate": 8.082425362229636e-06,
      "loss": 0.211,
      "step": 85870
    },
    {
      "epoch": 85.88,
      "learning_rate": 8.071229093996865e-06,
      "loss": 0.2544,
      "step": 85880
    },
    {
      "epoch": 85.89,
      "learning_rate": 8.060040144993874e-06,
      "loss": 0.1214,
      "step": 85890
    },
    {
      "epoch": 85.9,
      "learning_rate": 8.048858516444235e-06,
      "loss": 0.1906,
      "step": 85900
    },
    {
      "epoch": 85.91,
      "learning_rate": 8.037684209570776e-06,
      "loss": 0.2224,
      "step": 85910
    },
    {
      "epoch": 85.92,
      "learning_rate": 8.026517225595482e-06,
      "loss": 0.1673,
      "step": 85920
    },
    {
      "epoch": 85.93,
      "learning_rate": 8.015357565739575e-06,
      "loss": 0.1523,
      "step": 85930
    },
    {
      "epoch": 85.94,
      "learning_rate": 8.00420523122346e-06,
      "loss": 0.2322,
      "step": 85940
    },
    {
      "epoch": 85.95,
      "learning_rate": 7.993060223266737e-06,
      "loss": 0.1765,
      "step": 85950
    },
    {
      "epoch": 85.96,
      "learning_rate": 7.981922543088199e-06,
      "loss": 0.2056,
      "step": 85960
    },
    {
      "epoch": 85.97,
      "learning_rate": 7.970792191905861e-06,
      "loss": 0.1755,
      "step": 85970
    },
    {
      "epoch": 85.98,
      "learning_rate": 7.959669170936903e-06,
      "loss": 0.0812,
      "step": 85980
    },
    {
      "epoch": 85.99,
      "learning_rate": 7.948553481397723e-06,
      "loss": 0.1941,
      "step": 85990
    },
    {
      "epoch": 86.0,
      "learning_rate": 7.937445124503927e-06,
      "loss": 0.2893,
      "step": 86000
    },
    {
      "epoch": 86.0,
      "eval_accuracy": 0.7985,
      "eval_loss": 0.5740939974784851,
      "eval_runtime": 14.9471,
      "eval_samples_per_second": 133.805,
      "eval_steps_per_second": 16.726,
      "step": 86000
    },
    {
      "epoch": 86.01,
      "learning_rate": 7.926344101470325e-06,
      "loss": 0.1486,
      "step": 86010
    },
    {
      "epoch": 86.02,
      "learning_rate": 7.91525041351087e-06,
      "loss": 0.3035,
      "step": 86020
    },
    {
      "epoch": 86.03,
      "learning_rate": 7.904164061838785e-06,
      "loss": 0.1028,
      "step": 86030
    },
    {
      "epoch": 86.04,
      "learning_rate": 7.893085047666425e-06,
      "loss": 0.1379,
      "step": 86040
    },
    {
      "epoch": 86.05,
      "learning_rate": 7.882013372205387e-06,
      "loss": 0.133,
      "step": 86050
    },
    {
      "epoch": 86.06,
      "learning_rate": 7.87094903666646e-06,
      "loss": 0.3024,
      "step": 86060
    },
    {
      "epoch": 86.07,
      "learning_rate": 7.859892042259636e-06,
      "loss": 0.2037,
      "step": 86070
    },
    {
      "epoch": 86.08,
      "learning_rate": 7.848842390194055e-06,
      "loss": 0.0441,
      "step": 86080
    },
    {
      "epoch": 86.09,
      "learning_rate": 7.837800081678116e-06,
      "loss": 0.1283,
      "step": 86090
    },
    {
      "epoch": 86.1,
      "learning_rate": 7.82676511791939e-06,
      "loss": 0.1778,
      "step": 86100
    },
    {
      "epoch": 86.11,
      "learning_rate": 7.815737500124625e-06,
      "loss": 0.1627,
      "step": 86110
    },
    {
      "epoch": 86.12,
      "learning_rate": 7.804717229499799e-06,
      "loss": 0.0868,
      "step": 86120
    },
    {
      "epoch": 86.13,
      "learning_rate": 7.793704307250074e-06,
      "loss": 0.1728,
      "step": 86130
    },
    {
      "epoch": 86.14,
      "learning_rate": 7.782698734579817e-06,
      "loss": 0.2299,
      "step": 86140
    },
    {
      "epoch": 86.15,
      "learning_rate": 7.772800004061761e-06,
      "loss": 0.1888,
      "step": 86150
    },
    {
      "epoch": 86.16,
      "learning_rate": 7.761808398907565e-06,
      "loss": 0.0566,
      "step": 86160
    },
    {
      "epoch": 86.17,
      "learning_rate": 7.750824146820933e-06,
      "loss": 0.2707,
      "step": 86170
    },
    {
      "epoch": 86.18,
      "learning_rate": 7.739847249003053e-06,
      "loss": 0.1014,
      "step": 86180
    },
    {
      "epoch": 86.19,
      "learning_rate": 7.728877706654348e-06,
      "loss": 0.1085,
      "step": 86190
    },
    {
      "epoch": 86.2,
      "learning_rate": 7.717915520974443e-06,
      "loss": 0.1904,
      "step": 86200
    },
    {
      "epoch": 86.21,
      "learning_rate": 7.706960693162145e-06,
      "loss": 0.2683,
      "step": 86210
    },
    {
      "epoch": 86.22,
      "learning_rate": 7.696013224415446e-06,
      "loss": 0.2879,
      "step": 86220
    },
    {
      "epoch": 86.23,
      "learning_rate": 7.685073115931561e-06,
      "loss": 0.0483,
      "step": 86230
    },
    {
      "epoch": 86.24,
      "learning_rate": 7.674140368906861e-06,
      "loss": 0.1381,
      "step": 86240
    },
    {
      "epoch": 86.25,
      "learning_rate": 7.663214984536947e-06,
      "loss": 0.2691,
      "step": 86250
    },
    {
      "epoch": 86.26,
      "learning_rate": 7.652296964016605e-06,
      "loss": 0.1634,
      "step": 86260
    },
    {
      "epoch": 86.27,
      "learning_rate": 7.641386308539821e-06,
      "loss": 0.1282,
      "step": 86270
    },
    {
      "epoch": 86.28,
      "learning_rate": 7.63048301929974e-06,
      "loss": 0.2548,
      "step": 86280
    },
    {
      "epoch": 86.29,
      "learning_rate": 7.619587097488769e-06,
      "loss": 0.1382,
      "step": 86290
    },
    {
      "epoch": 86.3,
      "learning_rate": 7.608698544298436e-06,
      "loss": 0.2484,
      "step": 86300
    },
    {
      "epoch": 86.31,
      "learning_rate": 7.597817360919506e-06,
      "loss": 0.1908,
      "step": 86310
    },
    {
      "epoch": 86.32,
      "learning_rate": 7.586943548541927e-06,
      "loss": 0.1578,
      "step": 86320
    },
    {
      "epoch": 86.33,
      "learning_rate": 7.576077108354872e-06,
      "loss": 0.137,
      "step": 86330
    },
    {
      "epoch": 86.34,
      "learning_rate": 7.565218041546633e-06,
      "loss": 0.2607,
      "step": 86340
    },
    {
      "epoch": 86.35,
      "learning_rate": 7.554366349304761e-06,
      "loss": 0.249,
      "step": 86350
    },
    {
      "epoch": 86.36,
      "learning_rate": 7.543522032815996e-06,
      "loss": 0.1011,
      "step": 86360
    },
    {
      "epoch": 86.37,
      "learning_rate": 7.532685093266233e-06,
      "loss": 0.2599,
      "step": 86370
    },
    {
      "epoch": 86.38,
      "learning_rate": 7.52185553184059e-06,
      "loss": 0.2136,
      "step": 86380
    },
    {
      "epoch": 86.39,
      "learning_rate": 7.511033349723369e-06,
      "loss": 0.2436,
      "step": 86390
    },
    {
      "epoch": 86.4,
      "learning_rate": 7.500218548098091e-06,
      "loss": 0.1865,
      "step": 86400
    },
    {
      "epoch": 86.41,
      "learning_rate": 7.489411128147418e-06,
      "loss": 0.1547,
      "step": 86410
    },
    {
      "epoch": 86.42,
      "learning_rate": 7.478611091053255e-06,
      "loss": 0.213,
      "step": 86420
    },
    {
      "epoch": 86.43,
      "learning_rate": 7.4678184379966475e-06,
      "loss": 0.2036,
      "step": 86430
    },
    {
      "epoch": 86.44,
      "learning_rate": 7.457033170157886e-06,
      "loss": 0.1274,
      "step": 86440
    },
    {
      "epoch": 86.45,
      "learning_rate": 7.446255288716427e-06,
      "loss": 0.2114,
      "step": 86450
    },
    {
      "epoch": 86.46,
      "learning_rate": 7.435484794850944e-06,
      "loss": 0.2301,
      "step": 86460
    },
    {
      "epoch": 86.47,
      "learning_rate": 7.424721689739243e-06,
      "loss": 0.1805,
      "step": 86470
    },
    {
      "epoch": 86.48,
      "learning_rate": 7.413965974558395e-06,
      "loss": 0.0599,
      "step": 86480
    },
    {
      "epoch": 86.49,
      "learning_rate": 7.403217650484597e-06,
      "loss": 0.2125,
      "step": 86490
    },
    {
      "epoch": 86.5,
      "learning_rate": 7.392476718693302e-06,
      "loss": 0.1463,
      "step": 86500
    },
    {
      "epoch": 86.51,
      "learning_rate": 7.381743180359079e-06,
      "loss": 0.172,
      "step": 86510
    },
    {
      "epoch": 86.52,
      "learning_rate": 7.371017036655788e-06,
      "loss": 0.0717,
      "step": 86520
    },
    {
      "epoch": 86.53,
      "learning_rate": 7.360298288756384e-06,
      "loss": 0.1559,
      "step": 86530
    },
    {
      "epoch": 86.54,
      "learning_rate": 7.349586937833068e-06,
      "loss": 0.116,
      "step": 86540
    },
    {
      "epoch": 86.55,
      "learning_rate": 7.338882985057207e-06,
      "loss": 0.0761,
      "step": 86550
    },
    {
      "epoch": 86.56,
      "learning_rate": 7.328186431599378e-06,
      "loss": 0.1509,
      "step": 86560
    },
    {
      "epoch": 86.57,
      "learning_rate": 7.317497278629339e-06,
      "loss": 0.2918,
      "step": 86570
    },
    {
      "epoch": 86.58,
      "learning_rate": 7.306815527316046e-06,
      "loss": 0.0504,
      "step": 86580
    },
    {
      "epoch": 86.59,
      "learning_rate": 7.296141178827622e-06,
      "loss": 0.145,
      "step": 86590
    },
    {
      "epoch": 86.6,
      "learning_rate": 7.285474234331401e-06,
      "loss": 0.0696,
      "step": 86600
    },
    {
      "epoch": 86.61,
      "learning_rate": 7.2748146949939325e-06,
      "loss": 0.2781,
      "step": 86610
    },
    {
      "epoch": 86.62,
      "learning_rate": 7.264162561980885e-06,
      "loss": 0.1192,
      "step": 86620
    },
    {
      "epoch": 86.63,
      "learning_rate": 7.253517836457184e-06,
      "loss": 0.2629,
      "step": 86630
    },
    {
      "epoch": 86.64,
      "learning_rate": 7.242880519586924e-06,
      "loss": 0.2163,
      "step": 86640
    },
    {
      "epoch": 86.65,
      "learning_rate": 7.232250612533383e-06,
      "loss": 0.1937,
      "step": 86650
    },
    {
      "epoch": 86.66,
      "learning_rate": 7.2216281164590135e-06,
      "loss": 0.2257,
      "step": 86660
    },
    {
      "epoch": 86.67,
      "learning_rate": 7.211013032525512e-06,
      "loss": 0.1486,
      "step": 86670
    },
    {
      "epoch": 86.68,
      "learning_rate": 7.2004053618936824e-06,
      "loss": 0.1918,
      "step": 86680
    },
    {
      "epoch": 86.69,
      "learning_rate": 7.189805105723606e-06,
      "loss": 0.2955,
      "step": 86690
    },
    {
      "epoch": 86.7,
      "learning_rate": 7.179212265174472e-06,
      "loss": 0.212,
      "step": 86700
    },
    {
      "epoch": 86.71,
      "learning_rate": 7.169685049993626e-06,
      "loss": 0.2556,
      "step": 86710
    },
    {
      "epoch": 86.72,
      "learning_rate": 7.159106302315112e-06,
      "loss": 0.2189,
      "step": 86720
    },
    {
      "epoch": 86.73,
      "learning_rate": 7.148534973614722e-06,
      "loss": 0.2949,
      "step": 86730
    },
    {
      "epoch": 86.74,
      "learning_rate": 7.137971065048548e-06,
      "loss": 0.0839,
      "step": 86740
    },
    {
      "epoch": 86.75,
      "learning_rate": 7.127414577771806e-06,
      "loss": 0.1547,
      "step": 86750
    },
    {
      "epoch": 86.76,
      "learning_rate": 7.1168655129389824e-06,
      "loss": 0.0899,
      "step": 86760
    },
    {
      "epoch": 86.77,
      "learning_rate": 7.1063238717036615e-06,
      "loss": 0.2439,
      "step": 86770
    },
    {
      "epoch": 86.78,
      "learning_rate": 7.095789655218706e-06,
      "loss": 0.1536,
      "step": 86780
    },
    {
      "epoch": 86.79,
      "learning_rate": 7.0852628646360935e-06,
      "loss": 0.1786,
      "step": 86790
    },
    {
      "epoch": 86.8,
      "learning_rate": 7.074743501107036e-06,
      "loss": 0.2178,
      "step": 86800
    },
    {
      "epoch": 86.81,
      "learning_rate": 7.064231565781889e-06,
      "loss": 0.2533,
      "step": 86810
    },
    {
      "epoch": 86.82,
      "learning_rate": 7.053727059810241e-06,
      "loss": 0.146,
      "step": 86820
    },
    {
      "epoch": 86.83,
      "learning_rate": 7.043229984340848e-06,
      "loss": 0.1358,
      "step": 86830
    },
    {
      "epoch": 86.84,
      "learning_rate": 7.032740340521659e-06,
      "loss": 0.2217,
      "step": 86840
    },
    {
      "epoch": 86.85,
      "learning_rate": 7.022258129499789e-06,
      "loss": 0.3037,
      "step": 86850
    },
    {
      "epoch": 86.86,
      "learning_rate": 7.011783352421571e-06,
      "loss": 0.1685,
      "step": 86860
    },
    {
      "epoch": 86.87,
      "learning_rate": 7.001316010432514e-06,
      "loss": 0.1223,
      "step": 86870
    },
    {
      "epoch": 86.88,
      "learning_rate": 6.990856104677295e-06,
      "loss": 0.2023,
      "step": 86880
    },
    {
      "epoch": 86.89,
      "learning_rate": 6.980403636299814e-06,
      "loss": 0.2258,
      "step": 86890
    },
    {
      "epoch": 86.9,
      "learning_rate": 6.969958606443099e-06,
      "loss": 0.1379,
      "step": 86900
    },
    {
      "epoch": 86.91,
      "learning_rate": 6.959521016249461e-06,
      "loss": 0.2326,
      "step": 86910
    },
    {
      "epoch": 86.92,
      "learning_rate": 6.949090866860288e-06,
      "loss": 0.2212,
      "step": 86920
    },
    {
      "epoch": 86.93,
      "learning_rate": 6.938668159416233e-06,
      "loss": 0.0712,
      "step": 86930
    },
    {
      "epoch": 86.94,
      "learning_rate": 6.9282528950570935e-06,
      "loss": 0.1914,
      "step": 86940
    },
    {
      "epoch": 86.95,
      "learning_rate": 6.91784507492189e-06,
      "loss": 0.2904,
      "step": 86950
    },
    {
      "epoch": 86.96,
      "learning_rate": 6.907444700148757e-06,
      "loss": 0.213,
      "step": 86960
    },
    {
      "epoch": 86.97,
      "learning_rate": 6.897051771875123e-06,
      "loss": 0.2167,
      "step": 86970
    },
    {
      "epoch": 86.98,
      "learning_rate": 6.886666291237497e-06,
      "loss": 0.2193,
      "step": 86980
    },
    {
      "epoch": 86.99,
      "learning_rate": 6.876288259371662e-06,
      "loss": 0.0649,
      "step": 86990
    },
    {
      "epoch": 87.0,
      "learning_rate": 6.865917677412503e-06,
      "loss": 0.1884,
      "step": 87000
    },
    {
      "epoch": 87.0,
      "eval_accuracy": 0.796,
      "eval_loss": 0.5918381810188293,
      "eval_runtime": 14.8836,
      "eval_samples_per_second": 134.376,
      "eval_steps_per_second": 16.797,
      "step": 87000
    },
    {
      "epoch": 87.01,
      "learning_rate": 6.85555454649416e-06,
      "loss": 0.2483,
      "step": 87010
    },
    {
      "epoch": 87.02,
      "learning_rate": 6.845198867749888e-06,
      "loss": 0.2325,
      "step": 87020
    },
    {
      "epoch": 87.03,
      "learning_rate": 6.835885129424934e-06,
      "loss": 0.1718,
      "step": 87030
    },
    {
      "epoch": 87.04,
      "learning_rate": 6.825543612930801e-06,
      "loss": 0.2864,
      "step": 87040
    },
    {
      "epoch": 87.05,
      "learning_rate": 6.815209551892703e-06,
      "loss": 0.0368,
      "step": 87050
    },
    {
      "epoch": 87.06,
      "learning_rate": 6.804882947440787e-06,
      "loss": 0.128,
      "step": 87060
    },
    {
      "epoch": 87.07,
      "learning_rate": 6.794563800704333e-06,
      "loss": 0.2854,
      "step": 87070
    },
    {
      "epoch": 87.08,
      "learning_rate": 6.784252112811831e-06,
      "loss": 0.0991,
      "step": 87080
    },
    {
      "epoch": 87.09,
      "learning_rate": 6.773947884890959e-06,
      "loss": 0.0864,
      "step": 87090
    },
    {
      "epoch": 87.1,
      "learning_rate": 6.763651118068586e-06,
      "loss": 0.0805,
      "step": 87100
    },
    {
      "epoch": 87.11,
      "learning_rate": 6.753361813470717e-06,
      "loss": 0.1194,
      "step": 87110
    },
    {
      "epoch": 87.12,
      "learning_rate": 6.743079972222596e-06,
      "loss": 0.1356,
      "step": 87120
    },
    {
      "epoch": 87.13,
      "learning_rate": 6.732805595448646e-06,
      "loss": 0.101,
      "step": 87130
    },
    {
      "epoch": 87.14,
      "learning_rate": 6.722538684272411e-06,
      "loss": 0.1801,
      "step": 87140
    },
    {
      "epoch": 87.15,
      "learning_rate": 6.7122792398167175e-06,
      "loss": 0.2498,
      "step": 87150
    },
    {
      "epoch": 87.16,
      "learning_rate": 6.7020272632034606e-06,
      "loss": 0.1885,
      "step": 87160
    },
    {
      "epoch": 87.17,
      "learning_rate": 6.691782755553851e-06,
      "loss": 0.213,
      "step": 87170
    },
    {
      "epoch": 87.18,
      "learning_rate": 6.68154571798816e-06,
      "loss": 0.1711,
      "step": 87180
    },
    {
      "epoch": 87.19,
      "learning_rate": 6.671316151625933e-06,
      "loss": 0.3493,
      "step": 87190
    },
    {
      "epoch": 87.2,
      "learning_rate": 6.661094057585825e-06,
      "loss": 0.2591,
      "step": 87200
    },
    {
      "epoch": 87.21,
      "learning_rate": 6.650879436985743e-06,
      "loss": 0.201,
      "step": 87210
    },
    {
      "epoch": 87.22,
      "learning_rate": 6.640672290942692e-06,
      "loss": 0.2871,
      "step": 87220
    },
    {
      "epoch": 87.23,
      "learning_rate": 6.630472620572972e-06,
      "loss": 0.2643,
      "step": 87230
    },
    {
      "epoch": 87.24,
      "learning_rate": 6.620280426991956e-06,
      "loss": 0.1358,
      "step": 87240
    },
    {
      "epoch": 87.25,
      "learning_rate": 6.610095711314286e-06,
      "loss": 0.1205,
      "step": 87250
    },
    {
      "epoch": 87.26,
      "learning_rate": 6.599918474653706e-06,
      "loss": 0.1647,
      "step": 87260
    },
    {
      "epoch": 87.27,
      "learning_rate": 6.589748718123225e-06,
      "loss": 0.1045,
      "step": 87270
    },
    {
      "epoch": 87.28,
      "learning_rate": 6.579586442834953e-06,
      "loss": 0.1003,
      "step": 87280
    },
    {
      "epoch": 87.29,
      "learning_rate": 6.5694316499002335e-06,
      "loss": 0.1854,
      "step": 87290
    },
    {
      "epoch": 87.3,
      "learning_rate": 6.559284340429596e-06,
      "loss": 0.1548,
      "step": 87300
    },
    {
      "epoch": 87.31,
      "learning_rate": 6.549144515532728e-06,
      "loss": 0.0113,
      "step": 87310
    },
    {
      "epoch": 87.32,
      "learning_rate": 6.5390121763184925e-06,
      "loss": 0.2177,
      "step": 87320
    },
    {
      "epoch": 87.33,
      "learning_rate": 6.5288873238949514e-06,
      "loss": 0.137,
      "step": 87330
    },
    {
      "epoch": 87.34,
      "learning_rate": 6.518769959369372e-06,
      "loss": 0.0689,
      "step": 87340
    },
    {
      "epoch": 87.35,
      "learning_rate": 6.508660083848124e-06,
      "loss": 0.218,
      "step": 87350
    },
    {
      "epoch": 87.36,
      "learning_rate": 6.498557698436843e-06,
      "loss": 0.1145,
      "step": 87360
    },
    {
      "epoch": 87.37,
      "learning_rate": 6.488462804240294e-06,
      "loss": 0.346,
      "step": 87370
    },
    {
      "epoch": 87.38,
      "learning_rate": 6.478375402362468e-06,
      "loss": 0.1766,
      "step": 87380
    },
    {
      "epoch": 87.39,
      "learning_rate": 6.468295493906467e-06,
      "loss": 0.1874,
      "step": 87390
    },
    {
      "epoch": 87.4,
      "learning_rate": 6.45822307997465e-06,
      "loss": 0.1047,
      "step": 87400
    },
    {
      "epoch": 87.41,
      "learning_rate": 6.448158161668487e-06,
      "loss": 0.1248,
      "step": 87410
    },
    {
      "epoch": 87.42,
      "learning_rate": 6.438100740088698e-06,
      "loss": 0.1645,
      "step": 87420
    },
    {
      "epoch": 87.43,
      "learning_rate": 6.428050816335126e-06,
      "loss": 0.1631,
      "step": 87430
    },
    {
      "epoch": 87.44,
      "learning_rate": 6.418008391506826e-06,
      "loss": 0.1949,
      "step": 87440
    },
    {
      "epoch": 87.45,
      "learning_rate": 6.407973466702004e-06,
      "loss": 0.2159,
      "step": 87450
    },
    {
      "epoch": 87.46,
      "learning_rate": 6.39794604301809e-06,
      "loss": 0.0824,
      "step": 87460
    },
    {
      "epoch": 87.47,
      "learning_rate": 6.3879261215516485e-06,
      "loss": 0.245,
      "step": 87470
    },
    {
      "epoch": 87.48,
      "learning_rate": 6.377913703398443e-06,
      "loss": 0.233,
      "step": 87480
    },
    {
      "epoch": 87.49,
      "learning_rate": 6.367908789653425e-06,
      "loss": 0.1907,
      "step": 87490
    },
    {
      "epoch": 87.5,
      "learning_rate": 6.357911381410735e-06,
      "loss": 0.2432,
      "step": 87500
    },
    {
      "epoch": 87.51,
      "learning_rate": 6.347921479763632e-06,
      "loss": 0.1622,
      "step": 87510
    },
    {
      "epoch": 87.52,
      "learning_rate": 6.337939085804642e-06,
      "loss": 0.2363,
      "step": 87520
    },
    {
      "epoch": 87.53,
      "learning_rate": 6.327964200625374e-06,
      "loss": 0.1742,
      "step": 87530
    },
    {
      "epoch": 87.54,
      "learning_rate": 6.317996825316707e-06,
      "loss": 0.0493,
      "step": 87540
    },
    {
      "epoch": 87.55,
      "learning_rate": 6.308036960968643e-06,
      "loss": 0.2454,
      "step": 87550
    },
    {
      "epoch": 87.56,
      "learning_rate": 6.298084608670387e-06,
      "loss": 0.1581,
      "step": 87560
    },
    {
      "epoch": 87.57,
      "learning_rate": 6.288139769510301e-06,
      "loss": 0.1974,
      "step": 87570
    },
    {
      "epoch": 87.58,
      "learning_rate": 6.278202444575939e-06,
      "loss": 0.0873,
      "step": 87580
    },
    {
      "epoch": 87.59,
      "learning_rate": 6.26827263495405e-06,
      "loss": 0.172,
      "step": 87590
    },
    {
      "epoch": 87.6,
      "learning_rate": 6.2583503417305145e-06,
      "loss": 0.1328,
      "step": 87600
    },
    {
      "epoch": 87.61,
      "learning_rate": 6.248435565990431e-06,
      "loss": 0.1963,
      "step": 87610
    },
    {
      "epoch": 87.62,
      "learning_rate": 6.238528308818075e-06,
      "loss": 0.1894,
      "step": 87620
    },
    {
      "epoch": 87.63,
      "learning_rate": 6.228628571296887e-06,
      "loss": 0.2941,
      "step": 87630
    },
    {
      "epoch": 87.64,
      "learning_rate": 6.2187363545094766e-06,
      "loss": 0.0872,
      "step": 87640
    },
    {
      "epoch": 87.65,
      "learning_rate": 6.208851659537653e-06,
      "loss": 0.1441,
      "step": 87650
    },
    {
      "epoch": 87.66,
      "learning_rate": 6.198974487462377e-06,
      "loss": 0.3118,
      "step": 87660
    },
    {
      "epoch": 87.67,
      "learning_rate": 6.189104839363818e-06,
      "loss": 0.1212,
      "step": 87670
    },
    {
      "epoch": 87.68,
      "learning_rate": 6.179242716321287e-06,
      "loss": 0.1636,
      "step": 87680
    },
    {
      "epoch": 87.69,
      "learning_rate": 6.169388119413321e-06,
      "loss": 0.2514,
      "step": 87690
    },
    {
      "epoch": 87.7,
      "learning_rate": 6.1595410497175676e-06,
      "loss": 0.244,
      "step": 87700
    },
    {
      "epoch": 87.71,
      "learning_rate": 6.149701508310923e-06,
      "loss": 0.2546,
      "step": 87710
    },
    {
      "epoch": 87.72,
      "learning_rate": 6.139869496269384e-06,
      "loss": 0.2398,
      "step": 87720
    },
    {
      "epoch": 87.73,
      "learning_rate": 6.1300450146682e-06,
      "loss": 0.1571,
      "step": 87730
    },
    {
      "epoch": 87.74,
      "learning_rate": 6.120228064581737e-06,
      "loss": 0.3218,
      "step": 87740
    },
    {
      "epoch": 87.75,
      "learning_rate": 6.110418647083592e-06,
      "loss": 0.2712,
      "step": 87750
    },
    {
      "epoch": 87.76,
      "learning_rate": 6.100616763246477e-06,
      "loss": 0.1153,
      "step": 87760
    },
    {
      "epoch": 87.77,
      "learning_rate": 6.090822414142341e-06,
      "loss": 0.1175,
      "step": 87770
    },
    {
      "epoch": 87.78,
      "learning_rate": 6.081035600842243e-06,
      "loss": 0.1352,
      "step": 87780
    },
    {
      "epoch": 87.79,
      "learning_rate": 6.0712563244164795e-06,
      "loss": 0.2419,
      "step": 87790
    },
    {
      "epoch": 87.8,
      "learning_rate": 6.061484585934484e-06,
      "loss": 0.1275,
      "step": 87800
    },
    {
      "epoch": 87.81,
      "learning_rate": 6.051720386464903e-06,
      "loss": 0.3766,
      "step": 87810
    },
    {
      "epoch": 87.82,
      "learning_rate": 6.041963727075508e-06,
      "loss": 0.1598,
      "step": 87820
    },
    {
      "epoch": 87.83,
      "learning_rate": 6.032214608833286e-06,
      "loss": 0.0975,
      "step": 87830
    },
    {
      "epoch": 87.84,
      "learning_rate": 6.022473032804384e-06,
      "loss": 0.083,
      "step": 87840
    },
    {
      "epoch": 87.85,
      "learning_rate": 6.012739000054126e-06,
      "loss": 0.0901,
      "step": 87850
    },
    {
      "epoch": 87.86,
      "learning_rate": 6.003012511647001e-06,
      "loss": 0.1476,
      "step": 87860
    },
    {
      "epoch": 87.87,
      "learning_rate": 5.993293568646693e-06,
      "loss": 0.2295,
      "step": 87870
    },
    {
      "epoch": 87.88,
      "learning_rate": 5.983582172116066e-06,
      "loss": 0.1848,
      "step": 87880
    },
    {
      "epoch": 87.89,
      "learning_rate": 5.973878323117115e-06,
      "loss": 0.2353,
      "step": 87890
    },
    {
      "epoch": 87.9,
      "learning_rate": 5.9641820227110645e-06,
      "loss": 0.215,
      "step": 87900
    },
    {
      "epoch": 87.91,
      "learning_rate": 5.954493271958258e-06,
      "loss": 0.312,
      "step": 87910
    },
    {
      "epoch": 87.92,
      "learning_rate": 5.944812071918256e-06,
      "loss": 0.1482,
      "step": 87920
    },
    {
      "epoch": 87.93,
      "learning_rate": 5.935138423649788e-06,
      "loss": 0.214,
      "step": 87930
    },
    {
      "epoch": 87.94,
      "learning_rate": 5.925472328210756e-06,
      "loss": 0.1576,
      "step": 87940
    },
    {
      "epoch": 87.95,
      "learning_rate": 5.915813786658208e-06,
      "loss": 0.1617,
      "step": 87950
    },
    {
      "epoch": 87.96,
      "learning_rate": 5.9061628000484054e-06,
      "loss": 0.1199,
      "step": 87960
    },
    {
      "epoch": 87.97,
      "learning_rate": 5.896519369436756e-06,
      "loss": 0.1612,
      "step": 87970
    },
    {
      "epoch": 87.98,
      "learning_rate": 5.886883495877856e-06,
      "loss": 0.2452,
      "step": 87980
    },
    {
      "epoch": 87.99,
      "learning_rate": 5.8772551804254385e-06,
      "loss": 0.1774,
      "step": 87990
    },
    {
      "epoch": 88.0,
      "learning_rate": 5.867634424132503e-06,
      "loss": 0.1203,
      "step": 88000
    },
    {
      "epoch": 88.0,
      "eval_accuracy": 0.7985,
      "eval_loss": 0.6154037117958069,
      "eval_runtime": 14.8952,
      "eval_samples_per_second": 134.271,
      "eval_steps_per_second": 16.784,
      "step": 88000
    },
    {
      "epoch": 88.01,
      "learning_rate": 5.858021228051116e-06,
      "loss": 0.1028,
      "step": 88010
    },
    {
      "epoch": 88.02,
      "learning_rate": 5.848415593232586e-06,
      "loss": 0.1701,
      "step": 88020
    },
    {
      "epoch": 88.03,
      "learning_rate": 5.83881752072734e-06,
      "loss": 0.1982,
      "step": 88030
    },
    {
      "epoch": 88.04,
      "learning_rate": 5.82922701158503e-06,
      "loss": 0.2204,
      "step": 88040
    },
    {
      "epoch": 88.05,
      "learning_rate": 5.8196440668544594e-06,
      "loss": 0.1031,
      "step": 88050
    },
    {
      "epoch": 88.06,
      "learning_rate": 5.810068687583613e-06,
      "loss": 0.2513,
      "step": 88060
    },
    {
      "epoch": 88.07,
      "learning_rate": 5.800500874819622e-06,
      "loss": 0.0794,
      "step": 88070
    },
    {
      "epoch": 88.08,
      "learning_rate": 5.790940629608806e-06,
      "loss": 0.0581,
      "step": 88080
    },
    {
      "epoch": 88.09,
      "learning_rate": 5.781387952996688e-06,
      "loss": 0.1312,
      "step": 88090
    },
    {
      "epoch": 88.1,
      "learning_rate": 5.771842846027899e-06,
      "loss": 0.201,
      "step": 88100
    },
    {
      "epoch": 88.11,
      "learning_rate": 5.762305309746296e-06,
      "loss": 0.2576,
      "step": 88110
    },
    {
      "epoch": 88.12,
      "learning_rate": 5.752775345194893e-06,
      "loss": 0.1922,
      "step": 88120
    },
    {
      "epoch": 88.13,
      "learning_rate": 5.7432529534158665e-06,
      "loss": 0.1608,
      "step": 88130
    },
    {
      "epoch": 88.14,
      "learning_rate": 5.733738135450566e-06,
      "loss": 0.2074,
      "step": 88140
    },
    {
      "epoch": 88.15,
      "learning_rate": 5.724230892339535e-06,
      "loss": 0.186,
      "step": 88150
    },
    {
      "epoch": 88.16,
      "learning_rate": 5.7147312251224485e-06,
      "loss": 0.0758,
      "step": 88160
    },
    {
      "epoch": 88.17,
      "learning_rate": 5.705239134838194e-06,
      "loss": 0.3623,
      "step": 88170
    },
    {
      "epoch": 88.18,
      "learning_rate": 5.6957546225247815e-06,
      "loss": 0.2115,
      "step": 88180
    },
    {
      "epoch": 88.19,
      "learning_rate": 5.686277689219465e-06,
      "loss": 0.1194,
      "step": 88190
    },
    {
      "epoch": 88.2,
      "learning_rate": 5.676808335958607e-06,
      "loss": 0.2783,
      "step": 88200
    },
    {
      "epoch": 88.21,
      "learning_rate": 5.667346563777772e-06,
      "loss": 0.1673,
      "step": 88210
    },
    {
      "epoch": 88.22,
      "learning_rate": 5.657892373711664e-06,
      "loss": 0.1834,
      "step": 88220
    },
    {
      "epoch": 88.23,
      "learning_rate": 5.648445766794199e-06,
      "loss": 0.2956,
      "step": 88230
    },
    {
      "epoch": 88.24,
      "learning_rate": 5.639006744058416e-06,
      "loss": 0.1884,
      "step": 88240
    },
    {
      "epoch": 88.25,
      "learning_rate": 5.629575306536599e-06,
      "loss": 0.1336,
      "step": 88250
    },
    {
      "epoch": 88.26,
      "learning_rate": 5.620151455260113e-06,
      "loss": 0.1663,
      "step": 88260
    },
    {
      "epoch": 88.27,
      "learning_rate": 5.610735191259569e-06,
      "loss": 0.252,
      "step": 88270
    },
    {
      "epoch": 88.28,
      "learning_rate": 5.601326515564691e-06,
      "loss": 0.1276,
      "step": 88280
    },
    {
      "epoch": 88.29,
      "learning_rate": 5.5919254292044e-06,
      "loss": 0.128,
      "step": 88290
    },
    {
      "epoch": 88.3,
      "learning_rate": 5.582531933206788e-06,
      "loss": 0.1901,
      "step": 88300
    },
    {
      "epoch": 88.31,
      "learning_rate": 5.573146028599135e-06,
      "loss": 0.2158,
      "step": 88310
    },
    {
      "epoch": 88.32,
      "learning_rate": 5.5637677164078355e-06,
      "loss": 0.0589,
      "step": 88320
    },
    {
      "epoch": 88.33,
      "learning_rate": 5.554396997658503e-06,
      "loss": 0.1885,
      "step": 88330
    },
    {
      "epoch": 88.34,
      "learning_rate": 5.545033873375917e-06,
      "loss": 0.1683,
      "step": 88340
    },
    {
      "epoch": 88.35,
      "learning_rate": 5.535678344583986e-06,
      "loss": 0.2582,
      "step": 88350
    },
    {
      "epoch": 88.36,
      "learning_rate": 5.526330412305846e-06,
      "loss": 0.1539,
      "step": 88360
    },
    {
      "epoch": 88.37,
      "learning_rate": 5.51699007756374e-06,
      "loss": 0.0804,
      "step": 88370
    },
    {
      "epoch": 88.38,
      "learning_rate": 5.50765734137916e-06,
      "loss": 0.1603,
      "step": 88380
    },
    {
      "epoch": 88.39,
      "learning_rate": 5.498332204772679e-06,
      "loss": 0.233,
      "step": 88390
    },
    {
      "epoch": 88.4,
      "learning_rate": 5.4890146687641e-06,
      "loss": 0.3024,
      "step": 88400
    },
    {
      "epoch": 88.41,
      "learning_rate": 5.479704734372364e-06,
      "loss": 0.1537,
      "step": 88410
    },
    {
      "epoch": 88.42,
      "learning_rate": 5.470402402615601e-06,
      "loss": 0.1593,
      "step": 88420
    },
    {
      "epoch": 88.43,
      "learning_rate": 5.461107674511078e-06,
      "loss": 0.1284,
      "step": 88430
    },
    {
      "epoch": 88.44,
      "learning_rate": 5.4518205510752925e-06,
      "loss": 0.1157,
      "step": 88440
    },
    {
      "epoch": 88.45,
      "learning_rate": 5.44254103332383e-06,
      "loss": 0.1761,
      "step": 88450
    },
    {
      "epoch": 88.46,
      "learning_rate": 5.433269122271514e-06,
      "loss": 0.1766,
      "step": 88460
    },
    {
      "epoch": 88.47,
      "learning_rate": 5.42400481893229e-06,
      "loss": 0.1462,
      "step": 88470
    },
    {
      "epoch": 88.48,
      "learning_rate": 5.414748124319299e-06,
      "loss": 0.243,
      "step": 88480
    },
    {
      "epoch": 88.49,
      "learning_rate": 5.405499039444822e-06,
      "loss": 0.15,
      "step": 88490
    },
    {
      "epoch": 88.5,
      "learning_rate": 5.3962575653203415e-06,
      "loss": 0.1831,
      "step": 88500
    },
    {
      "epoch": 88.51,
      "learning_rate": 5.387023702956483e-06,
      "loss": 0.2038,
      "step": 88510
    },
    {
      "epoch": 88.52,
      "learning_rate": 5.377797453363056e-06,
      "loss": 0.0547,
      "step": 88520
    },
    {
      "epoch": 88.53,
      "learning_rate": 5.368578817549018e-06,
      "loss": 0.1363,
      "step": 88530
    },
    {
      "epoch": 88.54,
      "learning_rate": 5.3593677965225155e-06,
      "loss": 0.1914,
      "step": 88540
    },
    {
      "epoch": 88.55,
      "learning_rate": 5.350164391290857e-06,
      "loss": 0.0906,
      "step": 88550
    },
    {
      "epoch": 88.56,
      "learning_rate": 5.340968602860488e-06,
      "loss": 0.0878,
      "step": 88560
    },
    {
      "epoch": 88.57,
      "learning_rate": 5.331780432237062e-06,
      "loss": 0.0662,
      "step": 88570
    },
    {
      "epoch": 88.58,
      "learning_rate": 5.322599880425385e-06,
      "loss": 0.2601,
      "step": 88580
    },
    {
      "epoch": 88.59,
      "learning_rate": 5.313426948429436e-06,
      "loss": 0.1251,
      "step": 88590
    },
    {
      "epoch": 88.6,
      "learning_rate": 5.3042616372523386e-06,
      "loss": 0.1447,
      "step": 88600
    },
    {
      "epoch": 88.61,
      "learning_rate": 5.295103947896406e-06,
      "loss": 0.1688,
      "step": 88610
    },
    {
      "epoch": 88.62,
      "learning_rate": 5.285953881363089e-06,
      "loss": 0.0958,
      "step": 88620
    },
    {
      "epoch": 88.63,
      "learning_rate": 5.276811438653061e-06,
      "loss": 0.1348,
      "step": 88630
    },
    {
      "epoch": 88.64,
      "learning_rate": 5.267676620766098e-06,
      "loss": 0.1352,
      "step": 88640
    },
    {
      "epoch": 88.65,
      "learning_rate": 5.258549428701192e-06,
      "loss": 0.1835,
      "step": 88650
    },
    {
      "epoch": 88.66,
      "learning_rate": 5.249429863456453e-06,
      "loss": 0.1098,
      "step": 88660
    },
    {
      "epoch": 88.67,
      "learning_rate": 5.240317926029209e-06,
      "loss": 0.1729,
      "step": 88670
    },
    {
      "epoch": 88.68,
      "learning_rate": 5.231213617415894e-06,
      "loss": 0.204,
      "step": 88680
    },
    {
      "epoch": 88.69,
      "learning_rate": 5.2221169386121725e-06,
      "loss": 0.2881,
      "step": 88690
    },
    {
      "epoch": 88.7,
      "learning_rate": 5.213027890612831e-06,
      "loss": 0.1674,
      "step": 88700
    },
    {
      "epoch": 88.71,
      "learning_rate": 5.203946474411841e-06,
      "loss": 0.2095,
      "step": 88710
    },
    {
      "epoch": 88.72,
      "learning_rate": 5.194872691002324e-06,
      "loss": 0.1906,
      "step": 88720
    },
    {
      "epoch": 88.73,
      "learning_rate": 5.185806541376589e-06,
      "loss": 0.2437,
      "step": 88730
    },
    {
      "epoch": 88.74,
      "learning_rate": 5.176748026526073e-06,
      "loss": 0.1033,
      "step": 88740
    },
    {
      "epoch": 88.75,
      "learning_rate": 5.1676971474414105e-06,
      "loss": 0.1701,
      "step": 88750
    },
    {
      "epoch": 88.76,
      "learning_rate": 5.158653905112401e-06,
      "loss": 0.2794,
      "step": 88760
    },
    {
      "epoch": 88.77,
      "learning_rate": 5.14961830052801e-06,
      "loss": 0.1853,
      "step": 88770
    },
    {
      "epoch": 88.78,
      "learning_rate": 5.1405903346763256e-06,
      "loss": 0.221,
      "step": 88780
    },
    {
      "epoch": 88.79,
      "learning_rate": 5.1315700085446555e-06,
      "loss": 0.2744,
      "step": 88790
    },
    {
      "epoch": 88.8,
      "learning_rate": 5.122557323119453e-06,
      "loss": 0.2198,
      "step": 88800
    },
    {
      "epoch": 88.81,
      "learning_rate": 5.113552279386313e-06,
      "loss": 0.1562,
      "step": 88810
    },
    {
      "epoch": 88.82,
      "learning_rate": 5.104554878330022e-06,
      "loss": 0.3029,
      "step": 88820
    },
    {
      "epoch": 88.83,
      "learning_rate": 5.095565120934519e-06,
      "loss": 0.1208,
      "step": 88830
    },
    {
      "epoch": 88.84,
      "learning_rate": 5.0865830081829345e-06,
      "loss": 0.0882,
      "step": 88840
    },
    {
      "epoch": 88.85,
      "learning_rate": 5.077608541057498e-06,
      "loss": 0.1263,
      "step": 88850
    },
    {
      "epoch": 88.86,
      "learning_rate": 5.068641720539684e-06,
      "loss": 0.1895,
      "step": 88860
    },
    {
      "epoch": 88.87,
      "learning_rate": 5.059682547610058e-06,
      "loss": 0.0782,
      "step": 88870
    },
    {
      "epoch": 88.88,
      "learning_rate": 5.050731023248394e-06,
      "loss": 0.1043,
      "step": 88880
    },
    {
      "epoch": 88.89,
      "learning_rate": 5.041787148433618e-06,
      "loss": 0.2444,
      "step": 88890
    },
    {
      "epoch": 88.9,
      "learning_rate": 5.03285092414383e-06,
      "loss": 0.1194,
      "step": 88900
    },
    {
      "epoch": 88.91,
      "learning_rate": 5.0239223513562576e-06,
      "loss": 0.0688,
      "step": 88910
    },
    {
      "epoch": 88.92,
      "learning_rate": 5.015001431047344e-06,
      "loss": 0.1189,
      "step": 88920
    },
    {
      "epoch": 88.93,
      "learning_rate": 5.0060881641926425e-06,
      "loss": 0.2725,
      "step": 88930
    },
    {
      "epoch": 88.94,
      "learning_rate": 4.997182551766899e-06,
      "loss": 0.1942,
      "step": 88940
    },
    {
      "epoch": 88.95,
      "learning_rate": 4.988284594744033e-06,
      "loss": 0.1355,
      "step": 88950
    },
    {
      "epoch": 88.96,
      "learning_rate": 4.979394294097108e-06,
      "loss": 0.2163,
      "step": 88960
    },
    {
      "epoch": 88.97,
      "learning_rate": 4.970511650798339e-06,
      "loss": 0.3383,
      "step": 88970
    },
    {
      "epoch": 88.98,
      "learning_rate": 4.961636665819133e-06,
      "loss": 0.2269,
      "step": 88980
    },
    {
      "epoch": 88.99,
      "learning_rate": 4.952769340130036e-06,
      "loss": 0.2406,
      "step": 88990
    },
    {
      "epoch": 89.0,
      "learning_rate": 4.943909674700766e-06,
      "loss": 0.2516,
      "step": 89000
    },
    {
      "epoch": 89.0,
      "eval_accuracy": 0.794,
      "eval_loss": 0.6497082114219666,
      "eval_runtime": 14.7796,
      "eval_samples_per_second": 135.322,
      "eval_steps_per_second": 16.915,
      "step": 89000
    },
    {
      "epoch": 89.01,
      "learning_rate": 4.935057670500214e-06,
      "loss": 0.2808,
      "step": 89010
    },
    {
      "epoch": 89.02,
      "learning_rate": 4.926213328496414e-06,
      "loss": 0.202,
      "step": 89020
    },
    {
      "epoch": 89.03,
      "learning_rate": 4.917376649656568e-06,
      "loss": 0.2237,
      "step": 89030
    },
    {
      "epoch": 89.04,
      "learning_rate": 4.908547634947036e-06,
      "loss": 0.2944,
      "step": 89040
    },
    {
      "epoch": 89.05,
      "learning_rate": 4.899726285333369e-06,
      "loss": 0.1858,
      "step": 89050
    },
    {
      "epoch": 89.06,
      "learning_rate": 4.890912601780231e-06,
      "loss": 0.157,
      "step": 89060
    },
    {
      "epoch": 89.07,
      "learning_rate": 4.882106585251483e-06,
      "loss": 0.2019,
      "step": 89070
    },
    {
      "epoch": 89.08,
      "learning_rate": 4.873308236710138e-06,
      "loss": 0.117,
      "step": 89080
    },
    {
      "epoch": 89.09,
      "learning_rate": 4.864517557118386e-06,
      "loss": 0.2109,
      "step": 89090
    },
    {
      "epoch": 89.1,
      "learning_rate": 4.8557345474375315e-06,
      "loss": 0.1124,
      "step": 89100
    },
    {
      "epoch": 89.11,
      "learning_rate": 4.84695920862809e-06,
      "loss": 0.099,
      "step": 89110
    },
    {
      "epoch": 89.12,
      "learning_rate": 4.838191541649719e-06,
      "loss": 0.1329,
      "step": 89120
    },
    {
      "epoch": 89.13,
      "learning_rate": 4.8294315474612264e-06,
      "loss": 0.1745,
      "step": 89130
    },
    {
      "epoch": 89.14,
      "learning_rate": 4.820679227020596e-06,
      "loss": 0.0877,
      "step": 89140
    },
    {
      "epoch": 89.15,
      "learning_rate": 4.811934581284987e-06,
      "loss": 0.2282,
      "step": 89150
    },
    {
      "epoch": 89.16,
      "learning_rate": 4.8031976112106765e-06,
      "loss": 0.0503,
      "step": 89160
    },
    {
      "epoch": 89.17,
      "learning_rate": 4.79446831775315e-06,
      "loss": 0.2967,
      "step": 89170
    },
    {
      "epoch": 89.18,
      "learning_rate": 4.785746701867002e-06,
      "loss": 0.1088,
      "step": 89180
    },
    {
      "epoch": 89.19,
      "learning_rate": 4.777032764506036e-06,
      "loss": 0.3019,
      "step": 89190
    },
    {
      "epoch": 89.2,
      "learning_rate": 4.768326506623174e-06,
      "loss": 0.1607,
      "step": 89200
    },
    {
      "epoch": 89.21,
      "learning_rate": 4.759627929170545e-06,
      "loss": 0.2182,
      "step": 89210
    },
    {
      "epoch": 89.22,
      "learning_rate": 4.750937033099397e-06,
      "loss": 0.201,
      "step": 89220
    },
    {
      "epoch": 89.23,
      "learning_rate": 4.74225381936017e-06,
      "loss": 0.2527,
      "step": 89230
    },
    {
      "epoch": 89.24,
      "learning_rate": 4.73357828890242e-06,
      "loss": 0.1799,
      "step": 89240
    },
    {
      "epoch": 89.25,
      "learning_rate": 4.724910442674906e-06,
      "loss": 0.317,
      "step": 89250
    },
    {
      "epoch": 89.26,
      "learning_rate": 4.7162502816255275e-06,
      "loss": 0.0533,
      "step": 89260
    },
    {
      "epoch": 89.27,
      "learning_rate": 4.7075978067013606e-06,
      "loss": 0.2262,
      "step": 89270
    },
    {
      "epoch": 89.28,
      "learning_rate": 4.698953018848597e-06,
      "loss": 0.1893,
      "step": 89280
    },
    {
      "epoch": 89.29,
      "learning_rate": 4.690315919012641e-06,
      "loss": 0.2728,
      "step": 89290
    },
    {
      "epoch": 89.3,
      "learning_rate": 4.681686508138044e-06,
      "loss": 0.1068,
      "step": 89300
    },
    {
      "epoch": 89.31,
      "learning_rate": 4.673064787168468e-06,
      "loss": 0.1488,
      "step": 89310
    },
    {
      "epoch": 89.32,
      "learning_rate": 4.664450757046792e-06,
      "loss": 0.1882,
      "step": 89320
    },
    {
      "epoch": 89.33,
      "learning_rate": 4.655844418715038e-06,
      "loss": 0.1997,
      "step": 89330
    },
    {
      "epoch": 89.34,
      "learning_rate": 4.647245773114386e-06,
      "loss": 0.1645,
      "step": 89340
    },
    {
      "epoch": 89.35,
      "learning_rate": 4.63865482118515e-06,
      "loss": 0.1294,
      "step": 89350
    },
    {
      "epoch": 89.36,
      "learning_rate": 4.6300715638668554e-06,
      "loss": 0.2041,
      "step": 89360
    },
    {
      "epoch": 89.37,
      "learning_rate": 4.6214960020981155e-06,
      "loss": 0.1288,
      "step": 89370
    },
    {
      "epoch": 89.38,
      "learning_rate": 4.6129281368167735e-06,
      "loss": 0.1207,
      "step": 89380
    },
    {
      "epoch": 89.39,
      "learning_rate": 4.604367968959763e-06,
      "loss": 0.1907,
      "step": 89390
    },
    {
      "epoch": 89.4,
      "learning_rate": 4.59581549946326e-06,
      "loss": 0.1459,
      "step": 89400
    },
    {
      "epoch": 89.41,
      "learning_rate": 4.5872707292625075e-06,
      "loss": 0.0887,
      "step": 89410
    },
    {
      "epoch": 89.42,
      "learning_rate": 4.5787336592919664e-06,
      "loss": 0.0581,
      "step": 89420
    },
    {
      "epoch": 89.43,
      "learning_rate": 4.570204290485241e-06,
      "loss": 0.0916,
      "step": 89430
    },
    {
      "epoch": 89.44,
      "learning_rate": 4.561682623775084e-06,
      "loss": 0.2234,
      "step": 89440
    },
    {
      "epoch": 89.45,
      "learning_rate": 4.553168660093392e-06,
      "loss": 0.1693,
      "step": 89450
    },
    {
      "epoch": 89.46,
      "learning_rate": 4.5446624003712874e-06,
      "loss": 0.1395,
      "step": 89460
    },
    {
      "epoch": 89.47,
      "learning_rate": 4.536163845538959e-06,
      "loss": 0.1525,
      "step": 89470
    },
    {
      "epoch": 89.48,
      "learning_rate": 4.52767299652583e-06,
      "loss": 0.2567,
      "step": 89480
    },
    {
      "epoch": 89.49,
      "learning_rate": 4.520037821656858e-06,
      "loss": 0.1842,
      "step": 89490
    },
    {
      "epoch": 89.5,
      "learning_rate": 4.511561616257609e-06,
      "loss": 0.1119,
      "step": 89500
    },
    {
      "epoch": 89.51,
      "learning_rate": 4.503093119367998e-06,
      "loss": 0.1643,
      "step": 89510
    },
    {
      "epoch": 89.52,
      "learning_rate": 4.4946323319141355e-06,
      "loss": 0.239,
      "step": 89520
    },
    {
      "epoch": 89.53,
      "learning_rate": 4.48617925482129e-06,
      "loss": 0.2467,
      "step": 89530
    },
    {
      "epoch": 89.54,
      "learning_rate": 4.477733889013854e-06,
      "loss": 0.1858,
      "step": 89540
    },
    {
      "epoch": 89.55,
      "learning_rate": 4.469296235415407e-06,
      "loss": 0.2433,
      "step": 89550
    },
    {
      "epoch": 89.56,
      "learning_rate": 4.4608662949487005e-06,
      "loss": 0.2253,
      "step": 89560
    },
    {
      "epoch": 89.57,
      "learning_rate": 4.4524440685355824e-06,
      "loss": 0.1726,
      "step": 89570
    },
    {
      "epoch": 89.58,
      "learning_rate": 4.4440295570971315e-06,
      "loss": 0.1948,
      "step": 89580
    },
    {
      "epoch": 89.59,
      "learning_rate": 4.435622761553503e-06,
      "loss": 0.1564,
      "step": 89590
    },
    {
      "epoch": 89.6,
      "learning_rate": 4.4272236828241045e-06,
      "loss": 0.1853,
      "step": 89600
    },
    {
      "epoch": 89.61,
      "learning_rate": 4.4188323218274095e-06,
      "loss": 0.1939,
      "step": 89610
    },
    {
      "epoch": 89.62,
      "learning_rate": 4.410448679481099e-06,
      "loss": 0.1348,
      "step": 89620
    },
    {
      "epoch": 89.63,
      "learning_rate": 4.402072756701982e-06,
      "loss": 0.1651,
      "step": 89630
    },
    {
      "epoch": 89.64,
      "learning_rate": 4.393704554406061e-06,
      "loss": 0.2357,
      "step": 89640
    },
    {
      "epoch": 89.65,
      "learning_rate": 4.385344073508426e-06,
      "loss": 0.3018,
      "step": 89650
    },
    {
      "epoch": 89.66,
      "learning_rate": 4.376991314923423e-06,
      "loss": 0.2141,
      "step": 89660
    },
    {
      "epoch": 89.67,
      "learning_rate": 4.368646279564452e-06,
      "loss": 0.1398,
      "step": 89670
    },
    {
      "epoch": 89.68,
      "learning_rate": 4.360308968344154e-06,
      "loss": 0.2104,
      "step": 89680
    },
    {
      "epoch": 89.69,
      "learning_rate": 4.351979382174245e-06,
      "loss": 0.1782,
      "step": 89690
    },
    {
      "epoch": 89.7,
      "learning_rate": 4.343657521965657e-06,
      "loss": 0.1829,
      "step": 89700
    },
    {
      "epoch": 89.71,
      "learning_rate": 4.3353433886284375e-06,
      "loss": 0.2374,
      "step": 89710
    },
    {
      "epoch": 89.72,
      "learning_rate": 4.327036983071849e-06,
      "loss": 0.1739,
      "step": 89720
    },
    {
      "epoch": 89.73,
      "learning_rate": 4.318738306204217e-06,
      "loss": 0.0922,
      "step": 89730
    },
    {
      "epoch": 89.74,
      "learning_rate": 4.310447358933122e-06,
      "loss": 0.1668,
      "step": 89740
    },
    {
      "epoch": 89.75,
      "learning_rate": 4.302164142165198e-06,
      "loss": 0.2196,
      "step": 89750
    },
    {
      "epoch": 89.76,
      "learning_rate": 4.293888656806321e-06,
      "loss": 0.238,
      "step": 89760
    },
    {
      "epoch": 89.77,
      "learning_rate": 4.285620903761483e-06,
      "loss": 0.2341,
      "step": 89770
    },
    {
      "epoch": 89.78,
      "learning_rate": 4.2773608839348105e-06,
      "loss": 0.1206,
      "step": 89780
    },
    {
      "epoch": 89.79,
      "learning_rate": 4.269108598229631e-06,
      "loss": 0.0882,
      "step": 89790
    },
    {
      "epoch": 89.8,
      "learning_rate": 4.26086404754839e-06,
      "loss": 0.1712,
      "step": 89800
    },
    {
      "epoch": 89.81,
      "learning_rate": 4.252627232792707e-06,
      "loss": 0.0491,
      "step": 89810
    },
    {
      "epoch": 89.82,
      "learning_rate": 4.244398154863338e-06,
      "loss": 0.1246,
      "step": 89820
    },
    {
      "epoch": 89.83,
      "learning_rate": 4.236176814660211e-06,
      "loss": 0.1259,
      "step": 89830
    },
    {
      "epoch": 89.84,
      "learning_rate": 4.2279632130823836e-06,
      "loss": 0.2637,
      "step": 89840
    },
    {
      "epoch": 89.85,
      "learning_rate": 4.219757351028111e-06,
      "loss": 0.0749,
      "step": 89850
    },
    {
      "epoch": 89.86,
      "learning_rate": 4.211559229394751e-06,
      "loss": 0.2527,
      "step": 89860
    },
    {
      "epoch": 89.87,
      "learning_rate": 4.203368849078853e-06,
      "loss": 0.1317,
      "step": 89870
    },
    {
      "epoch": 89.88,
      "learning_rate": 4.195186210976084e-06,
      "loss": 0.109,
      "step": 89880
    },
    {
      "epoch": 89.89,
      "learning_rate": 4.187011315981312e-06,
      "loss": 0.1272,
      "step": 89890
    },
    {
      "epoch": 89.9,
      "learning_rate": 4.178844164988488e-06,
      "loss": 0.1493,
      "step": 89900
    },
    {
      "epoch": 89.91,
      "learning_rate": 4.170684758890813e-06,
      "loss": 0.2367,
      "step": 89910
    },
    {
      "epoch": 89.92,
      "learning_rate": 4.162533098580559e-06,
      "loss": 0.133,
      "step": 89920
    },
    {
      "epoch": 89.93,
      "learning_rate": 4.154389184949186e-06,
      "loss": 0.1214,
      "step": 89930
    },
    {
      "epoch": 89.94,
      "learning_rate": 4.146253018887283e-06,
      "loss": 0.1222,
      "step": 89940
    },
    {
      "epoch": 89.95,
      "learning_rate": 4.1381246012846454e-06,
      "loss": 0.087,
      "step": 89950
    },
    {
      "epoch": 89.96,
      "learning_rate": 4.1300039330301375e-06,
      "loss": 0.2635,
      "step": 89960
    },
    {
      "epoch": 89.97,
      "learning_rate": 4.121891015011858e-06,
      "loss": 0.2452,
      "step": 89970
    },
    {
      "epoch": 89.98,
      "learning_rate": 4.113785848117012e-06,
      "loss": 0.1178,
      "step": 89980
    },
    {
      "epoch": 89.99,
      "learning_rate": 4.105688433231977e-06,
      "loss": 0.1383,
      "step": 89990
    },
    {
      "epoch": 90.0,
      "learning_rate": 4.0975987712422585e-06,
      "loss": 0.0568,
      "step": 90000
    },
    {
      "epoch": 90.0,
      "eval_accuracy": 0.7985,
      "eval_loss": 0.6549001336097717,
      "eval_runtime": 14.8531,
      "eval_samples_per_second": 134.652,
      "eval_steps_per_second": 16.832,
      "step": 90000
    },
    {
      "epoch": 90.01,
      "learning_rate": 4.089516863032541e-06,
      "loss": 0.1809,
      "step": 90010
    },
    {
      "epoch": 90.02,
      "learning_rate": 4.081442709486651e-06,
      "loss": 0.0604,
      "step": 90020
    },
    {
      "epoch": 90.03,
      "learning_rate": 4.073376311487558e-06,
      "loss": 0.256,
      "step": 90030
    },
    {
      "epoch": 90.04,
      "learning_rate": 4.0653176699173895e-06,
      "loss": 0.1892,
      "step": 90040
    },
    {
      "epoch": 90.05,
      "learning_rate": 4.05726678565744e-06,
      "loss": 0.1555,
      "step": 90050
    },
    {
      "epoch": 90.06,
      "learning_rate": 4.049223659588139e-06,
      "loss": 0.2038,
      "step": 90060
    },
    {
      "epoch": 90.07,
      "learning_rate": 4.0411882925890486e-06,
      "loss": 0.0567,
      "step": 90070
    },
    {
      "epoch": 90.08,
      "learning_rate": 4.033160685538942e-06,
      "loss": 0.2708,
      "step": 90080
    },
    {
      "epoch": 90.09,
      "learning_rate": 4.025140839315657e-06,
      "loss": 0.1412,
      "step": 90090
    },
    {
      "epoch": 90.1,
      "learning_rate": 4.017128754796286e-06,
      "loss": 0.269,
      "step": 90100
    },
    {
      "epoch": 90.11,
      "learning_rate": 4.009124432856986e-06,
      "loss": 0.2985,
      "step": 90110
    },
    {
      "epoch": 90.12,
      "learning_rate": 4.0011278743731136e-06,
      "loss": 0.2475,
      "step": 90120
    },
    {
      "epoch": 90.13,
      "learning_rate": 3.993139080219138e-06,
      "loss": 0.2854,
      "step": 90130
    },
    {
      "epoch": 90.14,
      "learning_rate": 3.985158051268733e-06,
      "loss": 0.1379,
      "step": 90140
    },
    {
      "epoch": 90.15,
      "learning_rate": 3.977184788394652e-06,
      "loss": 0.3945,
      "step": 90150
    },
    {
      "epoch": 90.16,
      "learning_rate": 3.969219292468873e-06,
      "loss": 0.2453,
      "step": 90160
    },
    {
      "epoch": 90.17,
      "learning_rate": 3.961261564362472e-06,
      "loss": 0.2079,
      "step": 90170
    },
    {
      "epoch": 90.18,
      "learning_rate": 3.953311604945714e-06,
      "loss": 0.0176,
      "step": 90180
    },
    {
      "epoch": 90.19,
      "learning_rate": 3.945369415087968e-06,
      "loss": 0.1077,
      "step": 90190
    },
    {
      "epoch": 90.2,
      "learning_rate": 3.937434995657806e-06,
      "loss": 0.1423,
      "step": 90200
    },
    {
      "epoch": 90.21,
      "learning_rate": 3.929508347522902e-06,
      "loss": 0.2293,
      "step": 90210
    },
    {
      "epoch": 90.22,
      "learning_rate": 3.921589471550113e-06,
      "loss": 0.2393,
      "step": 90220
    },
    {
      "epoch": 90.23,
      "learning_rate": 3.913678368605436e-06,
      "loss": 0.2056,
      "step": 90230
    },
    {
      "epoch": 90.24,
      "learning_rate": 3.905775039554021e-06,
      "loss": 0.1859,
      "step": 90240
    },
    {
      "epoch": 90.25,
      "learning_rate": 3.897879485260152e-06,
      "loss": 0.1458,
      "step": 90250
    },
    {
      "epoch": 90.26,
      "learning_rate": 3.889991706587281e-06,
      "loss": 0.0914,
      "step": 90260
    },
    {
      "epoch": 90.27,
      "learning_rate": 3.882111704398016e-06,
      "loss": 0.1163,
      "step": 90270
    },
    {
      "epoch": 90.28,
      "learning_rate": 3.8742394795540865e-06,
      "loss": 0.1769,
      "step": 90280
    },
    {
      "epoch": 90.29,
      "learning_rate": 3.8663750329163855e-06,
      "loss": 0.1195,
      "step": 90290
    },
    {
      "epoch": 90.3,
      "learning_rate": 3.858518365344959e-06,
      "loss": 0.1027,
      "step": 90300
    },
    {
      "epoch": 90.31,
      "learning_rate": 3.85066947769902e-06,
      "loss": 0.0192,
      "step": 90310
    },
    {
      "epoch": 90.32,
      "learning_rate": 3.842828370836881e-06,
      "loss": 0.1636,
      "step": 90320
    },
    {
      "epoch": 90.33,
      "learning_rate": 3.834995045616065e-06,
      "loss": 0.1871,
      "step": 90330
    },
    {
      "epoch": 90.34,
      "learning_rate": 3.827169502893179e-06,
      "loss": 0.1638,
      "step": 90340
    },
    {
      "epoch": 90.35,
      "learning_rate": 3.8193517435240375e-06,
      "loss": 0.185,
      "step": 90350
    },
    {
      "epoch": 90.36,
      "learning_rate": 3.8115417683635658e-06,
      "loss": 0.0864,
      "step": 90360
    },
    {
      "epoch": 90.37,
      "learning_rate": 3.803739578265863e-06,
      "loss": 0.0484,
      "step": 90370
    },
    {
      "epoch": 90.38,
      "learning_rate": 3.795945174084156e-06,
      "loss": 0.1342,
      "step": 90380
    },
    {
      "epoch": 90.39,
      "learning_rate": 3.7881585566708366e-06,
      "loss": 0.1967,
      "step": 90390
    },
    {
      "epoch": 90.4,
      "learning_rate": 3.7803797268774166e-06,
      "loss": 0.1177,
      "step": 90400
    },
    {
      "epoch": 90.41,
      "learning_rate": 3.7726086855545984e-06,
      "loss": 0.0179,
      "step": 90410
    },
    {
      "epoch": 90.42,
      "learning_rate": 3.7648454335522103e-06,
      "loss": 0.0557,
      "step": 90420
    },
    {
      "epoch": 90.43,
      "learning_rate": 3.757089971719224e-06,
      "loss": 0.0532,
      "step": 90430
    },
    {
      "epoch": 90.44,
      "learning_rate": 3.74934230090376e-06,
      "loss": 0.1892,
      "step": 90440
    },
    {
      "epoch": 90.45,
      "learning_rate": 3.741602421953116e-06,
      "loss": 0.1457,
      "step": 90450
    },
    {
      "epoch": 90.46,
      "learning_rate": 3.7338703357136816e-06,
      "loss": 0.2961,
      "step": 90460
    },
    {
      "epoch": 90.47,
      "learning_rate": 3.7261460430310307e-06,
      "loss": 0.2284,
      "step": 90470
    },
    {
      "epoch": 90.48,
      "learning_rate": 3.718429544749904e-06,
      "loss": 0.2864,
      "step": 90480
    },
    {
      "epoch": 90.49,
      "learning_rate": 3.7107208417141517e-06,
      "loss": 0.2319,
      "step": 90490
    },
    {
      "epoch": 90.5,
      "learning_rate": 3.703019934766782e-06,
      "loss": 0.1375,
      "step": 90500
    },
    {
      "epoch": 90.51,
      "learning_rate": 3.6953268247499557e-06,
      "loss": 0.1411,
      "step": 90510
    },
    {
      "epoch": 90.52,
      "learning_rate": 3.6876415125049992e-06,
      "loss": 0.0427,
      "step": 90520
    },
    {
      "epoch": 90.53,
      "learning_rate": 3.6799639988723317e-06,
      "loss": 0.0548,
      "step": 90530
    },
    {
      "epoch": 90.54,
      "learning_rate": 3.6722942846915736e-06,
      "loss": 0.2588,
      "step": 90540
    },
    {
      "epoch": 90.55,
      "learning_rate": 3.664632370801479e-06,
      "loss": 0.1976,
      "step": 90550
    },
    {
      "epoch": 90.56,
      "learning_rate": 3.6569782580399444e-06,
      "loss": 0.1673,
      "step": 90560
    },
    {
      "epoch": 90.57,
      "learning_rate": 3.6493319472439996e-06,
      "loss": 0.1204,
      "step": 90570
    },
    {
      "epoch": 90.58,
      "learning_rate": 3.641693439249843e-06,
      "loss": 0.1383,
      "step": 90580
    },
    {
      "epoch": 90.59,
      "learning_rate": 3.634062734892798e-06,
      "loss": 0.339,
      "step": 90590
    },
    {
      "epoch": 90.6,
      "learning_rate": 3.6264398350073555e-06,
      "loss": 0.1229,
      "step": 90600
    },
    {
      "epoch": 90.61,
      "learning_rate": 3.6188247404271396e-06,
      "loss": 0.1452,
      "step": 90610
    },
    {
      "epoch": 90.62,
      "learning_rate": 3.6112174519849436e-06,
      "loss": 0.2581,
      "step": 90620
    },
    {
      "epoch": 90.63,
      "learning_rate": 3.603617970512668e-06,
      "loss": 0.0996,
      "step": 90630
    },
    {
      "epoch": 90.64,
      "learning_rate": 3.5960262968413977e-06,
      "loss": 0.1243,
      "step": 90640
    },
    {
      "epoch": 90.65,
      "learning_rate": 3.5884424318013195e-06,
      "loss": 0.2374,
      "step": 90650
    },
    {
      "epoch": 90.66,
      "learning_rate": 3.5808663762218277e-06,
      "loss": 0.0601,
      "step": 90660
    },
    {
      "epoch": 90.67,
      "learning_rate": 3.573298130931393e-06,
      "loss": 0.3193,
      "step": 90670
    },
    {
      "epoch": 90.68,
      "learning_rate": 3.5657376967577035e-06,
      "loss": 0.1727,
      "step": 90680
    },
    {
      "epoch": 90.69,
      "learning_rate": 3.5581850745275308e-06,
      "loss": 0.1446,
      "step": 90690
    },
    {
      "epoch": 90.7,
      "learning_rate": 3.5506402650668396e-06,
      "loss": 0.2012,
      "step": 90700
    },
    {
      "epoch": 90.71,
      "learning_rate": 3.543103269200695e-06,
      "loss": 0.239,
      "step": 90710
    },
    {
      "epoch": 90.72,
      "learning_rate": 3.535574087753346e-06,
      "loss": 0.1887,
      "step": 90720
    },
    {
      "epoch": 90.73,
      "learning_rate": 3.5280527215481663e-06,
      "loss": 0.1878,
      "step": 90730
    },
    {
      "epoch": 90.74,
      "learning_rate": 3.520539171407691e-06,
      "loss": 0.1093,
      "step": 90740
    },
    {
      "epoch": 90.75,
      "learning_rate": 3.5130334381535785e-06,
      "loss": 0.1877,
      "step": 90750
    },
    {
      "epoch": 90.76,
      "learning_rate": 3.505535522606648e-06,
      "loss": 0.2349,
      "step": 90760
    },
    {
      "epoch": 90.77,
      "learning_rate": 3.4980454255868762e-06,
      "loss": 0.0738,
      "step": 90770
    },
    {
      "epoch": 90.78,
      "learning_rate": 3.4905631479133416e-06,
      "loss": 0.3223,
      "step": 90780
    },
    {
      "epoch": 90.79,
      "learning_rate": 3.4830886904043147e-06,
      "loss": 0.2689,
      "step": 90790
    },
    {
      "epoch": 90.8,
      "learning_rate": 3.475622053877175e-06,
      "loss": 0.2451,
      "step": 90800
    },
    {
      "epoch": 90.81,
      "learning_rate": 3.468163239148486e-06,
      "loss": 0.2975,
      "step": 90810
    },
    {
      "epoch": 90.82,
      "learning_rate": 3.460712247033903e-06,
      "loss": 0.1279,
      "step": 90820
    },
    {
      "epoch": 90.83,
      "learning_rate": 3.453269078348292e-06,
      "loss": 0.171,
      "step": 90830
    },
    {
      "epoch": 90.84,
      "learning_rate": 3.445833733905584e-06,
      "loss": 0.162,
      "step": 90840
    },
    {
      "epoch": 90.85,
      "learning_rate": 3.438406214518938e-06,
      "loss": 0.3781,
      "step": 90850
    },
    {
      "epoch": 90.86,
      "learning_rate": 3.430986521000578e-06,
      "loss": 0.357,
      "step": 90860
    },
    {
      "epoch": 90.87,
      "learning_rate": 3.4235746541619395e-06,
      "loss": 0.1823,
      "step": 90870
    },
    {
      "epoch": 90.88,
      "learning_rate": 3.4161706148135653e-06,
      "loss": 0.1942,
      "step": 90880
    },
    {
      "epoch": 90.89,
      "learning_rate": 3.4087744037651493e-06,
      "loss": 0.1506,
      "step": 90890
    },
    {
      "epoch": 90.9,
      "learning_rate": 3.4013860218255198e-06,
      "loss": 0.1003,
      "step": 90900
    },
    {
      "epoch": 90.91,
      "learning_rate": 3.3940054698026796e-06,
      "loss": 0.1891,
      "step": 90910
    },
    {
      "epoch": 90.92,
      "learning_rate": 3.386632748503726e-06,
      "loss": 0.2359,
      "step": 90920
    },
    {
      "epoch": 90.93,
      "learning_rate": 3.379267858734963e-06,
      "loss": 0.236,
      "step": 90930
    },
    {
      "epoch": 90.94,
      "learning_rate": 3.3719108013017804e-06,
      "loss": 0.0689,
      "step": 90940
    },
    {
      "epoch": 90.95,
      "learning_rate": 3.364561577008751e-06,
      "loss": 0.0904,
      "step": 90950
    },
    {
      "epoch": 90.96,
      "learning_rate": 3.357220186659548e-06,
      "loss": 0.1713,
      "step": 90960
    },
    {
      "epoch": 90.97,
      "learning_rate": 3.349886631057039e-06,
      "loss": 0.2273,
      "step": 90970
    },
    {
      "epoch": 90.98,
      "learning_rate": 3.3425609110032142e-06,
      "loss": 0.0153,
      "step": 90980
    },
    {
      "epoch": 90.99,
      "learning_rate": 3.335243027299175e-06,
      "loss": 0.0853,
      "step": 90990
    },
    {
      "epoch": 91.0,
      "learning_rate": 3.3279329807452155e-06,
      "loss": 0.0914,
      "step": 91000
    },
    {
      "epoch": 91.0,
      "eval_accuracy": 0.796,
      "eval_loss": 0.6705971956253052,
      "eval_runtime": 15.0734,
      "eval_samples_per_second": 132.684,
      "eval_steps_per_second": 16.585,
      "step": 91000
    },
    {
      "epoch": 91.01,
      "learning_rate": 3.3206307721407534e-06,
      "loss": 0.1472,
      "step": 91010
    },
    {
      "epoch": 91.02,
      "learning_rate": 3.31333640228435e-06,
      "loss": 0.1372,
      "step": 91020
    },
    {
      "epoch": 91.03,
      "learning_rate": 3.3060498719736842e-06,
      "loss": 0.1585,
      "step": 91030
    },
    {
      "epoch": 91.04,
      "learning_rate": 3.298771182005627e-06,
      "loss": 0.1482,
      "step": 91040
    },
    {
      "epoch": 91.05,
      "learning_rate": 3.2915003331761253e-06,
      "loss": 0.2198,
      "step": 91050
    },
    {
      "epoch": 91.06,
      "learning_rate": 3.2842373262803674e-06,
      "loss": 0.1697,
      "step": 91060
    },
    {
      "epoch": 91.07,
      "learning_rate": 3.276982162112568e-06,
      "loss": 0.2144,
      "step": 91070
    },
    {
      "epoch": 91.08,
      "learning_rate": 3.2697348414661844e-06,
      "loss": 0.2067,
      "step": 91080
    },
    {
      "epoch": 91.09,
      "learning_rate": 3.262495365133749e-06,
      "loss": 0.2862,
      "step": 91090
    },
    {
      "epoch": 91.1,
      "learning_rate": 3.2552637339069627e-06,
      "loss": 0.1368,
      "step": 91100
    },
    {
      "epoch": 91.11,
      "learning_rate": 3.2480399485766585e-06,
      "loss": 0.0958,
      "step": 91110
    },
    {
      "epoch": 91.12,
      "learning_rate": 3.240824009932838e-06,
      "loss": 0.1778,
      "step": 91120
    },
    {
      "epoch": 91.13,
      "learning_rate": 3.233615918764612e-06,
      "loss": 0.0902,
      "step": 91130
    },
    {
      "epoch": 91.14,
      "learning_rate": 3.2264156758602585e-06,
      "loss": 0.1111,
      "step": 91140
    },
    {
      "epoch": 91.15,
      "learning_rate": 3.2192232820071633e-06,
      "loss": 0.0496,
      "step": 91150
    },
    {
      "epoch": 91.16,
      "learning_rate": 3.2120387379919066e-06,
      "loss": 0.1264,
      "step": 91160
    },
    {
      "epoch": 91.17,
      "learning_rate": 3.204862044600151e-06,
      "loss": 0.1175,
      "step": 91170
    },
    {
      "epoch": 91.18,
      "learning_rate": 3.1976932026167357e-06,
      "loss": 0.1462,
      "step": 91180
    },
    {
      "epoch": 91.19,
      "learning_rate": 3.1905322128256332e-06,
      "loss": 0.1164,
      "step": 91190
    },
    {
      "epoch": 91.2,
      "learning_rate": 3.183379076009984e-06,
      "loss": 0.1526,
      "step": 91200
    },
    {
      "epoch": 91.21,
      "learning_rate": 3.1762337929520125e-06,
      "loss": 0.0827,
      "step": 91210
    },
    {
      "epoch": 91.22,
      "learning_rate": 3.1690963644331267e-06,
      "loss": 0.1599,
      "step": 91220
    },
    {
      "epoch": 91.23,
      "learning_rate": 3.1619667912338775e-06,
      "loss": 0.2287,
      "step": 91230
    },
    {
      "epoch": 91.24,
      "learning_rate": 3.154845074133916e-06,
      "loss": 0.0546,
      "step": 91240
    },
    {
      "epoch": 91.25,
      "learning_rate": 3.147731213912086e-06,
      "loss": 0.2573,
      "step": 91250
    },
    {
      "epoch": 91.26,
      "learning_rate": 3.1406252113463396e-06,
      "loss": 0.2078,
      "step": 91260
    },
    {
      "epoch": 91.27,
      "learning_rate": 3.133527067213798e-06,
      "loss": 0.2031,
      "step": 91270
    },
    {
      "epoch": 91.28,
      "learning_rate": 3.1264367822906725e-06,
      "loss": 0.1763,
      "step": 91280
    },
    {
      "epoch": 91.29,
      "learning_rate": 3.1193543573523687e-06,
      "loss": 0.0477,
      "step": 91290
    },
    {
      "epoch": 91.3,
      "learning_rate": 3.1122797931733835e-06,
      "loss": 0.2611,
      "step": 91300
    },
    {
      "epoch": 91.31,
      "learning_rate": 3.105213090527414e-06,
      "loss": 0.2067,
      "step": 91310
    },
    {
      "epoch": 91.32,
      "learning_rate": 3.098154250187243e-06,
      "loss": 0.189,
      "step": 91320
    },
    {
      "epoch": 91.33,
      "learning_rate": 3.0911032729248274e-06,
      "loss": 0.1666,
      "step": 91330
    },
    {
      "epoch": 91.34,
      "learning_rate": 3.084060159511234e-06,
      "loss": 0.1948,
      "step": 91340
    },
    {
      "epoch": 91.35,
      "learning_rate": 3.0770249107167134e-06,
      "loss": 0.138,
      "step": 91350
    },
    {
      "epoch": 91.36,
      "learning_rate": 3.0699975273105996e-06,
      "loss": 0.06,
      "step": 91360
    },
    {
      "epoch": 91.37,
      "learning_rate": 3.0629780100614122e-06,
      "loss": 0.1651,
      "step": 91370
    },
    {
      "epoch": 91.38,
      "learning_rate": 3.0559663597367947e-06,
      "loss": 0.1772,
      "step": 91380
    },
    {
      "epoch": 91.39,
      "learning_rate": 3.0489625771035337e-06,
      "loss": 0.1663,
      "step": 91390
    },
    {
      "epoch": 91.4,
      "learning_rate": 3.041966662927542e-06,
      "loss": 0.2133,
      "step": 91400
    },
    {
      "epoch": 91.41,
      "learning_rate": 3.034978617973899e-06,
      "loss": 0.1028,
      "step": 91410
    },
    {
      "epoch": 91.42,
      "learning_rate": 3.0279984430067932e-06,
      "loss": 0.1673,
      "step": 91420
    },
    {
      "epoch": 91.43,
      "learning_rate": 3.0210261387895644e-06,
      "loss": 0.2664,
      "step": 91430
    },
    {
      "epoch": 91.44,
      "learning_rate": 3.0140617060846943e-06,
      "loss": 0.2764,
      "step": 91440
    },
    {
      "epoch": 91.45,
      "learning_rate": 3.0071051456538238e-06,
      "loss": 0.3252,
      "step": 91450
    },
    {
      "epoch": 91.46,
      "learning_rate": 3.000156458257677e-06,
      "loss": 0.2709,
      "step": 91460
    },
    {
      "epoch": 91.47,
      "learning_rate": 2.99321564465618e-06,
      "loss": 0.0674,
      "step": 91470
    },
    {
      "epoch": 91.48,
      "learning_rate": 2.986282705608359e-06,
      "loss": 0.1552,
      "step": 91480
    },
    {
      "epoch": 91.49,
      "learning_rate": 2.979357641872382e-06,
      "loss": 0.1136,
      "step": 91490
    },
    {
      "epoch": 91.5,
      "learning_rate": 2.9724404542055767e-06,
      "loss": 0.0613,
      "step": 91500
    },
    {
      "epoch": 91.51,
      "learning_rate": 2.9655311433643887e-06,
      "loss": 0.2648,
      "step": 91510
    },
    {
      "epoch": 91.52,
      "learning_rate": 2.9586297101044293e-06,
      "loss": 0.312,
      "step": 91520
    },
    {
      "epoch": 91.53,
      "learning_rate": 2.951736155180395e-06,
      "loss": 0.1219,
      "step": 91530
    },
    {
      "epoch": 91.54,
      "learning_rate": 2.9448504793461836e-06,
      "loss": 0.1153,
      "step": 91540
    },
    {
      "epoch": 91.55,
      "learning_rate": 2.9379726833547753e-06,
      "loss": 0.2215,
      "step": 91550
    },
    {
      "epoch": 91.56,
      "learning_rate": 2.931102767958335e-06,
      "loss": 0.1679,
      "step": 91560
    },
    {
      "epoch": 91.57,
      "learning_rate": 2.9242407339081453e-06,
      "loss": 0.1862,
      "step": 91570
    },
    {
      "epoch": 91.58,
      "learning_rate": 2.917386581954631e-06,
      "loss": 0.2827,
      "step": 91580
    },
    {
      "epoch": 91.59,
      "learning_rate": 2.910540312847334e-06,
      "loss": 0.1643,
      "step": 91590
    },
    {
      "epoch": 91.6,
      "learning_rate": 2.903701927334981e-06,
      "loss": 0.0541,
      "step": 91600
    },
    {
      "epoch": 91.61,
      "learning_rate": 2.896871426165373e-06,
      "loss": 0.1735,
      "step": 91610
    },
    {
      "epoch": 91.62,
      "learning_rate": 2.8900488100855047e-06,
      "loss": 0.1515,
      "step": 91620
    },
    {
      "epoch": 91.63,
      "learning_rate": 2.8832340798414788e-06,
      "loss": 0.0646,
      "step": 91630
    },
    {
      "epoch": 91.64,
      "learning_rate": 2.8764272361785577e-06,
      "loss": 0.0748,
      "step": 91640
    },
    {
      "epoch": 91.65,
      "learning_rate": 2.869628279841113e-06,
      "loss": 0.1831,
      "step": 91650
    },
    {
      "epoch": 91.66,
      "learning_rate": 2.8628372115726742e-06,
      "loss": 0.2148,
      "step": 91660
    },
    {
      "epoch": 91.67,
      "learning_rate": 2.856054032115898e-06,
      "loss": 0.2376,
      "step": 91670
    },
    {
      "epoch": 91.68,
      "learning_rate": 2.8492787422125906e-06,
      "loss": 0.2583,
      "step": 91680
    },
    {
      "epoch": 91.69,
      "learning_rate": 2.842511342603676e-06,
      "loss": 0.2589,
      "step": 91690
    },
    {
      "epoch": 91.7,
      "learning_rate": 2.8357518340292455e-06,
      "loss": 0.1,
      "step": 91700
    },
    {
      "epoch": 91.71,
      "learning_rate": 2.829000217228483e-06,
      "loss": 0.2077,
      "step": 91710
    },
    {
      "epoch": 91.72,
      "learning_rate": 2.822256492939756e-06,
      "loss": 0.2278,
      "step": 91720
    },
    {
      "epoch": 91.73,
      "learning_rate": 2.81552066190055e-06,
      "loss": 0.2502,
      "step": 91730
    },
    {
      "epoch": 91.74,
      "learning_rate": 2.8087927248474666e-06,
      "loss": 0.231,
      "step": 91740
    },
    {
      "epoch": 91.75,
      "learning_rate": 2.8020726825162683e-06,
      "loss": 0.1437,
      "step": 91750
    },
    {
      "epoch": 91.76,
      "learning_rate": 2.795360535641858e-06,
      "loss": 0.1624,
      "step": 91760
    },
    {
      "epoch": 91.77,
      "learning_rate": 2.7886562849582737e-06,
      "loss": 0.057,
      "step": 91770
    },
    {
      "epoch": 91.78,
      "learning_rate": 2.7819599311986545e-06,
      "loss": 0.2353,
      "step": 91780
    },
    {
      "epoch": 91.79,
      "learning_rate": 2.775271475095331e-06,
      "loss": 0.1552,
      "step": 91790
    },
    {
      "epoch": 91.8,
      "learning_rate": 2.7685909173797177e-06,
      "loss": 0.2907,
      "step": 91800
    },
    {
      "epoch": 91.81,
      "learning_rate": 2.7619182587824057e-06,
      "loss": 0.2104,
      "step": 91810
    },
    {
      "epoch": 91.82,
      "learning_rate": 2.755253500033111e-06,
      "loss": 0.4117,
      "step": 91820
    },
    {
      "epoch": 91.83,
      "learning_rate": 2.748596641860676e-06,
      "loss": 0.0796,
      "step": 91830
    },
    {
      "epoch": 91.84,
      "learning_rate": 2.741947684993076e-06,
      "loss": 0.0919,
      "step": 91840
    },
    {
      "epoch": 91.85,
      "learning_rate": 2.7353066301574465e-06,
      "loss": 0.046,
      "step": 91850
    },
    {
      "epoch": 91.86,
      "learning_rate": 2.728673478080032e-06,
      "loss": 0.2095,
      "step": 91860
    },
    {
      "epoch": 91.87,
      "learning_rate": 2.7220482294862345e-06,
      "loss": 0.2335,
      "step": 91870
    },
    {
      "epoch": 91.88,
      "learning_rate": 2.7154308851005585e-06,
      "loss": 0.1961,
      "step": 91880
    },
    {
      "epoch": 91.89,
      "learning_rate": 2.7088214456467e-06,
      "loss": 0.1008,
      "step": 91890
    },
    {
      "epoch": 91.9,
      "learning_rate": 2.7022199118474226e-06,
      "loss": 0.1035,
      "step": 91900
    },
    {
      "epoch": 91.91,
      "learning_rate": 2.6956262844246982e-06,
      "loss": 0.2103,
      "step": 91910
    },
    {
      "epoch": 91.92,
      "learning_rate": 2.689040564099559e-06,
      "loss": 0.18,
      "step": 91920
    },
    {
      "epoch": 91.93,
      "learning_rate": 2.682462751592229e-06,
      "loss": 0.087,
      "step": 91930
    },
    {
      "epoch": 91.94,
      "learning_rate": 2.6758928476220407e-06,
      "loss": 0.2521,
      "step": 91940
    },
    {
      "epoch": 91.95,
      "learning_rate": 2.6693308529074862e-06,
      "loss": 0.0834,
      "step": 91950
    },
    {
      "epoch": 91.96,
      "learning_rate": 2.66277676816615e-06,
      "loss": 0.1746,
      "step": 91960
    },
    {
      "epoch": 91.97,
      "learning_rate": 2.6562305941147915e-06,
      "loss": 0.1921,
      "step": 91970
    },
    {
      "epoch": 91.98,
      "learning_rate": 2.649692331469297e-06,
      "loss": 0.0609,
      "step": 91980
    },
    {
      "epoch": 91.99,
      "learning_rate": 2.643161980944661e-06,
      "loss": 0.2845,
      "step": 91990
    },
    {
      "epoch": 92.0,
      "learning_rate": 2.6366395432550538e-06,
      "loss": 0.1438,
      "step": 92000
    },
    {
      "epoch": 92.0,
      "eval_accuracy": 0.798,
      "eval_loss": 0.6903653144836426,
      "eval_runtime": 14.8003,
      "eval_samples_per_second": 135.133,
      "eval_steps_per_second": 16.892,
      "step": 92000
    },
    {
      "epoch": 92.01,
      "learning_rate": 2.630125019113738e-06,
      "loss": 0.0809,
      "step": 92010
    },
    {
      "epoch": 92.02,
      "learning_rate": 2.6236184092331525e-06,
      "loss": 0.225,
      "step": 92020
    },
    {
      "epoch": 92.03,
      "learning_rate": 2.6171197143248363e-06,
      "loss": 0.046,
      "step": 92030
    },
    {
      "epoch": 92.04,
      "learning_rate": 2.6106289350994875e-06,
      "loss": 0.1256,
      "step": 92040
    },
    {
      "epoch": 92.05,
      "learning_rate": 2.6041460722669217e-06,
      "loss": 0.2012,
      "step": 92050
    },
    {
      "epoch": 92.06,
      "learning_rate": 2.5976711265360967e-06,
      "loss": 0.1128,
      "step": 92060
    },
    {
      "epoch": 92.07,
      "learning_rate": 2.591204098615088e-06,
      "loss": 0.2698,
      "step": 92070
    },
    {
      "epoch": 92.08,
      "learning_rate": 2.584744989211146e-06,
      "loss": 0.189,
      "step": 92080
    },
    {
      "epoch": 92.09,
      "learning_rate": 2.5782937990306147e-06,
      "loss": 0.0955,
      "step": 92090
    },
    {
      "epoch": 92.1,
      "learning_rate": 2.571850528778996e-06,
      "loss": 0.1864,
      "step": 92100
    },
    {
      "epoch": 92.11,
      "learning_rate": 2.5654151791609013e-06,
      "loss": 0.26,
      "step": 92110
    },
    {
      "epoch": 92.12,
      "learning_rate": 2.5589877508801094e-06,
      "loss": 0.0975,
      "step": 92120
    },
    {
      "epoch": 92.13,
      "learning_rate": 2.552568244639483e-06,
      "loss": 0.181,
      "step": 92130
    },
    {
      "epoch": 92.14,
      "learning_rate": 2.5461566611410938e-06,
      "loss": 0.1161,
      "step": 92140
    },
    {
      "epoch": 92.15,
      "learning_rate": 2.5397530010860644e-06,
      "loss": 0.1338,
      "step": 92150
    },
    {
      "epoch": 92.16,
      "learning_rate": 2.53335726517471e-06,
      "loss": 0.1262,
      "step": 92160
    },
    {
      "epoch": 92.17,
      "learning_rate": 2.5269694541064535e-06,
      "loss": 0.2231,
      "step": 92170
    },
    {
      "epoch": 92.18,
      "learning_rate": 2.5205895685798533e-06,
      "loss": 0.1435,
      "step": 92180
    },
    {
      "epoch": 92.19,
      "learning_rate": 2.51421760929261e-06,
      "loss": 0.0905,
      "step": 92190
    },
    {
      "epoch": 92.2,
      "learning_rate": 2.50785357694154e-06,
      "loss": 0.0973,
      "step": 92200
    },
    {
      "epoch": 92.21,
      "learning_rate": 2.5014974722226217e-06,
      "loss": 0.1326,
      "step": 92210
    },
    {
      "epoch": 92.22,
      "learning_rate": 2.495149295830931e-06,
      "loss": 0.2164,
      "step": 92220
    },
    {
      "epoch": 92.23,
      "learning_rate": 2.488809048460713e-06,
      "loss": 0.3421,
      "step": 92230
    },
    {
      "epoch": 92.24,
      "learning_rate": 2.4824767308053132e-06,
      "loss": 0.2452,
      "step": 92240
    },
    {
      "epoch": 92.25,
      "learning_rate": 2.476152343557236e-06,
      "loss": 0.1957,
      "step": 92250
    },
    {
      "epoch": 92.26,
      "learning_rate": 2.4698358874080864e-06,
      "loss": 0.1765,
      "step": 92260
    },
    {
      "epoch": 92.27,
      "learning_rate": 2.4635273630486536e-06,
      "loss": 0.2103,
      "step": 92270
    },
    {
      "epoch": 92.28,
      "learning_rate": 2.457226771168802e-06,
      "loss": 0.274,
      "step": 92280
    },
    {
      "epoch": 92.29,
      "learning_rate": 2.4509341124575725e-06,
      "loss": 0.0098,
      "step": 92290
    },
    {
      "epoch": 92.3,
      "learning_rate": 2.444649387603098e-06,
      "loss": 0.251,
      "step": 92300
    },
    {
      "epoch": 92.31,
      "learning_rate": 2.4383725972926955e-06,
      "loss": 0.1197,
      "step": 92310
    },
    {
      "epoch": 92.32,
      "learning_rate": 2.432103742212757e-06,
      "loss": 0.272,
      "step": 92320
    },
    {
      "epoch": 92.33,
      "learning_rate": 2.4258428230488596e-06,
      "loss": 0.18,
      "step": 92330
    },
    {
      "epoch": 92.34,
      "learning_rate": 2.4195898404856723e-06,
      "loss": 0.1895,
      "step": 92340
    },
    {
      "epoch": 92.35,
      "learning_rate": 2.413344795207031e-06,
      "loss": 0.1409,
      "step": 92350
    },
    {
      "epoch": 92.36,
      "learning_rate": 2.4071076878958566e-06,
      "loss": 0.1604,
      "step": 92360
    },
    {
      "epoch": 92.37,
      "learning_rate": 2.400878519234245e-06,
      "loss": 0.2657,
      "step": 92370
    },
    {
      "epoch": 92.38,
      "learning_rate": 2.3946572899034094e-06,
      "loss": 0.2281,
      "step": 92380
    },
    {
      "epoch": 92.39,
      "learning_rate": 2.388444000583689e-06,
      "loss": 0.1241,
      "step": 92390
    },
    {
      "epoch": 92.4,
      "learning_rate": 2.3822386519545574e-06,
      "loss": 0.1338,
      "step": 92400
    },
    {
      "epoch": 92.41,
      "learning_rate": 2.3760412446946457e-06,
      "loss": 0.176,
      "step": 92410
    },
    {
      "epoch": 92.42,
      "learning_rate": 2.369851779481663e-06,
      "loss": 0.1172,
      "step": 92420
    },
    {
      "epoch": 92.43,
      "learning_rate": 2.363670256992492e-06,
      "loss": 0.1669,
      "step": 92430
    },
    {
      "epoch": 92.44,
      "learning_rate": 2.3574966779031425e-06,
      "loss": 0.2263,
      "step": 92440
    },
    {
      "epoch": 92.45,
      "learning_rate": 2.351331042888724e-06,
      "loss": 0.1685,
      "step": 92450
    },
    {
      "epoch": 92.46,
      "learning_rate": 2.345173352623522e-06,
      "loss": 0.1635,
      "step": 92460
    },
    {
      "epoch": 92.47,
      "learning_rate": 2.339023607780932e-06,
      "loss": 0.1827,
      "step": 92470
    },
    {
      "epoch": 92.48,
      "learning_rate": 2.332881809033482e-06,
      "loss": 0.2264,
      "step": 92480
    },
    {
      "epoch": 92.49,
      "learning_rate": 2.3267479570528188e-06,
      "loss": 0.1672,
      "step": 92490
    },
    {
      "epoch": 92.5,
      "learning_rate": 2.320622052509738e-06,
      "loss": 0.063,
      "step": 92500
    },
    {
      "epoch": 92.51,
      "learning_rate": 2.3145040960741464e-06,
      "loss": 0.2362,
      "step": 92510
    },
    {
      "epoch": 92.52,
      "learning_rate": 2.3083940884151164e-06,
      "loss": 0.1648,
      "step": 92520
    },
    {
      "epoch": 92.53,
      "learning_rate": 2.302292030200814e-06,
      "loss": 0.2366,
      "step": 92530
    },
    {
      "epoch": 92.54,
      "learning_rate": 2.2961979220985637e-06,
      "loss": 0.2329,
      "step": 92540
    },
    {
      "epoch": 92.55,
      "learning_rate": 2.2901117647747906e-06,
      "loss": 0.0766,
      "step": 92550
    },
    {
      "epoch": 92.56,
      "learning_rate": 2.2840335588950877e-06,
      "loss": 0.0923,
      "step": 92560
    },
    {
      "epoch": 92.57,
      "learning_rate": 2.2779633051241393e-06,
      "loss": 0.2138,
      "step": 92570
    },
    {
      "epoch": 92.58,
      "learning_rate": 2.2719010041257895e-06,
      "loss": 0.0132,
      "step": 92580
    },
    {
      "epoch": 92.59,
      "learning_rate": 2.265846656563e-06,
      "loss": 0.0839,
      "step": 92590
    },
    {
      "epoch": 92.6,
      "learning_rate": 2.2598002630978744e-06,
      "loss": 0.0751,
      "step": 92600
    },
    {
      "epoch": 92.61,
      "learning_rate": 2.253761824391617e-06,
      "loss": 0.0227,
      "step": 92610
    },
    {
      "epoch": 92.62,
      "learning_rate": 2.2477313411046083e-06,
      "loss": 0.0577,
      "step": 92620
    },
    {
      "epoch": 92.63,
      "learning_rate": 2.2417088138963033e-06,
      "loss": 0.0827,
      "step": 92630
    },
    {
      "epoch": 92.64,
      "learning_rate": 2.2356942434253427e-06,
      "loss": 0.2112,
      "step": 92640
    },
    {
      "epoch": 92.65,
      "learning_rate": 2.22968763034945e-06,
      "loss": 0.1999,
      "step": 92650
    },
    {
      "epoch": 92.66,
      "learning_rate": 2.2236889753255244e-06,
      "loss": 0.1156,
      "step": 92660
    },
    {
      "epoch": 92.67,
      "learning_rate": 2.2176982790095416e-06,
      "loss": 0.2647,
      "step": 92670
    },
    {
      "epoch": 92.68,
      "learning_rate": 2.211715542056644e-06,
      "loss": 0.159,
      "step": 92680
    },
    {
      "epoch": 92.69,
      "learning_rate": 2.2057407651211167e-06,
      "loss": 0.1673,
      "step": 92690
    },
    {
      "epoch": 92.7,
      "learning_rate": 2.1997739488563203e-06,
      "loss": 0.215,
      "step": 92700
    },
    {
      "epoch": 92.71,
      "learning_rate": 2.1938150939148e-06,
      "loss": 0.0614,
      "step": 92710
    },
    {
      "epoch": 92.72,
      "learning_rate": 2.1878642009481915e-06,
      "loss": 0.1314,
      "step": 92720
    },
    {
      "epoch": 92.73,
      "learning_rate": 2.182515205304691e-06,
      "loss": 0.2629,
      "step": 92730
    },
    {
      "epoch": 92.74,
      "learning_rate": 2.176579441882617e-06,
      "loss": 0.0594,
      "step": 92740
    },
    {
      "epoch": 92.75,
      "learning_rate": 2.170651642320323e-06,
      "loss": 0.1377,
      "step": 92750
    },
    {
      "epoch": 92.76,
      "learning_rate": 2.1647318072660735e-06,
      "loss": 0.1171,
      "step": 92760
    },
    {
      "epoch": 92.77,
      "learning_rate": 2.1588199373672428e-06,
      "loss": 0.285,
      "step": 92770
    },
    {
      "epoch": 92.78,
      "learning_rate": 2.1529160332703464e-06,
      "loss": 0.4084,
      "step": 92780
    },
    {
      "epoch": 92.79,
      "learning_rate": 2.147020095621027e-06,
      "loss": 0.2296,
      "step": 92790
    },
    {
      "epoch": 92.8,
      "learning_rate": 2.14113212506406e-06,
      "loss": 0.2189,
      "step": 92800
    },
    {
      "epoch": 92.81,
      "learning_rate": 2.1352521222433474e-06,
      "loss": 0.3303,
      "step": 92810
    },
    {
      "epoch": 92.82,
      "learning_rate": 2.1293800878019075e-06,
      "loss": 0.1401,
      "step": 92820
    },
    {
      "epoch": 92.83,
      "learning_rate": 2.123516022381902e-06,
      "loss": 0.1954,
      "step": 92830
    },
    {
      "epoch": 92.84,
      "learning_rate": 2.11765992662461e-06,
      "loss": 0.1195,
      "step": 92840
    },
    {
      "epoch": 92.85,
      "learning_rate": 2.11181180117046e-06,
      "loss": 0.1376,
      "step": 92850
    },
    {
      "epoch": 92.86,
      "learning_rate": 2.105971646658983e-06,
      "loss": 0.1409,
      "step": 92860
    },
    {
      "epoch": 92.87,
      "learning_rate": 2.1001394637288504e-06,
      "loss": 0.0506,
      "step": 92870
    },
    {
      "epoch": 92.88,
      "learning_rate": 2.0943152530178696e-06,
      "loss": 0.1912,
      "step": 92880
    },
    {
      "epoch": 92.89,
      "learning_rate": 2.088499015162956e-06,
      "loss": 0.1973,
      "step": 92890
    },
    {
      "epoch": 92.9,
      "learning_rate": 2.082690750800167e-06,
      "loss": 0.1254,
      "step": 92900
    },
    {
      "epoch": 92.91,
      "learning_rate": 2.076890460564687e-06,
      "loss": 0.0657,
      "step": 92910
    },
    {
      "epoch": 92.92,
      "learning_rate": 2.0710981450908327e-06,
      "loss": 0.1957,
      "step": 92920
    },
    {
      "epoch": 92.93,
      "learning_rate": 2.0653138050120392e-06,
      "loss": 0.1381,
      "step": 92930
    },
    {
      "epoch": 92.94,
      "learning_rate": 2.0595374409608676e-06,
      "loss": 0.3207,
      "step": 92940
    },
    {
      "epoch": 92.95,
      "learning_rate": 2.053769053569021e-06,
      "loss": 0.2364,
      "step": 92950
    },
    {
      "epoch": 92.96,
      "learning_rate": 2.048008643467311e-06,
      "loss": 0.2417,
      "step": 92960
    },
    {
      "epoch": 92.97,
      "learning_rate": 2.0422562112857004e-06,
      "loss": 0.0888,
      "step": 92970
    },
    {
      "epoch": 92.98,
      "learning_rate": 2.036511757653253e-06,
      "loss": 0.2678,
      "step": 92980
    },
    {
      "epoch": 92.99,
      "learning_rate": 2.0307752831981912e-06,
      "loss": 0.0733,
      "step": 92990
    },
    {
      "epoch": 93.0,
      "learning_rate": 2.0250467885478296e-06,
      "loss": 0.2157,
      "step": 93000
    },
    {
      "epoch": 93.0,
      "eval_accuracy": 0.798,
      "eval_loss": 0.7027524709701538,
      "eval_runtime": 14.504,
      "eval_samples_per_second": 137.893,
      "eval_steps_per_second": 17.237,
      "step": 93000
    },
    {
      "epoch": 93.01,
      "learning_rate": 2.019326274328642e-06,
      "loss": 0.0929,
      "step": 93010
    },
    {
      "epoch": 93.02,
      "learning_rate": 2.0136137411662034e-06,
      "loss": 0.1319,
      "step": 93020
    },
    {
      "epoch": 93.03,
      "learning_rate": 2.0079091896852307e-06,
      "loss": 0.182,
      "step": 93030
    },
    {
      "epoch": 93.04,
      "learning_rate": 2.0022126205095662e-06,
      "loss": 0.2647,
      "step": 93040
    },
    {
      "epoch": 93.05,
      "learning_rate": 1.9965240342621868e-06,
      "loss": 0.4251,
      "step": 93050
    },
    {
      "epoch": 93.06,
      "learning_rate": 1.9908434315651782e-06,
      "loss": 0.2035,
      "step": 93060
    },
    {
      "epoch": 93.07,
      "learning_rate": 1.9851708130397605e-06,
      "loss": 0.291,
      "step": 93070
    },
    {
      "epoch": 93.08,
      "learning_rate": 1.9795061793062866e-06,
      "loss": 0.1282,
      "step": 93080
    },
    {
      "epoch": 93.09,
      "learning_rate": 1.9738495309842285e-06,
      "loss": 0.1902,
      "step": 93090
    },
    {
      "epoch": 93.1,
      "learning_rate": 1.968200868692199e-06,
      "loss": 0.2177,
      "step": 93100
    },
    {
      "epoch": 93.11,
      "learning_rate": 1.9625601930479213e-06,
      "loss": 0.2084,
      "step": 93110
    },
    {
      "epoch": 93.12,
      "learning_rate": 1.956927504668243e-06,
      "loss": 0.262,
      "step": 93120
    },
    {
      "epoch": 93.13,
      "learning_rate": 1.951302804169172e-06,
      "loss": 0.1363,
      "step": 93130
    },
    {
      "epoch": 93.14,
      "learning_rate": 1.9456860921657824e-06,
      "loss": 0.1286,
      "step": 93140
    },
    {
      "epoch": 93.15,
      "learning_rate": 1.9400773692723247e-06,
      "loss": 0.1637,
      "step": 93150
    },
    {
      "epoch": 93.16,
      "learning_rate": 1.934476636102167e-06,
      "loss": 0.1146,
      "step": 93160
    },
    {
      "epoch": 93.17,
      "learning_rate": 1.928883893267802e-06,
      "loss": 0.2259,
      "step": 93170
    },
    {
      "epoch": 93.18,
      "learning_rate": 1.923299141380816e-06,
      "loss": 0.0949,
      "step": 93180
    },
    {
      "epoch": 93.19,
      "learning_rate": 1.9177223810519782e-06,
      "loss": 0.1367,
      "step": 93190
    },
    {
      "epoch": 93.2,
      "learning_rate": 1.912153612891143e-06,
      "loss": 0.1686,
      "step": 93200
    },
    {
      "epoch": 93.21,
      "learning_rate": 1.906592837507298e-06,
      "loss": 0.1663,
      "step": 93210
    },
    {
      "epoch": 93.22,
      "learning_rate": 1.9010400555085654e-06,
      "loss": 0.0777,
      "step": 93220
    },
    {
      "epoch": 93.23,
      "learning_rate": 1.8954952675021923e-06,
      "loss": 0.1406,
      "step": 93230
    },
    {
      "epoch": 93.24,
      "learning_rate": 1.889958474094544e-06,
      "loss": 0.3309,
      "step": 93240
    },
    {
      "epoch": 93.25,
      "learning_rate": 1.8844296758911192e-06,
      "loss": 0.0375,
      "step": 93250
    },
    {
      "epoch": 93.26,
      "learning_rate": 1.878908873496543e-06,
      "loss": 0.1557,
      "step": 93260
    },
    {
      "epoch": 93.27,
      "learning_rate": 1.8733960675145488e-06,
      "loss": 0.18,
      "step": 93270
    },
    {
      "epoch": 93.28,
      "learning_rate": 1.867891258548021e-06,
      "loss": 0.1177,
      "step": 93280
    },
    {
      "epoch": 93.29,
      "learning_rate": 1.862394447198945e-06,
      "loss": 0.1275,
      "step": 93290
    },
    {
      "epoch": 93.3,
      "learning_rate": 1.8569056340684562e-06,
      "loss": 0.1018,
      "step": 93300
    },
    {
      "epoch": 93.31,
      "learning_rate": 1.8514248197568e-06,
      "loss": 0.2252,
      "step": 93310
    },
    {
      "epoch": 93.32,
      "learning_rate": 1.8459520048633548e-06,
      "loss": 0.246,
      "step": 93320
    },
    {
      "epoch": 93.33,
      "learning_rate": 1.8404871899866003e-06,
      "loss": 0.1785,
      "step": 93330
    },
    {
      "epoch": 93.34,
      "learning_rate": 1.8350303757241835e-06,
      "loss": 0.2003,
      "step": 93340
    },
    {
      "epoch": 93.35,
      "learning_rate": 1.8295815626728271e-06,
      "loss": 0.1175,
      "step": 93350
    },
    {
      "epoch": 93.36,
      "learning_rate": 1.8241407514284379e-06,
      "loss": 0.2351,
      "step": 93360
    },
    {
      "epoch": 93.37,
      "learning_rate": 1.8187079425859895e-06,
      "loss": 0.1368,
      "step": 93370
    },
    {
      "epoch": 93.38,
      "learning_rate": 1.8132831367396155e-06,
      "loss": 0.3928,
      "step": 93380
    },
    {
      "epoch": 93.39,
      "learning_rate": 1.807866334482566e-06,
      "loss": 0.1211,
      "step": 93390
    },
    {
      "epoch": 93.4,
      "learning_rate": 1.8024575364072007e-06,
      "loss": 0.1918,
      "step": 93400
    },
    {
      "epoch": 93.41,
      "learning_rate": 1.797056743105038e-06,
      "loss": 0.1346,
      "step": 93410
    },
    {
      "epoch": 93.42,
      "learning_rate": 1.7916639551666973e-06,
      "loss": 0.0831,
      "step": 93420
    },
    {
      "epoch": 93.43,
      "learning_rate": 1.7862791731819066e-06,
      "loss": 0.2277,
      "step": 93430
    },
    {
      "epoch": 93.44,
      "learning_rate": 1.780902397739553e-06,
      "loss": 0.1287,
      "step": 93440
    },
    {
      "epoch": 93.45,
      "learning_rate": 1.7755336294276334e-06,
      "loss": 0.2026,
      "step": 93450
    },
    {
      "epoch": 93.46,
      "learning_rate": 1.770172868833261e-06,
      "loss": 0.2179,
      "step": 93460
    },
    {
      "epoch": 93.47,
      "learning_rate": 1.7648201165426923e-06,
      "loss": 0.0178,
      "step": 93470
    },
    {
      "epoch": 93.48,
      "learning_rate": 1.7594753731412753e-06,
      "loss": 0.2498,
      "step": 93480
    },
    {
      "epoch": 93.49,
      "learning_rate": 1.754138639213526e-06,
      "loss": 0.1589,
      "step": 93490
    },
    {
      "epoch": 93.5,
      "learning_rate": 1.748809915343044e-06,
      "loss": 0.0464,
      "step": 93500
    },
    {
      "epoch": 93.51,
      "learning_rate": 1.7434892021125884e-06,
      "loss": 0.0568,
      "step": 93510
    },
    {
      "epoch": 93.52,
      "learning_rate": 1.7381765001040104e-06,
      "loss": 0.1606,
      "step": 93520
    },
    {
      "epoch": 93.53,
      "learning_rate": 1.7328718098983035e-06,
      "loss": 0.0729,
      "step": 93530
    },
    {
      "epoch": 93.54,
      "learning_rate": 1.7275751320755704e-06,
      "loss": 0.0656,
      "step": 93540
    },
    {
      "epoch": 93.55,
      "learning_rate": 1.7222864672150644e-06,
      "loss": 0.1737,
      "step": 93550
    },
    {
      "epoch": 93.56,
      "learning_rate": 1.7170058158951394e-06,
      "loss": 0.1188,
      "step": 93560
    },
    {
      "epoch": 93.57,
      "learning_rate": 1.7117331786932837e-06,
      "loss": 0.1759,
      "step": 93570
    },
    {
      "epoch": 93.58,
      "learning_rate": 1.7064685561860942e-06,
      "loss": 0.307,
      "step": 93580
    },
    {
      "epoch": 93.59,
      "learning_rate": 1.7012119489493103e-06,
      "loss": 0.131,
      "step": 93590
    },
    {
      "epoch": 93.6,
      "learning_rate": 1.6959633575577808e-06,
      "loss": 0.0763,
      "step": 93600
    },
    {
      "epoch": 93.61,
      "learning_rate": 1.690722782585488e-06,
      "loss": 0.0943,
      "step": 93610
    },
    {
      "epoch": 93.62,
      "learning_rate": 1.6854902246055402e-06,
      "loss": 0.1232,
      "step": 93620
    },
    {
      "epoch": 93.63,
      "learning_rate": 1.6802656841901545e-06,
      "loss": 0.1713,
      "step": 93630
    },
    {
      "epoch": 93.64,
      "learning_rate": 1.6750491619106659e-06,
      "loss": 0.1721,
      "step": 93640
    },
    {
      "epoch": 93.65,
      "learning_rate": 1.6698406583375678e-06,
      "loss": 0.2798,
      "step": 93650
    },
    {
      "epoch": 93.66,
      "learning_rate": 1.6646401740404464e-06,
      "loss": 0.1666,
      "step": 93660
    },
    {
      "epoch": 93.67,
      "learning_rate": 1.6594477095880131e-06,
      "loss": 0.3259,
      "step": 93670
    },
    {
      "epoch": 93.68,
      "learning_rate": 1.6542632655481142e-06,
      "loss": 0.2307,
      "step": 93680
    },
    {
      "epoch": 93.69,
      "learning_rate": 1.6490868424877124e-06,
      "loss": 0.1623,
      "step": 93690
    },
    {
      "epoch": 93.7,
      "learning_rate": 1.6439184409728883e-06,
      "loss": 0.1886,
      "step": 93700
    },
    {
      "epoch": 93.71,
      "learning_rate": 1.6387580615688566e-06,
      "loss": 0.3019,
      "step": 93710
    },
    {
      "epoch": 93.72,
      "learning_rate": 1.6336057048399493e-06,
      "loss": 0.1512,
      "step": 93720
    },
    {
      "epoch": 93.73,
      "learning_rate": 1.628461371349607e-06,
      "loss": 0.2094,
      "step": 93730
    },
    {
      "epoch": 93.74,
      "learning_rate": 1.6233250616604298e-06,
      "loss": 0.2088,
      "step": 93740
    },
    {
      "epoch": 93.75,
      "learning_rate": 1.6181967763340937e-06,
      "loss": 0.0479,
      "step": 93750
    },
    {
      "epoch": 93.76,
      "learning_rate": 1.6130765159314414e-06,
      "loss": 0.11,
      "step": 93760
    },
    {
      "epoch": 93.77,
      "learning_rate": 1.6079642810124e-06,
      "loss": 0.0175,
      "step": 93770
    },
    {
      "epoch": 93.78,
      "learning_rate": 1.6028600721360391e-06,
      "loss": 0.1275,
      "step": 93780
    },
    {
      "epoch": 93.79,
      "learning_rate": 1.5977638898605539e-06,
      "loss": 0.1612,
      "step": 93790
    },
    {
      "epoch": 93.8,
      "learning_rate": 1.5926757347432484e-06,
      "loss": 0.1432,
      "step": 93800
    },
    {
      "epoch": 93.81,
      "learning_rate": 1.5875956073405527e-06,
      "loss": 0.178,
      "step": 93810
    },
    {
      "epoch": 93.82,
      "learning_rate": 1.582523508208039e-06,
      "loss": 0.3218,
      "step": 93820
    },
    {
      "epoch": 93.83,
      "learning_rate": 1.5774594379003635e-06,
      "loss": 0.1378,
      "step": 93830
    },
    {
      "epoch": 93.84,
      "learning_rate": 1.5724033969713418e-06,
      "loss": 0.1275,
      "step": 93840
    },
    {
      "epoch": 93.85,
      "learning_rate": 1.5673553859738813e-06,
      "loss": 0.2127,
      "step": 93850
    },
    {
      "epoch": 93.86,
      "learning_rate": 1.5623154054600322e-06,
      "loss": 0.0842,
      "step": 93860
    },
    {
      "epoch": 93.87,
      "learning_rate": 1.5572834559809621e-06,
      "loss": 0.1304,
      "step": 93870
    },
    {
      "epoch": 93.88,
      "learning_rate": 1.5522595380869557e-06,
      "loss": 0.2713,
      "step": 93880
    },
    {
      "epoch": 93.89,
      "learning_rate": 1.547243652327415e-06,
      "loss": 0.1788,
      "step": 93890
    },
    {
      "epoch": 93.9,
      "learning_rate": 1.5422357992508683e-06,
      "loss": 0.1229,
      "step": 93900
    },
    {
      "epoch": 93.91,
      "learning_rate": 1.5372359794049853e-06,
      "loss": 0.1276,
      "step": 93910
    },
    {
      "epoch": 93.92,
      "learning_rate": 1.532244193336521e-06,
      "loss": 0.3269,
      "step": 93920
    },
    {
      "epoch": 93.93,
      "learning_rate": 1.5272604415913714e-06,
      "loss": 0.3234,
      "step": 93930
    },
    {
      "epoch": 93.94,
      "learning_rate": 1.522284724714551e-06,
      "loss": 0.0578,
      "step": 93940
    },
    {
      "epoch": 93.95,
      "learning_rate": 1.5173170432502158e-06,
      "loss": 0.0838,
      "step": 93950
    },
    {
      "epoch": 93.96,
      "learning_rate": 1.5123573977415982e-06,
      "loss": 0.0134,
      "step": 93960
    },
    {
      "epoch": 93.97,
      "learning_rate": 1.5074057887310892e-06,
      "loss": 0.1939,
      "step": 93970
    },
    {
      "epoch": 93.98,
      "learning_rate": 1.5024622167601892e-06,
      "loss": 0.0803,
      "step": 93980
    },
    {
      "epoch": 93.99,
      "learning_rate": 1.4975266823695152e-06,
      "loss": 0.1686,
      "step": 93990
    },
    {
      "epoch": 94.0,
      "learning_rate": 1.4925991860988197e-06,
      "loss": 0.0743,
      "step": 94000
    },
    {
      "epoch": 94.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.7047796845436096,
      "eval_runtime": 15.1516,
      "eval_samples_per_second": 131.999,
      "eval_steps_per_second": 16.5,
      "step": 94000
    },
    {
      "epoch": 94.01,
      "learning_rate": 1.4876797284869623e-06,
      "loss": 0.1601,
      "step": 94010
    },
    {
      "epoch": 94.02,
      "learning_rate": 1.4827683100719218e-06,
      "loss": 0.1669,
      "step": 94020
    },
    {
      "epoch": 94.03,
      "learning_rate": 1.477864931390818e-06,
      "loss": 0.2156,
      "step": 94030
    },
    {
      "epoch": 94.04,
      "learning_rate": 1.4729695929798557e-06,
      "loss": 0.0556,
      "step": 94040
    },
    {
      "epoch": 94.05,
      "learning_rate": 1.4680822953743898e-06,
      "loss": 0.1135,
      "step": 94050
    },
    {
      "epoch": 94.06,
      "learning_rate": 1.4632030391088928e-06,
      "loss": 0.1333,
      "step": 94060
    },
    {
      "epoch": 94.07,
      "learning_rate": 1.4583318247169546e-06,
      "loss": 0.3077,
      "step": 94070
    },
    {
      "epoch": 94.08,
      "learning_rate": 1.453468652731274e-06,
      "loss": 0.2506,
      "step": 94080
    },
    {
      "epoch": 94.09,
      "learning_rate": 1.4486135236837005e-06,
      "loss": 0.1544,
      "step": 94090
    },
    {
      "epoch": 94.1,
      "learning_rate": 1.4437664381051512e-06,
      "loss": 0.1509,
      "step": 94100
    },
    {
      "epoch": 94.11,
      "learning_rate": 1.4389273965257186e-06,
      "loss": 0.1961,
      "step": 94110
    },
    {
      "epoch": 94.12,
      "learning_rate": 1.434096399474588e-06,
      "loss": 0.1638,
      "step": 94120
    },
    {
      "epoch": 94.13,
      "learning_rate": 1.4292734474800783e-06,
      "loss": 0.2847,
      "step": 94130
    },
    {
      "epoch": 94.14,
      "learning_rate": 1.424458541069609e-06,
      "loss": 0.0891,
      "step": 94140
    },
    {
      "epoch": 94.15,
      "learning_rate": 1.4196516807697261e-06,
      "loss": 0.1262,
      "step": 94150
    },
    {
      "epoch": 94.16,
      "learning_rate": 1.4148528671061254e-06,
      "loss": 0.1902,
      "step": 94160
    },
    {
      "epoch": 94.17,
      "learning_rate": 1.4100621006035707e-06,
      "loss": 0.1635,
      "step": 94170
    },
    {
      "epoch": 94.18,
      "learning_rate": 1.4052793817859843e-06,
      "loss": 0.1753,
      "step": 94180
    },
    {
      "epoch": 94.19,
      "learning_rate": 1.4005047111763895e-06,
      "loss": 0.1673,
      "step": 94190
    },
    {
      "epoch": 94.2,
      "learning_rate": 1.3957380892969605e-06,
      "loss": 0.2424,
      "step": 94200
    },
    {
      "epoch": 94.21,
      "learning_rate": 1.3909795166689387e-06,
      "loss": 0.1618,
      "step": 94210
    },
    {
      "epoch": 94.22,
      "learning_rate": 1.3862289938127408e-06,
      "loss": 0.084,
      "step": 94220
    },
    {
      "epoch": 94.23,
      "learning_rate": 1.3814865212478515e-06,
      "loss": 0.1908,
      "step": 94230
    },
    {
      "epoch": 94.24,
      "learning_rate": 1.3767520994929144e-06,
      "loss": 0.223,
      "step": 94240
    },
    {
      "epoch": 94.25,
      "learning_rate": 1.3720257290656732e-06,
      "loss": 0.2928,
      "step": 94250
    },
    {
      "epoch": 94.26,
      "learning_rate": 1.367307410483015e-06,
      "loss": 0.2885,
      "step": 94260
    },
    {
      "epoch": 94.27,
      "learning_rate": 1.362597144260902e-06,
      "loss": 0.1579,
      "step": 94270
    },
    {
      "epoch": 94.28,
      "learning_rate": 1.3578949309144548e-06,
      "loss": 0.0532,
      "step": 94280
    },
    {
      "epoch": 94.29,
      "learning_rate": 1.3532007709578963e-06,
      "loss": 0.1433,
      "step": 94290
    },
    {
      "epoch": 94.3,
      "learning_rate": 1.3485146649045735e-06,
      "loss": 0.3404,
      "step": 94300
    },
    {
      "epoch": 94.31,
      "learning_rate": 1.3438366132669603e-06,
      "loss": 0.192,
      "step": 94310
    },
    {
      "epoch": 94.32,
      "learning_rate": 1.3391666165566305e-06,
      "loss": 0.0807,
      "step": 94320
    },
    {
      "epoch": 94.33,
      "learning_rate": 1.3345046752842924e-06,
      "loss": 0.1305,
      "step": 94330
    },
    {
      "epoch": 94.34,
      "learning_rate": 1.3298507899597799e-06,
      "loss": 0.2733,
      "step": 94340
    },
    {
      "epoch": 94.35,
      "learning_rate": 1.3252049610920108e-06,
      "loss": 0.102,
      "step": 94350
    },
    {
      "epoch": 94.36,
      "learning_rate": 1.3205671891890535e-06,
      "loss": 0.0904,
      "step": 94360
    },
    {
      "epoch": 94.37,
      "learning_rate": 1.3159374747581025e-06,
      "loss": 0.2555,
      "step": 94370
    },
    {
      "epoch": 94.38,
      "learning_rate": 1.3113158183054528e-06,
      "loss": 0.2,
      "step": 94380
    },
    {
      "epoch": 94.39,
      "learning_rate": 1.3067022203365003e-06,
      "loss": 0.1043,
      "step": 94390
    },
    {
      "epoch": 94.4,
      "learning_rate": 1.3020966813558075e-06,
      "loss": 0.0953,
      "step": 94400
    },
    {
      "epoch": 94.41,
      "learning_rate": 1.2974992018670221e-06,
      "loss": 0.1064,
      "step": 94410
    },
    {
      "epoch": 94.42,
      "learning_rate": 1.2929097823729002e-06,
      "loss": 0.2744,
      "step": 94420
    },
    {
      "epoch": 94.43,
      "learning_rate": 1.2883284233753566e-06,
      "loss": 0.224,
      "step": 94430
    },
    {
      "epoch": 94.44,
      "learning_rate": 1.2837551253753909e-06,
      "loss": 0.0693,
      "step": 94440
    },
    {
      "epoch": 94.45,
      "learning_rate": 1.279189888873136e-06,
      "loss": 0.1524,
      "step": 94450
    },
    {
      "epoch": 94.46,
      "learning_rate": 1.2746327143678348e-06,
      "loss": 0.0906,
      "step": 94460
    },
    {
      "epoch": 94.47,
      "learning_rate": 1.270083602357863e-06,
      "loss": 0.1579,
      "step": 94470
    },
    {
      "epoch": 94.48,
      "learning_rate": 1.2655425533406816e-06,
      "loss": 0.2094,
      "step": 94480
    },
    {
      "epoch": 94.49,
      "learning_rate": 1.2610095678129263e-06,
      "loss": 0.2064,
      "step": 94490
    },
    {
      "epoch": 94.5,
      "learning_rate": 1.2564846462702837e-06,
      "loss": 0.1747,
      "step": 94500
    },
    {
      "epoch": 94.51,
      "learning_rate": 1.2519677892076169e-06,
      "loss": 0.1983,
      "step": 94510
    },
    {
      "epoch": 94.52,
      "learning_rate": 1.247458997118872e-06,
      "loss": 0.0688,
      "step": 94520
    },
    {
      "epoch": 94.53,
      "learning_rate": 1.2429582704971298e-06,
      "loss": 0.1707,
      "step": 94530
    },
    {
      "epoch": 94.54,
      "learning_rate": 1.2384656098345714e-06,
      "loss": 0.1848,
      "step": 94540
    },
    {
      "epoch": 94.55,
      "learning_rate": 1.2339810156225288e-06,
      "loss": 0.1178,
      "step": 94550
    },
    {
      "epoch": 94.56,
      "learning_rate": 1.2295044883514016e-06,
      "loss": 0.1322,
      "step": 94560
    },
    {
      "epoch": 94.57,
      "learning_rate": 1.2250360285107564e-06,
      "loss": 0.2421,
      "step": 94570
    },
    {
      "epoch": 94.58,
      "learning_rate": 1.2205756365892522e-06,
      "loss": 0.158,
      "step": 94580
    },
    {
      "epoch": 94.59,
      "learning_rate": 1.2161233130746739e-06,
      "loss": 0.1958,
      "step": 94590
    },
    {
      "epoch": 94.6,
      "learning_rate": 1.2116790584539155e-06,
      "loss": 0.1103,
      "step": 94600
    },
    {
      "epoch": 94.61,
      "learning_rate": 1.2072428732129962e-06,
      "loss": 0.3232,
      "step": 94610
    },
    {
      "epoch": 94.62,
      "learning_rate": 1.2028147578370452e-06,
      "loss": 0.0557,
      "step": 94620
    },
    {
      "epoch": 94.63,
      "learning_rate": 1.1983947128103244e-06,
      "loss": 0.208,
      "step": 94630
    },
    {
      "epoch": 94.64,
      "learning_rate": 1.193982738616206e-06,
      "loss": 0.0786,
      "step": 94640
    },
    {
      "epoch": 94.65,
      "learning_rate": 1.1895788357371622e-06,
      "loss": 0.05,
      "step": 94650
    },
    {
      "epoch": 94.66,
      "learning_rate": 1.1851830046548078e-06,
      "loss": 0.2652,
      "step": 94660
    },
    {
      "epoch": 94.67,
      "learning_rate": 1.1807952458498582e-06,
      "loss": 0.1436,
      "step": 94670
    },
    {
      "epoch": 94.68,
      "learning_rate": 1.1764155598021547e-06,
      "loss": 0.3117,
      "step": 94680
    },
    {
      "epoch": 94.69,
      "learning_rate": 1.1720439469906473e-06,
      "loss": 0.1411,
      "step": 94690
    },
    {
      "epoch": 94.7,
      "learning_rate": 1.1676804078934288e-06,
      "loss": 0.1183,
      "step": 94700
    },
    {
      "epoch": 94.71,
      "learning_rate": 1.1633249429876673e-06,
      "loss": 0.1615,
      "step": 94710
    },
    {
      "epoch": 94.72,
      "learning_rate": 1.158977552749682e-06,
      "loss": 0.0554,
      "step": 94720
    },
    {
      "epoch": 94.73,
      "learning_rate": 1.1546382376548924e-06,
      "loss": 0.2768,
      "step": 94730
    },
    {
      "epoch": 94.74,
      "learning_rate": 1.1503069981778356e-06,
      "loss": 0.0498,
      "step": 94740
    },
    {
      "epoch": 94.75,
      "learning_rate": 1.1459838347921746e-06,
      "loss": 0.312,
      "step": 94750
    },
    {
      "epoch": 94.76,
      "learning_rate": 1.1416687479706892e-06,
      "loss": 0.1385,
      "step": 94760
    },
    {
      "epoch": 94.77,
      "learning_rate": 1.1373617381852607e-06,
      "loss": 0.1596,
      "step": 94770
    },
    {
      "epoch": 94.78,
      "learning_rate": 1.1330628059069036e-06,
      "loss": 0.2491,
      "step": 94780
    },
    {
      "epoch": 94.79,
      "learning_rate": 1.128771951605742e-06,
      "loss": 0.0643,
      "step": 94790
    },
    {
      "epoch": 94.8,
      "learning_rate": 1.1244891757510171e-06,
      "loss": 0.1694,
      "step": 94800
    },
    {
      "epoch": 94.81,
      "learning_rate": 1.1202144788110795e-06,
      "loss": 0.1739,
      "step": 94810
    },
    {
      "epoch": 94.82,
      "learning_rate": 1.1159478612534135e-06,
      "loss": 0.14,
      "step": 94820
    },
    {
      "epoch": 94.83,
      "learning_rate": 1.1116893235446039e-06,
      "loss": 0.1267,
      "step": 94830
    },
    {
      "epoch": 94.84,
      "learning_rate": 1.1074388661503618e-06,
      "loss": 0.1985,
      "step": 94840
    },
    {
      "epoch": 94.85,
      "learning_rate": 1.1031964895355156e-06,
      "loss": 0.2392,
      "step": 94850
    },
    {
      "epoch": 94.86,
      "learning_rate": 1.0989621941639937e-06,
      "loss": 0.1453,
      "step": 94860
    },
    {
      "epoch": 94.87,
      "learning_rate": 1.0947359804988592e-06,
      "loss": 0.1492,
      "step": 94870
    },
    {
      "epoch": 94.88,
      "learning_rate": 1.0905178490022758e-06,
      "loss": 0.1677,
      "step": 94880
    },
    {
      "epoch": 94.89,
      "learning_rate": 1.0863078001355496e-06,
      "loss": 0.1133,
      "step": 94890
    },
    {
      "epoch": 94.9,
      "learning_rate": 1.0821058343590706e-06,
      "loss": 0.1656,
      "step": 94900
    },
    {
      "epoch": 94.91,
      "learning_rate": 1.077911952132371e-06,
      "loss": 0.2005,
      "step": 94910
    },
    {
      "epoch": 94.92,
      "learning_rate": 1.0737261539140674e-06,
      "loss": 0.1282,
      "step": 94920
    },
    {
      "epoch": 94.93,
      "learning_rate": 1.0695484401619354e-06,
      "loss": 0.2802,
      "step": 94930
    },
    {
      "epoch": 94.94,
      "learning_rate": 1.0653788113328176e-06,
      "loss": 0.0566,
      "step": 94940
    },
    {
      "epoch": 94.95,
      "learning_rate": 1.061217267882733e-06,
      "loss": 0.0625,
      "step": 94950
    },
    {
      "epoch": 94.96,
      "learning_rate": 1.0570638102667506e-06,
      "loss": 0.1212,
      "step": 94960
    },
    {
      "epoch": 94.97,
      "learning_rate": 1.052918438939107e-06,
      "loss": 0.0497,
      "step": 94970
    },
    {
      "epoch": 94.98,
      "learning_rate": 1.048781154353115e-06,
      "loss": 0.0963,
      "step": 94980
    },
    {
      "epoch": 94.99,
      "learning_rate": 1.0446519569612455e-06,
      "loss": 0.1741,
      "step": 94990
    },
    {
      "epoch": 95.0,
      "learning_rate": 1.0405308472150375e-06,
      "loss": 0.2417,
      "step": 95000
    },
    {
      "epoch": 95.0,
      "eval_accuracy": 0.8,
      "eval_loss": 0.7035161852836609,
      "eval_runtime": 15.1681,
      "eval_samples_per_second": 131.856,
      "eval_steps_per_second": 16.482,
      "step": 95000
    },
    {
      "epoch": 95.01,
      "learning_rate": 1.0364178255651805e-06,
      "loss": 0.0836,
      "step": 95010
    },
    {
      "epoch": 95.02,
      "learning_rate": 1.0323128924614648e-06,
      "loss": 0.1803,
      "step": 95020
    },
    {
      "epoch": 95.03,
      "learning_rate": 1.0282160483528063e-06,
      "loss": 0.1398,
      "step": 95030
    },
    {
      "epoch": 95.04,
      "learning_rate": 1.0241272936872297e-06,
      "loss": 0.0933,
      "step": 95040
    },
    {
      "epoch": 95.05,
      "learning_rate": 1.0200466289118607e-06,
      "loss": 0.1336,
      "step": 95050
    },
    {
      "epoch": 95.06,
      "learning_rate": 1.015974054472976e-06,
      "loss": 0.0871,
      "step": 95060
    },
    {
      "epoch": 95.07,
      "learning_rate": 1.0119095708159276e-06,
      "loss": 0.109,
      "step": 95070
    },
    {
      "epoch": 95.08,
      "learning_rate": 1.0078531783852178e-06,
      "loss": 0.12,
      "step": 95080
    },
    {
      "epoch": 95.09,
      "learning_rate": 1.0038048776244255e-06,
      "loss": 0.1262,
      "step": 95090
    },
    {
      "epoch": 95.1,
      "learning_rate": 9.997646689762966e-07,
      "loss": 0.1868,
      "step": 95100
    },
    {
      "epoch": 95.11,
      "learning_rate": 9.95732552882636e-07,
      "loss": 0.1176,
      "step": 95110
    },
    {
      "epoch": 95.12,
      "learning_rate": 9.91708529784399e-07,
      "loss": 0.0917,
      "step": 95120
    },
    {
      "epoch": 95.13,
      "learning_rate": 9.876926001216423e-07,
      "loss": 0.2888,
      "step": 95130
    },
    {
      "epoch": 95.14,
      "learning_rate": 9.836847643335643e-07,
      "loss": 0.0447,
      "step": 95140
    },
    {
      "epoch": 95.15,
      "learning_rate": 9.79685022858423e-07,
      "loss": 0.1026,
      "step": 95150
    },
    {
      "epoch": 95.16,
      "learning_rate": 9.756933761336516e-07,
      "loss": 0.2589,
      "step": 95160
    },
    {
      "epoch": 95.17,
      "learning_rate": 9.71709824595751e-07,
      "loss": 0.0925,
      "step": 95170
    },
    {
      "epoch": 95.18,
      "learning_rate": 9.677343686803646e-07,
      "loss": 0.1546,
      "step": 95180
    },
    {
      "epoch": 95.19,
      "learning_rate": 9.637670088222443e-07,
      "loss": 0.2837,
      "step": 95190
    },
    {
      "epoch": 95.2,
      "learning_rate": 9.598077454552516e-07,
      "loss": 0.1084,
      "step": 95200
    },
    {
      "epoch": 95.21,
      "learning_rate": 9.558565790123567e-07,
      "loss": 0.0566,
      "step": 95210
    },
    {
      "epoch": 95.22,
      "learning_rate": 9.519135099256808e-07,
      "loss": 0.1244,
      "step": 95220
    },
    {
      "epoch": 95.23,
      "learning_rate": 9.479785386263955e-07,
      "loss": 0.1259,
      "step": 95230
    },
    {
      "epoch": 95.24,
      "learning_rate": 9.440516655448566e-07,
      "loss": 0.1617,
      "step": 95240
    },
    {
      "epoch": 95.25,
      "learning_rate": 9.401328911104788e-07,
      "loss": 0.19,
      "step": 95250
    },
    {
      "epoch": 95.26,
      "learning_rate": 9.362222157518195e-07,
      "loss": 0.0539,
      "step": 95260
    },
    {
      "epoch": 95.27,
      "learning_rate": 9.323196398965449e-07,
      "loss": 0.2771,
      "step": 95270
    },
    {
      "epoch": 95.28,
      "learning_rate": 9.284251639714385e-07,
      "loss": 0.1393,
      "step": 95280
    },
    {
      "epoch": 95.29,
      "learning_rate": 9.24538788402393e-07,
      "loss": 0.277,
      "step": 95290
    },
    {
      "epoch": 95.3,
      "learning_rate": 9.206605136144102e-07,
      "loss": 0.2021,
      "step": 95300
    },
    {
      "epoch": 95.31,
      "learning_rate": 9.167903400316256e-07,
      "loss": 0.1103,
      "step": 95310
    },
    {
      "epoch": 95.32,
      "learning_rate": 9.129282680772593e-07,
      "loss": 0.1068,
      "step": 95320
    },
    {
      "epoch": 95.33,
      "learning_rate": 9.090742981736649e-07,
      "loss": 0.1153,
      "step": 95330
    },
    {
      "epoch": 95.34,
      "learning_rate": 9.052284307423136e-07,
      "loss": 0.1203,
      "step": 95340
    },
    {
      "epoch": 95.35,
      "learning_rate": 9.01390666203794e-07,
      "loss": 0.3858,
      "step": 95350
    },
    {
      "epoch": 95.36,
      "learning_rate": 8.975610049777704e-07,
      "loss": 0.0947,
      "step": 95360
    },
    {
      "epoch": 95.37,
      "learning_rate": 8.937394474830745e-07,
      "loss": 0.2013,
      "step": 95370
    },
    {
      "epoch": 95.38,
      "learning_rate": 8.899259941376053e-07,
      "loss": 0.1084,
      "step": 95380
    },
    {
      "epoch": 95.39,
      "learning_rate": 8.861206453584125e-07,
      "loss": 0.0901,
      "step": 95390
    },
    {
      "epoch": 95.4,
      "learning_rate": 8.823234015616382e-07,
      "loss": 0.2451,
      "step": 95400
    },
    {
      "epoch": 95.41,
      "learning_rate": 8.785342631625419e-07,
      "loss": 0.2138,
      "step": 95410
    },
    {
      "epoch": 95.42,
      "learning_rate": 8.747532305755006e-07,
      "loss": 0.1041,
      "step": 95420
    },
    {
      "epoch": 95.43,
      "learning_rate": 8.709803042140001e-07,
      "loss": 0.2632,
      "step": 95430
    },
    {
      "epoch": 95.44,
      "learning_rate": 8.672154844906353e-07,
      "loss": 0.1699,
      "step": 95440
    },
    {
      "epoch": 95.45,
      "learning_rate": 8.634587718171271e-07,
      "loss": 0.0103,
      "step": 95450
    },
    {
      "epoch": 95.46,
      "learning_rate": 8.597101666043133e-07,
      "loss": 0.2977,
      "step": 95460
    },
    {
      "epoch": 95.47,
      "learning_rate": 8.559696692621243e-07,
      "loss": 0.1231,
      "step": 95470
    },
    {
      "epoch": 95.48,
      "learning_rate": 8.522372801996163e-07,
      "loss": 0.1233,
      "step": 95480
    },
    {
      "epoch": 95.49,
      "learning_rate": 8.485129998249713e-07,
      "loss": 0.2178,
      "step": 95490
    },
    {
      "epoch": 95.5,
      "learning_rate": 8.447968285454465e-07,
      "loss": 0.1501,
      "step": 95500
    },
    {
      "epoch": 95.51,
      "learning_rate": 8.410887667674504e-07,
      "loss": 0.2241,
      "step": 95510
    },
    {
      "epoch": 95.52,
      "learning_rate": 8.373888148964919e-07,
      "loss": 0.2144,
      "step": 95520
    },
    {
      "epoch": 95.53,
      "learning_rate": 8.336969733371973e-07,
      "loss": 0.182,
      "step": 95530
    },
    {
      "epoch": 95.54,
      "learning_rate": 8.300132424932854e-07,
      "loss": 0.1924,
      "step": 95540
    },
    {
      "epoch": 95.55,
      "learning_rate": 8.263376227676172e-07,
      "loss": 0.1073,
      "step": 95550
    },
    {
      "epoch": 95.56,
      "learning_rate": 8.226701145621545e-07,
      "loss": 0.1268,
      "step": 95560
    },
    {
      "epoch": 95.57,
      "learning_rate": 8.190107182779515e-07,
      "loss": 0.1377,
      "step": 95570
    },
    {
      "epoch": 95.58,
      "learning_rate": 8.153594343152131e-07,
      "loss": 0.0112,
      "step": 95580
    },
    {
      "epoch": 95.59,
      "learning_rate": 8.117162630732282e-07,
      "loss": 0.2215,
      "step": 95590
    },
    {
      "epoch": 95.6,
      "learning_rate": 8.080812049504198e-07,
      "loss": 0.2039,
      "step": 95600
    },
    {
      "epoch": 95.61,
      "learning_rate": 8.044542603442949e-07,
      "loss": 0.1637,
      "step": 95610
    },
    {
      "epoch": 95.62,
      "learning_rate": 8.008354296515113e-07,
      "loss": 0.2558,
      "step": 95620
    },
    {
      "epoch": 95.63,
      "learning_rate": 7.972247132678022e-07,
      "loss": 0.4161,
      "step": 95630
    },
    {
      "epoch": 95.64,
      "learning_rate": 7.936221115880353e-07,
      "loss": 0.2429,
      "step": 95640
    },
    {
      "epoch": 95.65,
      "learning_rate": 7.900276250061872e-07,
      "loss": 0.2254,
      "step": 95650
    },
    {
      "epoch": 95.66,
      "learning_rate": 7.864412539153514e-07,
      "loss": 0.1945,
      "step": 95660
    },
    {
      "epoch": 95.67,
      "learning_rate": 7.828629987077145e-07,
      "loss": 0.1756,
      "step": 95670
    },
    {
      "epoch": 95.68,
      "learning_rate": 7.792928597746051e-07,
      "loss": 0.2018,
      "step": 95680
    },
    {
      "epoch": 95.69,
      "learning_rate": 7.757308375064358e-07,
      "loss": 0.2471,
      "step": 95690
    },
    {
      "epoch": 95.7,
      "learning_rate": 7.721769322927451e-07,
      "loss": 0.0746,
      "step": 95700
    },
    {
      "epoch": 95.71,
      "learning_rate": 7.686311445221804e-07,
      "loss": 0.2218,
      "step": 95710
    },
    {
      "epoch": 95.72,
      "learning_rate": 7.650934745825149e-07,
      "loss": 0.0956,
      "step": 95720
    },
    {
      "epoch": 95.73,
      "learning_rate": 7.615639228606141e-07,
      "loss": 0.0941,
      "step": 95730
    },
    {
      "epoch": 95.74,
      "learning_rate": 7.580424897424692e-07,
      "loss": 0.3012,
      "step": 95740
    },
    {
      "epoch": 95.75,
      "learning_rate": 7.545291756131721e-07,
      "loss": 0.111,
      "step": 95750
    },
    {
      "epoch": 95.76,
      "learning_rate": 7.510239808569407e-07,
      "loss": 0.2282,
      "step": 95760
    },
    {
      "epoch": 95.77,
      "learning_rate": 7.475269058570932e-07,
      "loss": 0.1517,
      "step": 95770
    },
    {
      "epoch": 95.78,
      "learning_rate": 7.440379509960737e-07,
      "loss": 0.0829,
      "step": 95780
    },
    {
      "epoch": 95.79,
      "learning_rate": 7.405571166554103e-07,
      "loss": 0.1633,
      "step": 95790
    },
    {
      "epoch": 95.8,
      "learning_rate": 7.370844032157819e-07,
      "loss": 0.3159,
      "step": 95800
    },
    {
      "epoch": 95.81,
      "learning_rate": 7.336198110569513e-07,
      "loss": 0.0861,
      "step": 95810
    },
    {
      "epoch": 95.82,
      "learning_rate": 7.301633405577906e-07,
      "loss": 0.1306,
      "step": 95820
    },
    {
      "epoch": 95.83,
      "learning_rate": 7.267149920963139e-07,
      "loss": 0.1883,
      "step": 95830
    },
    {
      "epoch": 95.84,
      "learning_rate": 7.232747660496113e-07,
      "loss": 0.1441,
      "step": 95840
    },
    {
      "epoch": 95.85,
      "learning_rate": 7.198426627939069e-07,
      "loss": 0.1949,
      "step": 95850
    },
    {
      "epoch": 95.86,
      "learning_rate": 7.164186827045338e-07,
      "loss": 0.1339,
      "step": 95860
    },
    {
      "epoch": 95.87,
      "learning_rate": 7.13002826155934e-07,
      "loss": 0.2223,
      "step": 95870
    },
    {
      "epoch": 95.88,
      "learning_rate": 7.095950935216505e-07,
      "loss": 0.1389,
      "step": 95880
    },
    {
      "epoch": 95.89,
      "learning_rate": 7.061954851743517e-07,
      "loss": 0.1328,
      "step": 95890
    },
    {
      "epoch": 95.9,
      "learning_rate": 7.028040014858155e-07,
      "loss": 0.1678,
      "step": 95900
    },
    {
      "epoch": 95.91,
      "learning_rate": 6.994206428269366e-07,
      "loss": 0.2229,
      "step": 95910
    },
    {
      "epoch": 95.92,
      "learning_rate": 6.960454095677026e-07,
      "loss": 0.1379,
      "step": 95920
    },
    {
      "epoch": 95.93,
      "learning_rate": 6.926783020772264e-07,
      "loss": 0.1556,
      "step": 95930
    },
    {
      "epoch": 95.94,
      "learning_rate": 6.893193207237302e-07,
      "loss": 0.1835,
      "step": 95940
    },
    {
      "epoch": 95.95,
      "learning_rate": 6.859684658745534e-07,
      "loss": 0.1127,
      "step": 95950
    },
    {
      "epoch": 95.96,
      "learning_rate": 6.826257378961364e-07,
      "loss": 0.1254,
      "step": 95960
    },
    {
      "epoch": 95.97,
      "learning_rate": 6.792911371540283e-07,
      "loss": 0.1887,
      "step": 95970
    },
    {
      "epoch": 95.98,
      "learning_rate": 6.75964664012904e-07,
      "loss": 0.185,
      "step": 95980
    },
    {
      "epoch": 95.99,
      "learning_rate": 6.726463188365478e-07,
      "loss": 0.203,
      "step": 95990
    },
    {
      "epoch": 96.0,
      "learning_rate": 6.693361019878274e-07,
      "loss": 0.2268,
      "step": 96000
    },
    {
      "epoch": 96.0,
      "eval_accuracy": 0.8,
      "eval_loss": 0.7064949870109558,
      "eval_runtime": 14.5535,
      "eval_samples_per_second": 137.424,
      "eval_steps_per_second": 17.178,
      "step": 96000
    },
    {
      "epoch": 96.01,
      "learning_rate": 6.660340138287618e-07,
      "loss": 0.0626,
      "step": 96010
    },
    {
      "epoch": 96.02,
      "learning_rate": 6.62740054720462e-07,
      "loss": 0.2796,
      "step": 96020
    },
    {
      "epoch": 96.03,
      "learning_rate": 6.5945422502314e-07,
      "loss": 0.1619,
      "step": 96030
    },
    {
      "epoch": 96.04,
      "learning_rate": 6.561765250961415e-07,
      "loss": 0.1887,
      "step": 96040
    },
    {
      "epoch": 96.05,
      "learning_rate": 6.529069552978966e-07,
      "loss": 0.2591,
      "step": 96050
    },
    {
      "epoch": 96.06,
      "learning_rate": 6.496455159859693e-07,
      "loss": 0.2106,
      "step": 96060
    },
    {
      "epoch": 96.07,
      "learning_rate": 6.463922075170241e-07,
      "loss": 0.1657,
      "step": 96070
    },
    {
      "epoch": 96.08,
      "learning_rate": 6.431470302468434e-07,
      "loss": 0.2253,
      "step": 96080
    },
    {
      "epoch": 96.09,
      "learning_rate": 6.399099845302929e-07,
      "loss": 0.3206,
      "step": 96090
    },
    {
      "epoch": 96.1,
      "learning_rate": 6.366810707214066e-07,
      "loss": 0.0697,
      "step": 96100
    },
    {
      "epoch": 96.11,
      "learning_rate": 6.334602891732682e-07,
      "loss": 0.1082,
      "step": 96110
    },
    {
      "epoch": 96.12,
      "learning_rate": 6.302476402381046e-07,
      "loss": 0.0931,
      "step": 96120
    },
    {
      "epoch": 96.13,
      "learning_rate": 6.270431242672431e-07,
      "loss": 0.1357,
      "step": 96130
    },
    {
      "epoch": 96.14,
      "learning_rate": 6.238467416111365e-07,
      "loss": 0.2657,
      "step": 96140
    },
    {
      "epoch": 96.15,
      "learning_rate": 6.206584926193137e-07,
      "loss": 0.1053,
      "step": 96150
    },
    {
      "epoch": 96.16,
      "learning_rate": 6.174783776404624e-07,
      "loss": 0.1427,
      "step": 96160
    },
    {
      "epoch": 96.17,
      "learning_rate": 6.143063970223294e-07,
      "loss": 0.0848,
      "step": 96170
    },
    {
      "epoch": 96.18,
      "learning_rate": 6.111425511118289e-07,
      "loss": 0.345,
      "step": 96180
    },
    {
      "epoch": 96.19,
      "learning_rate": 6.07986840254926e-07,
      "loss": 0.1237,
      "step": 96190
    },
    {
      "epoch": 96.2,
      "learning_rate": 6.048392647967443e-07,
      "loss": 0.142,
      "step": 96200
    },
    {
      "epoch": 96.21,
      "learning_rate": 6.016998250814752e-07,
      "loss": 0.2172,
      "step": 96210
    },
    {
      "epoch": 96.22,
      "learning_rate": 5.985685214524694e-07,
      "loss": 0.1275,
      "step": 96220
    },
    {
      "epoch": 96.23,
      "learning_rate": 5.954453542521359e-07,
      "loss": 0.13,
      "step": 96230
    },
    {
      "epoch": 96.24,
      "learning_rate": 5.923303238220517e-07,
      "loss": 0.1463,
      "step": 96240
    },
    {
      "epoch": 96.25,
      "learning_rate": 5.892234305028359e-07,
      "loss": 0.0575,
      "step": 96250
    },
    {
      "epoch": 96.26,
      "learning_rate": 5.861246746342751e-07,
      "loss": 0.0384,
      "step": 96260
    },
    {
      "epoch": 96.27,
      "learning_rate": 5.830340565552483e-07,
      "loss": 0.1789,
      "step": 96270
    },
    {
      "epoch": 96.28,
      "learning_rate": 5.799515766037266e-07,
      "loss": 0.1568,
      "step": 96280
    },
    {
      "epoch": 96.29,
      "learning_rate": 5.768772351168072e-07,
      "loss": 0.0347,
      "step": 96290
    },
    {
      "epoch": 96.3,
      "learning_rate": 5.738110324307044e-07,
      "loss": 0.1796,
      "step": 96300
    },
    {
      "epoch": 96.31,
      "learning_rate": 5.707529688807333e-07,
      "loss": 0.3021,
      "step": 96310
    },
    {
      "epoch": 96.32,
      "learning_rate": 5.677030448013098e-07,
      "loss": 0.1325,
      "step": 96320
    },
    {
      "epoch": 96.33,
      "learning_rate": 5.646612605259837e-07,
      "loss": 0.2282,
      "step": 96330
    },
    {
      "epoch": 96.34,
      "learning_rate": 5.616276163873723e-07,
      "loss": 0.2684,
      "step": 96340
    },
    {
      "epoch": 96.35,
      "learning_rate": 5.586021127172602e-07,
      "loss": 0.2117,
      "step": 96350
    },
    {
      "epoch": 96.36,
      "learning_rate": 5.555847498464994e-07,
      "loss": 0.1963,
      "step": 96360
    },
    {
      "epoch": 96.37,
      "learning_rate": 5.525755281050675e-07,
      "loss": 0.1002,
      "step": 96370
    },
    {
      "epoch": 96.38,
      "learning_rate": 5.495744478220348e-07,
      "loss": 0.2327,
      "step": 96380
    },
    {
      "epoch": 96.39,
      "learning_rate": 5.465815093256137e-07,
      "loss": 0.2518,
      "step": 96390
    },
    {
      "epoch": 96.4,
      "learning_rate": 5.435967129431007e-07,
      "loss": 0.0807,
      "step": 96400
    },
    {
      "epoch": 96.41,
      "learning_rate": 5.406200590009013e-07,
      "loss": 0.1313,
      "step": 96410
    },
    {
      "epoch": 96.42,
      "learning_rate": 5.376515478245552e-07,
      "loss": 0.1473,
      "step": 96420
    },
    {
      "epoch": 96.43,
      "learning_rate": 5.346911797386777e-07,
      "loss": 0.1164,
      "step": 96430
    },
    {
      "epoch": 96.44,
      "learning_rate": 5.317389550670098e-07,
      "loss": 0.1781,
      "step": 96440
    },
    {
      "epoch": 96.45,
      "learning_rate": 5.287948741324183e-07,
      "loss": 0.2047,
      "step": 96450
    },
    {
      "epoch": 96.46,
      "learning_rate": 5.258589372568456e-07,
      "loss": 0.0849,
      "step": 96460
    },
    {
      "epoch": 96.47,
      "learning_rate": 5.229311447613765e-07,
      "loss": 0.1472,
      "step": 96470
    },
    {
      "epoch": 96.48,
      "learning_rate": 5.200114969661717e-07,
      "loss": 0.1548,
      "step": 96480
    },
    {
      "epoch": 96.49,
      "learning_rate": 5.170999941905424e-07,
      "loss": 0.151,
      "step": 96490
    },
    {
      "epoch": 96.5,
      "learning_rate": 5.141966367528672e-07,
      "loss": 0.1279,
      "step": 96500
    },
    {
      "epoch": 96.51,
      "learning_rate": 5.113014249706671e-07,
      "loss": 0.3615,
      "step": 96510
    },
    {
      "epoch": 96.52,
      "learning_rate": 5.084143591605472e-07,
      "loss": 0.1208,
      "step": 96520
    },
    {
      "epoch": 96.53,
      "learning_rate": 5.0553543963823e-07,
      "loss": 0.1298,
      "step": 96530
    },
    {
      "epoch": 96.54,
      "learning_rate": 5.026646667185636e-07,
      "loss": 0.1368,
      "step": 96540
    },
    {
      "epoch": 96.55,
      "learning_rate": 4.998020407154801e-07,
      "loss": 0.1149,
      "step": 96550
    },
    {
      "epoch": 96.56,
      "learning_rate": 4.96947561942046e-07,
      "loss": 0.1363,
      "step": 96560
    },
    {
      "epoch": 96.57,
      "learning_rate": 4.941012307104031e-07,
      "loss": 0.2856,
      "step": 96570
    },
    {
      "epoch": 96.58,
      "learning_rate": 4.912630473318357e-07,
      "loss": 0.1932,
      "step": 96580
    },
    {
      "epoch": 96.59,
      "learning_rate": 4.884330121167124e-07,
      "loss": 0.1282,
      "step": 96590
    },
    {
      "epoch": 96.6,
      "learning_rate": 4.856111253745354e-07,
      "loss": 0.1817,
      "step": 96600
    },
    {
      "epoch": 96.61,
      "learning_rate": 4.827973874138913e-07,
      "loss": 0.2536,
      "step": 96610
    },
    {
      "epoch": 96.62,
      "learning_rate": 4.799917985424923e-07,
      "loss": 0.2025,
      "step": 96620
    },
    {
      "epoch": 96.63,
      "learning_rate": 4.771943590671512e-07,
      "loss": 0.0744,
      "step": 96630
    },
    {
      "epoch": 96.64,
      "learning_rate": 4.744050692937984e-07,
      "loss": 0.3011,
      "step": 96640
    },
    {
      "epoch": 96.65,
      "learning_rate": 4.716239295274482e-07,
      "loss": 0.1348,
      "step": 96650
    },
    {
      "epoch": 96.66,
      "learning_rate": 4.688509400722573e-07,
      "loss": 0.0898,
      "step": 96660
    },
    {
      "epoch": 96.67,
      "learning_rate": 4.6608610123146653e-07,
      "loss": 0.0733,
      "step": 96670
    },
    {
      "epoch": 96.68,
      "learning_rate": 4.6332941330745056e-07,
      "loss": 0.2316,
      "step": 96680
    },
    {
      "epoch": 96.69,
      "learning_rate": 4.6058087660166e-07,
      "loss": 0.156,
      "step": 96690
    },
    {
      "epoch": 96.7,
      "learning_rate": 4.578404914146794e-07,
      "loss": 0.1872,
      "step": 96700
    },
    {
      "epoch": 96.71,
      "learning_rate": 4.5510825804618567e-07,
      "loss": 0.0524,
      "step": 96710
    },
    {
      "epoch": 96.72,
      "learning_rate": 4.523841767949815e-07,
      "loss": 0.1642,
      "step": 96720
    },
    {
      "epoch": 96.73,
      "learning_rate": 4.496682479589536e-07,
      "loss": 0.2079,
      "step": 96730
    },
    {
      "epoch": 96.74,
      "learning_rate": 4.4696047183513106e-07,
      "loss": 0.1522,
      "step": 96740
    },
    {
      "epoch": 96.75,
      "learning_rate": 4.4426084871961864e-07,
      "loss": 0.1788,
      "step": 96750
    },
    {
      "epoch": 96.76,
      "learning_rate": 4.4156937890764686e-07,
      "loss": 0.2019,
      "step": 96760
    },
    {
      "epoch": 96.77,
      "learning_rate": 4.3888606269355533e-07,
      "loss": 0.1552,
      "step": 96770
    },
    {
      "epoch": 96.78,
      "learning_rate": 4.362109003707759e-07,
      "loss": 0.0453,
      "step": 96780
    },
    {
      "epoch": 96.79,
      "learning_rate": 4.3354389223186626e-07,
      "loss": 0.1205,
      "step": 96790
    },
    {
      "epoch": 96.8,
      "learning_rate": 4.308850385684931e-07,
      "loss": 0.2383,
      "step": 96800
    },
    {
      "epoch": 96.81,
      "learning_rate": 4.2849904258836774e-07,
      "loss": 0.2145,
      "step": 96810
    },
    {
      "epoch": 96.82,
      "learning_rate": 4.2585568322883457e-07,
      "loss": 0.0945,
      "step": 96820
    },
    {
      "epoch": 96.83,
      "learning_rate": 4.232204791855987e-07,
      "loss": 0.1248,
      "step": 96830
    },
    {
      "epoch": 96.84,
      "learning_rate": 4.2059343074685445e-07,
      "loss": 0.1626,
      "step": 96840
    },
    {
      "epoch": 96.85,
      "learning_rate": 4.179745381998723e-07,
      "loss": 0.1865,
      "step": 96850
    },
    {
      "epoch": 96.86,
      "learning_rate": 4.153638018310729e-07,
      "loss": 0.0547,
      "step": 96860
    },
    {
      "epoch": 96.87,
      "learning_rate": 4.1276122192594463e-07,
      "loss": 0.1887,
      "step": 96870
    },
    {
      "epoch": 96.88,
      "learning_rate": 4.1016679876910984e-07,
      "loss": 0.19,
      "step": 96880
    },
    {
      "epoch": 96.89,
      "learning_rate": 4.0758053264429156e-07,
      "loss": 0.1726,
      "step": 96890
    },
    {
      "epoch": 96.9,
      "learning_rate": 4.0500242383432194e-07,
      "loss": 0.126,
      "step": 96900
    },
    {
      "epoch": 96.91,
      "learning_rate": 4.0243247262112535e-07,
      "loss": 0.1195,
      "step": 96910
    },
    {
      "epoch": 96.92,
      "learning_rate": 3.9987067928576866e-07,
      "loss": 0.1571,
      "step": 96920
    },
    {
      "epoch": 96.93,
      "learning_rate": 3.9731704410838616e-07,
      "loss": 0.1745,
      "step": 96930
    },
    {
      "epoch": 96.94,
      "learning_rate": 3.9477156736825446e-07,
      "loss": 0.2309,
      "step": 96940
    },
    {
      "epoch": 96.95,
      "learning_rate": 3.9223424934373414e-07,
      "loss": 0.1726,
      "step": 96950
    },
    {
      "epoch": 96.96,
      "learning_rate": 3.8970509031230337e-07,
      "loss": 0.1949,
      "step": 96960
    },
    {
      "epoch": 96.97,
      "learning_rate": 3.871840905505491e-07,
      "loss": 0.0841,
      "step": 96970
    },
    {
      "epoch": 96.98,
      "learning_rate": 3.8467125033416757e-07,
      "loss": 0.1811,
      "step": 96980
    },
    {
      "epoch": 96.99,
      "learning_rate": 3.8216656993794725e-07,
      "loss": 0.1133,
      "step": 96990
    },
    {
      "epoch": 97.0,
      "learning_rate": 3.7967004963581906e-07,
      "loss": 0.1758,
      "step": 97000
    },
    {
      "epoch": 97.0,
      "eval_accuracy": 0.798,
      "eval_loss": 0.7233364582061768,
      "eval_runtime": 15.0096,
      "eval_samples_per_second": 133.248,
      "eval_steps_per_second": 16.656,
      "step": 97000
    },
    {
      "epoch": 97.01,
      "learning_rate": 3.771816897007729e-07,
      "loss": 0.0343,
      "step": 97010
    },
    {
      "epoch": 97.02,
      "learning_rate": 3.7470149040494945e-07,
      "loss": 0.1079,
      "step": 97020
    },
    {
      "epoch": 97.03,
      "learning_rate": 3.722294520195734e-07,
      "loss": 0.2751,
      "step": 97030
    },
    {
      "epoch": 97.04,
      "learning_rate": 3.6976557481497857e-07,
      "loss": 0.3379,
      "step": 97040
    },
    {
      "epoch": 97.05,
      "learning_rate": 3.6730985906061605e-07,
      "loss": 0.1335,
      "step": 97050
    },
    {
      "epoch": 97.06,
      "learning_rate": 3.6486230502503766e-07,
      "loss": 0.2003,
      "step": 97060
    },
    {
      "epoch": 97.07,
      "learning_rate": 3.624229129759126e-07,
      "loss": 0.1868,
      "step": 97070
    },
    {
      "epoch": 97.08,
      "learning_rate": 3.599916831799943e-07,
      "loss": 0.2366,
      "step": 97080
    },
    {
      "epoch": 97.09,
      "learning_rate": 3.575686159031699e-07,
      "loss": 0.1115,
      "step": 97090
    },
    {
      "epoch": 97.1,
      "learning_rate": 3.5515371141041914e-07,
      "loss": 0.0845,
      "step": 97100
    },
    {
      "epoch": 97.11,
      "learning_rate": 3.5274696996583085e-07,
      "loss": 0.2088,
      "step": 97110
    },
    {
      "epoch": 97.12,
      "learning_rate": 3.503483918325944e-07,
      "loss": 0.0704,
      "step": 97120
    },
    {
      "epoch": 97.13,
      "learning_rate": 3.479579772730418e-07,
      "loss": 0.1654,
      "step": 97130
    },
    {
      "epoch": 97.14,
      "learning_rate": 3.455757265485554e-07,
      "loss": 0.1466,
      "step": 97140
    },
    {
      "epoch": 97.15,
      "learning_rate": 3.4320163991966853e-07,
      "loss": 0.1945,
      "step": 97150
    },
    {
      "epoch": 97.16,
      "learning_rate": 3.4083571764600694e-07,
      "loss": 0.199,
      "step": 97160
    },
    {
      "epoch": 97.17,
      "learning_rate": 3.384779599862969e-07,
      "loss": 0.1633,
      "step": 97170
    },
    {
      "epoch": 97.18,
      "learning_rate": 3.3612836719839056e-07,
      "loss": 0.1789,
      "step": 97180
    },
    {
      "epoch": 97.19,
      "learning_rate": 3.337869395392323e-07,
      "loss": 0.1543,
      "step": 97190
    },
    {
      "epoch": 97.2,
      "learning_rate": 3.314536772648674e-07,
      "loss": 0.2139,
      "step": 97200
    },
    {
      "epoch": 97.21,
      "learning_rate": 3.2912858063047497e-07,
      "loss": 0.0907,
      "step": 97210
    },
    {
      "epoch": 97.22,
      "learning_rate": 3.268116498903101e-07,
      "loss": 0.2514,
      "step": 97220
    },
    {
      "epoch": 97.23,
      "learning_rate": 3.2450288529775327e-07,
      "loss": 0.1521,
      "step": 97230
    },
    {
      "epoch": 97.24,
      "learning_rate": 3.2220228710528593e-07,
      "loss": 0.1228,
      "step": 97240
    },
    {
      "epoch": 97.25,
      "learning_rate": 3.1990985556450687e-07,
      "loss": 0.2711,
      "step": 97250
    },
    {
      "epoch": 97.26,
      "learning_rate": 3.176255909260988e-07,
      "loss": 0.1427,
      "step": 97260
    },
    {
      "epoch": 97.27,
      "learning_rate": 3.153494934398787e-07,
      "loss": 0.1257,
      "step": 97270
    },
    {
      "epoch": 97.28,
      "learning_rate": 3.1308156335475566e-07,
      "loss": 0.1107,
      "step": 97280
    },
    {
      "epoch": 97.29,
      "learning_rate": 3.108218009187313e-07,
      "loss": 0.2879,
      "step": 97290
    },
    {
      "epoch": 97.3,
      "learning_rate": 3.085702063789497e-07,
      "loss": 0.1383,
      "step": 97300
    },
    {
      "epoch": 97.31,
      "learning_rate": 3.063267799816221e-07,
      "loss": 0.1131,
      "step": 97310
    },
    {
      "epoch": 97.32,
      "learning_rate": 3.0409152197211073e-07,
      "loss": 0.2354,
      "step": 97320
    },
    {
      "epoch": 97.33,
      "learning_rate": 3.0186443259484494e-07,
      "loss": 0.197,
      "step": 97330
    },
    {
      "epoch": 97.34,
      "learning_rate": 2.996455120933716e-07,
      "loss": 0.0706,
      "step": 97340
    },
    {
      "epoch": 97.35,
      "learning_rate": 2.97434760710355e-07,
      "loss": 0.1523,
      "step": 97350
    },
    {
      "epoch": 97.36,
      "learning_rate": 2.9523217868756834e-07,
      "loss": 0.2084,
      "step": 97360
    },
    {
      "epoch": 97.37,
      "learning_rate": 2.9303776626586064e-07,
      "loss": 0.086,
      "step": 97370
    },
    {
      "epoch": 97.38,
      "learning_rate": 2.9085152368523156e-07,
      "loss": 0.1539,
      "step": 97380
    },
    {
      "epoch": 97.39,
      "learning_rate": 2.886734511847566e-07,
      "loss": 0.1799,
      "step": 97390
    },
    {
      "epoch": 97.4,
      "learning_rate": 2.865035490026285e-07,
      "loss": 0.1791,
      "step": 97400
    },
    {
      "epoch": 97.41,
      "learning_rate": 2.843418173761325e-07,
      "loss": 0.1497,
      "step": 97410
    },
    {
      "epoch": 97.42,
      "learning_rate": 2.821882565416878e-07,
      "loss": 0.1786,
      "step": 97420
    },
    {
      "epoch": 97.43,
      "learning_rate": 2.8004286673479757e-07,
      "loss": 0.2528,
      "step": 97430
    },
    {
      "epoch": 97.44,
      "learning_rate": 2.7790564819008263e-07,
      "loss": 0.0917,
      "step": 97440
    },
    {
      "epoch": 97.45,
      "learning_rate": 2.75776601141256e-07,
      "loss": 0.2224,
      "step": 97450
    },
    {
      "epoch": 97.46,
      "learning_rate": 2.736557258211647e-07,
      "loss": 0.3851,
      "step": 97460
    },
    {
      "epoch": 97.47,
      "learning_rate": 2.7154302246172323e-07,
      "loss": 0.0787,
      "step": 97470
    },
    {
      "epoch": 97.48,
      "learning_rate": 2.6943849129398845e-07,
      "loss": 0.0758,
      "step": 97480
    },
    {
      "epoch": 97.49,
      "learning_rate": 2.6734213254810953e-07,
      "loss": 0.0463,
      "step": 97490
    },
    {
      "epoch": 97.5,
      "learning_rate": 2.652539464533282e-07,
      "loss": 0.0856,
      "step": 97500
    },
    {
      "epoch": 97.51,
      "learning_rate": 2.631739332380117e-07,
      "loss": 0.1353,
      "step": 97510
    },
    {
      "epoch": 97.52,
      "learning_rate": 2.611020931296365e-07,
      "loss": 0.1593,
      "step": 97520
    },
    {
      "epoch": 97.53,
      "learning_rate": 2.5903842635477126e-07,
      "loss": 0.2083,
      "step": 97530
    },
    {
      "epoch": 97.54,
      "learning_rate": 2.5698293313908547e-07,
      "loss": 0.1334,
      "step": 97540
    },
    {
      "epoch": 97.55,
      "learning_rate": 2.5493561370737437e-07,
      "loss": 0.0891,
      "step": 97550
    },
    {
      "epoch": 97.56,
      "learning_rate": 2.5289646828351717e-07,
      "loss": 0.288,
      "step": 97560
    },
    {
      "epoch": 97.57,
      "learning_rate": 2.508654970905355e-07,
      "loss": 0.1128,
      "step": 97570
    },
    {
      "epoch": 97.58,
      "learning_rate": 2.4884270035051e-07,
      "loss": 0.3133,
      "step": 97580
    },
    {
      "epoch": 97.59,
      "learning_rate": 2.468280782846638e-07,
      "loss": 0.1254,
      "step": 97590
    },
    {
      "epoch": 97.6,
      "learning_rate": 2.4482163111331223e-07,
      "loss": 0.3183,
      "step": 97600
    },
    {
      "epoch": 97.61,
      "learning_rate": 2.4282335905587147e-07,
      "loss": 0.1865,
      "step": 97610
    },
    {
      "epoch": 97.62,
      "learning_rate": 2.4083326233086673e-07,
      "loss": 0.2399,
      "step": 97620
    },
    {
      "epoch": 97.63,
      "learning_rate": 2.388513411559406e-07,
      "loss": 0.1483,
      "step": 97630
    },
    {
      "epoch": 97.64,
      "learning_rate": 2.368775957478364e-07,
      "loss": 0.1232,
      "step": 97640
    },
    {
      "epoch": 97.65,
      "learning_rate": 2.349120263223897e-07,
      "loss": 0.2807,
      "step": 97650
    },
    {
      "epoch": 97.66,
      "learning_rate": 2.3295463309455366e-07,
      "loss": 0.0691,
      "step": 97660
    },
    {
      "epoch": 97.67,
      "learning_rate": 2.3100541627839863e-07,
      "loss": 0.1317,
      "step": 97670
    },
    {
      "epoch": 97.68,
      "learning_rate": 2.2906437608706253e-07,
      "loss": 0.2334,
      "step": 97680
    },
    {
      "epoch": 97.69,
      "learning_rate": 2.2713151273284213e-07,
      "loss": 0.1353,
      "step": 97690
    },
    {
      "epoch": 97.7,
      "learning_rate": 2.2520682642709343e-07,
      "loss": 0.1116,
      "step": 97700
    },
    {
      "epoch": 97.71,
      "learning_rate": 2.2329031738030633e-07,
      "loss": 0.0639,
      "step": 97710
    },
    {
      "epoch": 97.72,
      "learning_rate": 2.2138198580206324e-07,
      "loss": 0.0637,
      "step": 97720
    },
    {
      "epoch": 97.73,
      "learning_rate": 2.194818319010555e-07,
      "loss": 0.1718,
      "step": 97730
    },
    {
      "epoch": 97.74,
      "learning_rate": 2.1758985588509192e-07,
      "loss": 0.0984,
      "step": 97740
    },
    {
      "epoch": 97.75,
      "learning_rate": 2.1570605796106532e-07,
      "loss": 0.234,
      "step": 97750
    },
    {
      "epoch": 97.76,
      "learning_rate": 2.1383043833498592e-07,
      "loss": 0.3827,
      "step": 97760
    },
    {
      "epoch": 97.77,
      "learning_rate": 2.1196299721197295e-07,
      "loss": 0.1949,
      "step": 97770
    },
    {
      "epoch": 97.78,
      "learning_rate": 2.101037347962381e-07,
      "loss": 0.1659,
      "step": 97780
    },
    {
      "epoch": 97.79,
      "learning_rate": 2.0825265129111867e-07,
      "loss": 0.0294,
      "step": 97790
    },
    {
      "epoch": 97.8,
      "learning_rate": 2.0640974689904443e-07,
      "loss": 0.2639,
      "step": 97800
    },
    {
      "epoch": 97.81,
      "learning_rate": 2.0457502182154585e-07,
      "loss": 0.1962,
      "step": 97810
    },
    {
      "epoch": 97.82,
      "learning_rate": 2.0274847625927071e-07,
      "loss": 0.0478,
      "step": 97820
    },
    {
      "epoch": 97.83,
      "learning_rate": 2.0093011041195928e-07,
      "loss": 0.1402,
      "step": 97830
    },
    {
      "epoch": 97.84,
      "learning_rate": 1.991199244784858e-07,
      "loss": 0.1065,
      "step": 97840
    },
    {
      "epoch": 97.85,
      "learning_rate": 1.973179186567836e-07,
      "loss": 0.111,
      "step": 97850
    },
    {
      "epoch": 97.86,
      "learning_rate": 1.955240931439367e-07,
      "loss": 0.1585,
      "step": 97860
    },
    {
      "epoch": 97.87,
      "learning_rate": 1.9373844813610485e-07,
      "loss": 0.0862,
      "step": 97870
    },
    {
      "epoch": 97.88,
      "learning_rate": 1.919609838285735e-07,
      "loss": 0.234,
      "step": 97880
    },
    {
      "epoch": 97.89,
      "learning_rate": 1.901917004157122e-07,
      "loss": 0.1059,
      "step": 97890
    },
    {
      "epoch": 97.9,
      "learning_rate": 1.884305980910078e-07,
      "loss": 0.2518,
      "step": 97900
    },
    {
      "epoch": 97.91,
      "learning_rate": 1.8667767704705627e-07,
      "loss": 0.1792,
      "step": 97910
    },
    {
      "epoch": 97.92,
      "learning_rate": 1.849329374755626e-07,
      "loss": 0.1888,
      "step": 97920
    },
    {
      "epoch": 97.93,
      "learning_rate": 1.8319637956730748e-07,
      "loss": 0.1187,
      "step": 97930
    },
    {
      "epoch": 97.94,
      "learning_rate": 1.8146800351222235e-07,
      "loss": 0.1755,
      "step": 97940
    },
    {
      "epoch": 97.95,
      "learning_rate": 1.7974780949929768e-07,
      "loss": 0.1692,
      "step": 97950
    },
    {
      "epoch": 97.96,
      "learning_rate": 1.7803579771667465e-07,
      "loss": 0.0469,
      "step": 97960
    },
    {
      "epoch": 97.97,
      "learning_rate": 1.763319683515535e-07,
      "loss": 0.1222,
      "step": 97970
    },
    {
      "epoch": 97.98,
      "learning_rate": 1.7463632159027686e-07,
      "loss": 0.2807,
      "step": 97980
    },
    {
      "epoch": 97.99,
      "learning_rate": 1.7294885761827138e-07,
      "loss": 0.0539,
      "step": 97990
    },
    {
      "epoch": 98.0,
      "learning_rate": 1.712695766200811e-07,
      "loss": 0.1091,
      "step": 98000
    },
    {
      "epoch": 98.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.716700553894043,
      "eval_runtime": 15.3343,
      "eval_samples_per_second": 130.426,
      "eval_steps_per_second": 16.303,
      "step": 98000
    },
    {
      "epoch": 98.01,
      "learning_rate": 1.6959847877934252e-07,
      "loss": 0.2547,
      "step": 98010
    },
    {
      "epoch": 98.02,
      "learning_rate": 1.6793556427880937e-07,
      "loss": 0.1856,
      "step": 98020
    },
    {
      "epoch": 98.03,
      "learning_rate": 1.6628083330033627e-07,
      "loss": 0.1991,
      "step": 98030
    },
    {
      "epoch": 98.04,
      "learning_rate": 1.6463428602487839e-07,
      "loss": 0.1249,
      "step": 98040
    },
    {
      "epoch": 98.05,
      "learning_rate": 1.6299592263250837e-07,
      "loss": 0.1717,
      "step": 98050
    },
    {
      "epoch": 98.06,
      "learning_rate": 1.6136574330238294e-07,
      "loss": 0.0745,
      "step": 98060
    },
    {
      "epoch": 98.07,
      "learning_rate": 1.5974374821278446e-07,
      "loss": 0.2078,
      "step": 98070
    },
    {
      "epoch": 98.08,
      "learning_rate": 1.581299375410794e-07,
      "loss": 0.1021,
      "step": 98080
    },
    {
      "epoch": 98.09,
      "learning_rate": 1.5652431146377653e-07,
      "loss": 0.3224,
      "step": 98090
    },
    {
      "epoch": 98.1,
      "learning_rate": 1.5492687015643544e-07,
      "loss": 0.2139,
      "step": 98100
    },
    {
      "epoch": 98.11,
      "learning_rate": 1.5333761379377474e-07,
      "loss": 0.1245,
      "step": 98110
    },
    {
      "epoch": 98.12,
      "learning_rate": 1.5175654254957203e-07,
      "loss": 0.175,
      "step": 98120
    },
    {
      "epoch": 98.13,
      "learning_rate": 1.5018365659674735e-07,
      "loss": 0.2444,
      "step": 98130
    },
    {
      "epoch": 98.14,
      "learning_rate": 1.486189561073048e-07,
      "loss": 0.157,
      "step": 98140
    },
    {
      "epoch": 98.15,
      "learning_rate": 1.4706244125235743e-07,
      "loss": 0.3451,
      "step": 98150
    },
    {
      "epoch": 98.16,
      "learning_rate": 1.4551411220211085e-07,
      "loss": 0.1687,
      "step": 98160
    },
    {
      "epoch": 98.17,
      "learning_rate": 1.4397396912591286e-07,
      "loss": 0.1515,
      "step": 98170
    },
    {
      "epoch": 98.18,
      "learning_rate": 1.4244201219217043e-07,
      "loss": 0.0583,
      "step": 98180
    },
    {
      "epoch": 98.19,
      "learning_rate": 1.4091824156841625e-07,
      "loss": 0.2216,
      "step": 98190
    },
    {
      "epoch": 98.2,
      "learning_rate": 1.394026574213003e-07,
      "loss": 0.3319,
      "step": 98200
    },
    {
      "epoch": 98.21,
      "learning_rate": 1.3789525991656503e-07,
      "loss": 0.1794,
      "step": 98210
    },
    {
      "epoch": 98.22,
      "learning_rate": 1.3639604921904523e-07,
      "loss": 0.1153,
      "step": 98220
    },
    {
      "epoch": 98.23,
      "learning_rate": 1.349050254926931e-07,
      "loss": 0.1463,
      "step": 98230
    },
    {
      "epoch": 98.24,
      "learning_rate": 1.334221889005782e-07,
      "loss": 0.2405,
      "step": 98240
    },
    {
      "epoch": 98.25,
      "learning_rate": 1.3194753960484583e-07,
      "loss": 0.2173,
      "step": 98250
    },
    {
      "epoch": 98.26,
      "learning_rate": 1.3048107776676697e-07,
      "loss": 0.2437,
      "step": 98260
    },
    {
      "epoch": 98.27,
      "learning_rate": 1.2902280354671334e-07,
      "loss": 0.1044,
      "step": 98270
    },
    {
      "epoch": 98.28,
      "learning_rate": 1.2757271710416574e-07,
      "loss": 0.1654,
      "step": 98280
    },
    {
      "epoch": 98.29,
      "learning_rate": 1.2613081859768893e-07,
      "loss": 0.1517,
      "step": 98290
    },
    {
      "epoch": 98.3,
      "learning_rate": 1.246971081849818e-07,
      "loss": 0.1014,
      "step": 98300
    },
    {
      "epoch": 98.31,
      "learning_rate": 1.2327158602281894e-07,
      "loss": 0.3154,
      "step": 98310
    },
    {
      "epoch": 98.32,
      "learning_rate": 1.2185425226710066e-07,
      "loss": 0.0629,
      "step": 98320
    },
    {
      "epoch": 98.33,
      "learning_rate": 1.2044510707282795e-07,
      "loss": 0.091,
      "step": 98330
    },
    {
      "epoch": 98.34,
      "learning_rate": 1.1904415059410255e-07,
      "loss": 0.1678,
      "step": 98340
    },
    {
      "epoch": 98.35,
      "learning_rate": 1.1765138298411858e-07,
      "loss": 0.117,
      "step": 98350
    },
    {
      "epoch": 98.36,
      "learning_rate": 1.1626680439519587e-07,
      "loss": 0.2032,
      "step": 98360
    },
    {
      "epoch": 98.37,
      "learning_rate": 1.1489041497875495e-07,
      "loss": 0.1324,
      "step": 98370
    },
    {
      "epoch": 98.38,
      "learning_rate": 1.1352221488530878e-07,
      "loss": 0.246,
      "step": 98380
    },
    {
      "epoch": 98.39,
      "learning_rate": 1.1216220426447098e-07,
      "loss": 0.1315,
      "step": 98390
    },
    {
      "epoch": 98.4,
      "learning_rate": 1.1081038326499758e-07,
      "loss": 0.0504,
      "step": 98400
    },
    {
      "epoch": 98.41,
      "learning_rate": 1.0946675203470368e-07,
      "loss": 0.2412,
      "step": 98410
    },
    {
      "epoch": 98.42,
      "learning_rate": 1.0813131072052172e-07,
      "loss": 0.011,
      "step": 98420
    },
    {
      "epoch": 98.43,
      "learning_rate": 1.068040594685099e-07,
      "loss": 0.2508,
      "step": 98430
    },
    {
      "epoch": 98.44,
      "learning_rate": 1.054849984238021e-07,
      "loss": 0.1787,
      "step": 98440
    },
    {
      "epoch": 98.45,
      "learning_rate": 1.0417412773064959e-07,
      "loss": 0.146,
      "step": 98450
    },
    {
      "epoch": 98.46,
      "learning_rate": 1.0287144753242105e-07,
      "loss": 0.1678,
      "step": 98460
    },
    {
      "epoch": 98.47,
      "learning_rate": 1.0157695797155252e-07,
      "loss": 0.1304,
      "step": 98470
    },
    {
      "epoch": 98.48,
      "learning_rate": 1.0029065918962242e-07,
      "loss": 0.156,
      "step": 98480
    },
    {
      "epoch": 98.49,
      "learning_rate": 9.901255132730156e-08,
      "loss": 0.1333,
      "step": 98490
    },
    {
      "epoch": 98.5,
      "learning_rate": 9.774263452435316e-08,
      "loss": 0.2359,
      "step": 98500
    },
    {
      "epoch": 98.51,
      "learning_rate": 9.648090891965776e-08,
      "loss": 0.1749,
      "step": 98510
    },
    {
      "epoch": 98.52,
      "learning_rate": 9.522737465118835e-08,
      "loss": 0.1931,
      "step": 98520
    },
    {
      "epoch": 98.53,
      "learning_rate": 9.398203185604359e-08,
      "loss": 0.2009,
      "step": 98530
    },
    {
      "epoch": 98.54,
      "learning_rate": 9.274488067039787e-08,
      "loss": 0.1295,
      "step": 98540
    },
    {
      "epoch": 98.55,
      "learning_rate": 9.151592122955964e-08,
      "loss": 0.2598,
      "step": 98550
    },
    {
      "epoch": 98.56,
      "learning_rate": 9.029515366790474e-08,
      "loss": 0.1854,
      "step": 98560
    },
    {
      "epoch": 98.57,
      "learning_rate": 8.908257811895968e-08,
      "loss": 0.1359,
      "step": 98570
    },
    {
      "epoch": 98.58,
      "learning_rate": 8.787819471530178e-08,
      "loss": 0.0444,
      "step": 98580
    },
    {
      "epoch": 98.59,
      "learning_rate": 8.668200358866728e-08,
      "loss": 0.1833,
      "step": 98590
    },
    {
      "epoch": 98.6,
      "learning_rate": 8.549400486985992e-08,
      "loss": 0.1412,
      "step": 98600
    },
    {
      "epoch": 98.61,
      "learning_rate": 8.431419868879241e-08,
      "loss": 0.0768,
      "step": 98610
    },
    {
      "epoch": 98.62,
      "learning_rate": 8.314258517448657e-08,
      "loss": 0.1962,
      "step": 98620
    },
    {
      "epoch": 98.63,
      "learning_rate": 8.197916445507324e-08,
      "loss": 0.0865,
      "step": 98630
    },
    {
      "epoch": 98.64,
      "learning_rate": 8.082393665778398e-08,
      "loss": 0.0693,
      "step": 98640
    },
    {
      "epoch": 98.65,
      "learning_rate": 7.967690190894271e-08,
      "loss": 0.1142,
      "step": 98650
    },
    {
      "epoch": 98.66,
      "learning_rate": 7.853806033399912e-08,
      "loss": 0.1146,
      "step": 98660
    },
    {
      "epoch": 98.67,
      "learning_rate": 7.740741205749523e-08,
      "loss": 0.075,
      "step": 98670
    },
    {
      "epoch": 98.68,
      "learning_rate": 7.628495720306548e-08,
      "loss": 0.1315,
      "step": 98680
    },
    {
      "epoch": 98.69,
      "learning_rate": 7.517069589347002e-08,
      "loss": 0.3335,
      "step": 98690
    },
    {
      "epoch": 98.7,
      "learning_rate": 7.406462825056137e-08,
      "loss": 0.2844,
      "step": 98700
    },
    {
      "epoch": 98.71,
      "learning_rate": 7.296675439529276e-08,
      "loss": 0.1343,
      "step": 98710
    },
    {
      "epoch": 98.72,
      "learning_rate": 7.187707444772651e-08,
      "loss": 0.2849,
      "step": 98720
    },
    {
      "epoch": 98.73,
      "learning_rate": 7.079558852703393e-08,
      "loss": 0.095,
      "step": 98730
    },
    {
      "epoch": 98.74,
      "learning_rate": 6.972229675147877e-08,
      "loss": 0.1605,
      "step": 98740
    },
    {
      "epoch": 98.75,
      "learning_rate": 6.865719923843383e-08,
      "loss": 0.2177,
      "step": 98750
    },
    {
      "epoch": 98.76,
      "learning_rate": 6.760029610438921e-08,
      "loss": 0.0536,
      "step": 98760
    },
    {
      "epoch": 98.77,
      "learning_rate": 6.655158746491085e-08,
      "loss": 0.1199,
      "step": 98770
    },
    {
      "epoch": 98.78,
      "learning_rate": 6.55110734346903e-08,
      "loss": 0.1675,
      "step": 98780
    },
    {
      "epoch": 98.79,
      "learning_rate": 6.447875412751991e-08,
      "loss": 0.1438,
      "step": 98790
    },
    {
      "epoch": 98.8,
      "learning_rate": 6.345462965629267e-08,
      "loss": 0.1714,
      "step": 98800
    },
    {
      "epoch": 98.81,
      "learning_rate": 6.243870013299401e-08,
      "loss": 0.0123,
      "step": 98810
    },
    {
      "epoch": 98.82,
      "learning_rate": 6.143096566873506e-08,
      "loss": 0.1962,
      "step": 98820
    },
    {
      "epoch": 98.83,
      "learning_rate": 6.0431426373711e-08,
      "loss": 0.0948,
      "step": 98830
    },
    {
      "epoch": 98.84,
      "learning_rate": 5.944008235724274e-08,
      "loss": 0.2167,
      "step": 98840
    },
    {
      "epoch": 98.85,
      "learning_rate": 5.8456933727735186e-08,
      "loss": 0.1575,
      "step": 98850
    },
    {
      "epoch": 98.86,
      "learning_rate": 5.748198059270237e-08,
      "loss": 0.1413,
      "step": 98860
    },
    {
      "epoch": 98.87,
      "learning_rate": 5.651522305876732e-08,
      "loss": 0.2032,
      "step": 98870
    },
    {
      "epoch": 98.88,
      "learning_rate": 5.555666123165381e-08,
      "loss": 0.1029,
      "step": 98880
    },
    {
      "epoch": 98.89,
      "learning_rate": 5.460629521618631e-08,
      "loss": 0.1433,
      "step": 98890
    },
    {
      "epoch": 98.9,
      "learning_rate": 5.3664125116290034e-08,
      "loss": 0.1717,
      "step": 98900
    },
    {
      "epoch": 98.91,
      "learning_rate": 5.273015103500755e-08,
      "loss": 0.29,
      "step": 98910
    },
    {
      "epoch": 98.92,
      "learning_rate": 5.180437307448215e-08,
      "loss": 0.1171,
      "step": 98920
    },
    {
      "epoch": 98.93,
      "learning_rate": 5.08867913359412e-08,
      "loss": 0.1823,
      "step": 98930
    },
    {
      "epoch": 98.94,
      "learning_rate": 4.997740591972943e-08,
      "loss": 0.0793,
      "step": 98940
    },
    {
      "epoch": 98.95,
      "learning_rate": 4.907621692530894e-08,
      "loss": 0.1174,
      "step": 98950
    },
    {
      "epoch": 98.96,
      "learning_rate": 4.818322445122591e-08,
      "loss": 0.1756,
      "step": 98960
    },
    {
      "epoch": 98.97,
      "learning_rate": 4.729842859514388e-08,
      "loss": 0.1172,
      "step": 98970
    },
    {
      "epoch": 98.98,
      "learning_rate": 4.6421829453810454e-08,
      "loss": 0.1605,
      "step": 98980
    },
    {
      "epoch": 98.99,
      "learning_rate": 4.563989849696859e-08,
      "loss": 0.1531,
      "step": 98990
    },
    {
      "epoch": 99.0,
      "learning_rate": 4.477887337703268e-08,
      "loss": 0.0475,
      "step": 99000
    },
    {
      "epoch": 99.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.7164206504821777,
      "eval_runtime": 14.338,
      "eval_samples_per_second": 139.49,
      "eval_steps_per_second": 17.436,
      "step": 99000
    },
    {
      "epoch": 99.01,
      "learning_rate": 4.39260452473833e-08,
      "loss": 0.1285,
      "step": 99010
    },
    {
      "epoch": 99.02,
      "learning_rate": 4.308141420128752e-08,
      "loss": 0.0931,
      "step": 99020
    },
    {
      "epoch": 99.03,
      "learning_rate": 4.224498033111312e-08,
      "loss": 0.1341,
      "step": 99030
    },
    {
      "epoch": 99.04,
      "learning_rate": 4.141674372832859e-08,
      "loss": 0.2182,
      "step": 99040
    },
    {
      "epoch": 99.05,
      "learning_rate": 4.059670448351149e-08,
      "loss": 0.2967,
      "step": 99050
    },
    {
      "epoch": 99.06,
      "learning_rate": 3.978486268634007e-08,
      "loss": 0.1514,
      "step": 99060
    },
    {
      "epoch": 99.07,
      "learning_rate": 3.898121842559332e-08,
      "loss": 0.2076,
      "step": 99070
    },
    {
      "epoch": 99.08,
      "learning_rate": 3.818577178915927e-08,
      "loss": 0.2431,
      "step": 99080
    },
    {
      "epoch": 99.09,
      "learning_rate": 3.739852286402667e-08,
      "loss": 0.0957,
      "step": 99090
    },
    {
      "epoch": 99.1,
      "learning_rate": 3.661947173628499e-08,
      "loss": 0.1905,
      "step": 99100
    },
    {
      "epoch": 99.11,
      "learning_rate": 3.584861849113274e-08,
      "loss": 0.1246,
      "step": 99110
    },
    {
      "epoch": 99.12,
      "learning_rate": 3.508596321286916e-08,
      "loss": 0.0877,
      "step": 99120
    },
    {
      "epoch": 99.13,
      "learning_rate": 3.43315059848942e-08,
      "loss": 0.2384,
      "step": 99130
    },
    {
      "epoch": 99.14,
      "learning_rate": 3.358524688971687e-08,
      "loss": 0.1502,
      "step": 99140
    },
    {
      "epoch": 99.15,
      "learning_rate": 3.284718600894687e-08,
      "loss": 0.1563,
      "step": 99150
    },
    {
      "epoch": 99.16,
      "learning_rate": 3.211732342330298e-08,
      "loss": 0.1616,
      "step": 99160
    },
    {
      "epoch": 99.17,
      "learning_rate": 3.139565921258802e-08,
      "loss": 0.1441,
      "step": 99170
    },
    {
      "epoch": 99.18,
      "learning_rate": 3.068219345573053e-08,
      "loss": 0.1961,
      "step": 99180
    },
    {
      "epoch": 99.19,
      "learning_rate": 2.9976926230759754e-08,
      "loss": 0.0902,
      "step": 99190
    },
    {
      "epoch": 99.2,
      "learning_rate": 2.927985761479734e-08,
      "loss": 0.1289,
      "step": 99200
    },
    {
      "epoch": 99.21,
      "learning_rate": 2.8590987684065648e-08,
      "loss": 0.0798,
      "step": 99210
    },
    {
      "epoch": 99.22,
      "learning_rate": 2.7910316513912734e-08,
      "loss": 0.1648,
      "step": 99220
    },
    {
      "epoch": 99.23,
      "learning_rate": 2.72378441787624e-08,
      "loss": 0.1375,
      "step": 99230
    },
    {
      "epoch": 99.24,
      "learning_rate": 2.6573570752164154e-08,
      "loss": 0.1018,
      "step": 99240
    },
    {
      "epoch": 99.25,
      "learning_rate": 2.5917496306759876e-08,
      "loss": 0.3073,
      "step": 99250
    },
    {
      "epoch": 99.26,
      "learning_rate": 2.526962091429219e-08,
      "loss": 0.1217,
      "step": 99260
    },
    {
      "epoch": 99.27,
      "learning_rate": 2.462994464562107e-08,
      "loss": 0.1805,
      "step": 99270
    },
    {
      "epoch": 99.28,
      "learning_rate": 2.3998467570698898e-08,
      "loss": 0.1507,
      "step": 99280
    },
    {
      "epoch": 99.29,
      "learning_rate": 2.3375189758570444e-08,
      "loss": 0.1934,
      "step": 99290
    },
    {
      "epoch": 99.3,
      "learning_rate": 2.2760111277406178e-08,
      "loss": 0.1144,
      "step": 99300
    },
    {
      "epoch": 99.31,
      "learning_rate": 2.2153232194477287e-08,
      "loss": 0.1889,
      "step": 99310
    },
    {
      "epoch": 99.32,
      "learning_rate": 2.155455257613903e-08,
      "loss": 0.1035,
      "step": 99320
    },
    {
      "epoch": 99.33,
      "learning_rate": 2.0964072487864026e-08,
      "loss": 0.2331,
      "step": 99330
    },
    {
      "epoch": 99.34,
      "learning_rate": 2.0381791994233952e-08,
      "loss": 0.1967,
      "step": 99340
    },
    {
      "epoch": 99.35,
      "learning_rate": 1.9807711158922877e-08,
      "loss": 0.1196,
      "step": 99350
    },
    {
      "epoch": 99.36,
      "learning_rate": 1.924183004469726e-08,
      "loss": 0.2591,
      "step": 99360
    },
    {
      "epoch": 99.37,
      "learning_rate": 1.8684148713465908e-08,
      "loss": 0.1322,
      "step": 99370
    },
    {
      "epoch": 99.38,
      "learning_rate": 1.813466722619672e-08,
      "loss": 0.1271,
      "step": 99380
    },
    {
      "epoch": 99.39,
      "learning_rate": 1.759338564299162e-08,
      "loss": 0.2344,
      "step": 99390
    },
    {
      "epoch": 99.4,
      "learning_rate": 1.7060304023036596e-08,
      "loss": 0.0746,
      "step": 99400
    },
    {
      "epoch": 99.41,
      "learning_rate": 1.6535422424626687e-08,
      "loss": 0.1568,
      "step": 99410
    },
    {
      "epoch": 99.42,
      "learning_rate": 1.6018740905174297e-08,
      "loss": 0.1841,
      "step": 99420
    },
    {
      "epoch": 99.43,
      "learning_rate": 1.5510259521175906e-08,
      "loss": 0.1771,
      "step": 99430
    },
    {
      "epoch": 99.44,
      "learning_rate": 1.50099783282287e-08,
      "loss": 0.1296,
      "step": 99440
    },
    {
      "epoch": 99.45,
      "learning_rate": 1.4517897381063904e-08,
      "loss": 0.2353,
      "step": 99450
    },
    {
      "epoch": 99.46,
      "learning_rate": 1.403401673347182e-08,
      "loss": 0.1314,
      "step": 99460
    },
    {
      "epoch": 99.47,
      "learning_rate": 1.3558336438385109e-08,
      "loss": 0.2214,
      "step": 99470
    },
    {
      "epoch": 99.48,
      "learning_rate": 1.3090856547820494e-08,
      "loss": 0.0403,
      "step": 99480
    },
    {
      "epoch": 99.49,
      "learning_rate": 1.263157711289542e-08,
      "loss": 0.1184,
      "step": 99490
    },
    {
      "epoch": 99.5,
      "learning_rate": 1.21804981838447e-08,
      "loss": 0.1711,
      "step": 99500
    },
    {
      "epoch": 99.51,
      "learning_rate": 1.173761980998722e-08,
      "loss": 0.0525,
      "step": 99510
    },
    {
      "epoch": 99.52,
      "learning_rate": 1.1302942039759234e-08,
      "loss": 0.039,
      "step": 99520
    },
    {
      "epoch": 99.53,
      "learning_rate": 1.087646492070604e-08,
      "loss": 0.1311,
      "step": 99530
    },
    {
      "epoch": 99.54,
      "learning_rate": 1.0458188499448683e-08,
      "loss": 0.1842,
      "step": 99540
    },
    {
      "epoch": 99.55,
      "learning_rate": 1.0048112821742227e-08,
      "loss": 0.1773,
      "step": 99550
    },
    {
      "epoch": 99.56,
      "learning_rate": 9.646237932425805e-09,
      "loss": 0.2464,
      "step": 99560
    },
    {
      "epoch": 99.57,
      "learning_rate": 9.25256387545592e-09,
      "loss": 0.088,
      "step": 99570
    },
    {
      "epoch": 99.58,
      "learning_rate": 8.867090693873146e-09,
      "loss": 0.3252,
      "step": 99580
    },
    {
      "epoch": 99.59,
      "learning_rate": 8.489818429843754e-09,
      "loss": 0.4103,
      "step": 99590
    },
    {
      "epoch": 99.6,
      "learning_rate": 8.120747124618077e-09,
      "loss": 0.1308,
      "step": 99600
    },
    {
      "epoch": 99.61,
      "learning_rate": 7.7598768185555e-09,
      "loss": 0.0862,
      "step": 99610
    },
    {
      "epoch": 99.62,
      "learning_rate": 7.40720755112445e-09,
      "loss": 0.3057,
      "step": 99620
    },
    {
      "epoch": 99.63,
      "learning_rate": 7.062739360894076e-09,
      "loss": 0.1871,
      "step": 99630
    },
    {
      "epoch": 99.64,
      "learning_rate": 6.726472285525919e-09,
      "loss": 0.0979,
      "step": 99640
    },
    {
      "epoch": 99.65,
      "learning_rate": 6.3984063618072175e-09,
      "loss": 0.2991,
      "step": 99650
    },
    {
      "epoch": 99.66,
      "learning_rate": 6.078541625609279e-09,
      "loss": 0.0859,
      "step": 99660
    },
    {
      "epoch": 99.67,
      "learning_rate": 5.766878111904127e-09,
      "loss": 0.056,
      "step": 99670
    },
    {
      "epoch": 99.68,
      "learning_rate": 5.463415854781161e-09,
      "loss": 0.1628,
      "step": 99680
    },
    {
      "epoch": 99.69,
      "learning_rate": 5.168154887430498e-09,
      "loss": 0.0918,
      "step": 99690
    },
    {
      "epoch": 99.7,
      "learning_rate": 4.881095242134647e-09,
      "loss": 0.0783,
      "step": 99700
    },
    {
      "epoch": 99.71,
      "learning_rate": 4.602236950293492e-09,
      "loss": 0.1774,
      "step": 99710
    },
    {
      "epoch": 99.72,
      "learning_rate": 4.331580042390981e-09,
      "loss": 0.1343,
      "step": 99720
    },
    {
      "epoch": 99.73,
      "learning_rate": 4.069124548036762e-09,
      "loss": 0.3364,
      "step": 99730
    },
    {
      "epoch": 99.74,
      "learning_rate": 3.814870495924549e-09,
      "loss": 0.0811,
      "step": 99740
    },
    {
      "epoch": 99.75,
      "learning_rate": 3.5688179138654296e-09,
      "loss": 0.1032,
      "step": 99750
    },
    {
      "epoch": 99.76,
      "learning_rate": 3.330966828762882e-09,
      "loss": 0.3053,
      "step": 99760
    },
    {
      "epoch": 99.77,
      "learning_rate": 3.1013172666377596e-09,
      "loss": 0.1653,
      "step": 99770
    },
    {
      "epoch": 99.78,
      "learning_rate": 2.879869252586653e-09,
      "loss": 0.1378,
      "step": 99780
    },
    {
      "epoch": 99.79,
      "learning_rate": 2.66662281084018e-09,
      "loss": 0.2329,
      "step": 99790
    },
    {
      "epoch": 99.8,
      "learning_rate": 2.461577964713024e-09,
      "loss": 0.1471,
      "step": 99800
    },
    {
      "epoch": 99.81,
      "learning_rate": 2.2647347366372415e-09,
      "loss": 0.1829,
      "step": 99810
    },
    {
      "epoch": 99.82,
      "learning_rate": 2.0760931481289545e-09,
      "loss": 0.2256,
      "step": 99820
    },
    {
      "epoch": 99.83,
      "learning_rate": 1.895653219821658e-09,
      "loss": 0.2678,
      "step": 99830
    },
    {
      "epoch": 99.84,
      "learning_rate": 1.7234149714412393e-09,
      "loss": 0.0701,
      "step": 99840
    },
    {
      "epoch": 99.85,
      "learning_rate": 1.5593784218392858e-09,
      "loss": 0.2443,
      "step": 99850
    },
    {
      "epoch": 99.86,
      "learning_rate": 1.4035435889431235e-09,
      "loss": 0.1432,
      "step": 99860
    },
    {
      "epoch": 99.87,
      "learning_rate": 1.2559104897891247e-09,
      "loss": 0.1077,
      "step": 99870
    },
    {
      "epoch": 99.88,
      "learning_rate": 1.1164791405393614e-09,
      "loss": 0.053,
      "step": 99880
    },
    {
      "epoch": 99.89,
      "learning_rate": 9.852495564316444e-10,
      "loss": 0.1254,
      "step": 99890
    },
    {
      "epoch": 99.9,
      "learning_rate": 8.622217518128305e-10,
      "loss": 0.2712,
      "step": 99900
    },
    {
      "epoch": 99.91,
      "learning_rate": 7.473957401471497e-10,
      "loss": 0.2008,
      "step": 99910
    },
    {
      "epoch": 99.92,
      "learning_rate": 6.407715339828979e-10,
      "loss": 0.2582,
      "step": 99920
    },
    {
      "epoch": 99.93,
      "learning_rate": 5.423491449857431e-10,
      "loss": 0.1617,
      "step": 99930
    },
    {
      "epoch": 99.94,
      "learning_rate": 4.5212858391374675e-10,
      "loss": 0.0809,
      "step": 99940
    },
    {
      "epoch": 99.95,
      "learning_rate": 3.701098606340158e-10,
      "loss": 0.138,
      "step": 99950
    },
    {
      "epoch": 99.96,
      "learning_rate": 2.962929841310302e-10,
      "loss": 0.1094,
      "step": 99960
    },
    {
      "epoch": 99.97,
      "learning_rate": 2.3067796245668236e-10,
      "loss": 0.1225,
      "step": 99970
    },
    {
      "epoch": 99.98,
      "learning_rate": 1.732648027968908e-10,
      "loss": 0.1387,
      "step": 99980
    },
    {
      "epoch": 99.99,
      "learning_rate": 1.240535114216401e-10,
      "loss": 0.1826,
      "step": 99990
    },
    {
      "epoch": 100.0,
      "learning_rate": 8.304409372661414e-11,
      "loss": 0.0115,
      "step": 100000
    },
    {
      "epoch": 100.0,
      "eval_accuracy": 0.7995,
      "eval_loss": 0.7164292335510254,
      "eval_runtime": 14.9123,
      "eval_samples_per_second": 134.117,
      "eval_steps_per_second": 16.765,
      "step": 100000
    },
    {
      "epoch": 100.0,
      "step": 100000,
      "total_flos": 6.19952585785344e+19,
      "train_loss": 0.25471370660319925,
      "train_runtime": 11327.2027,
      "train_samples_per_second": 70.626,
      "train_steps_per_second": 8.828
    }
  ],
  "max_steps": 100000,
  "num_train_epochs": 100,
  "total_flos": 6.19952585785344e+19,
  "trial_name": null,
  "trial_params": null
}
